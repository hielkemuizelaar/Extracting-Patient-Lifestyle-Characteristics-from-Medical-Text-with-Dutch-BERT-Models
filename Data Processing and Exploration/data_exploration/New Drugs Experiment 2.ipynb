{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61b949a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import random\n",
    "import sklearn\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy.stats import uniform as sp_randFloat\n",
    "from scipy.stats import randint as sp_randInt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e2e6c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(500)\n",
    "Corpus = pd.read_csv(r\"../input_data/drugs/labelled_drugs.csv\",encoding='latin-1', skiprows=[227225])\n",
    "Corpus = Corpus.rename({'drugs_report_content':'text', 'drugs_answer_label': 'label'}, axis=1)\n",
    "Corpus['text'] = Corpus['text'].str.replace('\\t',' ')\n",
    "Corpus.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "Corpus.drop_duplicates(inplace=True)\n",
    "Corpus['text'] = Corpus['text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3f9e271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "stemmer = SnowballStemmer(\"dutch\")\n",
    "Corpus['text'] = Corpus['text'].str.lower()\n",
    "Corpus['text'] = [stemmer.stem(text) for text in Corpus['text']]\n",
    "Corpus['label'] = Corpus['label'].str.replace('Niets gevonden','Nee')\n",
    "Corpus = Corpus.drop(Corpus[Corpus.label == '--'].index)\n",
    "Corpus_backup = Corpus.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7e1f549",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_filter = ['niet', 'niets', 'geen', 'zonder']\n",
    "with open('../helping_files/stopwords.txt') as file:\n",
    "    full_stopwords = [line.rstrip() for line in file]\n",
    "    filtered_stopwords = [item for item in full_stopwords if item not in stopwords_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c41a0ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Corpus['text'], Corpus['label'], test_size=0.2, random_state=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3527e4be",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3b796d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_priors = [list(item) for item in list(np.random.dirichlet(np.ones(2), size=5))]\n",
    "parameter_grid = {\n",
    "                  'clf__alpha': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                  'clf__fit_prior': [True, False],\n",
    "                  'clf__class_prior': random.sample(class_priors, k=len(class_priors)),\n",
    "                  'tfidf__max_df': [0.90, 0.95],\n",
    "                  'tfidf__min_df': [3, 5]\n",
    "                 }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13cbd9d",
   "metadata": {},
   "source": [
    "# Only negation stopwords kept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "536e1b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_stopwords = lambda x: ' '.join([item for item in x.split() if item not in full_stopwords])\n",
    "less_stopwords = lambda x: ' '.join([item for item in x.split() if item not in filtered_stopwords])\n",
    "\n",
    "Corpus[\"text\"] = Corpus[\"text\"].apply(less_stopwords)\n",
    "X_train, X_test, y_train, y_test = train_test_split(Corpus['text'], Corpus['label'], test_size=0.2, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c705623b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 1/5] END clf__alpha=0.001, clf__class_prior=[0.026158365516680847, 0.9738416344833192], clf__fit_prior=True, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.539 total time=  28.6s\n",
      "[CV 2/5] END clf__alpha=0.001, clf__class_prior=[0.026158365516680847, 0.9738416344833192], clf__fit_prior=True, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.531 total time=  25.3s\n",
      "[CV 3/5] END clf__alpha=0.001, clf__class_prior=[0.026158365516680847, 0.9738416344833192], clf__fit_prior=True, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.534 total time=  25.9s\n",
      "[CV 4/5] END clf__alpha=0.001, clf__class_prior=[0.026158365516680847, 0.9738416344833192], clf__fit_prior=True, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.534 total time=  26.6s\n",
      "[CV 5/5] END clf__alpha=0.001, clf__class_prior=[0.026158365516680847, 0.9738416344833192], clf__fit_prior=True, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.536 total time=  32.5s\n",
      "[CV 1/5] END clf__alpha=10, clf__class_prior=[0.4013117050654326, 0.5986882949345673], clf__fit_prior=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.498 total time=  31.6s\n",
      "[CV 2/5] END clf__alpha=10, clf__class_prior=[0.4013117050654326, 0.5986882949345673], clf__fit_prior=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.498 total time=  35.4s\n",
      "[CV 3/5] END clf__alpha=10, clf__class_prior=[0.4013117050654326, 0.5986882949345673], clf__fit_prior=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.498 total time=  26.8s\n",
      "[CV 4/5] END clf__alpha=10, clf__class_prior=[0.4013117050654326, 0.5986882949345673], clf__fit_prior=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.498 total time=  28.4s\n",
      "[CV 5/5] END clf__alpha=10, clf__class_prior=[0.4013117050654326, 0.5986882949345673], clf__fit_prior=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.498 total time=  25.7s\n",
      "[CV 1/5] END clf__alpha=0.1, clf__class_prior=[0.6375094214738516, 0.36249057852614847], clf__fit_prior=True, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.508 total time=  25.6s\n",
      "[CV 2/5] END clf__alpha=0.1, clf__class_prior=[0.6375094214738516, 0.36249057852614847], clf__fit_prior=True, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.505 total time=  27.3s\n",
      "[CV 3/5] END clf__alpha=0.1, clf__class_prior=[0.6375094214738516, 0.36249057852614847], clf__fit_prior=True, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.506 total time=  26.0s\n",
      "[CV 4/5] END clf__alpha=0.1, clf__class_prior=[0.6375094214738516, 0.36249057852614847], clf__fit_prior=True, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.509 total time=  29.0s\n",
      "[CV 5/5] END clf__alpha=0.1, clf__class_prior=[0.6375094214738516, 0.36249057852614847], clf__fit_prior=True, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.511 total time=  32.5s\n",
      "[CV 1/5] END clf__alpha=0.001, clf__class_prior=[0.25448839161455766, 0.7455116083854423], clf__fit_prior=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.518 total time=  29.9s\n",
      "[CV 2/5] END clf__alpha=0.001, clf__class_prior=[0.25448839161455766, 0.7455116083854423], clf__fit_prior=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.514 total time=  30.5s\n",
      "[CV 3/5] END clf__alpha=0.001, clf__class_prior=[0.25448839161455766, 0.7455116083854423], clf__fit_prior=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.516 total time=  26.0s\n",
      "[CV 4/5] END clf__alpha=0.001, clf__class_prior=[0.25448839161455766, 0.7455116083854423], clf__fit_prior=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.517 total time=  29.0s\n",
      "[CV 5/5] END clf__alpha=0.001, clf__class_prior=[0.25448839161455766, 0.7455116083854423], clf__fit_prior=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.520 total time=  26.3s\n",
      "[CV 1/5] END clf__alpha=100, clf__class_prior=[0.6375094214738516, 0.36249057852614847], clf__fit_prior=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.497 total time=  28.7s\n",
      "[CV 2/5] END clf__alpha=100, clf__class_prior=[0.6375094214738516, 0.36249057852614847], clf__fit_prior=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.497 total time=  25.6s\n",
      "[CV 3/5] END clf__alpha=100, clf__class_prior=[0.6375094214738516, 0.36249057852614847], clf__fit_prior=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.497 total time=  25.7s\n",
      "[CV 4/5] END clf__alpha=100, clf__class_prior=[0.6375094214738516, 0.36249057852614847], clf__fit_prior=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.497 total time=  28.6s\n",
      "[CV 5/5] END clf__alpha=100, clf__class_prior=[0.6375094214738516, 0.36249057852614847], clf__fit_prior=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.497 total time=  31.2s\n",
      "[CV 1/5] END clf__alpha=0.001, clf__class_prior=[0.25448839161455766, 0.7455116083854423], clf__fit_prior=True, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.519 total time=  33.7s\n",
      "[CV 2/5] END clf__alpha=0.001, clf__class_prior=[0.25448839161455766, 0.7455116083854423], clf__fit_prior=True, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.515 total time=  32.0s\n",
      "[CV 3/5] END clf__alpha=0.001, clf__class_prior=[0.25448839161455766, 0.7455116083854423], clf__fit_prior=True, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.517 total time=  32.4s\n",
      "[CV 4/5] END clf__alpha=0.001, clf__class_prior=[0.25448839161455766, 0.7455116083854423], clf__fit_prior=True, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.518 total time=  26.9s\n",
      "[CV 5/5] END clf__alpha=0.001, clf__class_prior=[0.25448839161455766, 0.7455116083854423], clf__fit_prior=True, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.521 total time=  32.9s\n",
      "[CV 1/5] END clf__alpha=1, clf__class_prior=[0.4013117050654326, 0.5986882949345673], clf__fit_prior=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.497 total time=  30.1s\n",
      "[CV 2/5] END clf__alpha=1, clf__class_prior=[0.4013117050654326, 0.5986882949345673], clf__fit_prior=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.497 total time=  29.3s\n",
      "[CV 3/5] END clf__alpha=1, clf__class_prior=[0.4013117050654326, 0.5986882949345673], clf__fit_prior=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.497 total time=  28.4s\n",
      "[CV 4/5] END clf__alpha=1, clf__class_prior=[0.4013117050654326, 0.5986882949345673], clf__fit_prior=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.497 total time=  27.7s\n",
      "[CV 5/5] END clf__alpha=1, clf__class_prior=[0.4013117050654326, 0.5986882949345673], clf__fit_prior=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.497 total time=  28.8s\n",
      "[CV 1/5] END clf__alpha=1e-05, clf__class_prior=[0.4013117050654326, 0.5986882949345673], clf__fit_prior=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.537 total time=  24.5s\n",
      "[CV 2/5] END clf__alpha=1e-05, clf__class_prior=[0.4013117050654326, 0.5986882949345673], clf__fit_prior=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.530 total time=  30.1s\n",
      "[CV 3/5] END clf__alpha=1e-05, clf__class_prior=[0.4013117050654326, 0.5986882949345673], clf__fit_prior=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.532 total time=  33.8s\n",
      "[CV 4/5] END clf__alpha=1e-05, clf__class_prior=[0.4013117050654326, 0.5986882949345673], clf__fit_prior=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.531 total time=  28.7s\n",
      "[CV 5/5] END clf__alpha=1e-05, clf__class_prior=[0.4013117050654326, 0.5986882949345673], clf__fit_prior=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.536 total time=  19.4s\n",
      "[CV 1/5] END clf__alpha=1e-05, clf__class_prior=[0.6375094214738516, 0.36249057852614847], clf__fit_prior=True, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.531 total time=  19.5s\n",
      "[CV 2/5] END clf__alpha=1e-05, clf__class_prior=[0.6375094214738516, 0.36249057852614847], clf__fit_prior=True, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.526 total time=  18.8s\n",
      "[CV 3/5] END clf__alpha=1e-05, clf__class_prior=[0.6375094214738516, 0.36249057852614847], clf__fit_prior=True, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.527 total time=  19.0s\n",
      "[CV 4/5] END clf__alpha=1e-05, clf__class_prior=[0.6375094214738516, 0.36249057852614847], clf__fit_prior=True, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.525 total time=  19.6s\n",
      "[CV 5/5] END clf__alpha=1e-05, clf__class_prior=[0.6375094214738516, 0.36249057852614847], clf__fit_prior=True, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.530 total time=  19.0s\n",
      "[CV 1/5] END clf__alpha=0.001, clf__class_prior=[0.026158365516680847, 0.9738416344833192], clf__fit_prior=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.537 total time=  18.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END clf__alpha=0.001, clf__class_prior=[0.026158365516680847, 0.9738416344833192], clf__fit_prior=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.530 total time=  19.2s\n",
      "[CV 3/5] END clf__alpha=0.001, clf__class_prior=[0.026158365516680847, 0.9738416344833192], clf__fit_prior=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.533 total time=  18.7s\n",
      "[CV 4/5] END clf__alpha=0.001, clf__class_prior=[0.026158365516680847, 0.9738416344833192], clf__fit_prior=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.533 total time=  18.7s\n",
      "[CV 5/5] END clf__alpha=0.001, clf__class_prior=[0.026158365516680847, 0.9738416344833192], clf__fit_prior=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.535 total time=  19.4s\n",
      "0.8955743243243244\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          Ja       0.07      0.78      0.13       291\n",
      "         Nee       1.00      0.90      0.94     29309\n",
      "\n",
      "    accuracy                           0.90     29600\n",
      "   macro avg       0.53      0.84      0.54     29600\n",
      "weighted avg       0.99      0.90      0.94     29600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ngram 1 Less stopwords\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1,1), lowercase=True, token_pattern=r\"(?u)\\b\\w\\w+\\b|\\+|\\-\")),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "random_search = RandomizedSearchCV(estimator=pipeline, param_distributions=parameter_grid, random_state=500, verbose=3, scoring='f1_macro')\n",
    "random_search.fit(X_train, y_train)  \n",
    "predicted_nb = random_search.predict(X_test)\n",
    "print(np.mean(predicted_nb == y_test))\n",
    "cm = confusion_matrix(y_test, predicted_nb)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=random_search.classes_)\n",
    "disp.plot()\n",
    "\n",
    "plt.show()\n",
    "print(metrics.classification_report(y_test, predicted_nb,\n",
    "    target_names=random_search.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4a012d",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5339d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESET CORPUS\n",
    "Corpus = Corpus_backup.copy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(Corpus['text'], Corpus['label'], test_size=0.2, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "069f6ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = {'clf__loss':              ['hinge', 'log_loss', 'log', 'modified_huber', 'squared_hinge', 'perceptron', 'squared_error', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "                  'clf__penalty':           ['l2', 'l1'],\n",
    "                  'clf__l1_ratio':          sp_randFloat(),\n",
    "                  'clf__fit_intercept':     [True, False],\n",
    "                  'clf__max_iter':          [int(x) for x in np.linspace(start = 10, stop = 100, num = 10)],\n",
    "                  'clf__tol':               sp_randFloat(),\n",
    "                  'clf__shuffle':           [True, False],\n",
    "                  'clf__epsilon':           sp_randFloat(),\n",
    "                  'clf__learning_rate':     ['constant', 'optimal', 'invscaling', 'adaptive'],\n",
    "                  'clf__eta0':              sp_randFloat(),\n",
    "                  'clf__power_t':           sp_randFloat(),\n",
    "                  'clf__class_weight':      ['balanced', None],\n",
    "                  'clf__warm_start':        [True, False],\n",
    "                  'clf__average':           [True, False],\n",
    "                  'tfidf__max_df':          [0.90, 0.95],\n",
    "                  'tfidf__min_df':          [3, 5]\n",
    "                 }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5955c7a",
   "metadata": {},
   "source": [
    "# Stopwords kept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1efa878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "-- Epoch 1\n",
      "Norm: 82.52, NNZs: 242, Bias: 0.000000, T: 71040, Avg. loss: 0.072852\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 111.05, NNZs: 92, Bias: 0.000000, T: 142080, Avg. loss: 0.050355\n",
      "Total training time: 1.04 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 132.94, NNZs: 68, Bias: 0.000000, T: 213120, Avg. loss: 0.044303\n",
      "Total training time: 1.73 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 151.11, NNZs: 60, Bias: 0.000000, T: 284160, Avg. loss: 0.041143\n",
      "Total training time: 2.52 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 167.17, NNZs: 54, Bias: 0.000000, T: 355200, Avg. loss: 0.039291\n",
      "Total training time: 3.23 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 181.54, NNZs: 50, Bias: 0.000000, T: 426240, Avg. loss: 0.037485\n",
      "Total training time: 3.88 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 184.16, NNZs: 49, Bias: 0.000000, T: 497280, Avg. loss: 0.036878\n",
      "Total training time: 4.62 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 186.76, NNZs: 49, Bias: 0.000000, T: 568320, Avg. loss: 0.036666\n",
      "Total training time: 5.37 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 189.34, NNZs: 49, Bias: 0.000000, T: 639360, Avg. loss: 0.036428\n",
      "Total training time: 5.85 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 191.87, NNZs: 48, Bias: 0.000000, T: 710400, Avg. loss: 0.036215\n",
      "Total training time: 6.37 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 194.37, NNZs: 48, Bias: 0.000000, T: 781440, Avg. loss: 0.035980\n",
      "Total training time: 6.89 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 194.86, NNZs: 48, Bias: 0.000000, T: 852480, Avg. loss: 0.035888\n",
      "Total training time: 7.43 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 195.35, NNZs: 48, Bias: 0.000000, T: 923520, Avg. loss: 0.035848\n",
      "Total training time: 8.04 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 195.84, NNZs: 48, Bias: 0.000000, T: 994560, Avg. loss: 0.035826\n",
      "Total training time: 8.70 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 196.32, NNZs: 48, Bias: 0.000000, T: 1065600, Avg. loss: 0.035785\n",
      "Total training time: 9.37 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 196.81, NNZs: 48, Bias: 0.000000, T: 1136640, Avg. loss: 0.035754\n",
      "Total training time: 10.10 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 196.91, NNZs: 48, Bias: 0.000000, T: 1207680, Avg. loss: 0.035728\n",
      "Total training time: 10.74 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 197.01, NNZs: 48, Bias: 0.000000, T: 1278720, Avg. loss: 0.035719\n",
      "Total training time: 11.32 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 197.10, NNZs: 48, Bias: 0.000000, T: 1349760, Avg. loss: 0.035710\n",
      "Total training time: 11.94 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 197.20, NNZs: 48, Bias: 0.000000, T: 1420800, Avg. loss: 0.035704\n",
      "Total training time: 12.51 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.06171699256249541, clf__eta0=0.6666115972798587, clf__fit_intercept=False, clf__l1_ratio=0.9792901432894962, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.15075392531110676, clf__shuffle=True, clf__tol=0.365636830734297, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.198 total time= 1.4min\n",
      "-- Epoch 1\n",
      "Norm: 82.25, NNZs: 260, Bias: 0.000000, T: 71040, Avg. loss: 0.073303\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 110.87, NNZs: 90, Bias: 0.000000, T: 142080, Avg. loss: 0.050579\n",
      "Total training time: 1.09 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 132.56, NNZs: 68, Bias: 0.000000, T: 213120, Avg. loss: 0.044778\n",
      "Total training time: 1.67 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 150.85, NNZs: 59, Bias: 0.000000, T: 284160, Avg. loss: 0.041464\n",
      "Total training time: 2.29 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 166.83, NNZs: 54, Bias: 0.000000, T: 355200, Avg. loss: 0.039263\n",
      "Total training time: 2.93 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 181.23, NNZs: 49, Bias: 0.000000, T: 426240, Avg. loss: 0.037892\n",
      "Total training time: 3.75 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 183.89, NNZs: 49, Bias: 0.000000, T: 497280, Avg. loss: 0.036945\n",
      "Total training time: 4.50 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 186.50, NNZs: 49, Bias: 0.000000, T: 568320, Avg. loss: 0.036720\n",
      "Total training time: 5.10 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 189.05, NNZs: 49, Bias: 0.000000, T: 639360, Avg. loss: 0.036523\n",
      "Total training time: 5.77 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 191.58, NNZs: 48, Bias: 0.000000, T: 710400, Avg. loss: 0.036328\n",
      "Total training time: 6.51 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 194.07, NNZs: 47, Bias: 0.000000, T: 781440, Avg. loss: 0.036149\n",
      "Total training time: 7.27 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 194.56, NNZs: 47, Bias: 0.000000, T: 852480, Avg. loss: 0.036063\n",
      "Total training time: 7.82 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 195.06, NNZs: 47, Bias: 0.000000, T: 923520, Avg. loss: 0.036009\n",
      "Total training time: 8.51 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 195.55, NNZs: 47, Bias: 0.000000, T: 994560, Avg. loss: 0.035962\n",
      "Total training time: 9.15 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 196.04, NNZs: 47, Bias: 0.000000, T: 1065600, Avg. loss: 0.035922\n",
      "Total training time: 9.76 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 196.52, NNZs: 47, Bias: 0.000000, T: 1136640, Avg. loss: 0.035895\n",
      "Total training time: 10.51 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 196.62, NNZs: 47, Bias: 0.000000, T: 1207680, Avg. loss: 0.035862\n",
      "Total training time: 10.99 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 196.72, NNZs: 47, Bias: 0.000000, T: 1278720, Avg. loss: 0.035855\n",
      "Total training time: 11.48 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 196.81, NNZs: 47, Bias: 0.000000, T: 1349760, Avg. loss: 0.035849\n",
      "Total training time: 12.10 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 196.91, NNZs: 47, Bias: 0.000000, T: 1420800, Avg. loss: 0.035839\n",
      "Total training time: 12.73 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.06171699256249541, clf__eta0=0.6666115972798587, clf__fit_intercept=False, clf__l1_ratio=0.9792901432894962, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.15075392531110676, clf__shuffle=True, clf__tol=0.365636830734297, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.195 total time= 1.4min\n",
      "-- Epoch 1\n",
      "Norm: 81.64, NNZs: 245, Bias: 0.000000, T: 71040, Avg. loss: 0.074410\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 110.52, NNZs: 93, Bias: 0.000000, T: 142080, Avg. loss: 0.051461\n",
      "Total training time: 1.14 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 132.35, NNZs: 68, Bias: 0.000000, T: 213120, Avg. loss: 0.045226\n",
      "Total training time: 1.80 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 150.66, NNZs: 58, Bias: 0.000000, T: 284160, Avg. loss: 0.041856\n",
      "Total training time: 2.94 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 166.83, NNZs: 52, Bias: 0.000000, T: 355200, Avg. loss: 0.039602\n",
      "Total training time: 4.11 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 181.34, NNZs: 48, Bias: 0.000000, T: 426240, Avg. loss: 0.038159\n",
      "Total training time: 5.21 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 183.98, NNZs: 48, Bias: 0.000000, T: 497280, Avg. loss: 0.037221\n",
      "Total training time: 6.10 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 186.61, NNZs: 48, Bias: 0.000000, T: 568320, Avg. loss: 0.037008\n",
      "Total training time: 6.67 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 189.20, NNZs: 48, Bias: 0.000000, T: 639360, Avg. loss: 0.036767\n",
      "Total training time: 7.42 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 191.76, NNZs: 48, Bias: 0.000000, T: 710400, Avg. loss: 0.036568\n",
      "Total training time: 8.20 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 194.27, NNZs: 48, Bias: 0.000000, T: 781440, Avg. loss: 0.036352\n",
      "Total training time: 8.86 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 194.76, NNZs: 48, Bias: 0.000000, T: 852480, Avg. loss: 0.036245\n",
      "Total training time: 9.56 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 195.26, NNZs: 48, Bias: 0.000000, T: 923520, Avg. loss: 0.036209\n",
      "Total training time: 10.31 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 195.75, NNZs: 48, Bias: 0.000000, T: 994560, Avg. loss: 0.036163\n",
      "Total training time: 11.06 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 196.24, NNZs: 48, Bias: 0.000000, T: 1065600, Avg. loss: 0.036128\n",
      "Total training time: 11.70 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 196.73, NNZs: 48, Bias: 0.000000, T: 1136640, Avg. loss: 0.036096\n",
      "Total training time: 12.30 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 196.83, NNZs: 48, Bias: 0.000000, T: 1207680, Avg. loss: 0.036068\n",
      "Total training time: 13.20 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 196.92, NNZs: 48, Bias: 0.000000, T: 1278720, Avg. loss: 0.036062\n",
      "Total training time: 14.25 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 197.02, NNZs: 48, Bias: 0.000000, T: 1349760, Avg. loss: 0.036055\n",
      "Total training time: 15.33 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 197.12, NNZs: 48, Bias: 0.000000, T: 1420800, Avg. loss: 0.036050\n",
      "Total training time: 16.29 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.06171699256249541, clf__eta0=0.6666115972798587, clf__fit_intercept=False, clf__l1_ratio=0.9792901432894962, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.15075392531110676, clf__shuffle=True, clf__tol=0.365636830734297, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.195 total time= 1.7min\n",
      "-- Epoch 1\n",
      "Norm: 82.14, NNZs: 260, Bias: 0.000000, T: 71040, Avg. loss: 0.072256\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 110.74, NNZs: 93, Bias: 0.000000, T: 142080, Avg. loss: 0.050018\n",
      "Total training time: 1.35 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 132.60, NNZs: 69, Bias: 0.000000, T: 213120, Avg. loss: 0.044312\n",
      "Total training time: 1.89 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 150.81, NNZs: 56, Bias: 0.000000, T: 284160, Avg. loss: 0.040818\n",
      "Total training time: 2.92 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 166.79, NNZs: 54, Bias: 0.000000, T: 355200, Avg. loss: 0.038854\n",
      "Total training time: 3.93 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 181.29, NNZs: 49, Bias: 0.000000, T: 426240, Avg. loss: 0.037321\n",
      "Total training time: 4.90 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 183.88, NNZs: 49, Bias: 0.000000, T: 497280, Avg. loss: 0.036413\n",
      "Total training time: 5.92 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 186.53, NNZs: 49, Bias: 0.000000, T: 568320, Avg. loss: 0.036217\n",
      "Total training time: 6.97 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 189.08, NNZs: 49, Bias: 0.000000, T: 639360, Avg. loss: 0.036000\n",
      "Total training time: 8.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 191.59, NNZs: 49, Bias: 0.000000, T: 710400, Avg. loss: 0.035815\n",
      "Total training time: 8.71 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 194.09, NNZs: 49, Bias: 0.000000, T: 781440, Avg. loss: 0.035660\n",
      "Total training time: 9.29 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 194.59, NNZs: 49, Bias: 0.000000, T: 852480, Avg. loss: 0.035543\n",
      "Total training time: 10.07 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 195.08, NNZs: 49, Bias: 0.000000, T: 923520, Avg. loss: 0.035481\n",
      "Total training time: 10.59 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 195.57, NNZs: 49, Bias: 0.000000, T: 994560, Avg. loss: 0.035446\n",
      "Total training time: 11.23 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 196.06, NNZs: 49, Bias: 0.000000, T: 1065600, Avg. loss: 0.035410\n",
      "Total training time: 11.81 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 196.55, NNZs: 49, Bias: 0.000000, T: 1136640, Avg. loss: 0.035379\n",
      "Total training time: 12.43 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 196.65, NNZs: 49, Bias: 0.000000, T: 1207680, Avg. loss: 0.035354\n",
      "Total training time: 13.09 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 196.74, NNZs: 49, Bias: 0.000000, T: 1278720, Avg. loss: 0.035349\n",
      "Total training time: 13.80 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 196.84, NNZs: 49, Bias: 0.000000, T: 1349760, Avg. loss: 0.035341\n",
      "Total training time: 14.23 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 196.94, NNZs: 49, Bias: 0.000000, T: 1420800, Avg. loss: 0.035334\n",
      "Total training time: 14.66 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.06171699256249541, clf__eta0=0.6666115972798587, clf__fit_intercept=False, clf__l1_ratio=0.9792901432894962, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.15075392531110676, clf__shuffle=True, clf__tol=0.365636830734297, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.195 total time= 1.6min\n",
      "-- Epoch 1\n",
      "Norm: 82.21, NNZs: 256, Bias: 0.000000, T: 71040, Avg. loss: 0.073683\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 111.19, NNZs: 91, Bias: 0.000000, T: 142080, Avg. loss: 0.050670\n",
      "Total training time: 1.30 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 133.04, NNZs: 73, Bias: 0.000000, T: 213120, Avg. loss: 0.044730\n",
      "Total training time: 2.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 151.32, NNZs: 58, Bias: 0.000000, T: 284160, Avg. loss: 0.041465\n",
      "Total training time: 2.71 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 167.39, NNZs: 53, Bias: 0.000000, T: 355200, Avg. loss: 0.039247\n",
      "Total training time: 3.80 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 181.92, NNZs: 50, Bias: 0.000000, T: 426240, Avg. loss: 0.037833\n",
      "Total training time: 4.91 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 184.57, NNZs: 49, Bias: 0.000000, T: 497280, Avg. loss: 0.036794\n",
      "Total training time: 6.01 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 187.15, NNZs: 49, Bias: 0.000000, T: 568320, Avg. loss: 0.036639\n",
      "Total training time: 7.11 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 189.73, NNZs: 49, Bias: 0.000000, T: 639360, Avg. loss: 0.036473\n",
      "Total training time: 8.19 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 192.27, NNZs: 49, Bias: 0.000000, T: 710400, Avg. loss: 0.036281\n",
      "Total training time: 9.23 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 194.75, NNZs: 49, Bias: 0.000000, T: 781440, Avg. loss: 0.036119\n",
      "Total training time: 9.79 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 195.25, NNZs: 49, Bias: 0.000000, T: 852480, Avg. loss: 0.036019\n",
      "Total training time: 10.44 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 195.75, NNZs: 48, Bias: 0.000000, T: 923520, Avg. loss: 0.035972\n",
      "Total training time: 11.50 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 196.24, NNZs: 48, Bias: 0.000000, T: 994560, Avg. loss: 0.035926\n",
      "Total training time: 12.59 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 196.73, NNZs: 48, Bias: 0.000000, T: 1065600, Avg. loss: 0.035886\n",
      "Total training time: 13.72 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 197.22, NNZs: 48, Bias: 0.000000, T: 1136640, Avg. loss: 0.035849\n",
      "Total training time: 14.87 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 197.31, NNZs: 48, Bias: 0.000000, T: 1207680, Avg. loss: 0.035825\n",
      "Total training time: 16.02 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 197.41, NNZs: 48, Bias: 0.000000, T: 1278720, Avg. loss: 0.035820\n",
      "Total training time: 17.09 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 197.51, NNZs: 48, Bias: 0.000000, T: 1349760, Avg. loss: 0.035811\n",
      "Total training time: 17.68 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 197.61, NNZs: 48, Bias: 0.000000, T: 1420800, Avg. loss: 0.035803\n",
      "Total training time: 18.25 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.06171699256249541, clf__eta0=0.6666115972798587, clf__fit_intercept=False, clf__l1_ratio=0.9792901432894962, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.15075392531110676, clf__shuffle=True, clf__tol=0.365636830734297, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.192 total time= 1.8min\n",
      "-- Epoch 1\n",
      "Norm: 40.14, NNZs: 44, Bias: 0.000000, T: 71040, Avg. loss: 0.001450\n",
      "Total training time: 0.30 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 40.62, NNZs: 43, Bias: 0.000000, T: 142080, Avg. loss: 0.001283\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 40.90, NNZs: 44, Bias: 0.000000, T: 213120, Avg. loss: 0.001271\n",
      "Total training time: 1.09 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 41.08, NNZs: 44, Bias: 0.000000, T: 284160, Avg. loss: 0.001256\n",
      "Total training time: 1.42 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 41.23, NNZs: 44, Bias: 0.000000, T: 355200, Avg. loss: 0.001258\n",
      "Total training time: 1.82 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 41.35, NNZs: 44, Bias: 0.000000, T: 426240, Avg. loss: 0.001248\n",
      "Total training time: 2.17 seconds.\n",
      "Convergence after 6 epochs took 2.22 seconds\n",
      "[CV 1/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.7915127974877743, clf__eta0=0.05539740212799926, clf__fit_intercept=False, clf__l1_ratio=0.9152680641407671, clf__learning_rate=optimal, clf__loss=squared_epsilon_insensitive, clf__max_iter=80, clf__penalty=l1, clf__power_t=0.6359093112142983, clf__shuffle=True, clf__tol=0.9361199211609239, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.856 total time= 1.4min\n",
      "-- Epoch 1\n",
      "Norm: 124708139569434.53, NNZs: 444351, Bias: 0.000000, T: 71040, Avg. loss: 146656601409980507095040.000000\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 117993428782247.98, NNZs: 444352, Bias: 0.000000, T: 142080, Avg. loss: 131822153263037963829248.000000\n",
      "Total training time: 1.07 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 114557790900575.78, NNZs: 444352, Bias: 0.000000, T: 213120, Avg. loss: 110125973223099760377856.000000\n",
      "Total training time: 1.53 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 112295648099775.27, NNZs: 444352, Bias: 0.000000, T: 284160, Avg. loss: 99880229622199711956992.000000\n",
      "Total training time: 2.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 110620481157883.23, NNZs: 444352, Bias: 0.000000, T: 355200, Avg. loss: 93624628702543641313280.000000\n",
      "Total training time: 2.60 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 109298672917601.27, NNZs: 444352, Bias: 0.000000, T: 426240, Avg. loss: 89166745776009806610432.000000\n",
      "Total training time: 3.42 seconds.\n",
      "Convergence after 6 epochs took 3.51 seconds\n",
      "[CV 2/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.7915127974877743, clf__eta0=0.05539740212799926, clf__fit_intercept=False, clf__l1_ratio=0.9152680641407671, clf__learning_rate=optimal, clf__loss=squared_epsilon_insensitive, clf__max_iter=80, clf__penalty=l1, clf__power_t=0.6359093112142983, clf__shuffle=True, clf__tol=0.9361199211609239, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.334 total time= 1.6min\n",
      "-- Epoch 1\n",
      "Norm: 80442899270032.92, NNZs: 443323, Bias: 0.000000, T: 71040, Avg. loss: 60486613812912047783936.000000\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 75116174040551.12, NNZs: 443334, Bias: 0.000000, T: 142080, Avg. loss: 51570043817888778813440.000000\n",
      "Total training time: 1.52 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 72369885838481.38, NNZs: 443334, Bias: 0.000000, T: 213120, Avg. loss: 41612420153987607560192.000000\n",
      "Total training time: 2.37 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 70557242772900.88, NNZs: 443334, Bias: 0.000000, T: 284160, Avg. loss: 37013875621949316530176.000000\n",
      "Total training time: 3.16 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 69216432029459.74, NNZs: 443334, Bias: 0.000000, T: 355200, Avg. loss: 34208043937967730851840.000000\n",
      "Total training time: 3.98 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 68158243131252.43, NNZs: 443334, Bias: 0.000000, T: 426240, Avg. loss: 32256487285325652033536.000000\n",
      "Total training time: 4.78 seconds.\n",
      "Convergence after 6 epochs took 4.87 seconds\n",
      "[CV 3/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.7915127974877743, clf__eta0=0.05539740212799926, clf__fit_intercept=False, clf__l1_ratio=0.9152680641407671, clf__learning_rate=optimal, clf__loss=squared_epsilon_insensitive, clf__max_iter=80, clf__penalty=l1, clf__power_t=0.6359093112142983, clf__shuffle=True, clf__tol=0.9361199211609239, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.344 total time= 1.5min\n",
      "-- Epoch 1\n",
      "Norm: 131223821269580.45, NNZs: 443727, Bias: 0.000000, T: 71040, Avg. loss: 159521657215647702056960.000000\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 124476708937037.61, NNZs: 443727, Bias: 0.000000, T: 142080, Avg. loss: 146504956397282505261056.000000\n",
      "Total training time: 1.18 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 121028119526320.84, NNZs: 443727, Bias: 0.000000, T: 213120, Avg. loss: 123448411762264461279232.000000\n",
      "Total training time: 1.90 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 118762393945383.94, NNZs: 443727, Bias: 0.000000, T: 284160, Avg. loss: 112495765869678221590528.000000\n",
      "Total training time: 2.72 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 117085942066605.11, NNZs: 443727, Bias: 0.000000, T: 355200, Avg. loss: 105855090099152031318016.000000\n",
      "Total training time: 3.35 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 115761599120184.22, NNZs: 443727, Bias: 0.000000, T: 426240, Avg. loss: 101086869568183798333440.000000\n",
      "Total training time: 3.88 seconds.\n",
      "Convergence after 6 epochs took 3.95 seconds\n",
      "[CV 4/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.7915127974877743, clf__eta0=0.05539740212799926, clf__fit_intercept=False, clf__l1_ratio=0.9152680641407671, clf__learning_rate=optimal, clf__loss=squared_epsilon_insensitive, clf__max_iter=80, clf__penalty=l1, clf__power_t=0.6359093112142983, clf__shuffle=True, clf__tol=0.9361199211609239, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.342 total time= 1.5min\n",
      "-- Epoch 1\n",
      "Norm: 127578112938813.05, NNZs: 441691, Bias: 0.000000, T: 71040, Avg. loss: 155505484502246052855808.000000\n",
      "Total training time: 0.81 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 120851315154696.05, NNZs: 441691, Bias: 0.000000, T: 142080, Avg. loss: 137304848866157399113728.000000\n",
      "Total training time: 1.51 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 117402270970849.39, NNZs: 441691, Bias: 0.000000, T: 213120, Avg. loss: 115282211708916889288704.000000\n",
      "Total training time: 2.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 115127941729844.05, NNZs: 441691, Bias: 0.000000, T: 284160, Avg. loss: 104819437801428469415936.000000\n",
      "Total training time: 2.55 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 113445364438487.56, NNZs: 441691, Bias: 0.000000, T: 355200, Avg. loss: 98344320186207506006016.000000\n",
      "Total training time: 3.17 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 112120570982513.00, NNZs: 441691, Bias: 0.000000, T: 426240, Avg. loss: 93738523416995473391616.000000\n",
      "Total training time: 3.67 seconds.\n",
      "Convergence after 6 epochs took 3.74 seconds\n",
      "[CV 5/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.7915127974877743, clf__eta0=0.05539740212799926, clf__fit_intercept=False, clf__l1_ratio=0.9152680641407671, clf__learning_rate=optimal, clf__loss=squared_epsilon_insensitive, clf__max_iter=80, clf__penalty=l1, clf__power_t=0.6359093112142983, clf__shuffle=True, clf__tol=0.9361199211609239, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.349 total time= 1.4min\n",
      "-- Epoch 1\n",
      "Norm: 80.50, NNZs: 223, Bias: 0.000000, T: 71040, Avg. loss: 0.020588\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 105.70, NNZs: 104, Bias: 0.000000, T: 142080, Avg. loss: 0.012792\n",
      "Total training time: 0.84 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 124.37, NNZs: 92, Bias: 0.000000, T: 213120, Avg. loss: 0.011252\n",
      "Total training time: 1.42 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 139.82, NNZs: 92, Bias: 0.000000, T: 284160, Avg. loss: 0.010297\n",
      "Total training time: 1.90 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 153.24, NNZs: 85, Bias: 0.000000, T: 355200, Avg. loss: 0.009882\n",
      "Total training time: 2.54 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 165.14, NNZs: 75, Bias: 0.000000, T: 426240, Avg. loss: 0.009598\n",
      "Total training time: 3.19 seconds.\n",
      "Convergence after 6 epochs took 3.27 seconds\n",
      "[CV 1/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.03646223783802971, clf__eta0=0.7491267567674796, clf__fit_intercept=False, clf__l1_ratio=0.775818217437024, clf__learning_rate=constant, clf__loss=squared_hinge, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.4028006727705291, clf__shuffle=True, clf__tol=0.1730703028465106, clf__warm_start=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.970 total time= 1.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 80.29, NNZs: 206, Bias: 0.000000, T: 71040, Avg. loss: 0.020663\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 105.06, NNZs: 93, Bias: 0.000000, T: 142080, Avg. loss: 0.012630\n",
      "Total training time: 0.98 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 123.59, NNZs: 86, Bias: 0.000000, T: 213120, Avg. loss: 0.011098\n",
      "Total training time: 1.54 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 138.95, NNZs: 81, Bias: 0.000000, T: 284160, Avg. loss: 0.010349\n",
      "Total training time: 1.97 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 152.28, NNZs: 78, Bias: 0.000000, T: 355200, Avg. loss: 0.009966\n",
      "Total training time: 2.39 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 164.18, NNZs: 73, Bias: 0.000000, T: 426240, Avg. loss: 0.009519\n",
      "Total training time: 2.88 seconds.\n",
      "Convergence after 6 epochs took 2.93 seconds\n",
      "[CV 2/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.03646223783802971, clf__eta0=0.7491267567674796, clf__fit_intercept=False, clf__l1_ratio=0.775818217437024, clf__learning_rate=constant, clf__loss=squared_hinge, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.4028006727705291, clf__shuffle=True, clf__tol=0.1730703028465106, clf__warm_start=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.967 total time= 1.6min\n",
      "-- Epoch 1\n",
      "Norm: 80.35, NNZs: 191, Bias: 0.000000, T: 71040, Avg. loss: 0.020436\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 105.22, NNZs: 103, Bias: 0.000000, T: 142080, Avg. loss: 0.012383\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 123.83, NNZs: 91, Bias: 0.000000, T: 213120, Avg. loss: 0.011062\n",
      "Total training time: 1.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 139.11, NNZs: 87, Bias: 0.000000, T: 284160, Avg. loss: 0.010231\n",
      "Total training time: 1.52 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 152.42, NNZs: 79, Bias: 0.000000, T: 355200, Avg. loss: 0.009647\n",
      "Total training time: 2.17 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 164.36, NNZs: 68, Bias: 0.000000, T: 426240, Avg. loss: 0.009482\n",
      "Total training time: 2.85 seconds.\n",
      "Convergence after 6 epochs took 2.94 seconds\n",
      "[CV 3/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.03646223783802971, clf__eta0=0.7491267567674796, clf__fit_intercept=False, clf__l1_ratio=0.775818217437024, clf__learning_rate=constant, clf__loss=squared_hinge, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.4028006727705291, clf__shuffle=True, clf__tol=0.1730703028465106, clf__warm_start=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.968 total time= 1.5min\n",
      "-- Epoch 1\n",
      "Norm: 80.71, NNZs: 204, Bias: 0.000000, T: 71040, Avg. loss: 0.020955\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 105.87, NNZs: 95, Bias: 0.000000, T: 142080, Avg. loss: 0.012653\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 124.53, NNZs: 90, Bias: 0.000000, T: 213120, Avg. loss: 0.011052\n",
      "Total training time: 1.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 139.82, NNZs: 82, Bias: 0.000000, T: 284160, Avg. loss: 0.010209\n",
      "Total training time: 1.29 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 153.06, NNZs: 75, Bias: 0.000000, T: 355200, Avg. loss: 0.009702\n",
      "Total training time: 1.64 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 164.97, NNZs: 71, Bias: 0.000000, T: 426240, Avg. loss: 0.009320\n",
      "Total training time: 2.06 seconds.\n",
      "Convergence after 6 epochs took 2.10 seconds\n",
      "[CV 4/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.03646223783802971, clf__eta0=0.7491267567674796, clf__fit_intercept=False, clf__l1_ratio=0.775818217437024, clf__learning_rate=constant, clf__loss=squared_hinge, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.4028006727705291, clf__shuffle=True, clf__tol=0.1730703028465106, clf__warm_start=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.965 total time= 1.4min\n",
      "-- Epoch 1\n",
      "Norm: 80.89, NNZs: 218, Bias: 0.000000, T: 71040, Avg. loss: 0.021095\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 105.88, NNZs: 103, Bias: 0.000000, T: 142080, Avg. loss: 0.012771\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 124.75, NNZs: 90, Bias: 0.000000, T: 213120, Avg. loss: 0.011392\n",
      "Total training time: 0.99 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 140.26, NNZs: 87, Bias: 0.000000, T: 284160, Avg. loss: 0.010543\n",
      "Total training time: 1.44 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 153.68, NNZs: 82, Bias: 0.000000, T: 355200, Avg. loss: 0.009919\n",
      "Total training time: 1.73 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 165.70, NNZs: 73, Bias: 0.000000, T: 426240, Avg. loss: 0.009595\n",
      "Total training time: 2.04 seconds.\n",
      "Convergence after 6 epochs took 2.08 seconds\n",
      "[CV 5/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.03646223783802971, clf__eta0=0.7491267567674796, clf__fit_intercept=False, clf__l1_ratio=0.775818217437024, clf__learning_rate=constant, clf__loss=squared_hinge, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.4028006727705291, clf__shuffle=True, clf__tol=0.1730703028465106, clf__warm_start=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.978 total time= 1.2min\n",
      "-- Epoch 1\n",
      "Norm: 272875464517145.66, NNZs: 444265, Bias: 0.000000, T: 71040, Avg. loss: 1231267950012298348724224.000000\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 205926308898472.03, NNZs: 443948, Bias: 0.000000, T: 142080, Avg. loss: 3608957366826784096518144.000000\n",
      "Total training time: 1.11 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 268012521532417.41, NNZs: 444263, Bias: 0.000000, T: 213120, Avg. loss: 2389805294943421434167296.000000\n",
      "Total training time: 1.78 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 218618881842247.28, NNZs: 444183, Bias: 0.000000, T: 284160, Avg. loss: 3355737205777675422007296.000000\n",
      "Total training time: 2.57 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 265249659005436.09, NNZs: 444267, Bias: 0.000000, T: 355200, Avg. loss: 2658770868139151486615552.000000\n",
      "Total training time: 3.25 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 222223602147655.22, NNZs: 444236, Bias: 0.000000, T: 426240, Avg. loss: 3507786776534218960797696.000000\n",
      "Total training time: 3.76 seconds.\n",
      "Convergence after 6 epochs took 3.80 seconds\n",
      "[CV 1/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.24457156361183285, clf__eta0=0.332929742792607, clf__fit_intercept=False, clf__l1_ratio=0.920539731041378, clf__learning_rate=constant, clf__loss=squared_error, clf__max_iter=100, clf__penalty=l1, clf__power_t=0.5734177157821045, clf__shuffle=True, clf__tol=0.6492274795888617, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.341 total time= 1.3min\n",
      "-- Epoch 1\n",
      "Norm: 267806392118455.62, NNZs: 444345, Bias: 0.000000, T: 71040, Avg. loss: 1239841482176479977537536.000000\n",
      "Total training time: 0.61 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 214843298382824.56, NNZs: 443964, Bias: 0.000000, T: 142080, Avg. loss: 3483080276640407002021888.000000\n",
      "Total training time: 1.20 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 267061667054829.78, NNZs: 444358, Bias: 0.000000, T: 213120, Avg. loss: 2634546526138920492597248.000000\n",
      "Total training time: 1.73 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 220386995094975.84, NNZs: 444281, Bias: 0.000000, T: 284160, Avg. loss: 3336617209126458683817984.000000\n",
      "Total training time: 2.39 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 266770099818808.34, NNZs: 444366, Bias: 0.000000, T: 355200, Avg. loss: 2720420745680481033388032.000000\n",
      "Total training time: 2.93 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 221560118532879.91, NNZs: 444337, Bias: 0.000000, T: 426240, Avg. loss: 3538948059384345494814720.000000\n",
      "Total training time: 3.62 seconds.\n",
      "Convergence after 6 epochs took 3.68 seconds\n",
      "[CV 2/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.24457156361183285, clf__eta0=0.332929742792607, clf__fit_intercept=False, clf__l1_ratio=0.920539731041378, clf__learning_rate=constant, clf__loss=squared_error, clf__max_iter=100, clf__penalty=l1, clf__power_t=0.5734177157821045, clf__shuffle=True, clf__tol=0.6492274795888617, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.340 total time= 1.3min\n",
      "-- Epoch 1\n",
      "Norm: 275192140956271.72, NNZs: 443317, Bias: 0.000000, T: 71040, Avg. loss: 1264759265383736789696512.000000\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 208458196959540.75, NNZs: 442957, Bias: 0.000000, T: 142080, Avg. loss: 3610612594413789029335040.000000\n",
      "Total training time: 1.19 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 270355941566869.72, NNZs: 443340, Bias: 0.000000, T: 213120, Avg. loss: 2320626294755488094486528.000000\n",
      "Total training time: 1.88 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 211599922784953.69, NNZs: 443249, Bias: 0.000000, T: 284160, Avg. loss: 3500342902711200841203712.000000\n",
      "Total training time: 2.47 seconds.\n",
      "-- Epoch 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 268020527913412.75, NNZs: 443347, Bias: 0.000000, T: 355200, Avg. loss: 2651393901766288569532416.000000\n",
      "Total training time: 2.97 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 222306958074966.59, NNZs: 443307, Bias: 0.000000, T: 426240, Avg. loss: 3478041668773821192077312.000000\n",
      "Total training time: 3.67 seconds.\n",
      "Convergence after 6 epochs took 3.71 seconds\n",
      "[CV 3/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.24457156361183285, clf__eta0=0.332929742792607, clf__fit_intercept=False, clf__l1_ratio=0.920539731041378, clf__learning_rate=constant, clf__loss=squared_error, clf__max_iter=100, clf__penalty=l1, clf__power_t=0.5734177157821045, clf__shuffle=True, clf__tol=0.6492274795888617, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.342 total time= 1.3min\n",
      "-- Epoch 1\n",
      "Norm: 272548206453686.81, NNZs: 443747, Bias: 0.000000, T: 71040, Avg. loss: 1312840370032062819729408.000000\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 208196816616706.06, NNZs: 443330, Bias: 0.000000, T: 142080, Avg. loss: 3709945647133346152579072.000000\n",
      "Total training time: 1.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 276909523506837.22, NNZs: 443745, Bias: 0.000000, T: 213120, Avg. loss: 2522656104402743023632384.000000\n",
      "Total training time: 1.49 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 203369057205054.84, NNZs: 443672, Bias: 0.000000, T: 284160, Avg. loss: 3771854938887256931303424.000000\n",
      "Total training time: 1.98 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 269055287791971.53, NNZs: 443747, Bias: 0.000000, T: 355200, Avg. loss: 2550002375934660661215232.000000\n",
      "Total training time: 2.49 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 224267320380411.84, NNZs: 443720, Bias: 0.000000, T: 426240, Avg. loss: 3590624398903401674440704.000000\n",
      "Total training time: 2.99 seconds.\n",
      "Convergence after 6 epochs took 3.03 seconds\n",
      "[CV 4/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.24457156361183285, clf__eta0=0.332929742792607, clf__fit_intercept=False, clf__l1_ratio=0.920539731041378, clf__learning_rate=constant, clf__loss=squared_error, clf__max_iter=100, clf__penalty=l1, clf__power_t=0.5734177157821045, clf__shuffle=True, clf__tol=0.6492274795888617, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.340 total time= 1.2min\n",
      "-- Epoch 1\n",
      "Norm: 269041208912861.91, NNZs: 441685, Bias: 0.000000, T: 71040, Avg. loss: 1303824105759407668723712.000000\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 211655196383343.31, NNZs: 441313, Bias: 0.000000, T: 142080, Avg. loss: 3466482893301556281606144.000000\n",
      "Total training time: 0.98 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 267881684052906.38, NNZs: 441682, Bias: 0.000000, T: 213120, Avg. loss: 2435335652859904507510784.000000\n",
      "Total training time: 1.47 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 219503997614584.12, NNZs: 441594, Bias: 0.000000, T: 284160, Avg. loss: 3420442204338113476558848.000000\n",
      "Total training time: 1.94 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 267870366291005.09, NNZs: 441687, Bias: 0.000000, T: 355200, Avg. loss: 2741906350467344142172160.000000\n",
      "Total training time: 2.42 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 235358226571490.12, NNZs: 441639, Bias: 0.000000, T: 426240, Avg. loss: 3494233442494364350676992.000000\n",
      "Total training time: 2.90 seconds.\n",
      "Convergence after 6 epochs took 2.94 seconds\n",
      "[CV 5/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.24457156361183285, clf__eta0=0.332929742792607, clf__fit_intercept=False, clf__l1_ratio=0.920539731041378, clf__learning_rate=constant, clf__loss=squared_error, clf__max_iter=100, clf__penalty=l1, clf__power_t=0.5734177157821045, clf__shuffle=True, clf__tol=0.6492274795888617, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.337 total time=  59.1s\n",
      "-- Epoch 1\n",
      "Norm: 3.97, NNZs: 728304, Bias: 0.389093, T: 71040, Avg. loss: 0.038119\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 4.04, NNZs: 728304, Bias: 0.448719, T: 142080, Avg. loss: 0.016801\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.04, NNZs: 728304, Bias: 0.483268, T: 213120, Avg. loss: 0.013131\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.03, NNZs: 728304, Bias: 0.507647, T: 284160, Avg. loss: 0.011378\n",
      "Total training time: 0.99 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.01, NNZs: 728304, Bias: 0.526443, T: 355200, Avg. loss: 0.010326\n",
      "Total training time: 1.24 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.99, NNZs: 728304, Bias: 0.541709, T: 426240, Avg. loss: 0.009612\n",
      "Total training time: 1.48 seconds.\n",
      "Convergence after 6 epochs took 1.53 seconds\n",
      "[CV 1/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.2527955528897454, clf__eta0=0.4377192284389271, clf__fit_intercept=True, clf__l1_ratio=0.6515110441465675, clf__learning_rate=invscaling, clf__loss=huber, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.47239053945705856, clf__shuffle=False, clf__tol=0.9089234089706554, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.498 total time=  59.2s\n",
      "-- Epoch 1\n",
      "Norm: 3.98, NNZs: 727889, Bias: 0.388266, T: 71040, Avg. loss: 0.037880\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 4.05, NNZs: 727889, Bias: 0.447595, T: 142080, Avg. loss: 0.016756\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.05, NNZs: 727889, Bias: 0.482013, T: 213120, Avg. loss: 0.013140\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.04, NNZs: 727889, Bias: 0.506325, T: 284160, Avg. loss: 0.011408\n",
      "Total training time: 1.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.02, NNZs: 727889, Bias: 0.525081, T: 355200, Avg. loss: 0.010366\n",
      "Total training time: 1.26 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.99, NNZs: 727889, Bias: 0.540326, T: 426240, Avg. loss: 0.009656\n",
      "Total training time: 1.51 seconds.\n",
      "Convergence after 6 epochs took 1.55 seconds\n",
      "[CV 2/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.2527955528897454, clf__eta0=0.4377192284389271, clf__fit_intercept=True, clf__l1_ratio=0.6515110441465675, clf__learning_rate=invscaling, clf__loss=huber, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.47239053945705856, clf__shuffle=False, clf__tol=0.9089234089706554, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.498 total time=  59.5s\n",
      "-- Epoch 1\n",
      "Norm: 3.97, NNZs: 727741, Bias: 0.388678, T: 71040, Avg. loss: 0.038077\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 4.04, NNZs: 727741, Bias: 0.448260, T: 142080, Avg. loss: 0.016811\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.05, NNZs: 727741, Bias: 0.482811, T: 213120, Avg. loss: 0.013160\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.03, NNZs: 727741, Bias: 0.507217, T: 284160, Avg. loss: 0.011410\n",
      "Total training time: 0.97 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.01, NNZs: 727741, Bias: 0.526043, T: 355200, Avg. loss: 0.010357\n",
      "Total training time: 1.21 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.99, NNZs: 727741, Bias: 0.541340, T: 426240, Avg. loss: 0.009641\n",
      "Total training time: 1.46 seconds.\n",
      "Convergence after 6 epochs took 1.51 seconds\n",
      "[CV 3/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.2527955528897454, clf__eta0=0.4377192284389271, clf__fit_intercept=True, clf__l1_ratio=0.6515110441465675, clf__learning_rate=invscaling, clf__loss=huber, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.47239053945705856, clf__shuffle=False, clf__tol=0.9089234089706554, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.498 total time=  59.2s\n",
      "-- Epoch 1\n",
      "Norm: 3.98, NNZs: 727636, Bias: 0.387710, T: 71040, Avg. loss: 0.037901\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 4.05, NNZs: 727636, Bias: 0.447187, T: 142080, Avg. loss: 0.016791\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.06, NNZs: 727636, Bias: 0.481684, T: 213120, Avg. loss: 0.013137\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.04, NNZs: 727636, Bias: 0.506040, T: 284160, Avg. loss: 0.011388\n",
      "Total training time: 0.93 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.02, NNZs: 727636, Bias: 0.524822, T: 355200, Avg. loss: 0.010338\n",
      "Total training time: 1.17 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 4.00, NNZs: 727636, Bias: 0.540075, T: 426240, Avg. loss: 0.009624\n",
      "Total training time: 1.41 seconds.\n",
      "Convergence after 6 epochs took 1.46 seconds\n",
      "[CV 4/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.2527955528897454, clf__eta0=0.4377192284389271, clf__fit_intercept=True, clf__l1_ratio=0.6515110441465675, clf__learning_rate=invscaling, clf__loss=huber, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.47239053945705856, clf__shuffle=False, clf__tol=0.9089234089706554, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.498 total time=  58.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 3.98, NNZs: 724373, Bias: 0.389208, T: 71040, Avg. loss: 0.037999\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 4.05, NNZs: 724373, Bias: 0.448434, T: 142080, Avg. loss: 0.016736\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.05, NNZs: 724373, Bias: 0.482745, T: 213120, Avg. loss: 0.013125\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.04, NNZs: 724373, Bias: 0.506987, T: 284160, Avg. loss: 0.011393\n",
      "Total training time: 0.98 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.02, NNZs: 724373, Bias: 0.525699, T: 355200, Avg. loss: 0.010349\n",
      "Total training time: 1.25 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.99, NNZs: 724373, Bias: 0.540910, T: 426240, Avg. loss: 0.009639\n",
      "Total training time: 1.50 seconds.\n",
      "Convergence after 6 epochs took 1.54 seconds\n",
      "[CV 5/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.2527955528897454, clf__eta0=0.4377192284389271, clf__fit_intercept=True, clf__l1_ratio=0.6515110441465675, clf__learning_rate=invscaling, clf__loss=huber, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.47239053945705856, clf__shuffle=False, clf__tol=0.9089234089706554, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.498 total time=  59.1s\n",
      "-- Epoch 1\n",
      "Norm: 9.96, NNZs: 247485, Bias: 0.940684, T: 71040, Avg. loss: 0.026995\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 8.51, NNZs: 260417, Bias: 0.908386, T: 142080, Avg. loss: 0.007698\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 8.21, NNZs: 270896, Bias: 0.889281, T: 213120, Avg. loss: 0.007357\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 8.09, NNZs: 278036, Bias: 0.875944, T: 284160, Avg. loss: 0.007220\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 8.04, NNZs: 283563, Bias: 0.866072, T: 355200, Avg. loss: 0.007158\n",
      "Total training time: 1.20 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 8.01, NNZs: 286951, Bias: 0.857637, T: 426240, Avg. loss: 0.007122\n",
      "Total training time: 1.45 seconds.\n",
      "Convergence after 6 epochs took 1.49 seconds\n",
      "[CV 1/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.3241670976844645, clf__eta0=0.9631840511405841, clf__fit_intercept=True, clf__l1_ratio=0.5912641309775509, clf__learning_rate=optimal, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.6710686638981408, clf__shuffle=True, clf__tol=0.09654933943827881, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.760 total time=  58.5s\n",
      "-- Epoch 1\n",
      "Norm: 9.94, NNZs: 247440, Bias: 0.924992, T: 71040, Avg. loss: 0.027531\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 8.51, NNZs: 260704, Bias: 0.895146, T: 142080, Avg. loss: 0.007658\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 8.19, NNZs: 270152, Bias: 0.877658, T: 213120, Avg. loss: 0.007428\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 8.05, NNZs: 276258, Bias: 0.867198, T: 284160, Avg. loss: 0.007315\n",
      "Total training time: 0.96 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 7.99, NNZs: 280969, Bias: 0.858833, T: 355200, Avg. loss: 0.007206\n",
      "Total training time: 1.23 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 7.96, NNZs: 285003, Bias: 0.852771, T: 426240, Avg. loss: 0.007180\n",
      "Total training time: 1.49 seconds.\n",
      "Convergence after 6 epochs took 1.54 seconds\n",
      "[CV 2/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.3241670976844645, clf__eta0=0.9631840511405841, clf__fit_intercept=True, clf__l1_ratio=0.5912641309775509, clf__learning_rate=optimal, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.6710686638981408, clf__shuffle=True, clf__tol=0.09654933943827881, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.759 total time= 1.0min\n",
      "-- Epoch 1\n",
      "Norm: 9.80, NNZs: 244042, Bias: 0.935776, T: 71040, Avg. loss: 0.027228\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 8.44, NNZs: 255400, Bias: 0.899289, T: 142080, Avg. loss: 0.007762\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 8.14, NNZs: 264921, Bias: 0.883433, T: 213120, Avg. loss: 0.007514\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 8.01, NNZs: 270539, Bias: 0.870995, T: 284160, Avg. loss: 0.007379\n",
      "Total training time: 0.98 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 7.96, NNZs: 275091, Bias: 0.860148, T: 355200, Avg. loss: 0.007280\n",
      "Total training time: 1.23 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 7.93, NNZs: 278552, Bias: 0.853228, T: 426240, Avg. loss: 0.007233\n",
      "Total training time: 1.46 seconds.\n",
      "Convergence after 6 epochs took 1.50 seconds\n",
      "[CV 3/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.3241670976844645, clf__eta0=0.9631840511405841, clf__fit_intercept=True, clf__l1_ratio=0.5912641309775509, clf__learning_rate=optimal, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.6710686638981408, clf__shuffle=True, clf__tol=0.09654933943827881, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.761 total time=  58.5s\n",
      "-- Epoch 1\n",
      "Norm: 10.02, NNZs: 247947, Bias: 0.910725, T: 71040, Avg. loss: 0.027430\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 8.58, NNZs: 259635, Bias: 0.878231, T: 142080, Avg. loss: 0.007579\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 8.27, NNZs: 268368, Bias: 0.859429, T: 213120, Avg. loss: 0.007224\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 8.13, NNZs: 275323, Bias: 0.849631, T: 284160, Avg. loss: 0.007129\n",
      "Total training time: 0.93 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 8.08, NNZs: 280585, Bias: 0.840552, T: 355200, Avg. loss: 0.007053\n",
      "Total training time: 1.17 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 8.05, NNZs: 284528, Bias: 0.833549, T: 426240, Avg. loss: 0.006992\n",
      "Total training time: 1.40 seconds.\n",
      "Convergence after 6 epochs took 1.45 seconds\n",
      "[CV 4/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.3241670976844645, clf__eta0=0.9631840511405841, clf__fit_intercept=True, clf__l1_ratio=0.5912641309775509, clf__learning_rate=optimal, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.6710686638981408, clf__shuffle=True, clf__tol=0.09654933943827881, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.770 total time=  59.4s\n",
      "-- Epoch 1\n",
      "Norm: 9.92, NNZs: 246035, Bias: 0.910773, T: 71040, Avg. loss: 0.027138\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 8.47, NNZs: 257501, Bias: 0.885102, T: 142080, Avg. loss: 0.007827\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 8.16, NNZs: 266191, Bias: 0.868802, T: 213120, Avg. loss: 0.007460\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 8.03, NNZs: 272175, Bias: 0.858861, T: 284160, Avg. loss: 0.007315\n",
      "Total training time: 0.91 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 7.98, NNZs: 276789, Bias: 0.848668, T: 355200, Avg. loss: 0.007257\n",
      "Total training time: 1.14 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 7.94, NNZs: 281061, Bias: 0.843858, T: 426240, Avg. loss: 0.007204\n",
      "Total training time: 1.36 seconds.\n",
      "Convergence after 6 epochs took 1.40 seconds\n",
      "[CV 5/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.3241670976844645, clf__eta0=0.9631840511405841, clf__fit_intercept=True, clf__l1_ratio=0.5912641309775509, clf__learning_rate=optimal, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.6710686638981408, clf__shuffle=True, clf__tol=0.09654933943827881, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.763 total time=  58.6s\n",
      "-- Epoch 1\n",
      "Norm: 411.48, NNZs: 415, Bias: 0.000000, T: 71040, Avg. loss: 0.185069\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 490.81, NNZs: 138, Bias: 0.000000, T: 142080, Avg. loss: 0.028033\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 549.94, NNZs: 90, Bias: 0.000000, T: 213120, Avg. loss: 0.020933\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 601.10, NNZs: 77, Bias: 0.000000, T: 284160, Avg. loss: 0.019153\n",
      "Total training time: 0.93 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 641.62, NNZs: 65, Bias: 0.000000, T: 355200, Avg. loss: 0.016875\n",
      "Total training time: 1.15 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 682.03, NNZs: 71, Bias: 0.000000, T: 426240, Avg. loss: 0.017169\n",
      "Total training time: 1.37 seconds.\n",
      "Convergence after 6 epochs took 1.41 seconds\n",
      "[CV 1/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.3509613152086368, clf__eta0=0.9934401124631351, clf__fit_intercept=False, clf__l1_ratio=0.5204998682261415, clf__learning_rate=constant, clf__loss=hinge, clf__max_iter=40, clf__penalty=l1, clf__power_t=0.5098574122392232, clf__shuffle=False, clf__tol=0.5563103350645606, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.969 total time=  57.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 398.77, NNZs: 376, Bias: 0.000000, T: 71040, Avg. loss: 0.194694\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 485.60, NNZs: 125, Bias: 0.000000, T: 142080, Avg. loss: 0.028227\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 547.26, NNZs: 100, Bias: 0.000000, T: 213120, Avg. loss: 0.024437\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 595.82, NNZs: 80, Bias: 0.000000, T: 284160, Avg. loss: 0.021288\n",
      "Total training time: 0.98 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 636.48, NNZs: 72, Bias: 0.000000, T: 355200, Avg. loss: 0.019024\n",
      "Total training time: 1.22 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 674.57, NNZs: 70, Bias: 0.000000, T: 426240, Avg. loss: 0.017713\n",
      "Total training time: 1.47 seconds.\n",
      "Convergence after 6 epochs took 1.51 seconds\n",
      "[CV 2/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.3509613152086368, clf__eta0=0.9934401124631351, clf__fit_intercept=False, clf__l1_ratio=0.5204998682261415, clf__learning_rate=constant, clf__loss=hinge, clf__max_iter=40, clf__penalty=l1, clf__power_t=0.5098574122392232, clf__shuffle=False, clf__tol=0.5563103350645606, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.981 total time=  57.8s\n",
      "-- Epoch 1\n",
      "Norm: 407.68, NNZs: 402, Bias: 0.000000, T: 71040, Avg. loss: 0.217282\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 478.83, NNZs: 120, Bias: 0.000000, T: 142080, Avg. loss: 0.026482\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 539.22, NNZs: 82, Bias: 0.000000, T: 213120, Avg. loss: 0.022732\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 584.01, NNZs: 73, Bias: 0.000000, T: 284160, Avg. loss: 0.018026\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 625.78, NNZs: 70, Bias: 0.000000, T: 355200, Avg. loss: 0.017834\n",
      "Total training time: 1.16 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 660.70, NNZs: 63, Bias: 0.000000, T: 426240, Avg. loss: 0.016675\n",
      "Total training time: 1.37 seconds.\n",
      "Convergence after 6 epochs took 1.41 seconds\n",
      "[CV 3/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.3509613152086368, clf__eta0=0.9934401124631351, clf__fit_intercept=False, clf__l1_ratio=0.5204998682261415, clf__learning_rate=constant, clf__loss=hinge, clf__max_iter=40, clf__penalty=l1, clf__power_t=0.5098574122392232, clf__shuffle=False, clf__tol=0.5563103350645606, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.966 total time=  57.6s\n",
      "-- Epoch 1\n",
      "Norm: 419.30, NNZs: 438, Bias: 0.000000, T: 71040, Avg. loss: 0.212840\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 497.37, NNZs: 132, Bias: 0.000000, T: 142080, Avg. loss: 0.027437\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 552.82, NNZs: 98, Bias: 0.000000, T: 213120, Avg. loss: 0.021726\n",
      "Total training time: 0.97 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 598.96, NNZs: 81, Bias: 0.000000, T: 284160, Avg. loss: 0.020248\n",
      "Total training time: 1.34 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 639.51, NNZs: 78, Bias: 0.000000, T: 355200, Avg. loss: 0.017685\n",
      "Total training time: 1.62 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 671.39, NNZs: 63, Bias: 0.000000, T: 426240, Avg. loss: 0.015757\n",
      "Total training time: 1.97 seconds.\n",
      "Convergence after 6 epochs took 2.03 seconds\n",
      "[CV 4/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.3509613152086368, clf__eta0=0.9934401124631351, clf__fit_intercept=False, clf__l1_ratio=0.5204998682261415, clf__learning_rate=constant, clf__loss=hinge, clf__max_iter=40, clf__penalty=l1, clf__power_t=0.5098574122392232, clf__shuffle=False, clf__tol=0.5563103350645606, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.985 total time= 1.1min\n",
      "-- Epoch 1\n",
      "Norm: 405.02, NNZs: 392, Bias: 0.000000, T: 71040, Avg. loss: 0.226762\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 485.89, NNZs: 125, Bias: 0.000000, T: 142080, Avg. loss: 0.025424\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 540.50, NNZs: 84, Bias: 0.000000, T: 213120, Avg. loss: 0.018230\n",
      "Total training time: 1.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 592.61, NNZs: 93, Bias: 0.000000, T: 284160, Avg. loss: 0.018368\n",
      "Total training time: 1.55 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 631.47, NNZs: 73, Bias: 0.000000, T: 355200, Avg. loss: 0.015994\n",
      "Total training time: 1.98 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 666.07, NNZs: 68, Bias: 0.000000, T: 426240, Avg. loss: 0.015020\n",
      "Total training time: 2.22 seconds.\n",
      "Convergence after 6 epochs took 2.26 seconds\n",
      "[CV 5/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.3509613152086368, clf__eta0=0.9934401124631351, clf__fit_intercept=False, clf__l1_ratio=0.5204998682261415, clf__learning_rate=constant, clf__loss=hinge, clf__max_iter=40, clf__penalty=l1, clf__power_t=0.5098574122392232, clf__shuffle=False, clf__tol=0.5563103350645606, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.978 total time= 1.2min\n",
      "-- Epoch 1\n",
      "Norm: 1.73, NNZs: 444255, Bias: 0.000000, T: 71040, Avg. loss: 0.832908\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.86, NNZs: 444255, Bias: 0.000000, T: 142080, Avg. loss: 0.831968\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.94, NNZs: 444255, Bias: 0.000000, T: 213120, Avg. loss: 0.820211\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.01, NNZs: 444255, Bias: 0.000000, T: 284160, Avg. loss: 0.806809\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.07, NNZs: 444255, Bias: 0.000000, T: 355200, Avg. loss: 0.795559\n",
      "Total training time: 1.08 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.12, NNZs: 444255, Bias: 0.000000, T: 426240, Avg. loss: 0.784900\n",
      "Total training time: 1.26 seconds.\n",
      "Convergence after 6 epochs took 1.31 seconds\n",
      "[CV 1/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.28658617296069355, clf__eta0=0.03398405924608927, clf__fit_intercept=False, clf__l1_ratio=0.08227014493927165, clf__learning_rate=invscaling, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.5467473202425025, clf__shuffle=True, clf__tol=0.9099604695658384, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.452 total time= 1.2min\n",
      "-- Epoch 1\n",
      "Norm: 1.48, NNZs: 444371, Bias: 0.000000, T: 71040, Avg. loss: 0.801595\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.67, NNZs: 444371, Bias: 0.000000, T: 142080, Avg. loss: 0.830206\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.77, NNZs: 444371, Bias: 0.000000, T: 213120, Avg. loss: 0.818989\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.85, NNZs: 444371, Bias: 0.000000, T: 284160, Avg. loss: 0.808119\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.92, NNZs: 444371, Bias: 0.000000, T: 355200, Avg. loss: 0.797046\n",
      "Total training time: 1.16 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.99, NNZs: 444371, Bias: 0.000000, T: 426240, Avg. loss: 0.786925\n",
      "Total training time: 1.44 seconds.\n",
      "Convergence after 6 epochs took 1.48 seconds\n",
      "[CV 2/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.28658617296069355, clf__eta0=0.03398405924608927, clf__fit_intercept=False, clf__l1_ratio=0.08227014493927165, clf__learning_rate=invscaling, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.5467473202425025, clf__shuffle=True, clf__tol=0.9099604695658384, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.450 total time= 1.2min\n",
      "-- Epoch 1\n",
      "Norm: 1.55, NNZs: 443325, Bias: 0.000000, T: 71040, Avg. loss: 0.818970\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.72, NNZs: 443325, Bias: 0.000000, T: 142080, Avg. loss: 0.832386\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.81, NNZs: 443325, Bias: 0.000000, T: 213120, Avg. loss: 0.820448\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.89, NNZs: 443325, Bias: 0.000000, T: 284160, Avg. loss: 0.808801\n",
      "Total training time: 1.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.96, NNZs: 443325, Bias: 0.000000, T: 355200, Avg. loss: 0.797014\n",
      "Total training time: 1.24 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.02, NNZs: 443325, Bias: 0.000000, T: 426240, Avg. loss: 0.786505\n",
      "Total training time: 1.44 seconds.\n",
      "Convergence after 6 epochs took 1.48 seconds\n",
      "[CV 3/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.28658617296069355, clf__eta0=0.03398405924608927, clf__fit_intercept=False, clf__l1_ratio=0.08227014493927165, clf__learning_rate=invscaling, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.5467473202425025, clf__shuffle=True, clf__tol=0.9099604695658384, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.456 total time= 1.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 1.54, NNZs: 443728, Bias: 0.000000, T: 71040, Avg. loss: 0.812345\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.70, NNZs: 443728, Bias: 0.000000, T: 142080, Avg. loss: 0.832796\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.80, NNZs: 443728, Bias: 0.000000, T: 213120, Avg. loss: 0.821139\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.89, NNZs: 443728, Bias: 0.000000, T: 284160, Avg. loss: 0.808144\n",
      "Total training time: 1.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.95, NNZs: 443728, Bias: 0.000000, T: 355200, Avg. loss: 0.797896\n",
      "Total training time: 1.18 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.02, NNZs: 443728, Bias: 0.000000, T: 426240, Avg. loss: 0.785881\n",
      "Total training time: 1.37 seconds.\n",
      "Convergence after 6 epochs took 1.43 seconds\n",
      "[CV 4/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.28658617296069355, clf__eta0=0.03398405924608927, clf__fit_intercept=False, clf__l1_ratio=0.08227014493927165, clf__learning_rate=invscaling, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.5467473202425025, clf__shuffle=True, clf__tol=0.9099604695658384, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.458 total time= 1.2min\n",
      "-- Epoch 1\n",
      "Norm: 1.64, NNZs: 441678, Bias: 0.000000, T: 71040, Avg. loss: 0.824343\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.77, NNZs: 441678, Bias: 0.000000, T: 142080, Avg. loss: 0.838627\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.86, NNZs: 441678, Bias: 0.000000, T: 213120, Avg. loss: 0.823199\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.93, NNZs: 441678, Bias: 0.000000, T: 284160, Avg. loss: 0.811858\n",
      "Total training time: 0.97 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.99, NNZs: 441678, Bias: 0.000000, T: 355200, Avg. loss: 0.800500\n",
      "Total training time: 1.22 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.05, NNZs: 441678, Bias: 0.000000, T: 426240, Avg. loss: 0.789515\n",
      "Total training time: 1.47 seconds.\n",
      "Convergence after 6 epochs took 1.51 seconds\n",
      "[CV 5/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.28658617296069355, clf__eta0=0.03398405924608927, clf__fit_intercept=False, clf__l1_ratio=0.08227014493927165, clf__learning_rate=invscaling, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.5467473202425025, clf__shuffle=True, clf__tol=0.9099604695658384, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.451 total time= 1.3min\n",
      "-- Epoch 1\n",
      "Norm: 67.90, NNZs: 444245, Bias: 0.000000, T: 71040, Avg. loss: 0.292008\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 67.13, NNZs: 444245, Bias: 0.000000, T: 142080, Avg. loss: 0.250773\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 67.14, NNZs: 444245, Bias: 0.000000, T: 213120, Avg. loss: 0.250988\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 67.14, NNZs: 444245, Bias: 0.000000, T: 284160, Avg. loss: 0.250990\n",
      "Total training time: 1.09 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 67.14, NNZs: 444245, Bias: 0.000000, T: 355200, Avg. loss: 0.250990\n",
      "Total training time: 1.36 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 67.14, NNZs: 444245, Bias: 0.000000, T: 426240, Avg. loss: 0.250990\n",
      "Total training time: 1.59 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 48.18, NNZs: 444245, Bias: 0.000000, T: 497280, Avg. loss: 0.185360\n",
      "Total training time: 1.83 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 45.81, NNZs: 444245, Bias: 0.000000, T: 568320, Avg. loss: 0.182038\n",
      "Total training time: 2.05 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 45.71, NNZs: 444245, Bias: 0.000000, T: 639360, Avg. loss: 0.182969\n",
      "Total training time: 2.27 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 45.70, NNZs: 444245, Bias: 0.000000, T: 710400, Avg. loss: 0.183106\n",
      "Total training time: 2.49 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 45.70, NNZs: 444245, Bias: 0.000000, T: 781440, Avg. loss: 0.183087\n",
      "Total training time: 2.78 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 44.76, NNZs: 444245, Bias: 0.000000, T: 852480, Avg. loss: 0.166282\n",
      "Total training time: 3.02 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 44.10, NNZs: 444245, Bias: 0.000000, T: 923520, Avg. loss: 0.166465\n",
      "Total training time: 3.30 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 43.68, NNZs: 444245, Bias: 0.000000, T: 994560, Avg. loss: 0.167774\n",
      "Total training time: 3.63 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 43.41, NNZs: 444245, Bias: 0.000000, T: 1065600, Avg. loss: 0.168881\n",
      "Total training time: 4.02 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 43.25, NNZs: 444245, Bias: 0.000000, T: 1136640, Avg. loss: 0.169668\n",
      "Total training time: 4.31 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 43.20, NNZs: 444245, Bias: 0.000000, T: 1207680, Avg. loss: 0.163799\n",
      "Total training time: 4.53 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 43.15, NNZs: 444245, Bias: 0.000000, T: 1278720, Avg. loss: 0.166494\n",
      "Total training time: 4.92 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 43.10, NNZs: 444245, Bias: 0.000000, T: 1349760, Avg. loss: 0.166596\n",
      "Total training time: 5.17 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 43.05, NNZs: 444245, Bias: 0.000000, T: 1420800, Avg. loss: 0.166698\n",
      "Total training time: 5.46 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.42493015701647596, clf__eta0=0.6773009699604285, clf__fit_intercept=False, clf__l1_ratio=0.7301998277223162, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.017782879504616322, clf__shuffle=False, clf__tol=0.19519881462597577, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.669 total time= 1.3min\n",
      "-- Epoch 1\n",
      "Norm: 70.57, NNZs: 444368, Bias: 0.000000, T: 71040, Avg. loss: 0.300047\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 69.72, NNZs: 444368, Bias: 0.000000, T: 142080, Avg. loss: 0.263157\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 69.73, NNZs: 444368, Bias: 0.000000, T: 213120, Avg. loss: 0.263238\n",
      "Total training time: 0.72 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 69.73, NNZs: 444368, Bias: 0.000000, T: 284160, Avg. loss: 0.263240\n",
      "Total training time: 0.96 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 69.73, NNZs: 444368, Bias: 0.000000, T: 355200, Avg. loss: 0.263240\n",
      "Total training time: 1.35 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 69.73, NNZs: 444368, Bias: 0.000000, T: 426240, Avg. loss: 0.263240\n",
      "Total training time: 1.67 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 48.69, NNZs: 444368, Bias: 0.000000, T: 497280, Avg. loss: 0.184567\n",
      "Total training time: 2.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 45.89, NNZs: 444368, Bias: 0.000000, T: 568320, Avg. loss: 0.181576\n",
      "Total training time: 2.23 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 45.66, NNZs: 444368, Bias: 0.000000, T: 639360, Avg. loss: 0.183310\n",
      "Total training time: 2.46 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 45.65, NNZs: 444368, Bias: 0.000000, T: 710400, Avg. loss: 0.183642\n",
      "Total training time: 2.77 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 45.65, NNZs: 444368, Bias: 0.000000, T: 781440, Avg. loss: 0.183624\n",
      "Total training time: 3.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 44.71, NNZs: 444368, Bias: 0.000000, T: 852480, Avg. loss: 0.167595\n",
      "Total training time: 3.21 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 44.05, NNZs: 444368, Bias: 0.000000, T: 923520, Avg. loss: 0.166632\n",
      "Total training time: 3.49 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 43.63, NNZs: 444368, Bias: 0.000000, T: 994560, Avg. loss: 0.167902\n",
      "Total training time: 3.74 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 43.37, NNZs: 444368, Bias: 0.000000, T: 1065600, Avg. loss: 0.168992\n",
      "Total training time: 3.95 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 43.20, NNZs: 444368, Bias: 0.000000, T: 1136640, Avg. loss: 0.169768\n",
      "Total training time: 4.31 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 43.15, NNZs: 444368, Bias: 0.000000, T: 1207680, Avg. loss: 0.164555\n",
      "Total training time: 4.69 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 43.10, NNZs: 444368, Bias: 0.000000, T: 1278720, Avg. loss: 0.166482\n",
      "Total training time: 5.02 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 43.04, NNZs: 444368, Bias: 0.000000, T: 1349760, Avg. loss: 0.166576\n",
      "Total training time: 5.26 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 42.99, NNZs: 444368, Bias: 0.000000, T: 1420800, Avg. loss: 0.166683\n",
      "Total training time: 5.53 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.42493015701647596, clf__eta0=0.6773009699604285, clf__fit_intercept=False, clf__l1_ratio=0.7301998277223162, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.017782879504616322, clf__shuffle=False, clf__tol=0.19519881462597577, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.656 total time= 1.3min\n",
      "-- Epoch 1\n",
      "Norm: 70.82, NNZs: 443344, Bias: 0.000000, T: 71040, Avg. loss: 0.299524\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 69.72, NNZs: 443344, Bias: 0.000000, T: 142080, Avg. loss: 0.256302\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 69.75, NNZs: 443344, Bias: 0.000000, T: 213120, Avg. loss: 0.256660\n",
      "Total training time: 1.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 69.75, NNZs: 443344, Bias: 0.000000, T: 284160, Avg. loss: 0.256653\n",
      "Total training time: 1.38 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 69.75, NNZs: 443344, Bias: 0.000000, T: 355200, Avg. loss: 0.256653\n",
      "Total training time: 1.66 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 69.75, NNZs: 443344, Bias: 0.000000, T: 426240, Avg. loss: 0.256653\n",
      "Total training time: 1.88 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 49.08, NNZs: 443344, Bias: 0.000000, T: 497280, Avg. loss: 0.185854\n",
      "Total training time: 2.21 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 46.27, NNZs: 443344, Bias: 0.000000, T: 568320, Avg. loss: 0.182085\n",
      "Total training time: 2.48 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 46.11, NNZs: 443344, Bias: 0.000000, T: 639360, Avg. loss: 0.184096\n",
      "Total training time: 2.77 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 46.09, NNZs: 443344, Bias: 0.000000, T: 710400, Avg. loss: 0.184307\n",
      "Total training time: 3.07 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 46.09, NNZs: 443344, Bias: 0.000000, T: 781440, Avg. loss: 0.184299\n",
      "Total training time: 3.36 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 45.08, NNZs: 443344, Bias: 0.000000, T: 852480, Avg. loss: 0.165903\n",
      "Total training time: 3.58 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 44.38, NNZs: 443344, Bias: 0.000000, T: 923520, Avg. loss: 0.166655\n",
      "Total training time: 3.79 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 43.94, NNZs: 443344, Bias: 0.000000, T: 994560, Avg. loss: 0.168321\n",
      "Total training time: 4.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 43.66, NNZs: 443344, Bias: 0.000000, T: 1065600, Avg. loss: 0.169600\n",
      "Total training time: 4.23 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 43.48, NNZs: 443344, Bias: 0.000000, T: 1136640, Avg. loss: 0.170472\n",
      "Total training time: 4.48 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 43.43, NNZs: 443344, Bias: 0.000000, T: 1207680, Avg. loss: 0.166463\n",
      "Total training time: 4.83 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 43.38, NNZs: 443344, Bias: 0.000000, T: 1278720, Avg. loss: 0.167343\n",
      "Total training time: 5.05 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 43.32, NNZs: 443344, Bias: 0.000000, T: 1349760, Avg. loss: 0.167332\n",
      "Total training time: 5.29 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 43.27, NNZs: 443344, Bias: 0.000000, T: 1420800, Avg. loss: 0.167389\n",
      "Total training time: 5.51 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.42493015701647596, clf__eta0=0.6773009699604285, clf__fit_intercept=False, clf__l1_ratio=0.7301998277223162, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.017782879504616322, clf__shuffle=False, clf__tol=0.19519881462597577, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.677 total time= 1.3min\n",
      "-- Epoch 1\n",
      "Norm: 70.70, NNZs: 443734, Bias: 0.000000, T: 71040, Avg. loss: 0.299594\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 69.68, NNZs: 443734, Bias: 0.000000, T: 142080, Avg. loss: 0.260357\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 69.71, NNZs: 443734, Bias: 0.000000, T: 213120, Avg. loss: 0.260607\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 69.70, NNZs: 443734, Bias: 0.000000, T: 284160, Avg. loss: 0.260599\n",
      "Total training time: 1.08 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 69.71, NNZs: 443734, Bias: 0.000000, T: 355200, Avg. loss: 0.260599\n",
      "Total training time: 1.45 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 69.71, NNZs: 443734, Bias: 0.000000, T: 426240, Avg. loss: 0.260599\n",
      "Total training time: 1.66 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 49.02, NNZs: 443734, Bias: 0.000000, T: 497280, Avg. loss: 0.181595\n",
      "Total training time: 2.01 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 46.29, NNZs: 443734, Bias: 0.000000, T: 568320, Avg. loss: 0.181399\n",
      "Total training time: 2.26 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 46.13, NNZs: 443734, Bias: 0.000000, T: 639360, Avg. loss: 0.183113\n",
      "Total training time: 2.53 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 46.12, NNZs: 443734, Bias: 0.000000, T: 710400, Avg. loss: 0.183311\n",
      "Total training time: 2.74 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 46.12, NNZs: 443734, Bias: 0.000000, T: 781440, Avg. loss: 0.183303\n",
      "Total training time: 2.96 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 45.14, NNZs: 443734, Bias: 0.000000, T: 852480, Avg. loss: 0.165027\n",
      "Total training time: 3.29 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 44.43, NNZs: 443734, Bias: 0.000000, T: 923520, Avg. loss: 0.165273\n",
      "Total training time: 3.60 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 43.98, NNZs: 443734, Bias: 0.000000, T: 994560, Avg. loss: 0.167048\n",
      "Total training time: 3.84 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 43.70, NNZs: 443734, Bias: 0.000000, T: 1065600, Avg. loss: 0.168415\n",
      "Total training time: 4.16 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 43.52, NNZs: 443734, Bias: 0.000000, T: 1136640, Avg. loss: 0.169345\n",
      "Total training time: 4.52 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 43.47, NNZs: 443734, Bias: 0.000000, T: 1207680, Avg. loss: 0.164759\n",
      "Total training time: 4.81 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 43.42, NNZs: 443734, Bias: 0.000000, T: 1278720, Avg. loss: 0.166194\n",
      "Total training time: 5.04 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 43.37, NNZs: 443734, Bias: 0.000000, T: 1349760, Avg. loss: 0.166187\n",
      "Total training time: 5.31 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 43.32, NNZs: 443734, Bias: 0.000000, T: 1420800, Avg. loss: 0.166245\n",
      "Total training time: 5.60 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.42493015701647596, clf__eta0=0.6773009699604285, clf__fit_intercept=False, clf__l1_ratio=0.7301998277223162, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.017782879504616322, clf__shuffle=False, clf__tol=0.19519881462597577, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.676 total time= 1.3min\n",
      "-- Epoch 1\n",
      "Norm: 76.04, NNZs: 441685, Bias: 0.000000, T: 71040, Avg. loss: 0.301523\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 75.19, NNZs: 441685, Bias: 0.000000, T: 142080, Avg. loss: 0.265102\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 75.20, NNZs: 441685, Bias: 0.000000, T: 213120, Avg. loss: 0.265314\n",
      "Total training time: 0.82 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 75.20, NNZs: 441685, Bias: 0.000000, T: 284160, Avg. loss: 0.265308\n",
      "Total training time: 1.11 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 75.20, NNZs: 441685, Bias: 0.000000, T: 355200, Avg. loss: 0.265308\n",
      "Total training time: 1.39 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 75.20, NNZs: 441685, Bias: 0.000000, T: 426240, Avg. loss: 0.265308\n",
      "Total training time: 1.66 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 50.31, NNZs: 441685, Bias: 0.000000, T: 497280, Avg. loss: 0.199518\n",
      "Total training time: 2.01 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 46.88, NNZs: 441685, Bias: 0.000000, T: 568320, Avg. loss: 0.185445\n",
      "Total training time: 2.27 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 46.60, NNZs: 441685, Bias: 0.000000, T: 639360, Avg. loss: 0.186993\n",
      "Total training time: 2.51 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 46.58, NNZs: 441685, Bias: 0.000000, T: 710400, Avg. loss: 0.187287\n",
      "Total training time: 2.76 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 46.58, NNZs: 441685, Bias: 0.000000, T: 781440, Avg. loss: 0.187355\n",
      "Total training time: 3.03 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 45.47, NNZs: 441685, Bias: 0.000000, T: 852480, Avg. loss: 0.178056\n",
      "Total training time: 3.29 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 44.73, NNZs: 441685, Bias: 0.000000, T: 923520, Avg. loss: 0.169336\n",
      "Total training time: 3.56 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 44.26, NNZs: 441685, Bias: 0.000000, T: 994560, Avg. loss: 0.170890\n",
      "Total training time: 3.91 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 43.96, NNZs: 441685, Bias: 0.000000, T: 1065600, Avg. loss: 0.172217\n",
      "Total training time: 4.22 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 43.76, NNZs: 441685, Bias: 0.000000, T: 1136640, Avg. loss: 0.173144\n",
      "Total training time: 4.49 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 43.68, NNZs: 441685, Bias: 0.000000, T: 1207680, Avg. loss: 0.174166\n",
      "Total training time: 4.82 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 43.62, NNZs: 441685, Bias: 0.000000, T: 1278720, Avg. loss: 0.169905\n",
      "Total training time: 5.08 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 43.56, NNZs: 441685, Bias: 0.000000, T: 1349760, Avg. loss: 0.169864\n",
      "Total training time: 5.40 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 43.51, NNZs: 441685, Bias: 0.000000, T: 1420800, Avg. loss: 0.169957\n",
      "Total training time: 5.63 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.42493015701647596, clf__eta0=0.6773009699604285, clf__fit_intercept=False, clf__l1_ratio=0.7301998277223162, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.017782879504616322, clf__shuffle=False, clf__tol=0.19519881462597577, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.681 total time= 1.3min\n",
      "-- Epoch 1\n",
      "Norm: 51.76, NNZs: 265495, Bias: 1.940048, T: 71040, Avg. loss: 0.325073\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 30.88, NNZs: 286014, Bias: 1.710811, T: 142080, Avg. loss: 0.008165\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 22.88, NNZs: 289290, Bias: 1.572568, T: 213120, Avg. loss: 0.002501\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 18.51, NNZs: 295237, Bias: 1.512285, T: 284160, Avg. loss: 0.001647\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 15.83, NNZs: 295934, Bias: 1.448747, T: 355200, Avg. loss: 0.000468\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 13.75, NNZs: 297081, Bias: 1.423808, T: 426240, Avg. loss: 0.000500\n",
      "Total training time: 0.94 seconds.\n",
      "Convergence after 6 epochs took 1.00 seconds\n",
      "[CV 1/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.21123614325601048, clf__eta0=0.32979731781585486, clf__fit_intercept=True, clf__l1_ratio=0.4775095579144826, clf__learning_rate=optimal, clf__loss=perceptron, clf__max_iter=30, clf__penalty=l2, clf__power_t=0.6427671735097384, clf__shuffle=False, clf__tol=0.2651165400908262, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.862 total time= 1.2min\n",
      "-- Epoch 1\n",
      "Norm: 53.16, NNZs: 272458, Bias: 2.530043, T: 71040, Avg. loss: 0.303651\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 32.73, NNZs: 288776, Bias: 2.203405, T: 142080, Avg. loss: 0.010108\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 24.63, NNZs: 291957, Bias: 2.042159, T: 213120, Avg. loss: 0.002777\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 19.85, NNZs: 293288, Bias: 1.965001, T: 284160, Avg. loss: 0.001144\n",
      "Total training time: 0.56 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 17.10, NNZs: 294811, Bias: 1.893763, T: 355200, Avg. loss: 0.000809\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 15.13, NNZs: 295422, Bias: 1.842500, T: 426240, Avg. loss: 0.000630\n",
      "Total training time: 0.87 seconds.\n",
      "Convergence after 6 epochs took 0.93 seconds\n",
      "[CV 2/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.21123614325601048, clf__eta0=0.32979731781585486, clf__fit_intercept=True, clf__l1_ratio=0.4775095579144826, clf__learning_rate=optimal, clf__loss=perceptron, clf__max_iter=30, clf__penalty=l2, clf__power_t=0.6427671735097384, clf__shuffle=False, clf__tol=0.2651165400908262, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.869 total time= 1.2min\n",
      "-- Epoch 1\n",
      "Norm: 50.98, NNZs: 262507, Bias: 2.167365, T: 71040, Avg. loss: 0.329580\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 31.68, NNZs: 288642, Bias: 1.836040, T: 142080, Avg. loss: 0.008314\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 23.57, NNZs: 294615, Bias: 1.695948, T: 213120, Avg. loss: 0.002814\n",
      "Total training time: 0.43 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 19.19, NNZs: 296662, Bias: 1.614260, T: 284160, Avg. loss: 0.001300\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 16.24, NNZs: 297544, Bias: 1.566086, T: 355200, Avg. loss: 0.000627\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 14.41, NNZs: 298024, Bias: 1.514584, T: 426240, Avg. loss: 0.000436\n",
      "Total training time: 0.84 seconds.\n",
      "Convergence after 6 epochs took 0.87 seconds\n",
      "[CV 3/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.21123614325601048, clf__eta0=0.32979731781585486, clf__fit_intercept=True, clf__l1_ratio=0.4775095579144826, clf__learning_rate=optimal, clf__loss=perceptron, clf__max_iter=30, clf__penalty=l2, clf__power_t=0.6427671735097384, clf__shuffle=False, clf__tol=0.2651165400908262, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.882 total time= 1.2min\n",
      "-- Epoch 1\n",
      "Norm: 52.40, NNZs: 271857, Bias: 2.051437, T: 71040, Avg. loss: 0.331188\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 31.56, NNZs: 290311, Bias: 1.753057, T: 142080, Avg. loss: 0.008089\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 23.31, NNZs: 295068, Bias: 1.628370, T: 213120, Avg. loss: 0.002533\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 19.07, NNZs: 296561, Bias: 1.524994, T: 284160, Avg. loss: 0.000972\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 16.17, NNZs: 298734, Bias: 1.479962, T: 355200, Avg. loss: 0.000744\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 14.26, NNZs: 299492, Bias: 1.433886, T: 426240, Avg. loss: 0.000484\n",
      "Total training time: 0.93 seconds.\n",
      "Convergence after 6 epochs took 1.02 seconds\n",
      "[CV 4/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.21123614325601048, clf__eta0=0.32979731781585486, clf__fit_intercept=True, clf__l1_ratio=0.4775095579144826, clf__learning_rate=optimal, clf__loss=perceptron, clf__max_iter=30, clf__penalty=l2, clf__power_t=0.6427671735097384, clf__shuffle=False, clf__tol=0.2651165400908262, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.801 total time= 1.2min\n",
      "-- Epoch 1\n",
      "Norm: 51.08, NNZs: 266516, Bias: 1.949151, T: 71040, Avg. loss: 0.281550\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 31.67, NNZs: 289706, Bias: 1.653036, T: 142080, Avg. loss: 0.009114\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 22.90, NNZs: 295878, Bias: 1.585602, T: 213120, Avg. loss: 0.002334\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 18.78, NNZs: 298687, Bias: 1.492733, T: 284160, Avg. loss: 0.001395\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 16.05, NNZs: 299910, Bias: 1.430967, T: 355200, Avg. loss: 0.000680\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 13.97, NNZs: 300514, Bias: 1.395991, T: 426240, Avg. loss: 0.000360\n",
      "Total training time: 1.06 seconds.\n",
      "Convergence after 6 epochs took 1.10 seconds\n",
      "[CV 5/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.21123614325601048, clf__eta0=0.32979731781585486, clf__fit_intercept=True, clf__l1_ratio=0.4775095579144826, clf__learning_rate=optimal, clf__loss=perceptron, clf__max_iter=30, clf__penalty=l2, clf__power_t=0.6427671735097384, clf__shuffle=False, clf__tol=0.2651165400908262, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.909 total time= 1.2min\n",
      "-- Epoch 1\n",
      "Norm: 443.05, NNZs: 250, Bias: 0.000000, T: 88800, Avg. loss: 0.178299\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 529.31, NNZs: 96, Bias: 0.000000, T: 177600, Avg. loss: 0.023081\n",
      "Total training time: 0.81 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 599.36, NNZs: 84, Bias: 0.000000, T: 266400, Avg. loss: 0.021017\n",
      "Total training time: 1.18 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 651.42, NNZs: 70, Bias: 0.000000, T: 355200, Avg. loss: 0.019027\n",
      "Total training time: 1.61 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 695.45, NNZs: 66, Bias: 0.000000, T: 444000, Avg. loss: 0.017093\n",
      "Total training time: 2.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 738.77, NNZs: 58, Bias: 0.000000, T: 532800, Avg. loss: 0.016877\n",
      "Total training time: 2.42 seconds.\n",
      "Convergence after 6 epochs took 2.48 seconds\n",
      "0.9992567567567567\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          Ja       0.93      1.00      0.96       291\n",
      "         Nee       1.00      1.00      1.00     29309\n",
      "\n",
      "    accuracy                           1.00     29600\n",
      "   macro avg       0.96      1.00      0.98     29600\n",
      "weighted avg       1.00      1.00      1.00     29600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ngram 2 Stopwords kept\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1,2), lowercase=True, token_pattern=r\"(?u)\\b\\w\\w+\\b|\\+|\\-\")),\n",
    "    ('clf', SGDClassifier(early_stopping=True, n_iter_no_change=5, validation_fraction = 0.25, verbose=3)),\n",
    "])\n",
    "random_search = RandomizedSearchCV(estimator=pipeline, param_distributions=parameter_grid, random_state=500, verbose=3, scoring='f1_macro')\n",
    "random_search.fit(X_train, y_train)  \n",
    "predicted_nb = random_search.predict(X_test)\n",
    "print(np.mean(predicted_nb == y_test))\n",
    "cm = confusion_matrix(y_test, predicted_nb)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=random_search.classes_)\n",
    "disp.plot()\n",
    "\n",
    "plt.show()\n",
    "print(metrics.classification_report(y_test, predicted_nb,\n",
    "    target_names=random_search.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1d3d3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "-- Epoch 1\n",
      "Norm: 87.93, NNZs: 361, Bias: 0.000000, T: 71040, Avg. loss: 0.081515\n",
      "Total training time: 1.05 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 118.73, NNZs: 105, Bias: 0.000000, T: 142080, Avg. loss: 0.053753\n",
      "Total training time: 2.14 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 142.08, NNZs: 76, Bias: 0.000000, T: 213120, Avg. loss: 0.046827\n",
      "Total training time: 3.23 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 161.38, NNZs: 61, Bias: 0.000000, T: 284160, Avg. loss: 0.043371\n",
      "Total training time: 4.30 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 178.36, NNZs: 54, Bias: 0.000000, T: 355200, Avg. loss: 0.041255\n",
      "Total training time: 5.37 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 193.56, NNZs: 52, Bias: 0.000000, T: 426240, Avg. loss: 0.039422\n",
      "Total training time: 6.45 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 196.34, NNZs: 52, Bias: 0.000000, T: 497280, Avg. loss: 0.038820\n",
      "Total training time: 7.55 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 199.08, NNZs: 51, Bias: 0.000000, T: 568320, Avg. loss: 0.038648\n",
      "Total training time: 8.63 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 201.80, NNZs: 50, Bias: 0.000000, T: 639360, Avg. loss: 0.038451\n",
      "Total training time: 9.69 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 204.47, NNZs: 50, Bias: 0.000000, T: 710400, Avg. loss: 0.038262\n",
      "Total training time: 10.76 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 207.11, NNZs: 49, Bias: 0.000000, T: 781440, Avg. loss: 0.038038\n",
      "Total training time: 11.87 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 207.62, NNZs: 49, Bias: 0.000000, T: 852480, Avg. loss: 0.037956\n",
      "Total training time: 12.99 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 208.14, NNZs: 49, Bias: 0.000000, T: 923520, Avg. loss: 0.037924\n",
      "Total training time: 14.07 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 208.66, NNZs: 49, Bias: 0.000000, T: 994560, Avg. loss: 0.037900\n",
      "Total training time: 15.19 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 209.17, NNZs: 49, Bias: 0.000000, T: 1065600, Avg. loss: 0.037861\n",
      "Total training time: 16.31 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 209.68, NNZs: 49, Bias: 0.000000, T: 1136640, Avg. loss: 0.037842\n",
      "Total training time: 17.47 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 209.78, NNZs: 49, Bias: 0.000000, T: 1207680, Avg. loss: 0.037814\n",
      "Total training time: 18.55 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 209.89, NNZs: 49, Bias: 0.000000, T: 1278720, Avg. loss: 0.037807\n",
      "Total training time: 19.60 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 209.99, NNZs: 49, Bias: 0.000000, T: 1349760, Avg. loss: 0.037799\n",
      "Total training time: 20.69 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 210.09, NNZs: 49, Bias: 0.000000, T: 1420800, Avg. loss: 0.037794\n",
      "Total training time: 21.84 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.06171699256249541, clf__eta0=0.6666115972798587, clf__fit_intercept=False, clf__l1_ratio=0.9792901432894962, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.15075392531110676, clf__shuffle=True, clf__tol=0.365636830734297, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.211 total time= 2.4min\n",
      "-- Epoch 1\n",
      "Norm: 87.77, NNZs: 385, Bias: 0.000000, T: 71040, Avg. loss: 0.081782\n",
      "Total training time: 0.99 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 118.56, NNZs: 104, Bias: 0.000000, T: 142080, Avg. loss: 0.053818\n",
      "Total training time: 2.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 141.70, NNZs: 73, Bias: 0.000000, T: 213120, Avg. loss: 0.047138\n",
      "Total training time: 3.07 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 161.18, NNZs: 61, Bias: 0.000000, T: 284160, Avg. loss: 0.043395\n",
      "Total training time: 4.11 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 178.11, NNZs: 55, Bias: 0.000000, T: 355200, Avg. loss: 0.041037\n",
      "Total training time: 5.11 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 193.29, NNZs: 52, Bias: 0.000000, T: 426240, Avg. loss: 0.039622\n",
      "Total training time: 6.14 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 196.11, NNZs: 51, Bias: 0.000000, T: 497280, Avg. loss: 0.038788\n",
      "Total training time: 7.17 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 198.87, NNZs: 51, Bias: 0.000000, T: 568320, Avg. loss: 0.038567\n",
      "Total training time: 8.17 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 201.58, NNZs: 50, Bias: 0.000000, T: 639360, Avg. loss: 0.038375\n",
      "Total training time: 9.19 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 204.24, NNZs: 50, Bias: 0.000000, T: 710400, Avg. loss: 0.038187\n",
      "Total training time: 10.23 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 206.86, NNZs: 50, Bias: 0.000000, T: 781440, Avg. loss: 0.038042\n",
      "Total training time: 11.24 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 207.38, NNZs: 50, Bias: 0.000000, T: 852480, Avg. loss: 0.037977\n",
      "Total training time: 12.26 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 207.91, NNZs: 50, Bias: 0.000000, T: 923520, Avg. loss: 0.037932\n",
      "Total training time: 13.24 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 208.42, NNZs: 50, Bias: 0.000000, T: 994560, Avg. loss: 0.037892\n",
      "Total training time: 14.26 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 208.94, NNZs: 50, Bias: 0.000000, T: 1065600, Avg. loss: 0.037857\n",
      "Total training time: 15.29 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 209.45, NNZs: 50, Bias: 0.000000, T: 1136640, Avg. loss: 0.037833\n",
      "Total training time: 16.37 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 209.55, NNZs: 50, Bias: 0.000000, T: 1207680, Avg. loss: 0.037806\n",
      "Total training time: 17.36 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 209.66, NNZs: 50, Bias: 0.000000, T: 1278720, Avg. loss: 0.037800\n",
      "Total training time: 18.42 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 209.76, NNZs: 50, Bias: 0.000000, T: 1349760, Avg. loss: 0.037794\n",
      "Total training time: 19.50 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 209.86, NNZs: 50, Bias: 0.000000, T: 1420800, Avg. loss: 0.037787\n",
      "Total training time: 20.62 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.06171699256249541, clf__eta0=0.6666115972798587, clf__fit_intercept=False, clf__l1_ratio=0.9792901432894962, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.15075392531110676, clf__shuffle=True, clf__tol=0.365636830734297, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.210 total time= 2.2min\n",
      "-- Epoch 1\n",
      "Norm: 87.12, NNZs: 365, Bias: 0.000000, T: 71040, Avg. loss: 0.082948\n",
      "Total training time: 1.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 118.15, NNZs: 102, Bias: 0.000000, T: 142080, Avg. loss: 0.054849\n",
      "Total training time: 2.10 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 141.44, NNZs: 72, Bias: 0.000000, T: 213120, Avg. loss: 0.047613\n",
      "Total training time: 3.20 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 160.91, NNZs: 64, Bias: 0.000000, T: 284160, Avg. loss: 0.043832\n",
      "Total training time: 4.30 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 178.09, NNZs: 52, Bias: 0.000000, T: 355200, Avg. loss: 0.041437\n",
      "Total training time: 5.51 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 193.35, NNZs: 51, Bias: 0.000000, T: 426240, Avg. loss: 0.039857\n",
      "Total training time: 6.73 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 196.13, NNZs: 51, Bias: 0.000000, T: 497280, Avg. loss: 0.039003\n",
      "Total training time: 7.86 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 198.89, NNZs: 49, Bias: 0.000000, T: 568320, Avg. loss: 0.038829\n",
      "Total training time: 8.98 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 201.64, NNZs: 49, Bias: 0.000000, T: 639360, Avg. loss: 0.038607\n",
      "Total training time: 10.12 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 204.32, NNZs: 49, Bias: 0.000000, T: 710400, Avg. loss: 0.038398\n",
      "Total training time: 11.27 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 206.97, NNZs: 49, Bias: 0.000000, T: 781440, Avg. loss: 0.038192\n",
      "Total training time: 12.41 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 207.49, NNZs: 49, Bias: 0.000000, T: 852480, Avg. loss: 0.038096\n",
      "Total training time: 13.65 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 208.01, NNZs: 49, Bias: 0.000000, T: 923520, Avg. loss: 0.038062\n",
      "Total training time: 14.78 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 208.53, NNZs: 49, Bias: 0.000000, T: 994560, Avg. loss: 0.038021\n",
      "Total training time: 15.84 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 209.05, NNZs: 49, Bias: 0.000000, T: 1065600, Avg. loss: 0.037989\n",
      "Total training time: 16.98 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 209.56, NNZs: 49, Bias: 0.000000, T: 1136640, Avg. loss: 0.037959\n",
      "Total training time: 18.05 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 209.66, NNZs: 49, Bias: 0.000000, T: 1207680, Avg. loss: 0.037937\n",
      "Total training time: 19.12 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 209.77, NNZs: 49, Bias: 0.000000, T: 1278720, Avg. loss: 0.037931\n",
      "Total training time: 20.18 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 209.87, NNZs: 49, Bias: 0.000000, T: 1349760, Avg. loss: 0.037924\n",
      "Total training time: 21.28 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 209.97, NNZs: 49, Bias: 0.000000, T: 1420800, Avg. loss: 0.037920\n",
      "Total training time: 22.37 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.06171699256249541, clf__eta0=0.6666115972798587, clf__fit_intercept=False, clf__l1_ratio=0.9792901432894962, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.15075392531110676, clf__shuffle=True, clf__tol=0.365636830734297, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.210 total time= 2.3min\n",
      "-- Epoch 1\n",
      "Norm: 87.65, NNZs: 393, Bias: 0.000000, T: 71040, Avg. loss: 0.080698\n",
      "Total training time: 1.04 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 118.41, NNZs: 104, Bias: 0.000000, T: 142080, Avg. loss: 0.053364\n",
      "Total training time: 2.16 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 141.74, NNZs: 72, Bias: 0.000000, T: 213120, Avg. loss: 0.046645\n",
      "Total training time: 3.30 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 161.13, NNZs: 59, Bias: 0.000000, T: 284160, Avg. loss: 0.042705\n",
      "Total training time: 4.41 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 178.02, NNZs: 54, Bias: 0.000000, T: 355200, Avg. loss: 0.040581\n",
      "Total training time: 5.51 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 193.33, NNZs: 52, Bias: 0.000000, T: 426240, Avg. loss: 0.038954\n",
      "Total training time: 6.67 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 196.05, NNZs: 52, Bias: 0.000000, T: 497280, Avg. loss: 0.038209\n",
      "Total training time: 7.78 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 198.84, NNZs: 51, Bias: 0.000000, T: 568320, Avg. loss: 0.038059\n",
      "Total training time: 8.88 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 201.55, NNZs: 51, Bias: 0.000000, T: 639360, Avg. loss: 0.037836\n",
      "Total training time: 9.97 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 204.20, NNZs: 51, Bias: 0.000000, T: 710400, Avg. loss: 0.037667\n",
      "Total training time: 11.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 206.84, NNZs: 51, Bias: 0.000000, T: 781440, Avg. loss: 0.037527\n",
      "Total training time: 12.11 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 207.36, NNZs: 51, Bias: 0.000000, T: 852480, Avg. loss: 0.037428\n",
      "Total training time: 13.17 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 207.88, NNZs: 51, Bias: 0.000000, T: 923520, Avg. loss: 0.037374\n",
      "Total training time: 14.22 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 208.40, NNZs: 51, Bias: 0.000000, T: 994560, Avg. loss: 0.037340\n",
      "Total training time: 15.27 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 208.92, NNZs: 51, Bias: 0.000000, T: 1065600, Avg. loss: 0.037308\n",
      "Total training time: 16.37 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 209.43, NNZs: 51, Bias: 0.000000, T: 1136640, Avg. loss: 0.037277\n",
      "Total training time: 17.44 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 209.54, NNZs: 51, Bias: 0.000000, T: 1207680, Avg. loss: 0.037257\n",
      "Total training time: 18.54 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 209.64, NNZs: 51, Bias: 0.000000, T: 1278720, Avg. loss: 0.037252\n",
      "Total training time: 19.64 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 209.74, NNZs: 51, Bias: 0.000000, T: 1349760, Avg. loss: 0.037245\n",
      "Total training time: 20.75 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 209.84, NNZs: 51, Bias: 0.000000, T: 1420800, Avg. loss: 0.037239\n",
      "Total training time: 21.90 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.06171699256249541, clf__eta0=0.6666115972798587, clf__fit_intercept=False, clf__l1_ratio=0.9792901432894962, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.15075392531110676, clf__shuffle=True, clf__tol=0.365636830734297, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.210 total time= 2.3min\n",
      "-- Epoch 1\n",
      "Norm: 87.79, NNZs: 379, Bias: 0.000000, T: 71040, Avg. loss: 0.082076\n",
      "Total training time: 1.05 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 118.96, NNZs: 107, Bias: 0.000000, T: 142080, Avg. loss: 0.053905\n",
      "Total training time: 2.14 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 142.30, NNZs: 76, Bias: 0.000000, T: 213120, Avg. loss: 0.047039\n",
      "Total training time: 3.25 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 161.76, NNZs: 62, Bias: 0.000000, T: 284160, Avg. loss: 0.043332\n",
      "Total training time: 4.32 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 178.78, NNZs: 54, Bias: 0.000000, T: 355200, Avg. loss: 0.040864\n",
      "Total training time: 5.41 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 194.10, NNZs: 51, Bias: 0.000000, T: 426240, Avg. loss: 0.039401\n",
      "Total training time: 6.50 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 196.93, NNZs: 51, Bias: 0.000000, T: 497280, Avg. loss: 0.038398\n",
      "Total training time: 7.61 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 199.65, NNZs: 51, Bias: 0.000000, T: 568320, Avg. loss: 0.038232\n",
      "Total training time: 8.73 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 202.38, NNZs: 50, Bias: 0.000000, T: 639360, Avg. loss: 0.038106\n",
      "Total training time: 9.82 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 205.05, NNZs: 50, Bias: 0.000000, T: 710400, Avg. loss: 0.037920\n",
      "Total training time: 10.93 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 207.67, NNZs: 50, Bias: 0.000000, T: 781440, Avg. loss: 0.037786\n",
      "Total training time: 12.06 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 208.20, NNZs: 50, Bias: 0.000000, T: 852480, Avg. loss: 0.037705\n",
      "Total training time: 13.16 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 208.72, NNZs: 50, Bias: 0.000000, T: 923520, Avg. loss: 0.037673\n",
      "Total training time: 14.23 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 209.24, NNZs: 50, Bias: 0.000000, T: 994560, Avg. loss: 0.037634\n",
      "Total training time: 15.38 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 209.76, NNZs: 50, Bias: 0.000000, T: 1065600, Avg. loss: 0.037599\n",
      "Total training time: 16.49 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 210.27, NNZs: 50, Bias: 0.000000, T: 1136640, Avg. loss: 0.037569\n",
      "Total training time: 17.63 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 210.37, NNZs: 50, Bias: 0.000000, T: 1207680, Avg. loss: 0.037549\n",
      "Total training time: 18.75 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 210.48, NNZs: 50, Bias: 0.000000, T: 1278720, Avg. loss: 0.037545\n",
      "Total training time: 19.91 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 210.58, NNZs: 50, Bias: 0.000000, T: 1349760, Avg. loss: 0.037538\n",
      "Total training time: 21.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 210.68, NNZs: 50, Bias: 0.000000, T: 1420800, Avg. loss: 0.037532\n",
      "Total training time: 22.11 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.06171699256249541, clf__eta0=0.6666115972798587, clf__fit_intercept=False, clf__l1_ratio=0.9792901432894962, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.15075392531110676, clf__shuffle=True, clf__tol=0.365636830734297, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.207 total time= 2.3min\n",
      "-- Epoch 1\n",
      "Norm: 36.10, NNZs: 49, Bias: 0.000000, T: 71040, Avg. loss: 0.001525\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 36.71, NNZs: 46, Bias: 0.000000, T: 142080, Avg. loss: 0.001416\n",
      "Total training time: 1.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 37.04, NNZs: 46, Bias: 0.000000, T: 213120, Avg. loss: 0.001398\n",
      "Total training time: 1.50 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 37.28, NNZs: 45, Bias: 0.000000, T: 284160, Avg. loss: 0.001380\n",
      "Total training time: 1.99 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 37.46, NNZs: 45, Bias: 0.000000, T: 355200, Avg. loss: 0.001381\n",
      "Total training time: 2.47 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 37.60, NNZs: 44, Bias: 0.000000, T: 426240, Avg. loss: 0.001369\n",
      "Total training time: 2.96 seconds.\n",
      "Convergence after 6 epochs took 3.02 seconds\n",
      "[CV 1/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.7915127974877743, clf__eta0=0.05539740212799926, clf__fit_intercept=False, clf__l1_ratio=0.9152680641407671, clf__learning_rate=optimal, clf__loss=squared_epsilon_insensitive, clf__max_iter=80, clf__penalty=l1, clf__power_t=0.6359093112142983, clf__shuffle=True, clf__tol=0.9361199211609239, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.856 total time= 1.8min\n",
      "-- Epoch 1\n",
      "Norm: 109730308840585.92, NNZs: 821051, Bias: 0.000000, T: 71040, Avg. loss: 90944331665307468824576.000000\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 103627245009471.42, NNZs: 821052, Bias: 0.000000, T: 142080, Avg. loss: 103052419220873330819072.000000\n",
      "Total training time: 1.46 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 100469614079903.02, NNZs: 821052, Bias: 0.000000, T: 213120, Avg. loss: 86491020445485851738112.000000\n",
      "Total training time: 2.15 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 98375017559544.92, NNZs: 821052, Bias: 0.000000, T: 284160, Avg. loss: 78681574404137198551040.000000\n",
      "Total training time: 2.87 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 96817879808995.20, NNZs: 821052, Bias: 0.000000, T: 355200, Avg. loss: 73799762654943328075776.000000\n",
      "Total training time: 3.58 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 95583481085740.81, NNZs: 821052, Bias: 0.000000, T: 426240, Avg. loss: 70365762608907501436928.000000\n",
      "Total training time: 4.26 seconds.\n",
      "Convergence after 6 epochs took 4.32 seconds\n",
      "[CV 2/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.7915127974877743, clf__eta0=0.05539740212799926, clf__fit_intercept=False, clf__l1_ratio=0.9152680641407671, clf__learning_rate=optimal, clf__loss=squared_epsilon_insensitive, clf__max_iter=80, clf__penalty=l1, clf__power_t=0.6359093112142983, clf__shuffle=True, clf__tol=0.9361199211609239, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.347 total time= 1.9min\n",
      "-- Epoch 1\n",
      "Norm: 45.46, NNZs: 45, Bias: 0.000000, T: 71040, Avg. loss: 0.001496\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 45.93, NNZs: 45, Bias: 0.000000, T: 142080, Avg. loss: 0.001334\n",
      "Total training time: 1.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 46.20, NNZs: 45, Bias: 0.000000, T: 213120, Avg. loss: 0.001325\n",
      "Total training time: 1.51 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 46.38, NNZs: 45, Bias: 0.000000, T: 284160, Avg. loss: 0.001321\n",
      "Total training time: 2.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 46.53, NNZs: 44, Bias: 0.000000, T: 355200, Avg. loss: 0.001324\n",
      "Total training time: 2.50 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 46.64, NNZs: 44, Bias: 0.000000, T: 426240, Avg. loss: 0.001319\n",
      "Total training time: 2.98 seconds.\n",
      "Convergence after 6 epochs took 3.05 seconds\n",
      "[CV 3/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.7915127974877743, clf__eta0=0.05539740212799926, clf__fit_intercept=False, clf__l1_ratio=0.9152680641407671, clf__learning_rate=optimal, clf__loss=squared_epsilon_insensitive, clf__max_iter=80, clf__penalty=l1, clf__power_t=0.6359093112142983, clf__shuffle=True, clf__tol=0.9361199211609239, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.858 total time= 1.8min\n",
      "-- Epoch 1\n",
      "Norm: 119079486434412.25, NNZs: 820969, Bias: 0.000000, T: 71040, Avg. loss: 105221820358491176435712.000000\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 112911895565477.11, NNZs: 820969, Bias: 0.000000, T: 142080, Avg. loss: 121394137128270242512896.000000\n",
      "Total training time: 1.41 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 109708106026503.27, NNZs: 820969, Bias: 0.000000, T: 213120, Avg. loss: 102962650025507852124160.000000\n",
      "Total training time: 2.11 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 107589857381379.31, NNZs: 820969, Bias: 0.000000, T: 284160, Avg. loss: 94279132115657579036672.000000\n",
      "Total training time: 2.90 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 106015190345035.33, NNZs: 820969, Bias: 0.000000, T: 355200, Avg. loss: 88828425417042918637568.000000\n",
      "Total training time: 3.62 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 104766851667219.38, NNZs: 820969, Bias: 0.000000, T: 426240, Avg. loss: 84947098505753716064256.000000\n",
      "Total training time: 4.35 seconds.\n",
      "Convergence after 6 epochs took 4.42 seconds\n",
      "[CV 4/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.7915127974877743, clf__eta0=0.05539740212799926, clf__fit_intercept=False, clf__l1_ratio=0.9152680641407671, clf__learning_rate=optimal, clf__loss=squared_epsilon_insensitive, clf__max_iter=80, clf__penalty=l1, clf__power_t=0.6359093112142983, clf__shuffle=True, clf__tol=0.9361199211609239, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.346 total time= 1.8min\n",
      "-- Epoch 1\n",
      "Norm: 109114631062786.50, NNZs: 816973, Bias: 0.000000, T: 71040, Avg. loss: 92138079850335817433088.000000\n",
      "Total training time: 0.67 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 103112791473642.00, NNZs: 816976, Bias: 0.000000, T: 142080, Avg. loss: 101271381745987359866880.000000\n",
      "Total training time: 1.38 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 100017760439240.59, NNZs: 816976, Bias: 0.000000, T: 213120, Avg. loss: 85093311514363897577472.000000\n",
      "Total training time: 2.09 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 97960403921800.03, NNZs: 816976, Bias: 0.000000, T: 284160, Avg. loss: 77506435031240298987520.000000\n",
      "Total training time: 2.78 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 96432192576196.16, NNZs: 816976, Bias: 0.000000, T: 355200, Avg. loss: 72775266741671671365632.000000\n",
      "Total training time: 3.48 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 95225372405401.48, NNZs: 816976, Bias: 0.000000, T: 426240, Avg. loss: 69397020102792405057536.000000\n",
      "Total training time: 4.19 seconds.\n",
      "Convergence after 6 epochs took 4.26 seconds\n",
      "[CV 5/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.7915127974877743, clf__eta0=0.05539740212799926, clf__fit_intercept=False, clf__l1_ratio=0.9152680641407671, clf__learning_rate=optimal, clf__loss=squared_epsilon_insensitive, clf__max_iter=80, clf__penalty=l1, clf__power_t=0.6359093112142983, clf__shuffle=True, clf__tol=0.9361199211609239, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.342 total time= 1.8min\n",
      "-- Epoch 1\n",
      "Norm: 83.79, NNZs: 315, Bias: 0.000000, T: 71040, Avg. loss: 0.020585\n",
      "Total training time: 0.61 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 109.51, NNZs: 104, Bias: 0.000000, T: 142080, Avg. loss: 0.013085\n",
      "Total training time: 1.26 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 128.78, NNZs: 91, Bias: 0.000000, T: 213120, Avg. loss: 0.011933\n",
      "Total training time: 1.89 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 145.05, NNZs: 85, Bias: 0.000000, T: 284160, Avg. loss: 0.011373\n",
      "Total training time: 2.53 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 159.30, NNZs: 82, Bias: 0.000000, T: 355200, Avg. loss: 0.011142\n",
      "Total training time: 3.20 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 172.11, NNZs: 72, Bias: 0.000000, T: 426240, Avg. loss: 0.010978\n",
      "Total training time: 3.85 seconds.\n",
      "Convergence after 6 epochs took 3.93 seconds\n",
      "[CV 1/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.03646223783802971, clf__eta0=0.7491267567674796, clf__fit_intercept=False, clf__l1_ratio=0.775818217437024, clf__learning_rate=constant, clf__loss=squared_hinge, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.4028006727705291, clf__shuffle=True, clf__tol=0.1730703028465106, clf__warm_start=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.968 total time= 1.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 83.34, NNZs: 303, Bias: 0.000000, T: 71040, Avg. loss: 0.020455\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 108.64, NNZs: 95, Bias: 0.000000, T: 142080, Avg. loss: 0.012874\n",
      "Total training time: 1.42 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 127.75, NNZs: 86, Bias: 0.000000, T: 213120, Avg. loss: 0.011690\n",
      "Total training time: 1.99 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 143.91, NNZs: 85, Bias: 0.000000, T: 284160, Avg. loss: 0.011353\n",
      "Total training time: 2.60 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 158.11, NNZs: 72, Bias: 0.000000, T: 355200, Avg. loss: 0.011178\n",
      "Total training time: 3.14 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 170.89, NNZs: 69, Bias: 0.000000, T: 426240, Avg. loss: 0.010831\n",
      "Total training time: 3.69 seconds.\n",
      "Convergence after 6 epochs took 3.76 seconds\n",
      "[CV 2/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.03646223783802971, clf__eta0=0.7491267567674796, clf__fit_intercept=False, clf__l1_ratio=0.775818217437024, clf__learning_rate=constant, clf__loss=squared_hinge, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.4028006727705291, clf__shuffle=True, clf__tol=0.1730703028465106, clf__warm_start=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.953 total time= 1.8min\n",
      "-- Epoch 1\n",
      "Norm: 83.48, NNZs: 273, Bias: 0.000000, T: 71040, Avg. loss: 0.020385\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 108.95, NNZs: 97, Bias: 0.000000, T: 142080, Avg. loss: 0.012782\n",
      "Total training time: 1.09 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 128.14, NNZs: 89, Bias: 0.000000, T: 213120, Avg. loss: 0.011678\n",
      "Total training time: 1.67 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 144.20, NNZs: 83, Bias: 0.000000, T: 284160, Avg. loss: 0.011158\n",
      "Total training time: 2.27 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 158.30, NNZs: 75, Bias: 0.000000, T: 355200, Avg. loss: 0.010786\n",
      "Total training time: 2.88 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 171.06, NNZs: 68, Bias: 0.000000, T: 426240, Avg. loss: 0.010663\n",
      "Total training time: 3.45 seconds.\n",
      "Convergence after 6 epochs took 3.53 seconds\n",
      "[CV 3/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.03646223783802971, clf__eta0=0.7491267567674796, clf__fit_intercept=False, clf__l1_ratio=0.775818217437024, clf__learning_rate=constant, clf__loss=squared_hinge, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.4028006727705291, clf__shuffle=True, clf__tol=0.1730703028465106, clf__warm_start=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.965 total time= 1.8min\n",
      "-- Epoch 1\n",
      "Norm: 83.81, NNZs: 275, Bias: 0.000000, T: 71040, Avg. loss: 0.020873\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 109.53, NNZs: 95, Bias: 0.000000, T: 142080, Avg. loss: 0.013099\n",
      "Total training time: 1.11 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 128.78, NNZs: 88, Bias: 0.000000, T: 213120, Avg. loss: 0.011904\n",
      "Total training time: 1.64 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 144.86, NNZs: 80, Bias: 0.000000, T: 284160, Avg. loss: 0.011372\n",
      "Total training time: 2.15 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 159.07, NNZs: 75, Bias: 0.000000, T: 355200, Avg. loss: 0.011160\n",
      "Total training time: 2.69 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 172.03, NNZs: 71, Bias: 0.000000, T: 426240, Avg. loss: 0.010948\n",
      "Total training time: 3.25 seconds.\n",
      "Convergence after 6 epochs took 3.33 seconds\n",
      "[CV 4/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.03646223783802971, clf__eta0=0.7491267567674796, clf__fit_intercept=False, clf__l1_ratio=0.775818217437024, clf__learning_rate=constant, clf__loss=squared_hinge, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.4028006727705291, clf__shuffle=True, clf__tol=0.1730703028465106, clf__warm_start=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.964 total time= 1.8min\n",
      "-- Epoch 1\n",
      "Norm: 84.00, NNZs: 317, Bias: 0.000000, T: 71040, Avg. loss: 0.020946\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 109.59, NNZs: 96, Bias: 0.000000, T: 142080, Avg. loss: 0.013126\n",
      "Total training time: 1.04 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 128.94, NNZs: 84, Bias: 0.000000, T: 213120, Avg. loss: 0.011956\n",
      "Total training time: 1.58 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 145.10, NNZs: 79, Bias: 0.000000, T: 284160, Avg. loss: 0.011466\n",
      "Total training time: 2.09 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 159.37, NNZs: 76, Bias: 0.000000, T: 355200, Avg. loss: 0.011107\n",
      "Total training time: 2.61 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 172.30, NNZs: 72, Bias: 0.000000, T: 426240, Avg. loss: 0.010962\n",
      "Total training time: 3.12 seconds.\n",
      "Convergence after 6 epochs took 3.19 seconds\n",
      "[CV 5/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.03646223783802971, clf__eta0=0.7491267567674796, clf__fit_intercept=False, clf__l1_ratio=0.775818217437024, clf__learning_rate=constant, clf__loss=squared_hinge, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.4028006727705291, clf__shuffle=True, clf__tol=0.1730703028465106, clf__warm_start=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.970 total time= 1.8min\n",
      "-- Epoch 1\n",
      "Norm: 275705316883353.06, NNZs: 821726, Bias: 0.000000, T: 71040, Avg. loss: 1088345054294063263514624.000000\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 209904224323321.22, NNZs: 821060, Bias: 0.000000, T: 142080, Avg. loss: 3542908176949194333880320.000000\n",
      "Total training time: 1.50 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 272094163213819.34, NNZs: 821731, Bias: 0.000000, T: 213120, Avg. loss: 2218651024399787834212352.000000\n",
      "Total training time: 2.32 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 215898065451346.44, NNZs: 821598, Bias: 0.000000, T: 284160, Avg. loss: 3219568826332142098186240.000000\n",
      "Total training time: 3.14 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 263927552224199.69, NNZs: 821733, Bias: 0.000000, T: 355200, Avg. loss: 2368205966898438034423808.000000\n",
      "Total training time: 3.95 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 240004286951489.34, NNZs: 821682, Bias: 0.000000, T: 426240, Avg. loss: 3124344668924128301940736.000000\n",
      "Total training time: 4.77 seconds.\n",
      "Convergence after 6 epochs took 4.84 seconds\n",
      "[CV 1/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.24457156361183285, clf__eta0=0.332929742792607, clf__fit_intercept=False, clf__l1_ratio=0.920539731041378, clf__learning_rate=constant, clf__loss=squared_error, clf__max_iter=100, clf__penalty=l1, clf__power_t=0.5734177157821045, clf__shuffle=True, clf__tol=0.6492274795888617, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.338 total time= 1.8min\n",
      "-- Epoch 1\n",
      "Norm: 271399557546860.84, NNZs: 820963, Bias: 0.000000, T: 71040, Avg. loss: 1120277339172443237908480.000000\n",
      "Total training time: 0.81 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 211328189478548.16, NNZs: 820474, Bias: 0.000000, T: 142080, Avg. loss: 2947438169779338592911360.000000\n",
      "Total training time: 1.65 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 267464895147899.50, NNZs: 821016, Bias: 0.000000, T: 213120, Avg. loss: 2148212532630092341313536.000000\n",
      "Total training time: 2.47 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 229530210412688.53, NNZs: 820905, Bias: 0.000000, T: 284160, Avg. loss: 2927672215764278951542784.000000\n",
      "Total training time: 3.28 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 266384446677855.53, NNZs: 821026, Bias: 0.000000, T: 355200, Avg. loss: 2572750166336449766490112.000000\n",
      "Total training time: 4.08 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 240549336564891.47, NNZs: 820978, Bias: 0.000000, T: 426240, Avg. loss: 3256675139710046284283904.000000\n",
      "Total training time: 4.86 seconds.\n",
      "Convergence after 6 epochs took 4.92 seconds\n",
      "[CV 2/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.24457156361183285, clf__eta0=0.332929742792607, clf__fit_intercept=False, clf__l1_ratio=0.920539731041378, clf__learning_rate=constant, clf__loss=squared_error, clf__max_iter=100, clf__penalty=l1, clf__power_t=0.5734177157821045, clf__shuffle=True, clf__tol=0.6492274795888617, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.341 total time= 1.8min\n",
      "-- Epoch 1\n",
      "Norm: 272238097721302.38, NNZs: 819514, Bias: 0.000000, T: 71040, Avg. loss: 1029298246354406301761536.000000\n",
      "Total training time: 0.82 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 220295470524188.72, NNZs: 819005, Bias: 0.000000, T: 142080, Avg. loss: 3262218877001059750903808.000000\n",
      "Total training time: 1.63 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 267958185299197.66, NNZs: 819568, Bias: 0.000000, T: 213120, Avg. loss: 2214049909828433781719040.000000\n",
      "Total training time: 2.40 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 227785606772914.47, NNZs: 819439, Bias: 0.000000, T: 284160, Avg. loss: 3134270974615990090858496.000000\n",
      "Total training time: 3.16 seconds.\n",
      "-- Epoch 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 270909417622476.53, NNZs: 819577, Bias: 0.000000, T: 355200, Avg. loss: 2229194187811481223954432.000000\n",
      "Total training time: 3.97 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 232199386517852.44, NNZs: 819520, Bias: 0.000000, T: 426240, Avg. loss: 3073730996006176597999616.000000\n",
      "Total training time: 4.77 seconds.\n",
      "Convergence after 6 epochs took 4.83 seconds\n",
      "[CV 3/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.24457156361183285, clf__eta0=0.332929742792607, clf__fit_intercept=False, clf__l1_ratio=0.920539731041378, clf__learning_rate=constant, clf__loss=squared_error, clf__max_iter=100, clf__penalty=l1, clf__power_t=0.5734177157821045, clf__shuffle=True, clf__tol=0.6492274795888617, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.343 total time= 1.8min\n",
      "-- Epoch 1\n",
      "Norm: 277929644534741.78, NNZs: 820997, Bias: 0.000000, T: 71040, Avg. loss: 1170095845691375774334976.000000\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 208038697347671.12, NNZs: 820301, Bias: 0.000000, T: 142080, Avg. loss: 3367533826778858126311424.000000\n",
      "Total training time: 1.58 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 275207349525962.62, NNZs: 821001, Bias: 0.000000, T: 213120, Avg. loss: 2166830531274159377350656.000000\n",
      "Total training time: 2.40 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 217189573660173.59, NNZs: 820853, Bias: 0.000000, T: 284160, Avg. loss: 3132842263872055992647680.000000\n",
      "Total training time: 3.25 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 271684987445144.00, NNZs: 821003, Bias: 0.000000, T: 355200, Avg. loss: 2353134806025827451404288.000000\n",
      "Total training time: 4.13 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 232129027246591.34, NNZs: 820940, Bias: 0.000000, T: 426240, Avg. loss: 3168870577881101849591808.000000\n",
      "Total training time: 4.91 seconds.\n",
      "Convergence after 6 epochs took 4.97 seconds\n",
      "[CV 4/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.24457156361183285, clf__eta0=0.332929742792607, clf__fit_intercept=False, clf__l1_ratio=0.920539731041378, clf__learning_rate=constant, clf__loss=squared_error, clf__max_iter=100, clf__penalty=l1, clf__power_t=0.5734177157821045, clf__shuffle=True, clf__tol=0.6492274795888617, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.341 total time= 1.7min\n",
      "-- Epoch 1\n",
      "Norm: 281717919779217.69, NNZs: 816975, Bias: 0.000000, T: 71040, Avg. loss: 1143045923755814106955776.000000\n",
      "Total training time: 0.72 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 205196752651010.06, NNZs: 816325, Bias: 0.000000, T: 142080, Avg. loss: 3077616992361277567270912.000000\n",
      "Total training time: 1.51 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 272011290042827.56, NNZs: 816974, Bias: 0.000000, T: 213120, Avg. loss: 2278781250725539267739648.000000\n",
      "Total training time: 2.29 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 222947087362444.78, NNZs: 816792, Bias: 0.000000, T: 284160, Avg. loss: 3358962305312248198856704.000000\n",
      "Total training time: 3.06 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 264307182755598.97, NNZs: 816984, Bias: 0.000000, T: 355200, Avg. loss: 2402169577275837334421504.000000\n",
      "Total training time: 3.80 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 232785646622348.31, NNZs: 816915, Bias: 0.000000, T: 426240, Avg. loss: 3074557400289245512335360.000000\n",
      "Total training time: 4.54 seconds.\n",
      "Convergence after 6 epochs took 4.60 seconds\n",
      "[CV 5/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.24457156361183285, clf__eta0=0.332929742792607, clf__fit_intercept=False, clf__l1_ratio=0.920539731041378, clf__learning_rate=constant, clf__loss=squared_error, clf__max_iter=100, clf__penalty=l1, clf__power_t=0.5734177157821045, clf__shuffle=True, clf__tol=0.6492274795888617, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.337 total time= 1.7min\n",
      "-- Epoch 1\n",
      "Norm: 4.07, NNZs: 1461258, Bias: 0.438762, T: 71040, Avg. loss: 0.042437\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 4.10, NNZs: 1461258, Bias: 0.502049, T: 142080, Avg. loss: 0.016729\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.07, NNZs: 1461258, Bias: 0.536812, T: 213120, Avg. loss: 0.012785\n",
      "Total training time: 1.29 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.04, NNZs: 1461258, Bias: 0.560917, T: 284160, Avg. loss: 0.010898\n",
      "Total training time: 1.74 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.00, NNZs: 1461258, Bias: 0.579310, T: 355200, Avg. loss: 0.009778\n",
      "Total training time: 2.24 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.97, NNZs: 1461258, Bias: 0.594113, T: 426240, Avg. loss: 0.009032\n",
      "Total training time: 2.72 seconds.\n",
      "Convergence after 6 epochs took 2.79 seconds\n",
      "[CV 1/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.2527955528897454, clf__eta0=0.4377192284389271, clf__fit_intercept=True, clf__l1_ratio=0.6515110441465675, clf__learning_rate=invscaling, clf__loss=huber, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.47239053945705856, clf__shuffle=False, clf__tol=0.9089234089706554, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.498 total time= 1.9min\n",
      "-- Epoch 1\n",
      "Norm: 4.08, NNZs: 1461310, Bias: 0.438171, T: 71040, Avg. loss: 0.042174\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 4.11, NNZs: 1461310, Bias: 0.501115, T: 142080, Avg. loss: 0.016656\n",
      "Total training time: 0.84 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.08, NNZs: 1461310, Bias: 0.535711, T: 213120, Avg. loss: 0.012754\n",
      "Total training time: 1.29 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.05, NNZs: 1461310, Bias: 0.559707, T: 284160, Avg. loss: 0.010890\n",
      "Total training time: 1.74 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.01, NNZs: 1461310, Bias: 0.578020, T: 355200, Avg. loss: 0.009783\n",
      "Total training time: 2.19 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.98, NNZs: 1461310, Bias: 0.592765, T: 426240, Avg. loss: 0.009045\n",
      "Total training time: 2.64 seconds.\n",
      "Convergence after 6 epochs took 2.71 seconds\n",
      "[CV 2/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.2527955528897454, clf__eta0=0.4377192284389271, clf__fit_intercept=True, clf__l1_ratio=0.6515110441465675, clf__learning_rate=invscaling, clf__loss=huber, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.47239053945705856, clf__shuffle=False, clf__tol=0.9089234089706554, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.498 total time= 1.8min\n",
      "-- Epoch 1\n",
      "Norm: 4.07, NNZs: 1459910, Bias: 0.438455, T: 71040, Avg. loss: 0.042370\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 4.10, NNZs: 1459910, Bias: 0.501739, T: 142080, Avg. loss: 0.016729\n",
      "Total training time: 0.82 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.07, NNZs: 1459910, Bias: 0.536483, T: 213120, Avg. loss: 0.012792\n",
      "Total training time: 1.27 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.04, NNZs: 1459910, Bias: 0.560585, T: 284160, Avg. loss: 0.010909\n",
      "Total training time: 1.72 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.01, NNZs: 1459910, Bias: 0.578977, T: 355200, Avg. loss: 0.009790\n",
      "Total training time: 2.16 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.98, NNZs: 1459910, Bias: 0.593785, T: 426240, Avg. loss: 0.009044\n",
      "Total training time: 2.61 seconds.\n",
      "Convergence after 6 epochs took 2.67 seconds\n",
      "[CV 3/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.2527955528897454, clf__eta0=0.4377192284389271, clf__fit_intercept=True, clf__l1_ratio=0.6515110441465675, clf__learning_rate=invscaling, clf__loss=huber, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.47239053945705856, clf__shuffle=False, clf__tol=0.9089234089706554, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.498 total time= 1.7min\n",
      "-- Epoch 1\n",
      "Norm: 4.08, NNZs: 1460609, Bias: 0.437499, T: 71040, Avg. loss: 0.042187\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 4.11, NNZs: 1460609, Bias: 0.500646, T: 142080, Avg. loss: 0.016723\n",
      "Total training time: 0.90 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.08, NNZs: 1460609, Bias: 0.535391, T: 213120, Avg. loss: 0.012783\n",
      "Total training time: 1.35 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.05, NNZs: 1460609, Bias: 0.559491, T: 284160, Avg. loss: 0.010898\n",
      "Total training time: 1.81 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.02, NNZs: 1460609, Bias: 0.577877, T: 355200, Avg. loss: 0.009778\n",
      "Total training time: 2.28 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.99, NNZs: 1460609, Bias: 0.592675, T: 426240, Avg. loss: 0.009032\n",
      "Total training time: 2.75 seconds.\n",
      "Convergence after 6 epochs took 2.82 seconds\n",
      "[CV 4/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.2527955528897454, clf__eta0=0.4377192284389271, clf__fit_intercept=True, clf__l1_ratio=0.6515110441465675, clf__learning_rate=invscaling, clf__loss=huber, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.47239053945705856, clf__shuffle=False, clf__tol=0.9089234089706554, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.498 total time= 1.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 4.08, NNZs: 1453530, Bias: 0.439073, T: 71040, Avg. loss: 0.042313\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 4.11, NNZs: 1453530, Bias: 0.501973, T: 142080, Avg. loss: 0.016634\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.08, NNZs: 1453530, Bias: 0.536461, T: 213120, Avg. loss: 0.012743\n",
      "Total training time: 1.33 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.05, NNZs: 1453530, Bias: 0.560378, T: 284160, Avg. loss: 0.010880\n",
      "Total training time: 1.82 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.01, NNZs: 1453530, Bias: 0.578634, T: 355200, Avg. loss: 0.009771\n",
      "Total training time: 2.28 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.98, NNZs: 1453530, Bias: 0.593336, T: 426240, Avg. loss: 0.009032\n",
      "Total training time: 2.76 seconds.\n",
      "Convergence after 6 epochs took 2.83 seconds\n",
      "[CV 5/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.2527955528897454, clf__eta0=0.4377192284389271, clf__fit_intercept=True, clf__l1_ratio=0.6515110441465675, clf__learning_rate=invscaling, clf__loss=huber, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.47239053945705856, clf__shuffle=False, clf__tol=0.9089234089706554, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.498 total time= 1.8min\n",
      "-- Epoch 1\n",
      "Norm: 10.28, NNZs: 387308, Bias: 0.902092, T: 71040, Avg. loss: 0.019721\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 9.12, NNZs: 411673, Bias: 0.865461, T: 142080, Avg. loss: 0.006358\n",
      "Total training time: 0.91 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 8.89, NNZs: 434729, Bias: 0.846064, T: 213120, Avg. loss: 0.006051\n",
      "Total training time: 1.38 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 8.78, NNZs: 452947, Bias: 0.832593, T: 284160, Avg. loss: 0.005905\n",
      "Total training time: 1.84 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 8.74, NNZs: 465686, Bias: 0.822249, T: 355200, Avg. loss: 0.005843\n",
      "Total training time: 2.31 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 8.72, NNZs: 476696, Bias: 0.813437, T: 426240, Avg. loss: 0.005810\n",
      "Total training time: 2.76 seconds.\n",
      "Convergence after 6 epochs took 2.84 seconds\n",
      "[CV 1/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.3241670976844645, clf__eta0=0.9631840511405841, clf__fit_intercept=True, clf__l1_ratio=0.5912641309775509, clf__learning_rate=optimal, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.6710686638981408, clf__shuffle=True, clf__tol=0.09654933943827881, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.869 total time= 1.8min\n",
      "-- Epoch 1\n",
      "Norm: 10.24, NNZs: 383797, Bias: 0.887225, T: 71040, Avg. loss: 0.019979\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 9.12, NNZs: 410065, Bias: 0.852346, T: 142080, Avg. loss: 0.006339\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 8.88, NNZs: 431735, Bias: 0.836092, T: 213120, Avg. loss: 0.006077\n",
      "Total training time: 1.42 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 8.79, NNZs: 448011, Bias: 0.825722, T: 284160, Avg. loss: 0.005979\n",
      "Total training time: 1.90 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 8.75, NNZs: 461035, Bias: 0.816065, T: 355200, Avg. loss: 0.005836\n",
      "Total training time: 2.38 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 8.72, NNZs: 470189, Bias: 0.809807, T: 426240, Avg. loss: 0.005827\n",
      "Total training time: 2.83 seconds.\n",
      "Convergence after 6 epochs took 2.91 seconds\n",
      "[CV 2/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.3241670976844645, clf__eta0=0.9631840511405841, clf__fit_intercept=True, clf__l1_ratio=0.5912641309775509, clf__learning_rate=optimal, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.6710686638981408, clf__shuffle=True, clf__tol=0.09654933943827881, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.844 total time= 1.8min\n",
      "-- Epoch 1\n",
      "Norm: 10.23, NNZs: 387307, Bias: 0.893729, T: 71040, Avg. loss: 0.020384\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 9.10, NNZs: 410185, Bias: 0.857424, T: 142080, Avg. loss: 0.006428\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 8.87, NNZs: 430047, Bias: 0.839161, T: 213120, Avg. loss: 0.006172\n",
      "Total training time: 1.25 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 8.78, NNZs: 445472, Bias: 0.825427, T: 284160, Avg. loss: 0.006015\n",
      "Total training time: 1.70 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 8.73, NNZs: 456534, Bias: 0.815111, T: 355200, Avg. loss: 0.005915\n",
      "Total training time: 2.14 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 8.70, NNZs: 466011, Bias: 0.808675, T: 426240, Avg. loss: 0.005882\n",
      "Total training time: 2.61 seconds.\n",
      "Convergence after 6 epochs took 2.69 seconds\n",
      "[CV 3/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.3241670976844645, clf__eta0=0.9631840511405841, clf__fit_intercept=True, clf__l1_ratio=0.5912641309775509, clf__learning_rate=optimal, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.6710686638981408, clf__shuffle=True, clf__tol=0.09654933943827881, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.865 total time= 1.8min\n",
      "-- Epoch 1\n",
      "Norm: 10.26, NNZs: 377040, Bias: 0.875571, T: 71040, Avg. loss: 0.019779\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 9.14, NNZs: 402908, Bias: 0.842158, T: 142080, Avg. loss: 0.006297\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 8.90, NNZs: 425983, Bias: 0.819937, T: 213120, Avg. loss: 0.005977\n",
      "Total training time: 1.41 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 8.81, NNZs: 442163, Bias: 0.810167, T: 284160, Avg. loss: 0.005857\n",
      "Total training time: 1.87 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 8.76, NNZs: 454234, Bias: 0.801788, T: 355200, Avg. loss: 0.005783\n",
      "Total training time: 2.36 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 8.73, NNZs: 465173, Bias: 0.795453, T: 426240, Avg. loss: 0.005717\n",
      "Total training time: 2.88 seconds.\n",
      "Convergence after 6 epochs took 2.96 seconds\n",
      "[CV 4/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.3241670976844645, clf__eta0=0.9631840511405841, clf__fit_intercept=True, clf__l1_ratio=0.5912641309775509, clf__learning_rate=optimal, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.6710686638981408, clf__shuffle=True, clf__tol=0.09654933943827881, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.876 total time= 1.8min\n",
      "-- Epoch 1\n",
      "Norm: 10.31, NNZs: 382999, Bias: 0.886971, T: 71040, Avg. loss: 0.020700\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 9.11, NNZs: 408214, Bias: 0.856044, T: 142080, Avg. loss: 0.006544\n",
      "Total training time: 0.84 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 8.86, NNZs: 429180, Bias: 0.837585, T: 213120, Avg. loss: 0.006174\n",
      "Total training time: 1.26 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 8.76, NNZs: 444783, Bias: 0.826583, T: 284160, Avg. loss: 0.006023\n",
      "Total training time: 1.68 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 8.71, NNZs: 457515, Bias: 0.816840, T: 355200, Avg. loss: 0.005960\n",
      "Total training time: 2.08 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 8.68, NNZs: 467361, Bias: 0.810204, T: 426240, Avg. loss: 0.005907\n",
      "Total training time: 2.51 seconds.\n",
      "Convergence after 6 epochs took 2.59 seconds\n",
      "[CV 5/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.3241670976844645, clf__eta0=0.9631840511405841, clf__fit_intercept=True, clf__l1_ratio=0.5912641309775509, clf__learning_rate=optimal, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.6710686638981408, clf__shuffle=True, clf__tol=0.09654933943827881, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.871 total time= 1.8min\n",
      "-- Epoch 1\n",
      "Norm: 413.48, NNZs: 321, Bias: 0.000000, T: 71040, Avg. loss: 0.160883\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 509.39, NNZs: 130, Bias: 0.000000, T: 142080, Avg. loss: 0.036111\n",
      "Total training time: 0.81 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 582.94, NNZs: 93, Bias: 0.000000, T: 213120, Avg. loss: 0.028010\n",
      "Total training time: 1.19 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 642.17, NNZs: 73, Bias: 0.000000, T: 284160, Avg. loss: 0.024765\n",
      "Total training time: 1.56 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 690.37, NNZs: 71, Bias: 0.000000, T: 355200, Avg. loss: 0.024711\n",
      "Total training time: 1.94 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 733.39, NNZs: 65, Bias: 0.000000, T: 426240, Avg. loss: 0.025802\n",
      "Total training time: 2.31 seconds.\n",
      "Convergence after 6 epochs took 2.37 seconds\n",
      "[CV 1/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.3509613152086368, clf__eta0=0.9934401124631351, clf__fit_intercept=False, clf__l1_ratio=0.5204998682261415, clf__learning_rate=constant, clf__loss=hinge, clf__max_iter=40, clf__penalty=l1, clf__power_t=0.5098574122392232, clf__shuffle=False, clf__tol=0.5563103350645606, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.981 total time= 1.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 406.39, NNZs: 355, Bias: 0.000000, T: 71040, Avg. loss: 0.146349\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 497.53, NNZs: 121, Bias: 0.000000, T: 142080, Avg. loss: 0.032249\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 572.19, NNZs: 105, Bias: 0.000000, T: 213120, Avg. loss: 0.027586\n",
      "Total training time: 1.12 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 629.75, NNZs: 85, Bias: 0.000000, T: 284160, Avg. loss: 0.025333\n",
      "Total training time: 1.53 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 680.74, NNZs: 80, Bias: 0.000000, T: 355200, Avg. loss: 0.021923\n",
      "Total training time: 1.95 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 726.12, NNZs: 72, Bias: 0.000000, T: 426240, Avg. loss: 0.022485\n",
      "Total training time: 2.36 seconds.\n",
      "Convergence after 6 epochs took 2.42 seconds\n",
      "[CV 2/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.3509613152086368, clf__eta0=0.9934401124631351, clf__fit_intercept=False, clf__l1_ratio=0.5204998682261415, clf__learning_rate=constant, clf__loss=hinge, clf__max_iter=40, clf__penalty=l1, clf__power_t=0.5098574122392232, clf__shuffle=False, clf__tol=0.5563103350645606, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.984 total time= 1.7min\n",
      "-- Epoch 1\n",
      "Norm: 409.04, NNZs: 358, Bias: 0.000000, T: 71040, Avg. loss: 0.173489\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 497.23, NNZs: 116, Bias: 0.000000, T: 142080, Avg. loss: 0.032677\n",
      "Total training time: 0.82 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 565.56, NNZs: 95, Bias: 0.000000, T: 213120, Avg. loss: 0.024715\n",
      "Total training time: 1.20 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 622.20, NNZs: 81, Bias: 0.000000, T: 284160, Avg. loss: 0.020648\n",
      "Total training time: 1.59 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 667.94, NNZs: 73, Bias: 0.000000, T: 355200, Avg. loss: 0.018622\n",
      "Total training time: 1.99 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 706.80, NNZs: 65, Bias: 0.000000, T: 426240, Avg. loss: 0.017520\n",
      "Total training time: 2.39 seconds.\n",
      "Convergence after 6 epochs took 2.45 seconds\n",
      "[CV 3/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.3509613152086368, clf__eta0=0.9934401124631351, clf__fit_intercept=False, clf__l1_ratio=0.5204998682261415, clf__learning_rate=constant, clf__loss=hinge, clf__max_iter=40, clf__penalty=l1, clf__power_t=0.5098574122392232, clf__shuffle=False, clf__tol=0.5563103350645606, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.964 total time= 1.7min\n",
      "-- Epoch 1\n",
      "Norm: 399.51, NNZs: 326, Bias: 0.000000, T: 71040, Avg. loss: 0.154975\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 501.06, NNZs: 148, Bias: 0.000000, T: 142080, Avg. loss: 0.030147\n",
      "Total training time: 0.81 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 571.07, NNZs: 103, Bias: 0.000000, T: 213120, Avg. loss: 0.026139\n",
      "Total training time: 1.23 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 622.35, NNZs: 75, Bias: 0.000000, T: 284160, Avg. loss: 0.021643\n",
      "Total training time: 1.65 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 667.97, NNZs: 67, Bias: 0.000000, T: 355200, Avg. loss: 0.019442\n",
      "Total training time: 2.06 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 712.59, NNZs: 64, Bias: 0.000000, T: 426240, Avg. loss: 0.020055\n",
      "Total training time: 2.50 seconds.\n",
      "Convergence after 6 epochs took 2.56 seconds\n",
      "[CV 4/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.3509613152086368, clf__eta0=0.9934401124631351, clf__fit_intercept=False, clf__l1_ratio=0.5204998682261415, clf__learning_rate=constant, clf__loss=hinge, clf__max_iter=40, clf__penalty=l1, clf__power_t=0.5098574122392232, clf__shuffle=False, clf__tol=0.5563103350645606, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.978 total time= 1.7min\n",
      "-- Epoch 1\n",
      "Norm: 402.41, NNZs: 294, Bias: 0.000000, T: 71040, Avg. loss: 0.168346\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 492.23, NNZs: 128, Bias: 0.000000, T: 142080, Avg. loss: 0.031695\n",
      "Total training time: 0.82 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 566.20, NNZs: 99, Bias: 0.000000, T: 213120, Avg. loss: 0.023802\n",
      "Total training time: 1.21 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 622.85, NNZs: 86, Bias: 0.000000, T: 284160, Avg. loss: 0.022180\n",
      "Total training time: 1.59 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 668.58, NNZs: 70, Bias: 0.000000, T: 355200, Avg. loss: 0.019742\n",
      "Total training time: 1.96 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 713.47, NNZs: 66, Bias: 0.000000, T: 426240, Avg. loss: 0.019784\n",
      "Total training time: 2.35 seconds.\n",
      "Convergence after 6 epochs took 2.41 seconds\n",
      "[CV 5/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.3509613152086368, clf__eta0=0.9934401124631351, clf__fit_intercept=False, clf__l1_ratio=0.5204998682261415, clf__learning_rate=constant, clf__loss=hinge, clf__max_iter=40, clf__penalty=l1, clf__power_t=0.5098574122392232, clf__shuffle=False, clf__tol=0.5563103350645606, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.988 total time= 1.7min\n",
      "-- Epoch 1\n",
      "Norm: 1.78, NNZs: 821712, Bias: 0.000000, T: 71040, Avg. loss: 0.817249\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.92, NNZs: 821712, Bias: 0.000000, T: 142080, Avg. loss: 0.824115\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.01, NNZs: 821712, Bias: 0.000000, T: 213120, Avg. loss: 0.817987\n",
      "Total training time: 0.82 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.08, NNZs: 821712, Bias: 0.000000, T: 284160, Avg. loss: 0.809864\n",
      "Total training time: 1.10 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.14, NNZs: 821712, Bias: 0.000000, T: 355200, Avg. loss: 0.802353\n",
      "Total training time: 1.37 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.19, NNZs: 821712, Bias: 0.000000, T: 426240, Avg. loss: 0.794740\n",
      "Total training time: 1.64 seconds.\n",
      "Convergence after 6 epochs took 1.70 seconds\n",
      "[CV 1/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.28658617296069355, clf__eta0=0.03398405924608927, clf__fit_intercept=False, clf__l1_ratio=0.08227014493927165, clf__learning_rate=invscaling, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.5467473202425025, clf__shuffle=True, clf__tol=0.9099604695658384, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.445 total time= 1.7min\n",
      "-- Epoch 1\n",
      "Norm: 1.52, NNZs: 821070, Bias: 0.000000, T: 71040, Avg. loss: 0.788884\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.73, NNZs: 821070, Bias: 0.000000, T: 142080, Avg. loss: 0.822939\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.84, NNZs: 821070, Bias: 0.000000, T: 213120, Avg. loss: 0.818766\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.92, NNZs: 821070, Bias: 0.000000, T: 284160, Avg. loss: 0.811713\n",
      "Total training time: 1.07 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.98, NNZs: 821070, Bias: 0.000000, T: 355200, Avg. loss: 0.803991\n",
      "Total training time: 1.34 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.04, NNZs: 821070, Bias: 0.000000, T: 426240, Avg. loss: 0.796461\n",
      "Total training time: 1.62 seconds.\n",
      "Convergence after 6 epochs took 1.69 seconds\n",
      "[CV 2/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.28658617296069355, clf__eta0=0.03398405924608927, clf__fit_intercept=False, clf__l1_ratio=0.08227014493927165, clf__learning_rate=invscaling, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.5467473202425025, clf__shuffle=True, clf__tol=0.9099604695658384, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.442 total time= 1.7min\n",
      "-- Epoch 1\n",
      "Norm: 1.59, NNZs: 819571, Bias: 0.000000, T: 71040, Avg. loss: 0.804189\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.78, NNZs: 819571, Bias: 0.000000, T: 142080, Avg. loss: 0.825277\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.89, NNZs: 819571, Bias: 0.000000, T: 213120, Avg. loss: 0.819856\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.96, NNZs: 819571, Bias: 0.000000, T: 284160, Avg. loss: 0.812644\n",
      "Total training time: 1.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.02, NNZs: 819571, Bias: 0.000000, T: 355200, Avg. loss: 0.804275\n",
      "Total training time: 1.28 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.07, NNZs: 819571, Bias: 0.000000, T: 426240, Avg. loss: 0.796258\n",
      "Total training time: 1.55 seconds.\n",
      "Convergence after 6 epochs took 1.61 seconds\n",
      "[CV 3/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.28658617296069355, clf__eta0=0.03398405924608927, clf__fit_intercept=False, clf__l1_ratio=0.08227014493927165, clf__learning_rate=invscaling, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.5467473202425025, clf__shuffle=True, clf__tol=0.9099604695658384, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.450 total time= 1.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 1.56, NNZs: 820953, Bias: 0.000000, T: 71040, Avg. loss: 0.797298\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.76, NNZs: 820953, Bias: 0.000000, T: 142080, Avg. loss: 0.824577\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.86, NNZs: 820953, Bias: 0.000000, T: 213120, Avg. loss: 0.819372\n",
      "Total training time: 0.72 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.94, NNZs: 820953, Bias: 0.000000, T: 284160, Avg. loss: 0.810775\n",
      "Total training time: 0.98 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.01, NNZs: 820953, Bias: 0.000000, T: 355200, Avg. loss: 0.804232\n",
      "Total training time: 1.24 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.06, NNZs: 820953, Bias: 0.000000, T: 426240, Avg. loss: 0.795612\n",
      "Total training time: 1.50 seconds.\n",
      "Convergence after 6 epochs took 1.56 seconds\n",
      "[CV 4/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.28658617296069355, clf__eta0=0.03398405924608927, clf__fit_intercept=False, clf__l1_ratio=0.08227014493927165, clf__learning_rate=invscaling, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.5467473202425025, clf__shuffle=True, clf__tol=0.9099604695658384, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.451 total time= 1.7min\n",
      "-- Epoch 1\n",
      "Norm: 1.69, NNZs: 816973, Bias: 0.000000, T: 71040, Avg. loss: 0.808274\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.85, NNZs: 816973, Bias: 0.000000, T: 142080, Avg. loss: 0.831904\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.93, NNZs: 816973, Bias: 0.000000, T: 213120, Avg. loss: 0.823247\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.00, NNZs: 816973, Bias: 0.000000, T: 284160, Avg. loss: 0.815333\n",
      "Total training time: 1.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.05, NNZs: 816973, Bias: 0.000000, T: 355200, Avg. loss: 0.806973\n",
      "Total training time: 1.30 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.11, NNZs: 816973, Bias: 0.000000, T: 426240, Avg. loss: 0.798508\n",
      "Total training time: 1.56 seconds.\n",
      "Convergence after 6 epochs took 1.62 seconds\n",
      "[CV 5/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.28658617296069355, clf__eta0=0.03398405924608927, clf__fit_intercept=False, clf__l1_ratio=0.08227014493927165, clf__learning_rate=invscaling, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.5467473202425025, clf__shuffle=True, clf__tol=0.9099604695658384, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.442 total time= 1.7min\n",
      "-- Epoch 1\n",
      "Norm: 67.76, NNZs: 821702, Bias: 0.000000, T: 71040, Avg. loss: 0.270458\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 66.93, NNZs: 821702, Bias: 0.000000, T: 142080, Avg. loss: 0.232254\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 66.95, NNZs: 821702, Bias: 0.000000, T: 213120, Avg. loss: 0.232468\n",
      "Total training time: 1.08 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 66.95, NNZs: 821702, Bias: 0.000000, T: 284160, Avg. loss: 0.232470\n",
      "Total training time: 1.45 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 66.95, NNZs: 821702, Bias: 0.000000, T: 355200, Avg. loss: 0.232470\n",
      "Total training time: 1.87 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 66.95, NNZs: 821702, Bias: 0.000000, T: 426240, Avg. loss: 0.232470\n",
      "Total training time: 2.24 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 48.44, NNZs: 821702, Bias: 0.000000, T: 497280, Avg. loss: 0.181003\n",
      "Total training time: 2.62 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 46.18, NNZs: 821702, Bias: 0.000000, T: 568320, Avg. loss: 0.179015\n",
      "Total training time: 2.98 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 46.09, NNZs: 821702, Bias: 0.000000, T: 639360, Avg. loss: 0.180152\n",
      "Total training time: 3.33 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 46.08, NNZs: 821702, Bias: 0.000000, T: 710400, Avg. loss: 0.180415\n",
      "Total training time: 3.70 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 46.08, NNZs: 821702, Bias: 0.000000, T: 781440, Avg. loss: 0.180405\n",
      "Total training time: 4.05 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 45.20, NNZs: 821702, Bias: 0.000000, T: 852480, Avg. loss: 0.166093\n",
      "Total training time: 4.40 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 44.56, NNZs: 821702, Bias: 0.000000, T: 923520, Avg. loss: 0.165173\n",
      "Total training time: 4.75 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 44.16, NNZs: 821702, Bias: 0.000000, T: 994560, Avg. loss: 0.166338\n",
      "Total training time: 5.12 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 43.90, NNZs: 821702, Bias: 0.000000, T: 1065600, Avg. loss: 0.167460\n",
      "Total training time: 5.48 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 43.73, NNZs: 821702, Bias: 0.000000, T: 1136640, Avg. loss: 0.168280\n",
      "Total training time: 5.85 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 43.70, NNZs: 821702, Bias: 0.000000, T: 1207680, Avg. loss: 0.163467\n",
      "Total training time: 6.23 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 43.64, NNZs: 821702, Bias: 0.000000, T: 1278720, Avg. loss: 0.165626\n",
      "Total training time: 6.60 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 43.60, NNZs: 821702, Bias: 0.000000, T: 1349760, Avg. loss: 0.165698\n",
      "Total training time: 6.97 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 43.55, NNZs: 821702, Bias: 0.000000, T: 1420800, Avg. loss: 0.165748\n",
      "Total training time: 7.35 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.42493015701647596, clf__eta0=0.6773009699604285, clf__fit_intercept=False, clf__l1_ratio=0.7301998277223162, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.017782879504616322, clf__shuffle=False, clf__tol=0.19519881462597577, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.709 total time= 1.8min\n",
      "-- Epoch 1\n",
      "Norm: 68.66, NNZs: 821062, Bias: 0.000000, T: 71040, Avg. loss: 0.272687\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 67.75, NNZs: 821062, Bias: 0.000000, T: 142080, Avg. loss: 0.237687\n",
      "Total training time: 0.72 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 67.77, NNZs: 821062, Bias: 0.000000, T: 213120, Avg. loss: 0.237843\n",
      "Total training time: 1.09 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 67.77, NNZs: 821062, Bias: 0.000000, T: 284160, Avg. loss: 0.237842\n",
      "Total training time: 1.44 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 67.77, NNZs: 821062, Bias: 0.000000, T: 355200, Avg. loss: 0.237842\n",
      "Total training time: 1.85 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 67.77, NNZs: 821062, Bias: 0.000000, T: 426240, Avg. loss: 0.237842\n",
      "Total training time: 2.21 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 48.61, NNZs: 821062, Bias: 0.000000, T: 497280, Avg. loss: 0.180510\n",
      "Total training time: 2.58 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 46.15, NNZs: 821062, Bias: 0.000000, T: 568320, Avg. loss: 0.178072\n",
      "Total training time: 2.95 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 45.98, NNZs: 821062, Bias: 0.000000, T: 639360, Avg. loss: 0.179754\n",
      "Total training time: 3.34 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 45.97, NNZs: 821062, Bias: 0.000000, T: 710400, Avg. loss: 0.180125\n",
      "Total training time: 3.72 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 45.97, NNZs: 821062, Bias: 0.000000, T: 781440, Avg. loss: 0.180122\n",
      "Total training time: 4.07 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 45.08, NNZs: 821062, Bias: 0.000000, T: 852480, Avg. loss: 0.166476\n",
      "Total training time: 4.44 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 44.46, NNZs: 821062, Bias: 0.000000, T: 923520, Avg. loss: 0.164788\n",
      "Total training time: 4.81 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 44.06, NNZs: 821062, Bias: 0.000000, T: 994560, Avg. loss: 0.165918\n",
      "Total training time: 5.19 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 43.81, NNZs: 821062, Bias: 0.000000, T: 1065600, Avg. loss: 0.166992\n",
      "Total training time: 5.56 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 43.65, NNZs: 821062, Bias: 0.000000, T: 1136640, Avg. loss: 0.167768\n",
      "Total training time: 5.95 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 43.61, NNZs: 821062, Bias: 0.000000, T: 1207680, Avg. loss: 0.163546\n",
      "Total training time: 6.34 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 43.56, NNZs: 821062, Bias: 0.000000, T: 1278720, Avg. loss: 0.164942\n",
      "Total training time: 6.75 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 43.51, NNZs: 821062, Bias: 0.000000, T: 1349760, Avg. loss: 0.165023\n",
      "Total training time: 7.13 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 43.46, NNZs: 821062, Bias: 0.000000, T: 1420800, Avg. loss: 0.165099\n",
      "Total training time: 7.52 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.42493015701647596, clf__eta0=0.6773009699604285, clf__fit_intercept=False, clf__l1_ratio=0.7301998277223162, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.017782879504616322, clf__shuffle=False, clf__tol=0.19519881462597577, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.705 total time= 1.8min\n",
      "-- Epoch 1\n",
      "Norm: 69.55, NNZs: 819571, Bias: 0.000000, T: 71040, Avg. loss: 0.275933\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 68.48, NNZs: 819571, Bias: 0.000000, T: 142080, Avg. loss: 0.237503\n",
      "Total training time: 0.82 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 68.50, NNZs: 819571, Bias: 0.000000, T: 213120, Avg. loss: 0.237879\n",
      "Total training time: 1.21 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 68.50, NNZs: 819571, Bias: 0.000000, T: 284160, Avg. loss: 0.237868\n",
      "Total training time: 1.62 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 68.50, NNZs: 819571, Bias: 0.000000, T: 355200, Avg. loss: 0.237869\n",
      "Total training time: 2.07 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 68.50, NNZs: 819571, Bias: 0.000000, T: 426240, Avg. loss: 0.237869\n",
      "Total training time: 2.52 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 49.13, NNZs: 819571, Bias: 0.000000, T: 497280, Avg. loss: 0.182050\n",
      "Total training time: 2.89 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 46.62, NNZs: 819571, Bias: 0.000000, T: 568320, Avg. loss: 0.179760\n",
      "Total training time: 3.27 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 46.49, NNZs: 819571, Bias: 0.000000, T: 639360, Avg. loss: 0.181752\n",
      "Total training time: 3.66 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 46.48, NNZs: 819571, Bias: 0.000000, T: 710400, Avg. loss: 0.182051\n",
      "Total training time: 4.07 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 46.49, NNZs: 819571, Bias: 0.000000, T: 781440, Avg. loss: 0.182060\n",
      "Total training time: 4.47 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 45.53, NNZs: 819571, Bias: 0.000000, T: 852480, Avg. loss: 0.166026\n",
      "Total training time: 4.87 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 44.85, NNZs: 819571, Bias: 0.000000, T: 923520, Avg. loss: 0.165633\n",
      "Total training time: 5.27 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 44.42, NNZs: 819571, Bias: 0.000000, T: 994560, Avg. loss: 0.167164\n",
      "Total training time: 5.67 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 44.15, NNZs: 819571, Bias: 0.000000, T: 1065600, Avg. loss: 0.168465\n",
      "Total training time: 6.05 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 43.97, NNZs: 819571, Bias: 0.000000, T: 1136640, Avg. loss: 0.169371\n",
      "Total training time: 6.45 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 43.92, NNZs: 819571, Bias: 0.000000, T: 1207680, Avg. loss: 0.166747\n",
      "Total training time: 6.87 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 43.87, NNZs: 819571, Bias: 0.000000, T: 1278720, Avg. loss: 0.166782\n",
      "Total training time: 7.27 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 43.82, NNZs: 819571, Bias: 0.000000, T: 1349760, Avg. loss: 0.166718\n",
      "Total training time: 7.63 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 43.77, NNZs: 819571, Bias: 0.000000, T: 1420800, Avg. loss: 0.166732\n",
      "Total training time: 8.01 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.42493015701647596, clf__eta0=0.6773009699604285, clf__fit_intercept=False, clf__l1_ratio=0.7301998277223162, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.017782879504616322, clf__shuffle=False, clf__tol=0.19519881462597577, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.720 total time= 1.8min\n",
      "-- Epoch 1\n",
      "Norm: 69.56, NNZs: 820976, Bias: 0.000000, T: 71040, Avg. loss: 0.271677\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 68.57, NNZs: 820976, Bias: 0.000000, T: 142080, Avg. loss: 0.236088\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 68.59, NNZs: 820976, Bias: 0.000000, T: 213120, Avg. loss: 0.236373\n",
      "Total training time: 1.16 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 68.59, NNZs: 820976, Bias: 0.000000, T: 284160, Avg. loss: 0.236365\n",
      "Total training time: 1.56 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 68.59, NNZs: 820976, Bias: 0.000000, T: 355200, Avg. loss: 0.236365\n",
      "Total training time: 2.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 68.59, NNZs: 820976, Bias: 0.000000, T: 426240, Avg. loss: 0.236365\n",
      "Total training time: 2.41 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 49.11, NNZs: 820976, Bias: 0.000000, T: 497280, Avg. loss: 0.178583\n",
      "Total training time: 2.79 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 46.67, NNZs: 820976, Bias: 0.000000, T: 568320, Avg. loss: 0.179027\n",
      "Total training time: 3.18 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 46.54, NNZs: 820976, Bias: 0.000000, T: 639360, Avg. loss: 0.180850\n",
      "Total training time: 3.56 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 46.53, NNZs: 820976, Bias: 0.000000, T: 710400, Avg. loss: 0.181137\n",
      "Total training time: 3.96 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 46.54, NNZs: 820976, Bias: 0.000000, T: 781440, Avg. loss: 0.181135\n",
      "Total training time: 4.38 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 45.61, NNZs: 820976, Bias: 0.000000, T: 852480, Avg. loss: 0.165460\n",
      "Total training time: 4.80 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 44.93, NNZs: 820976, Bias: 0.000000, T: 923520, Avg. loss: 0.164584\n",
      "Total training time: 5.27 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 44.49, NNZs: 820976, Bias: 0.000000, T: 994560, Avg. loss: 0.166201\n",
      "Total training time: 5.67 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 44.21, NNZs: 820976, Bias: 0.000000, T: 1065600, Avg. loss: 0.167594\n",
      "Total training time: 6.08 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 44.03, NNZs: 820976, Bias: 0.000000, T: 1136640, Avg. loss: 0.168563\n",
      "Total training time: 6.49 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 43.98, NNZs: 820976, Bias: 0.000000, T: 1207680, Avg. loss: 0.165211\n",
      "Total training time: 6.91 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 43.93, NNZs: 820976, Bias: 0.000000, T: 1278720, Avg. loss: 0.166004\n",
      "Total training time: 7.38 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 43.88, NNZs: 820976, Bias: 0.000000, T: 1349760, Avg. loss: 0.165947\n",
      "Total training time: 7.79 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 43.83, NNZs: 820976, Bias: 0.000000, T: 1420800, Avg. loss: 0.165951\n",
      "Total training time: 8.25 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.42493015701647596, clf__eta0=0.6773009699604285, clf__fit_intercept=False, clf__l1_ratio=0.7301998277223162, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.017782879504616322, clf__shuffle=False, clf__tol=0.19519881462597577, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.729 total time= 1.8min\n",
      "-- Epoch 1\n",
      "Norm: 74.61, NNZs: 816977, Bias: 0.000000, T: 71040, Avg. loss: 0.275827\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 73.75, NNZs: 816977, Bias: 0.000000, T: 142080, Avg. loss: 0.241947\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 73.77, NNZs: 816977, Bias: 0.000000, T: 213120, Avg. loss: 0.242162\n",
      "Total training time: 1.13 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 73.77, NNZs: 816977, Bias: 0.000000, T: 284160, Avg. loss: 0.242157\n",
      "Total training time: 1.50 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 73.77, NNZs: 816977, Bias: 0.000000, T: 355200, Avg. loss: 0.242157\n",
      "Total training time: 1.92 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 73.77, NNZs: 816977, Bias: 0.000000, T: 426240, Avg. loss: 0.242157\n",
      "Total training time: 2.35 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 50.29, NNZs: 816977, Bias: 0.000000, T: 497280, Avg. loss: 0.197586\n",
      "Total training time: 2.74 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 47.13, NNZs: 816977, Bias: 0.000000, T: 568320, Avg. loss: 0.182966\n",
      "Total training time: 3.13 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 46.92, NNZs: 816977, Bias: 0.000000, T: 639360, Avg. loss: 0.184023\n",
      "Total training time: 3.53 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 46.90, NNZs: 816977, Bias: 0.000000, T: 710400, Avg. loss: 0.184430\n",
      "Total training time: 3.92 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 46.90, NNZs: 816977, Bias: 0.000000, T: 781440, Avg. loss: 0.184516\n",
      "Total training time: 4.29 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 45.82, NNZs: 816977, Bias: 0.000000, T: 852480, Avg. loss: 0.176000\n",
      "Total training time: 4.72 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 45.13, NNZs: 816977, Bias: 0.000000, T: 923520, Avg. loss: 0.168113\n",
      "Total training time: 5.16 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 44.67, NNZs: 816977, Bias: 0.000000, T: 994560, Avg. loss: 0.169510\n",
      "Total training time: 5.60 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 44.39, NNZs: 816977, Bias: 0.000000, T: 1065600, Avg. loss: 0.170824\n",
      "Total training time: 6.03 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 44.20, NNZs: 816977, Bias: 0.000000, T: 1136640, Avg. loss: 0.171757\n",
      "Total training time: 6.45 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 44.13, NNZs: 816977, Bias: 0.000000, T: 1207680, Avg. loss: 0.171960\n",
      "Total training time: 6.83 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 44.07, NNZs: 816977, Bias: 0.000000, T: 1278720, Avg. loss: 0.168978\n",
      "Total training time: 7.24 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 44.02, NNZs: 816977, Bias: 0.000000, T: 1349760, Avg. loss: 0.168868\n",
      "Total training time: 7.62 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 43.97, NNZs: 816977, Bias: 0.000000, T: 1420800, Avg. loss: 0.168931\n",
      "Total training time: 8.06 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.42493015701647596, clf__eta0=0.6773009699604285, clf__fit_intercept=False, clf__l1_ratio=0.7301998277223162, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.017782879504616322, clf__shuffle=False, clf__tol=0.19519881462597577, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.727 total time= 1.8min\n",
      "-- Epoch 1\n",
      "Norm: 49.14, NNZs: 448212, Bias: 1.527304, T: 71040, Avg. loss: 0.264427\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 28.16, NNZs: 483564, Bias: 1.410684, T: 142080, Avg. loss: 0.005034\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 21.32, NNZs: 492753, Bias: 1.237508, T: 213120, Avg. loss: 0.001974\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 17.05, NNZs: 496780, Bias: 1.184182, T: 284160, Avg. loss: 0.001206\n",
      "Total training time: 0.91 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 14.46, NNZs: 498898, Bias: 1.131194, T: 355200, Avg. loss: 0.000437\n",
      "Total training time: 1.12 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 12.54, NNZs: 500446, Bias: 1.102851, T: 426240, Avg. loss: 0.000254\n",
      "Total training time: 1.32 seconds.\n",
      "Convergence after 6 epochs took 1.38 seconds\n",
      "[CV 1/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.21123614325601048, clf__eta0=0.32979731781585486, clf__fit_intercept=True, clf__l1_ratio=0.4775095579144826, clf__learning_rate=optimal, clf__loss=perceptron, clf__max_iter=30, clf__penalty=l2, clf__power_t=0.6427671735097384, clf__shuffle=False, clf__tol=0.2651165400908262, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.930 total time= 1.8min\n",
      "-- Epoch 1\n",
      "Norm: 50.15, NNZs: 448625, Bias: 2.040958, T: 71040, Avg. loss: 0.247522\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 30.18, NNZs: 483512, Bias: 1.782924, T: 142080, Avg. loss: 0.007173\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 22.65, NNZs: 491766, Bias: 1.609283, T: 213120, Avg. loss: 0.001529\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 18.10, NNZs: 494784, Bias: 1.546779, T: 284160, Avg. loss: 0.000771\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 15.46, NNZs: 496641, Bias: 1.487110, T: 355200, Avg. loss: 0.000507\n",
      "Total training time: 0.99 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 13.68, NNZs: 497283, Bias: 1.435324, T: 426240, Avg. loss: 0.000247\n",
      "Total training time: 1.21 seconds.\n",
      "Convergence after 6 epochs took 1.27 seconds\n",
      "[CV 2/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.21123614325601048, clf__eta0=0.32979731781585486, clf__fit_intercept=True, clf__l1_ratio=0.4775095579144826, clf__learning_rate=optimal, clf__loss=perceptron, clf__max_iter=30, clf__penalty=l2, clf__power_t=0.6427671735097384, clf__shuffle=False, clf__tol=0.2651165400908262, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.899 total time= 1.7min\n",
      "-- Epoch 1\n",
      "Norm: 52.50, NNZs: 471960, Bias: 1.646322, T: 71040, Avg. loss: 0.284167\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 30.65, NNZs: 504123, Bias: 1.436998, T: 142080, Avg. loss: 0.004927\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 21.63, NNZs: 507060, Bias: 1.375283, T: 213120, Avg. loss: 0.000959\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 17.65, NNZs: 509731, Bias: 1.272020, T: 284160, Avg. loss: 0.000597\n",
      "Total training time: 0.85 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 14.81, NNZs: 511840, Bias: 1.235252, T: 355200, Avg. loss: 0.000416\n",
      "Total training time: 1.06 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 12.90, NNZs: 513876, Bias: 1.198371, T: 426240, Avg. loss: 0.000186\n",
      "Total training time: 1.26 seconds.\n",
      "Convergence after 6 epochs took 1.32 seconds\n",
      "[CV 3/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.21123614325601048, clf__eta0=0.32979731781585486, clf__fit_intercept=True, clf__l1_ratio=0.4775095579144826, clf__learning_rate=optimal, clf__loss=perceptron, clf__max_iter=30, clf__penalty=l2, clf__power_t=0.6427671735097384, clf__shuffle=False, clf__tol=0.2651165400908262, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.899 total time= 1.7min\n",
      "-- Epoch 1\n",
      "Norm: 50.19, NNZs: 455007, Bias: 1.659650, T: 71040, Avg. loss: 0.262479\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 29.26, NNZs: 494168, Bias: 1.483391, T: 142080, Avg. loss: 0.005189\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 21.54, NNZs: 503562, Bias: 1.365434, T: 213120, Avg. loss: 0.001671\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 17.73, NNZs: 511483, Bias: 1.266844, T: 284160, Avg. loss: 0.000957\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 14.81, NNZs: 514854, Bias: 1.231628, T: 355200, Avg. loss: 0.000429\n",
      "Total training time: 0.98 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 13.12, NNZs: 516137, Bias: 1.180903, T: 426240, Avg. loss: 0.000283\n",
      "Total training time: 1.19 seconds.\n",
      "Convergence after 6 epochs took 1.25 seconds\n",
      "[CV 4/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.21123614325601048, clf__eta0=0.32979731781585486, clf__fit_intercept=True, clf__l1_ratio=0.4775095579144826, clf__learning_rate=optimal, clf__loss=perceptron, clf__max_iter=30, clf__penalty=l2, clf__power_t=0.6427671735097384, clf__shuffle=False, clf__tol=0.2651165400908262, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.884 total time= 1.7min\n",
      "-- Epoch 1\n",
      "Norm: 48.21, NNZs: 448935, Bias: 1.615566, T: 71040, Avg. loss: 0.221896\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 28.74, NNZs: 478076, Bias: 1.338374, T: 142080, Avg. loss: 0.004819\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 21.45, NNZs: 488569, Bias: 1.213109, T: 213120, Avg. loss: 0.001871\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 16.90, NNZs: 491115, Bias: 1.179229, T: 284160, Avg. loss: 0.000589\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 14.13, NNZs: 493789, Bias: 1.148838, T: 355200, Avg. loss: 0.000489\n",
      "Total training time: 0.97 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 12.67, NNZs: 494702, Bias: 1.087289, T: 426240, Avg. loss: 0.000225\n",
      "Total training time: 1.17 seconds.\n",
      "Convergence after 6 epochs took 1.23 seconds\n",
      "[CV 5/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.21123614325601048, clf__eta0=0.32979731781585486, clf__fit_intercept=True, clf__l1_ratio=0.4775095579144826, clf__learning_rate=optimal, clf__loss=perceptron, clf__max_iter=30, clf__penalty=l2, clf__power_t=0.6427671735097384, clf__shuffle=False, clf__tol=0.2651165400908262, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.687 total time= 1.7min\n",
      "-- Epoch 1\n",
      "Norm: 437.95, NNZs: 203, Bias: 0.000000, T: 88800, Avg. loss: 0.122668\n",
      "Total training time: 0.56 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 551.11, NNZs: 97, Bias: 0.000000, T: 177600, Avg. loss: 0.030314\n",
      "Total training time: 1.20 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 627.72, NNZs: 78, Bias: 0.000000, T: 266400, Avg. loss: 0.023311\n",
      "Total training time: 1.85 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 686.11, NNZs: 66, Bias: 0.000000, T: 355200, Avg. loss: 0.020205\n",
      "Total training time: 2.50 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 741.71, NNZs: 67, Bias: 0.000000, T: 444000, Avg. loss: 0.020461\n",
      "Total training time: 3.12 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 788.11, NNZs: 58, Bias: 0.000000, T: 532800, Avg. loss: 0.019217\n",
      "Total training time: 3.77 seconds.\n",
      "Convergence after 6 epochs took 3.85 seconds\n",
      "0.999054054054054\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          Ja       0.91      1.00      0.95       291\n",
      "         Nee       1.00      1.00      1.00     29309\n",
      "\n",
      "    accuracy                           1.00     29600\n",
      "   macro avg       0.96      1.00      0.98     29600\n",
      "weighted avg       1.00      1.00      1.00     29600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ngram 3 Stopwords kept\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1,3), lowercase=True, token_pattern=r\"(?u)\\b\\w\\w+\\b|\\+|\\-\")),\n",
    "    ('clf', SGDClassifier(early_stopping=True, n_iter_no_change=5, validation_fraction = 0.25, verbose=3)),\n",
    "])\n",
    "random_search = RandomizedSearchCV(estimator=pipeline, param_distributions=parameter_grid, random_state=500, verbose=3, scoring='f1_macro')\n",
    "random_search.fit(X_train, y_train)  \n",
    "predicted_nb = random_search.predict(X_test)\n",
    "print(np.mean(predicted_nb == y_test))\n",
    "cm = confusion_matrix(y_test, predicted_nb)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=random_search.classes_)\n",
    "disp.plot()\n",
    "\n",
    "plt.show()\n",
    "print(metrics.classification_report(y_test, predicted_nb,\n",
    "    target_names=random_search.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf9ef15",
   "metadata": {},
   "source": [
    "# Only negation stopwords kept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81d5b7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_stopwords = lambda x: ' '.join([item for item in x.split() if item not in full_stopwords])\n",
    "less_stopwords = lambda x: ' '.join([item for item in x.split() if item not in filtered_stopwords])\n",
    "\n",
    "Corpus[\"text\"] = Corpus[\"text\"].apply(less_stopwords)\n",
    "X_train, X_test, y_train, y_test = train_test_split(Corpus['text'], Corpus['label'], test_size=0.2, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23369cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "-- Epoch 1\n",
      "Norm: 86.64, NNZs: 265, Bias: 0.000000, T: 71040, Avg. loss: 0.076358\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 115.81, NNZs: 109, Bias: 0.000000, T: 142080, Avg. loss: 0.051820\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 138.17, NNZs: 86, Bias: 0.000000, T: 213120, Avg. loss: 0.045733\n",
      "Total training time: 1.34 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 156.75, NNZs: 69, Bias: 0.000000, T: 284160, Avg. loss: 0.043109\n",
      "Total training time: 1.77 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 172.96, NNZs: 61, Bias: 0.000000, T: 355200, Avg. loss: 0.040795\n",
      "Total training time: 2.21 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 187.40, NNZs: 58, Bias: 0.000000, T: 426240, Avg. loss: 0.039478\n",
      "Total training time: 2.65 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 190.11, NNZs: 55, Bias: 0.000000, T: 497280, Avg. loss: 0.038851\n",
      "Total training time: 3.10 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 192.76, NNZs: 54, Bias: 0.000000, T: 568320, Avg. loss: 0.038567\n",
      "Total training time: 3.55 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 195.33, NNZs: 53, Bias: 0.000000, T: 639360, Avg. loss: 0.038266\n",
      "Total training time: 3.99 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 197.88, NNZs: 52, Bias: 0.000000, T: 710400, Avg. loss: 0.038073\n",
      "Total training time: 4.45 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 200.39, NNZs: 51, Bias: 0.000000, T: 781440, Avg. loss: 0.037881\n",
      "Total training time: 4.90 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 200.88, NNZs: 51, Bias: 0.000000, T: 852480, Avg. loss: 0.037719\n",
      "Total training time: 5.35 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 201.36, NNZs: 51, Bias: 0.000000, T: 923520, Avg. loss: 0.037685\n",
      "Total training time: 5.81 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 201.85, NNZs: 51, Bias: 0.000000, T: 994560, Avg. loss: 0.037650\n",
      "Total training time: 6.25 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 202.34, NNZs: 51, Bias: 0.000000, T: 1065600, Avg. loss: 0.037620\n",
      "Total training time: 6.69 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 202.84, NNZs: 50, Bias: 0.000000, T: 1136640, Avg. loss: 0.037586\n",
      "Total training time: 7.13 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 202.93, NNZs: 50, Bias: 0.000000, T: 1207680, Avg. loss: 0.037551\n",
      "Total training time: 7.56 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 203.03, NNZs: 50, Bias: 0.000000, T: 1278720, Avg. loss: 0.037546\n",
      "Total training time: 8.02 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 203.13, NNZs: 50, Bias: 0.000000, T: 1349760, Avg. loss: 0.037537\n",
      "Total training time: 8.48 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 203.22, NNZs: 50, Bias: 0.000000, T: 1420800, Avg. loss: 0.037528\n",
      "Total training time: 8.93 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.06171699256249541, clf__eta0=0.6666115972798587, clf__fit_intercept=False, clf__l1_ratio=0.9792901432894962, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.15075392531110676, clf__shuffle=True, clf__tol=0.365636830734297, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.217 total time=  59.1s\n",
      "-- Epoch 1\n",
      "Norm: 86.68, NNZs: 284, Bias: 0.000000, T: 71040, Avg. loss: 0.076620\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 116.37, NNZs: 111, Bias: 0.000000, T: 142080, Avg. loss: 0.051610\n",
      "Total training time: 0.93 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 138.95, NNZs: 83, Bias: 0.000000, T: 213120, Avg. loss: 0.045762\n",
      "Total training time: 1.40 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 157.70, NNZs: 69, Bias: 0.000000, T: 284160, Avg. loss: 0.042451\n",
      "Total training time: 1.86 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 174.11, NNZs: 62, Bias: 0.000000, T: 355200, Avg. loss: 0.040412\n",
      "Total training time: 2.37 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 188.71, NNZs: 56, Bias: 0.000000, T: 426240, Avg. loss: 0.038884\n",
      "Total training time: 2.83 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 191.40, NNZs: 56, Bias: 0.000000, T: 497280, Avg. loss: 0.038151\n",
      "Total training time: 3.29 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 194.04, NNZs: 56, Bias: 0.000000, T: 568320, Avg. loss: 0.037936\n",
      "Total training time: 3.75 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 196.65, NNZs: 54, Bias: 0.000000, T: 639360, Avg. loss: 0.037684\n",
      "Total training time: 4.21 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 199.23, NNZs: 54, Bias: 0.000000, T: 710400, Avg. loss: 0.037453\n",
      "Total training time: 4.67 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 201.75, NNZs: 52, Bias: 0.000000, T: 781440, Avg. loss: 0.037252\n",
      "Total training time: 5.18 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 202.25, NNZs: 52, Bias: 0.000000, T: 852480, Avg. loss: 0.037102\n",
      "Total training time: 5.62 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 202.74, NNZs: 52, Bias: 0.000000, T: 923520, Avg. loss: 0.037071\n",
      "Total training time: 6.03 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 203.24, NNZs: 52, Bias: 0.000000, T: 994560, Avg. loss: 0.037023\n",
      "Total training time: 6.45 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 203.73, NNZs: 52, Bias: 0.000000, T: 1065600, Avg. loss: 0.036983\n",
      "Total training time: 6.87 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 204.22, NNZs: 52, Bias: 0.000000, T: 1136640, Avg. loss: 0.036943\n",
      "Total training time: 7.29 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 204.32, NNZs: 52, Bias: 0.000000, T: 1207680, Avg. loss: 0.036914\n",
      "Total training time: 7.71 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 204.42, NNZs: 52, Bias: 0.000000, T: 1278720, Avg. loss: 0.036907\n",
      "Total training time: 8.13 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 204.52, NNZs: 52, Bias: 0.000000, T: 1349760, Avg. loss: 0.036899\n",
      "Total training time: 8.57 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 204.61, NNZs: 52, Bias: 0.000000, T: 1420800, Avg. loss: 0.036891\n",
      "Total training time: 8.98 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.06171699256249541, clf__eta0=0.6666115972798587, clf__fit_intercept=False, clf__l1_ratio=0.9792901432894962, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.15075392531110676, clf__shuffle=True, clf__tol=0.365636830734297, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.214 total time=  58.9s\n",
      "-- Epoch 1\n",
      "Norm: 86.75, NNZs: 262, Bias: 0.000000, T: 71040, Avg. loss: 0.076347\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 116.66, NNZs: 109, Bias: 0.000000, T: 142080, Avg. loss: 0.051401\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 139.07, NNZs: 87, Bias: 0.000000, T: 213120, Avg. loss: 0.045322\n",
      "Total training time: 1.37 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 157.81, NNZs: 71, Bias: 0.000000, T: 284160, Avg. loss: 0.042211\n",
      "Total training time: 1.84 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 174.19, NNZs: 64, Bias: 0.000000, T: 355200, Avg. loss: 0.040235\n",
      "Total training time: 2.32 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 188.89, NNZs: 58, Bias: 0.000000, T: 426240, Avg. loss: 0.038409\n",
      "Total training time: 2.79 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 191.60, NNZs: 57, Bias: 0.000000, T: 497280, Avg. loss: 0.037786\n",
      "Total training time: 3.28 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 194.25, NNZs: 56, Bias: 0.000000, T: 568320, Avg. loss: 0.037561\n",
      "Total training time: 3.73 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 196.85, NNZs: 54, Bias: 0.000000, T: 639360, Avg. loss: 0.037286\n",
      "Total training time: 4.18 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 199.41, NNZs: 53, Bias: 0.000000, T: 710400, Avg. loss: 0.037035\n",
      "Total training time: 4.71 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 201.96, NNZs: 51, Bias: 0.000000, T: 781440, Avg. loss: 0.036902\n",
      "Total training time: 5.20 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 202.46, NNZs: 51, Bias: 0.000000, T: 852480, Avg. loss: 0.036742\n",
      "Total training time: 5.67 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 202.95, NNZs: 51, Bias: 0.000000, T: 923520, Avg. loss: 0.036700\n",
      "Total training time: 6.14 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 203.45, NNZs: 51, Bias: 0.000000, T: 994560, Avg. loss: 0.036655\n",
      "Total training time: 6.63 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 203.94, NNZs: 51, Bias: 0.000000, T: 1065600, Avg. loss: 0.036620\n",
      "Total training time: 7.14 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 204.43, NNZs: 51, Bias: 0.000000, T: 1136640, Avg. loss: 0.036585\n",
      "Total training time: 7.60 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 204.53, NNZs: 51, Bias: 0.000000, T: 1207680, Avg. loss: 0.036556\n",
      "Total training time: 8.05 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 204.63, NNZs: 51, Bias: 0.000000, T: 1278720, Avg. loss: 0.036547\n",
      "Total training time: 8.52 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 204.73, NNZs: 51, Bias: 0.000000, T: 1349760, Avg. loss: 0.036540\n",
      "Total training time: 8.96 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 204.82, NNZs: 51, Bias: 0.000000, T: 1420800, Avg. loss: 0.036533\n",
      "Total training time: 9.42 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.06171699256249541, clf__eta0=0.6666115972798587, clf__fit_intercept=False, clf__l1_ratio=0.9792901432894962, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.15075392531110676, clf__shuffle=True, clf__tol=0.365636830734297, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.211 total time=  58.4s\n",
      "-- Epoch 1\n",
      "Norm: 86.29, NNZs: 271, Bias: 0.000000, T: 71040, Avg. loss: 0.076123\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 116.00, NNZs: 109, Bias: 0.000000, T: 142080, Avg. loss: 0.051077\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 138.29, NNZs: 84, Bias: 0.000000, T: 213120, Avg. loss: 0.045246\n",
      "Total training time: 1.28 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 157.05, NNZs: 70, Bias: 0.000000, T: 284160, Avg. loss: 0.042437\n",
      "Total training time: 1.70 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 173.40, NNZs: 63, Bias: 0.000000, T: 355200, Avg. loss: 0.040116\n",
      "Total training time: 2.16 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 187.88, NNZs: 57, Bias: 0.000000, T: 426240, Avg. loss: 0.038744\n",
      "Total training time: 2.62 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 190.58, NNZs: 57, Bias: 0.000000, T: 497280, Avg. loss: 0.037839\n",
      "Total training time: 3.06 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 193.23, NNZs: 57, Bias: 0.000000, T: 568320, Avg. loss: 0.037602\n",
      "Total training time: 3.51 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 195.81, NNZs: 57, Bias: 0.000000, T: 639360, Avg. loss: 0.037405\n",
      "Total training time: 3.96 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 198.35, NNZs: 55, Bias: 0.000000, T: 710400, Avg. loss: 0.037243\n",
      "Total training time: 4.41 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 200.89, NNZs: 55, Bias: 0.000000, T: 781440, Avg. loss: 0.037073\n",
      "Total training time: 4.82 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 201.38, NNZs: 55, Bias: 0.000000, T: 852480, Avg. loss: 0.036931\n",
      "Total training time: 5.25 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 201.87, NNZs: 55, Bias: 0.000000, T: 923520, Avg. loss: 0.036892\n",
      "Total training time: 5.68 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 202.36, NNZs: 54, Bias: 0.000000, T: 994560, Avg. loss: 0.036869\n",
      "Total training time: 6.11 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 202.86, NNZs: 53, Bias: 0.000000, T: 1065600, Avg. loss: 0.036829\n",
      "Total training time: 6.55 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 203.35, NNZs: 53, Bias: 0.000000, T: 1136640, Avg. loss: 0.036796\n",
      "Total training time: 7.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 203.44, NNZs: 53, Bias: 0.000000, T: 1207680, Avg. loss: 0.036765\n",
      "Total training time: 7.46 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 203.54, NNZs: 53, Bias: 0.000000, T: 1278720, Avg. loss: 0.036758\n",
      "Total training time: 7.93 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 203.64, NNZs: 53, Bias: 0.000000, T: 1349760, Avg. loss: 0.036750\n",
      "Total training time: 8.36 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 203.74, NNZs: 52, Bias: 0.000000, T: 1420800, Avg. loss: 0.036744\n",
      "Total training time: 8.80 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.06171699256249541, clf__eta0=0.6666115972798587, clf__fit_intercept=False, clf__l1_ratio=0.9792901432894962, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.15075392531110676, clf__shuffle=True, clf__tol=0.365636830734297, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.212 total time=  59.3s\n",
      "-- Epoch 1\n",
      "Norm: 86.26, NNZs: 281, Bias: 0.000000, T: 71040, Avg. loss: 0.077045\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 115.99, NNZs: 113, Bias: 0.000000, T: 142080, Avg. loss: 0.051198\n",
      "Total training time: 0.99 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 138.56, NNZs: 86, Bias: 0.000000, T: 213120, Avg. loss: 0.045402\n",
      "Total training time: 1.49 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 157.36, NNZs: 70, Bias: 0.000000, T: 284160, Avg. loss: 0.042208\n",
      "Total training time: 1.98 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 173.64, NNZs: 62, Bias: 0.000000, T: 355200, Avg. loss: 0.040405\n",
      "Total training time: 2.45 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 188.26, NNZs: 58, Bias: 0.000000, T: 426240, Avg. loss: 0.038791\n",
      "Total training time: 2.92 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 190.90, NNZs: 58, Bias: 0.000000, T: 497280, Avg. loss: 0.037984\n",
      "Total training time: 3.38 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 193.52, NNZs: 55, Bias: 0.000000, T: 568320, Avg. loss: 0.037784\n",
      "Total training time: 3.85 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 196.11, NNZs: 54, Bias: 0.000000, T: 639360, Avg. loss: 0.037555\n",
      "Total training time: 4.32 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 198.66, NNZs: 54, Bias: 0.000000, T: 710400, Avg. loss: 0.037375\n",
      "Total training time: 4.81 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 201.18, NNZs: 54, Bias: 0.000000, T: 781440, Avg. loss: 0.037161\n",
      "Total training time: 5.26 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 201.68, NNZs: 54, Bias: 0.000000, T: 852480, Avg. loss: 0.037023\n",
      "Total training time: 5.75 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 202.17, NNZs: 54, Bias: 0.000000, T: 923520, Avg. loss: 0.036986\n",
      "Total training time: 6.24 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 202.67, NNZs: 54, Bias: 0.000000, T: 994560, Avg. loss: 0.036953\n",
      "Total training time: 6.72 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 203.16, NNZs: 54, Bias: 0.000000, T: 1065600, Avg. loss: 0.036910\n",
      "Total training time: 7.21 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 203.64, NNZs: 54, Bias: 0.000000, T: 1136640, Avg. loss: 0.036884\n",
      "Total training time: 7.68 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 203.74, NNZs: 54, Bias: 0.000000, T: 1207680, Avg. loss: 0.036862\n",
      "Total training time: 8.13 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 203.84, NNZs: 54, Bias: 0.000000, T: 1278720, Avg. loss: 0.036854\n",
      "Total training time: 8.66 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 203.94, NNZs: 54, Bias: 0.000000, T: 1349760, Avg. loss: 0.036846\n",
      "Total training time: 9.14 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 204.03, NNZs: 54, Bias: 0.000000, T: 1420800, Avg. loss: 0.036840\n",
      "Total training time: 9.62 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.06171699256249541, clf__eta0=0.6666115972798587, clf__fit_intercept=False, clf__l1_ratio=0.9792901432894962, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.15075392531110676, clf__shuffle=True, clf__tol=0.365636830734297, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.210 total time= 1.0min\n",
      "-- Epoch 1\n",
      "Norm: 79836036074109.19, NNZs: 395434, Bias: 0.000000, T: 71040, Avg. loss: 61720040850122893950976.000000\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 74432730973072.62, NNZs: 395436, Bias: 0.000000, T: 142080, Avg. loss: 50476040900109353877504.000000\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 71656164686750.97, NNZs: 395436, Bias: 0.000000, T: 213120, Avg. loss: 40447248144885832744960.000000\n",
      "Total training time: 1.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 69826018888253.57, NNZs: 395436, Bias: 0.000000, T: 284160, Avg. loss: 35829194586496224460800.000000\n",
      "Total training time: 1.37 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 68474175658741.10, NNZs: 395436, Bias: 0.000000, T: 355200, Avg. loss: 33018885845337189122048.000000\n",
      "Total training time: 1.71 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 67408821345421.58, NNZs: 395436, Bias: 0.000000, T: 426240, Avg. loss: 31052880881790650155008.000000\n",
      "Total training time: 2.05 seconds.\n",
      "Convergence after 6 epochs took 2.09 seconds\n",
      "[CV 1/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.7915127974877743, clf__eta0=0.05539740212799926, clf__fit_intercept=False, clf__l1_ratio=0.9152680641407671, clf__learning_rate=optimal, clf__loss=squared_epsilon_insensitive, clf__max_iter=80, clf__penalty=l1, clf__power_t=0.6359093112142983, clf__shuffle=True, clf__tol=0.9361199211609239, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.341 total time=  52.3s\n",
      "-- Epoch 1\n",
      "Norm: 116480373089098.48, NNZs: 395485, Bias: 0.000000, T: 71040, Avg. loss: 131612203033253308792832.000000\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 109988572737067.31, NNZs: 395486, Bias: 0.000000, T: 142080, Avg. loss: 112912994704693387067392.000000\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 106670007101410.98, NNZs: 395486, Bias: 0.000000, T: 213120, Avg. loss: 93521623905757386768384.000000\n",
      "Total training time: 1.10 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 104483550319161.22, NNZs: 395486, Bias: 0.000000, T: 284160, Avg. loss: 84643797481069779877888.000000\n",
      "Total training time: 1.46 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 102865320366718.02, NNZs: 395486, Bias: 0.000000, T: 355200, Avg. loss: 79126936658078221729792.000000\n",
      "Total training time: 1.83 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 101590663210200.11, NNZs: 395486, Bias: 0.000000, T: 426240, Avg. loss: 75207104786108604481536.000000\n",
      "Total training time: 2.17 seconds.\n",
      "Convergence after 6 epochs took 2.21 seconds\n",
      "[CV 2/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.7915127974877743, clf__eta0=0.05539740212799926, clf__fit_intercept=False, clf__l1_ratio=0.9152680641407671, clf__learning_rate=optimal, clf__loss=squared_epsilon_insensitive, clf__max_iter=80, clf__penalty=l1, clf__power_t=0.6359093112142983, clf__shuffle=True, clf__tol=0.9361199211609239, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.345 total time=  51.4s\n",
      "-- Epoch 1\n",
      "Norm: 105354957225124.23, NNZs: 394733, Bias: 0.000000, T: 71040, Avg. loss: 115039666215214662025216.000000\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 99079860436305.11, NNZs: 394739, Bias: 0.000000, T: 142080, Avg. loss: 90470837239612637708288.000000\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 95873846398438.00, NNZs: 394739, Bias: 0.000000, T: 213120, Avg. loss: 74092950216306669387776.000000\n",
      "Total training time: 1.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 93762403338616.88, NNZs: 394739, Bias: 0.000000, T: 284160, Avg. loss: 66509337241950156226560.000000\n",
      "Total training time: 1.36 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 92200858691238.69, NNZs: 394739, Bias: 0.000000, T: 355200, Avg. loss: 61874919911495414317056.000000\n",
      "Total training time: 1.70 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 90970526186071.66, NNZs: 394739, Bias: 0.000000, T: 426240, Avg. loss: 58597099754721439121408.000000\n",
      "Total training time: 2.03 seconds.\n",
      "Convergence after 6 epochs took 2.06 seconds\n",
      "[CV 3/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.7915127974877743, clf__eta0=0.05539740212799926, clf__fit_intercept=False, clf__l1_ratio=0.9152680641407671, clf__learning_rate=optimal, clf__loss=squared_epsilon_insensitive, clf__max_iter=80, clf__penalty=l1, clf__power_t=0.6359093112142983, clf__shuffle=True, clf__tol=0.9361199211609239, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.340 total time=  50.2s\n",
      "-- Epoch 1\n",
      "Norm: 108025412562950.92, NNZs: 395342, Bias: 0.000000, T: 71040, Avg. loss: 115889750198089483812864.000000\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 101764765798305.59, NNZs: 395345, Bias: 0.000000, T: 142080, Avg. loss: 95304438341414219153408.000000\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 98571517367308.05, NNZs: 395345, Bias: 0.000000, T: 213120, Avg. loss: 78526850617677981941760.000000\n",
      "Total training time: 1.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 96462635514085.25, NNZs: 395345, Bias: 0.000000, T: 284160, Avg. loss: 70812453581077857959936.000000\n",
      "Total training time: 1.38 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 94901978369315.69, NNZs: 395345, Bias: 0.000000, T: 355200, Avg. loss: 66003711471410791579648.000000\n",
      "Total training time: 1.73 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 93671930909881.83, NNZs: 395345, Bias: 0.000000, T: 426240, Avg. loss: 62612832338851529752576.000000\n",
      "Total training time: 2.08 seconds.\n",
      "Convergence after 6 epochs took 2.11 seconds\n",
      "[CV 4/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.7915127974877743, clf__eta0=0.05539740212799926, clf__fit_intercept=False, clf__l1_ratio=0.9152680641407671, clf__learning_rate=optimal, clf__loss=squared_epsilon_insensitive, clf__max_iter=80, clf__penalty=l1, clf__power_t=0.6359093112142983, clf__shuffle=True, clf__tol=0.9361199211609239, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.349 total time=  50.1s\n",
      "-- Epoch 1\n",
      "Norm: 126733127415470.97, NNZs: 393398, Bias: 0.000000, T: 71040, Avg. loss: 161809646928025754796032.000000\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 119898279296446.48, NNZs: 393399, Bias: 0.000000, T: 142080, Avg. loss: 135041686758984838545408.000000\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 116425739157881.88, NNZs: 393399, Bias: 0.000000, T: 213120, Avg. loss: 112480371615920570761216.000000\n",
      "Total training time: 1.04 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 114138926607032.42, NNZs: 393399, Bias: 0.000000, T: 284160, Avg. loss: 101950471867316192673792.000000\n",
      "Total training time: 1.37 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 112450409097581.25, NNZs: 393399, Bias: 0.000000, T: 355200, Avg. loss: 95462320354767604285440.000000\n",
      "Total training time: 1.72 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 111120762883958.16, NNZs: 393399, Bias: 0.000000, T: 426240, Avg. loss: 90889910875942421528576.000000\n",
      "Total training time: 2.07 seconds.\n",
      "Convergence after 6 epochs took 2.11 seconds\n",
      "[CV 5/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.7915127974877743, clf__eta0=0.05539740212799926, clf__fit_intercept=False, clf__l1_ratio=0.9152680641407671, clf__learning_rate=optimal, clf__loss=squared_epsilon_insensitive, clf__max_iter=80, clf__penalty=l1, clf__power_t=0.6359093112142983, clf__shuffle=True, clf__tol=0.9361199211609239, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.342 total time=  50.6s\n",
      "-- Epoch 1\n",
      "Norm: 82.01, NNZs: 215, Bias: 0.000000, T: 71040, Avg. loss: 0.020415\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 107.45, NNZs: 111, Bias: 0.000000, T: 142080, Avg. loss: 0.012711\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 126.51, NNZs: 97, Bias: 0.000000, T: 213120, Avg. loss: 0.011508\n",
      "Total training time: 0.85 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 142.11, NNZs: 92, Bias: 0.000000, T: 284160, Avg. loss: 0.010742\n",
      "Total training time: 1.10 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 155.79, NNZs: 86, Bias: 0.000000, T: 355200, Avg. loss: 0.010383\n",
      "Total training time: 1.37 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 168.07, NNZs: 83, Bias: 0.000000, T: 426240, Avg. loss: 0.010207\n",
      "Total training time: 1.63 seconds.\n",
      "Convergence after 6 epochs took 1.67 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.03646223783802971, clf__eta0=0.7491267567674796, clf__fit_intercept=False, clf__l1_ratio=0.775818217437024, clf__learning_rate=constant, clf__loss=squared_hinge, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.4028006727705291, clf__shuffle=True, clf__tol=0.1730703028465106, clf__warm_start=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.973 total time=  50.4s\n",
      "-- Epoch 1\n",
      "Norm: 81.56, NNZs: 217, Bias: 0.000000, T: 71040, Avg. loss: 0.020241\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 107.09, NNZs: 111, Bias: 0.000000, T: 142080, Avg. loss: 0.012648\n",
      "Total training time: 0.67 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 126.06, NNZs: 99, Bias: 0.000000, T: 213120, Avg. loss: 0.011409\n",
      "Total training time: 0.99 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 141.81, NNZs: 96, Bias: 0.000000, T: 284160, Avg. loss: 0.010661\n",
      "Total training time: 1.28 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 155.48, NNZs: 89, Bias: 0.000000, T: 355200, Avg. loss: 0.010285\n",
      "Total training time: 1.57 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 167.81, NNZs: 88, Bias: 0.000000, T: 426240, Avg. loss: 0.010055\n",
      "Total training time: 1.86 seconds.\n",
      "Convergence after 6 epochs took 1.90 seconds\n",
      "[CV 2/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.03646223783802971, clf__eta0=0.7491267567674796, clf__fit_intercept=False, clf__l1_ratio=0.775818217437024, clf__learning_rate=constant, clf__loss=squared_hinge, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.4028006727705291, clf__shuffle=True, clf__tol=0.1730703028465106, clf__warm_start=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.966 total time=  52.1s\n",
      "-- Epoch 1\n",
      "Norm: 81.64, NNZs: 247, Bias: 0.000000, T: 71040, Avg. loss: 0.019934\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 106.79, NNZs: 114, Bias: 0.000000, T: 142080, Avg. loss: 0.012150\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 125.62, NNZs: 102, Bias: 0.000000, T: 213120, Avg. loss: 0.011030\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 141.06, NNZs: 89, Bias: 0.000000, T: 284160, Avg. loss: 0.010114\n",
      "Total training time: 1.19 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 154.57, NNZs: 83, Bias: 0.000000, T: 355200, Avg. loss: 0.009848\n",
      "Total training time: 1.48 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 166.73, NNZs: 83, Bias: 0.000000, T: 426240, Avg. loss: 0.009604\n",
      "Total training time: 1.77 seconds.\n",
      "Convergence after 6 epochs took 1.81 seconds\n",
      "[CV 3/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.03646223783802971, clf__eta0=0.7491267567674796, clf__fit_intercept=False, clf__l1_ratio=0.775818217437024, clf__learning_rate=constant, clf__loss=squared_hinge, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.4028006727705291, clf__shuffle=True, clf__tol=0.1730703028465106, clf__warm_start=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.963 total time=  51.4s\n",
      "-- Epoch 1\n",
      "Norm: 81.45, NNZs: 221, Bias: 0.000000, T: 71040, Avg. loss: 0.020238\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 106.85, NNZs: 99, Bias: 0.000000, T: 142080, Avg. loss: 0.012549\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 125.72, NNZs: 88, Bias: 0.000000, T: 213120, Avg. loss: 0.011106\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 141.13, NNZs: 86, Bias: 0.000000, T: 284160, Avg. loss: 0.010399\n",
      "Total training time: 1.17 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 154.61, NNZs: 81, Bias: 0.000000, T: 355200, Avg. loss: 0.010025\n",
      "Total training time: 1.44 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 166.78, NNZs: 84, Bias: 0.000000, T: 426240, Avg. loss: 0.009824\n",
      "Total training time: 1.71 seconds.\n",
      "Convergence after 6 epochs took 1.75 seconds\n",
      "[CV 4/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.03646223783802971, clf__eta0=0.7491267567674796, clf__fit_intercept=False, clf__l1_ratio=0.775818217437024, clf__learning_rate=constant, clf__loss=squared_hinge, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.4028006727705291, clf__shuffle=True, clf__tol=0.1730703028465106, clf__warm_start=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.972 total time=  50.9s\n",
      "-- Epoch 1\n",
      "Norm: 81.75, NNZs: 212, Bias: 0.000000, T: 71040, Avg. loss: 0.020114\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 107.05, NNZs: 116, Bias: 0.000000, T: 142080, Avg. loss: 0.012555\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 125.91, NNZs: 99, Bias: 0.000000, T: 213120, Avg. loss: 0.011306\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 141.65, NNZs: 94, Bias: 0.000000, T: 284160, Avg. loss: 0.010727\n",
      "Total training time: 1.06 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 155.24, NNZs: 90, Bias: 0.000000, T: 355200, Avg. loss: 0.010316\n",
      "Total training time: 1.34 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 167.47, NNZs: 90, Bias: 0.000000, T: 426240, Avg. loss: 0.010049\n",
      "Total training time: 1.61 seconds.\n",
      "Convergence after 6 epochs took 1.64 seconds\n",
      "[CV 5/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.03646223783802971, clf__eta0=0.7491267567674796, clf__fit_intercept=False, clf__l1_ratio=0.775818217437024, clf__learning_rate=constant, clf__loss=squared_hinge, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.4028006727705291, clf__shuffle=True, clf__tol=0.1730703028465106, clf__warm_start=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.980 total time=  51.0s\n",
      "-- Epoch 1\n",
      "Norm: 268200362347454.53, NNZs: 395414, Bias: 0.000000, T: 71040, Avg. loss: 1291611571891493287231488.000000\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 216144824161274.47, NNZs: 395111, Bias: 0.000000, T: 142080, Avg. loss: 3325065022133939938000896.000000\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 268673796656919.06, NNZs: 395416, Bias: 0.000000, T: 213120, Avg. loss: 2693413551617429521563648.000000\n",
      "Total training time: 1.19 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 225151642791359.66, NNZs: 395341, Bias: 0.000000, T: 284160, Avg. loss: 3241616382465201858936832.000000\n",
      "Total training time: 1.60 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 263949437373781.94, NNZs: 395414, Bias: 0.000000, T: 355200, Avg. loss: 2597180502352288842514432.000000\n",
      "Total training time: 2.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 232016398495785.53, NNZs: 395391, Bias: 0.000000, T: 426240, Avg. loss: 3338522771459275248107520.000000\n",
      "Total training time: 2.42 seconds.\n",
      "Convergence after 6 epochs took 2.45 seconds\n",
      "[CV 1/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.24457156361183285, clf__eta0=0.332929742792607, clf__fit_intercept=False, clf__l1_ratio=0.920539731041378, clf__learning_rate=constant, clf__loss=squared_error, clf__max_iter=100, clf__penalty=l1, clf__power_t=0.5734177157821045, clf__shuffle=True, clf__tol=0.6492274795888617, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.341 total time=  50.1s\n",
      "-- Epoch 1\n",
      "Norm: 271329952903815.50, NNZs: 395489, Bias: 0.000000, T: 71040, Avg. loss: 1390105240729531419983872.000000\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 206229013446087.00, NNZs: 395113, Bias: 0.000000, T: 142080, Avg. loss: 3497557179717551009038336.000000\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 273474709261620.84, NNZs: 395492, Bias: 0.000000, T: 213120, Avg. loss: 2431452009226681244975104.000000\n",
      "Total training time: 1.18 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 214814826580180.16, NNZs: 395417, Bias: 0.000000, T: 284160, Avg. loss: 3421597419243957141897216.000000\n",
      "Total training time: 1.58 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 271908442346967.56, NNZs: 395491, Bias: 0.000000, T: 355200, Avg. loss: 2629013919966593567162368.000000\n",
      "Total training time: 1.97 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 226896373253505.72, NNZs: 395469, Bias: 0.000000, T: 426240, Avg. loss: 3419737106372167976615936.000000\n",
      "Total training time: 2.36 seconds.\n",
      "Convergence after 6 epochs took 2.40 seconds\n",
      "[CV 2/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.24457156361183285, clf__eta0=0.332929742792607, clf__fit_intercept=False, clf__l1_ratio=0.920539731041378, clf__learning_rate=constant, clf__loss=squared_error, clf__max_iter=100, clf__penalty=l1, clf__power_t=0.5734177157821045, clf__shuffle=True, clf__tol=0.6492274795888617, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.346 total time=  50.4s\n",
      "-- Epoch 1\n",
      "Norm: 273657275407955.88, NNZs: 394739, Bias: 0.000000, T: 71040, Avg. loss: 1350989492408514026405888.000000\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 203668534740163.72, NNZs: 394321, Bias: 0.000000, T: 142080, Avg. loss: 3754656363543301887885312.000000\n",
      "Total training time: 0.84 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 270961863645178.91, NNZs: 394745, Bias: 0.000000, T: 213120, Avg. loss: 2540873380939995902115840.000000\n",
      "Total training time: 1.26 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 232152629718171.34, NNZs: 394658, Bias: 0.000000, T: 284160, Avg. loss: 3390488081156215406592000.000000\n",
      "Total training time: 1.67 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 264515581424021.00, NNZs: 394744, Bias: 0.000000, T: 355200, Avg. loss: 2405236325652317664706560.000000\n",
      "Total training time: 2.08 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 238565228889103.28, NNZs: 394714, Bias: 0.000000, T: 426240, Avg. loss: 3244447243043161677758464.000000\n",
      "Total training time: 2.50 seconds.\n",
      "Convergence after 6 epochs took 2.54 seconds\n",
      "[CV 3/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.24457156361183285, clf__eta0=0.332929742792607, clf__fit_intercept=False, clf__l1_ratio=0.920539731041378, clf__learning_rate=constant, clf__loss=squared_error, clf__max_iter=100, clf__penalty=l1, clf__power_t=0.5734177157821045, clf__shuffle=True, clf__tol=0.6492274795888617, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.342 total time=  50.2s\n",
      "-- Epoch 1\n",
      "Norm: 272286078421327.25, NNZs: 395338, Bias: 0.000000, T: 71040, Avg. loss: 1342877325314070887268352.000000\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 214256948850829.28, NNZs: 394957, Bias: 0.000000, T: 142080, Avg. loss: 3850351821043284060405760.000000\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 272628373130675.41, NNZs: 395339, Bias: 0.000000, T: 213120, Avg. loss: 2576956659154006547890176.000000\n",
      "Total training time: 1.19 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 229105268334554.22, NNZs: 395235, Bias: 0.000000, T: 284160, Avg. loss: 3453558766021944698470400.000000\n",
      "Total training time: 1.60 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 270234760955692.59, NNZs: 395342, Bias: 0.000000, T: 355200, Avg. loss: 2800281855137002381377536.000000\n",
      "Total training time: 2.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 216929080478604.50, NNZs: 395293, Bias: 0.000000, T: 426240, Avg. loss: 3366230212036475479916544.000000\n",
      "Total training time: 2.43 seconds.\n",
      "Convergence after 6 epochs took 2.46 seconds\n",
      "[CV 4/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.24457156361183285, clf__eta0=0.332929742792607, clf__fit_intercept=False, clf__l1_ratio=0.920539731041378, clf__learning_rate=constant, clf__loss=squared_error, clf__max_iter=100, clf__penalty=l1, clf__power_t=0.5734177157821045, clf__shuffle=True, clf__tol=0.6492274795888617, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.341 total time=  50.7s\n",
      "-- Epoch 1\n",
      "Norm: 266920562224308.50, NNZs: 393375, Bias: 0.000000, T: 71040, Avg. loss: 1293205411706536818900992.000000\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 201440535593792.44, NNZs: 393024, Bias: 0.000000, T: 142080, Avg. loss: 3413582101206104293769216.000000\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 264143700832823.47, NNZs: 393376, Bias: 0.000000, T: 213120, Avg. loss: 2705061773304975849422848.000000\n",
      "Total training time: 1.19 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 225435580523373.50, NNZs: 393281, Bias: 0.000000, T: 284160, Avg. loss: 3368304039729478015909888.000000\n",
      "Total training time: 1.62 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 263236800163158.72, NNZs: 393379, Bias: 0.000000, T: 355200, Avg. loss: 2487526749822026464100352.000000\n",
      "Total training time: 2.06 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 233891430043698.53, NNZs: 393342, Bias: 0.000000, T: 426240, Avg. loss: 3182476503985710954446848.000000\n",
      "Total training time: 2.51 seconds.\n",
      "Convergence after 6 epochs took 2.54 seconds\n",
      "[CV 5/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.24457156361183285, clf__eta0=0.332929742792607, clf__fit_intercept=False, clf__l1_ratio=0.920539731041378, clf__learning_rate=constant, clf__loss=squared_error, clf__max_iter=100, clf__penalty=l1, clf__power_t=0.5734177157821045, clf__shuffle=True, clf__tol=0.6492274795888617, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.346 total time=  50.0s\n",
      "-- Epoch 1\n",
      "Norm: 4.07, NNZs: 675919, Bias: 0.420493, T: 71040, Avg. loss: 0.040316\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 4.14, NNZs: 675919, Bias: 0.480709, T: 142080, Avg. loss: 0.015922\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.14, NNZs: 675919, Bias: 0.514053, T: 213120, Avg. loss: 0.012281\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.11, NNZs: 675919, Bias: 0.537002, T: 284160, Avg. loss: 0.010638\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.09, NNZs: 675919, Bias: 0.554417, T: 355200, Avg. loss: 0.009681\n",
      "Total training time: 1.18 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 4.05, NNZs: 675919, Bias: 0.568421, T: 426240, Avg. loss: 0.009040\n",
      "Total training time: 1.41 seconds.\n",
      "Convergence after 6 epochs took 1.45 seconds\n",
      "[CV 1/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.2527955528897454, clf__eta0=0.4377192284389271, clf__fit_intercept=True, clf__l1_ratio=0.6515110441465675, clf__learning_rate=invscaling, clf__loss=huber, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.47239053945705856, clf__shuffle=False, clf__tol=0.9089234089706554, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.498 total time=  50.0s\n",
      "-- Epoch 1\n",
      "Norm: 4.07, NNZs: 675629, Bias: 0.418748, T: 71040, Avg. loss: 0.040255\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 4.15, NNZs: 675629, Bias: 0.478983, T: 142080, Avg. loss: 0.015958\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.14, NNZs: 675629, Bias: 0.512344, T: 213120, Avg. loss: 0.012318\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.12, NNZs: 675629, Bias: 0.535299, T: 284160, Avg. loss: 0.010675\n",
      "Total training time: 0.84 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.09, NNZs: 675629, Bias: 0.552725, T: 355200, Avg. loss: 0.009718\n",
      "Total training time: 1.06 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 4.06, NNZs: 675629, Bias: 0.566747, T: 426240, Avg. loss: 0.009077\n",
      "Total training time: 1.28 seconds.\n",
      "Convergence after 6 epochs took 1.32 seconds\n",
      "[CV 2/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.2527955528897454, clf__eta0=0.4377192284389271, clf__fit_intercept=True, clf__l1_ratio=0.6515110441465675, clf__learning_rate=invscaling, clf__loss=huber, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.47239053945705856, clf__shuffle=False, clf__tol=0.9089234089706554, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.498 total time=  50.6s\n",
      "-- Epoch 1\n",
      "Norm: 4.07, NNZs: 675168, Bias: 0.418120, T: 71040, Avg. loss: 0.040260\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 4.15, NNZs: 675168, Bias: 0.478568, T: 142080, Avg. loss: 0.016011\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.14, NNZs: 675168, Bias: 0.512063, T: 213120, Avg. loss: 0.012353\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.12, NNZs: 675168, Bias: 0.535101, T: 284160, Avg. loss: 0.010703\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.09, NNZs: 675168, Bias: 0.552584, T: 355200, Avg. loss: 0.009741\n",
      "Total training time: 1.08 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 4.06, NNZs: 675168, Bias: 0.566647, T: 426240, Avg. loss: 0.009096\n",
      "Total training time: 1.30 seconds.\n",
      "Convergence after 6 epochs took 1.34 seconds\n",
      "[CV 3/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.2527955528897454, clf__eta0=0.4377192284389271, clf__fit_intercept=True, clf__l1_ratio=0.6515110441465675, clf__learning_rate=invscaling, clf__loss=huber, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.47239053945705856, clf__shuffle=False, clf__tol=0.9089234089706554, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.498 total time=  49.7s\n",
      "-- Epoch 1\n",
      "Norm: 4.07, NNZs: 675003, Bias: 0.418942, T: 71040, Avg. loss: 0.040131\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 4.15, NNZs: 675003, Bias: 0.479185, T: 142080, Avg. loss: 0.015915\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.14, NNZs: 675003, Bias: 0.512543, T: 213120, Avg. loss: 0.012264\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.12, NNZs: 675003, Bias: 0.535477, T: 284160, Avg. loss: 0.010621\n",
      "Total training time: 0.82 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.10, NNZs: 675003, Bias: 0.552868, T: 355200, Avg. loss: 0.009666\n",
      "Total training time: 1.05 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 6\n",
      "Norm: 4.07, NNZs: 675003, Bias: 0.566846, T: 426240, Avg. loss: 0.009029\n",
      "Total training time: 1.28 seconds.\n",
      "Convergence after 6 epochs took 1.32 seconds\n",
      "[CV 4/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.2527955528897454, clf__eta0=0.4377192284389271, clf__fit_intercept=True, clf__l1_ratio=0.6515110441465675, clf__learning_rate=invscaling, clf__loss=huber, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.47239053945705856, clf__shuffle=False, clf__tol=0.9089234089706554, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.498 total time=  49.5s\n",
      "-- Epoch 1\n",
      "Norm: 4.08, NNZs: 671845, Bias: 0.418664, T: 71040, Avg. loss: 0.040182\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 4.15, NNZs: 671845, Bias: 0.478812, T: 142080, Avg. loss: 0.015951\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.15, NNZs: 671845, Bias: 0.512126, T: 213120, Avg. loss: 0.012319\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.12, NNZs: 671845, Bias: 0.535069, T: 284160, Avg. loss: 0.010676\n",
      "Total training time: 1.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.10, NNZs: 671845, Bias: 0.552492, T: 355200, Avg. loss: 0.009718\n",
      "Total training time: 1.27 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 4.06, NNZs: 671845, Bias: 0.566510, T: 426240, Avg. loss: 0.009075\n",
      "Total training time: 1.54 seconds.\n",
      "Convergence after 6 epochs took 1.58 seconds\n",
      "[CV 5/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.2527955528897454, clf__eta0=0.4377192284389271, clf__fit_intercept=True, clf__l1_ratio=0.6515110441465675, clf__learning_rate=invscaling, clf__loss=huber, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.47239053945705856, clf__shuffle=False, clf__tol=0.9089234089706554, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.498 total time=  50.8s\n",
      "-- Epoch 1\n",
      "Norm: 10.07, NNZs: 220266, Bias: 0.917810, T: 71040, Avg. loss: 0.026982\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 8.70, NNZs: 230535, Bias: 0.887203, T: 142080, Avg. loss: 0.007262\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 8.41, NNZs: 238440, Bias: 0.863794, T: 213120, Avg. loss: 0.006900\n",
      "Total training time: 0.61 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 8.29, NNZs: 244453, Bias: 0.854846, T: 284160, Avg. loss: 0.006813\n",
      "Total training time: 0.82 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 8.24, NNZs: 247738, Bias: 0.844305, T: 355200, Avg. loss: 0.006720\n",
      "Total training time: 1.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 8.20, NNZs: 250622, Bias: 0.837189, T: 426240, Avg. loss: 0.006669\n",
      "Total training time: 1.26 seconds.\n",
      "Convergence after 6 epochs took 1.30 seconds\n",
      "[CV 1/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.3241670976844645, clf__eta0=0.9631840511405841, clf__fit_intercept=True, clf__l1_ratio=0.5912641309775509, clf__learning_rate=optimal, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.6710686638981408, clf__shuffle=True, clf__tol=0.09654933943827881, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.803 total time=  49.6s\n",
      "-- Epoch 1\n",
      "Norm: 10.13, NNZs: 213673, Bias: 0.907518, T: 71040, Avg. loss: 0.027019\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 8.68, NNZs: 224403, Bias: 0.880762, T: 142080, Avg. loss: 0.007240\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 8.37, NNZs: 232550, Bias: 0.863996, T: 213120, Avg. loss: 0.006990\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 8.26, NNZs: 238161, Bias: 0.853263, T: 284160, Avg. loss: 0.006891\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 8.19, NNZs: 243177, Bias: 0.847950, T: 355200, Avg. loss: 0.006768\n",
      "Total training time: 1.09 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 8.16, NNZs: 246235, Bias: 0.839299, T: 426240, Avg. loss: 0.006758\n",
      "Total training time: 1.31 seconds.\n",
      "Convergence after 6 epochs took 1.35 seconds\n",
      "[CV 2/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.3241670976844645, clf__eta0=0.9631840511405841, clf__fit_intercept=True, clf__l1_ratio=0.5912641309775509, clf__learning_rate=optimal, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.6710686638981408, clf__shuffle=True, clf__tol=0.09654933943827881, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.800 total time=  50.0s\n",
      "-- Epoch 1\n",
      "Norm: 10.08, NNZs: 213043, Bias: 0.924820, T: 71040, Avg. loss: 0.025988\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 8.68, NNZs: 223200, Bias: 0.889487, T: 142080, Avg. loss: 0.007439\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 8.36, NNZs: 230515, Bias: 0.873760, T: 213120, Avg. loss: 0.007126\n",
      "Total training time: 0.61 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 8.25, NNZs: 235112, Bias: 0.861310, T: 284160, Avg. loss: 0.006928\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 8.20, NNZs: 238795, Bias: 0.850329, T: 355200, Avg. loss: 0.006911\n",
      "Total training time: 1.06 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 8.16, NNZs: 241723, Bias: 0.844770, T: 426240, Avg. loss: 0.006820\n",
      "Total training time: 1.29 seconds.\n",
      "Convergence after 6 epochs took 1.33 seconds\n",
      "[CV 3/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.3241670976844645, clf__eta0=0.9631840511405841, clf__fit_intercept=True, clf__l1_ratio=0.5912641309775509, clf__learning_rate=optimal, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.6710686638981408, clf__shuffle=True, clf__tol=0.09654933943827881, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.802 total time=  49.7s\n",
      "-- Epoch 1\n",
      "Norm: 10.25, NNZs: 215664, Bias: 0.905680, T: 71040, Avg. loss: 0.026330\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 8.84, NNZs: 225893, Bias: 0.876611, T: 142080, Avg. loss: 0.007089\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 8.53, NNZs: 233233, Bias: 0.858256, T: 213120, Avg. loss: 0.006786\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 8.41, NNZs: 238552, Bias: 0.848524, T: 284160, Avg. loss: 0.006626\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 8.36, NNZs: 242260, Bias: 0.837085, T: 355200, Avg. loss: 0.006551\n",
      "Total training time: 1.14 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 8.32, NNZs: 244837, Bias: 0.832266, T: 426240, Avg. loss: 0.006488\n",
      "Total training time: 1.37 seconds.\n",
      "Convergence after 6 epochs took 1.41 seconds\n",
      "[CV 4/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.3241670976844645, clf__eta0=0.9631840511405841, clf__fit_intercept=True, clf__l1_ratio=0.5912641309775509, clf__learning_rate=optimal, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.6710686638981408, clf__shuffle=True, clf__tol=0.09654933943827881, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.813 total time=  49.7s\n",
      "-- Epoch 1\n",
      "Norm: 10.13, NNZs: 210663, Bias: 0.911553, T: 71040, Avg. loss: 0.026468\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 8.73, NNZs: 221745, Bias: 0.882635, T: 142080, Avg. loss: 0.007200\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 8.44, NNZs: 230174, Bias: 0.863186, T: 213120, Avg. loss: 0.006854\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 8.34, NNZs: 235773, Bias: 0.852630, T: 284160, Avg. loss: 0.006740\n",
      "Total training time: 0.85 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 8.27, NNZs: 240480, Bias: 0.845495, T: 355200, Avg. loss: 0.006675\n",
      "Total training time: 1.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 8.24, NNZs: 243625, Bias: 0.839867, T: 426240, Avg. loss: 0.006560\n",
      "Total training time: 1.26 seconds.\n",
      "Convergence after 6 epochs took 1.29 seconds\n",
      "[CV 5/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.3241670976844645, clf__eta0=0.9631840511405841, clf__fit_intercept=True, clf__l1_ratio=0.5912641309775509, clf__learning_rate=optimal, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.6710686638981408, clf__shuffle=True, clf__tol=0.09654933943827881, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.793 total time=  49.3s\n",
      "-- Epoch 1\n",
      "Norm: 399.58, NNZs: 473, Bias: 0.000000, T: 71040, Avg. loss: 0.202112\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 485.45, NNZs: 176, Bias: 0.000000, T: 142080, Avg. loss: 0.040934\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 551.01, NNZs: 116, Bias: 0.000000, T: 213120, Avg. loss: 0.028899\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 605.61, NNZs: 109, Bias: 0.000000, T: 284160, Avg. loss: 0.026459\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 657.85, NNZs: 106, Bias: 0.000000, T: 355200, Avg. loss: 0.023242\n",
      "Total training time: 1.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 700.40, NNZs: 93, Bias: 0.000000, T: 426240, Avg. loss: 0.024994\n",
      "Total training time: 1.24 seconds.\n",
      "Convergence after 6 epochs took 1.27 seconds\n",
      "[CV 1/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.3509613152086368, clf__eta0=0.9934401124631351, clf__fit_intercept=False, clf__l1_ratio=0.5204998682261415, clf__learning_rate=constant, clf__loss=hinge, clf__max_iter=40, clf__penalty=l1, clf__power_t=0.5098574122392232, clf__shuffle=False, clf__tol=0.5563103350645606, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.933 total time=  48.8s\n",
      "-- Epoch 1\n",
      "Norm: 373.99, NNZs: 390, Bias: 0.000000, T: 71040, Avg. loss: 0.206064\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 450.05, NNZs: 138, Bias: 0.000000, T: 142080, Avg. loss: 0.028906\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 515.52, NNZs: 107, Bias: 0.000000, T: 213120, Avg. loss: 0.024604\n",
      "Total training time: 0.61 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 574.26, NNZs: 94, Bias: 0.000000, T: 284160, Avg. loss: 0.024740\n",
      "Total training time: 0.81 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 616.36, NNZs: 87, Bias: 0.000000, T: 355200, Avg. loss: 0.017621\n",
      "Total training time: 1.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 657.88, NNZs: 82, Bias: 0.000000, T: 426240, Avg. loss: 0.019651\n",
      "Total training time: 1.20 seconds.\n",
      "Convergence after 6 epochs took 1.24 seconds\n",
      "[CV 2/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.3509613152086368, clf__eta0=0.9934401124631351, clf__fit_intercept=False, clf__l1_ratio=0.5204998682261415, clf__learning_rate=constant, clf__loss=hinge, clf__max_iter=40, clf__penalty=l1, clf__power_t=0.5098574122392232, clf__shuffle=False, clf__tol=0.5563103350645606, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.965 total time=  49.0s\n",
      "-- Epoch 1\n",
      "Norm: 374.92, NNZs: 392, Bias: 0.000000, T: 71040, Avg. loss: 0.201683\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 442.36, NNZs: 121, Bias: 0.000000, T: 142080, Avg. loss: 0.025267\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 503.69, NNZs: 90, Bias: 0.000000, T: 213120, Avg. loss: 0.021703\n",
      "Total training time: 0.61 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 558.42, NNZs: 83, Bias: 0.000000, T: 284160, Avg. loss: 0.021498\n",
      "Total training time: 0.82 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 598.82, NNZs: 78, Bias: 0.000000, T: 355200, Avg. loss: 0.017355\n",
      "Total training time: 1.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 641.41, NNZs: 81, Bias: 0.000000, T: 426240, Avg. loss: 0.019784\n",
      "Total training time: 1.22 seconds.\n",
      "Convergence after 6 epochs took 1.26 seconds\n",
      "[CV 3/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.3509613152086368, clf__eta0=0.9934401124631351, clf__fit_intercept=False, clf__l1_ratio=0.5204998682261415, clf__learning_rate=constant, clf__loss=hinge, clf__max_iter=40, clf__penalty=l1, clf__power_t=0.5098574122392232, clf__shuffle=False, clf__tol=0.5563103350645606, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.952 total time=  49.5s\n",
      "-- Epoch 1\n",
      "Norm: 394.21, NNZs: 442, Bias: 0.000000, T: 71040, Avg. loss: 0.220080\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 484.21, NNZs: 158, Bias: 0.000000, T: 142080, Avg. loss: 0.038327\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 560.56, NNZs: 133, Bias: 0.000000, T: 213120, Avg. loss: 0.031119\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 614.34, NNZs: 115, Bias: 0.000000, T: 284160, Avg. loss: 0.027336\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 667.90, NNZs: 111, Bias: 0.000000, T: 355200, Avg. loss: 0.025731\n",
      "Total training time: 0.97 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 713.71, NNZs: 105, Bias: 0.000000, T: 426240, Avg. loss: 0.027391\n",
      "Total training time: 1.17 seconds.\n",
      "Convergence after 6 epochs took 1.20 seconds\n",
      "[CV 4/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.3509613152086368, clf__eta0=0.9934401124631351, clf__fit_intercept=False, clf__l1_ratio=0.5204998682261415, clf__learning_rate=constant, clf__loss=hinge, clf__max_iter=40, clf__penalty=l1, clf__power_t=0.5098574122392232, clf__shuffle=False, clf__tol=0.5563103350645606, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.941 total time=  48.6s\n",
      "-- Epoch 1\n",
      "Norm: 392.60, NNZs: 455, Bias: 0.000000, T: 71040, Avg. loss: 0.193180\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 471.84, NNZs: 154, Bias: 0.000000, T: 142080, Avg. loss: 0.035536\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 534.79, NNZs: 108, Bias: 0.000000, T: 213120, Avg. loss: 0.026507\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 591.15, NNZs: 108, Bias: 0.000000, T: 284160, Avg. loss: 0.025106\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 638.41, NNZs: 92, Bias: 0.000000, T: 355200, Avg. loss: 0.021586\n",
      "Total training time: 1.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 684.50, NNZs: 97, Bias: 0.000000, T: 426240, Avg. loss: 0.024821\n",
      "Total training time: 1.20 seconds.\n",
      "Convergence after 6 epochs took 1.23 seconds\n",
      "[CV 5/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.3509613152086368, clf__eta0=0.9934401124631351, clf__fit_intercept=False, clf__l1_ratio=0.5204998682261415, clf__learning_rate=constant, clf__loss=hinge, clf__max_iter=40, clf__penalty=l1, clf__power_t=0.5098574122392232, clf__shuffle=False, clf__tol=0.5563103350645606, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.836 total time=  48.6s\n",
      "-- Epoch 1\n",
      "Norm: 1.46, NNZs: 395430, Bias: 0.000000, T: 71040, Avg. loss: 0.789348\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.66, NNZs: 395430, Bias: 0.000000, T: 142080, Avg. loss: 0.821486\n",
      "Total training time: 0.30 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.77, NNZs: 395430, Bias: 0.000000, T: 213120, Avg. loss: 0.816688\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.85, NNZs: 395430, Bias: 0.000000, T: 284160, Avg. loss: 0.807304\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.92, NNZs: 395430, Bias: 0.000000, T: 355200, Avg. loss: 0.797841\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.98, NNZs: 395430, Bias: 0.000000, T: 426240, Avg. loss: 0.789567\n",
      "Total training time: 0.95 seconds.\n",
      "Convergence after 6 epochs took 0.99 seconds\n",
      "[CV 1/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.28658617296069355, clf__eta0=0.03398405924608927, clf__fit_intercept=False, clf__l1_ratio=0.08227014493927165, clf__learning_rate=invscaling, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.5467473202425025, clf__shuffle=True, clf__tol=0.9099604695658384, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.439 total time=  48.4s\n",
      "-- Epoch 1\n",
      "Norm: 1.54, NNZs: 395486, Bias: 0.000000, T: 71040, Avg. loss: 0.812497\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.72, NNZs: 395486, Bias: 0.000000, T: 142080, Avg. loss: 0.829544\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.82, NNZs: 395486, Bias: 0.000000, T: 213120, Avg. loss: 0.821238\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.89, NNZs: 395486, Bias: 0.000000, T: 284160, Avg. loss: 0.810534\n",
      "Total training time: 0.61 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.96, NNZs: 395486, Bias: 0.000000, T: 355200, Avg. loss: 0.800295\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.02, NNZs: 395486, Bias: 0.000000, T: 426240, Avg. loss: 0.791160\n",
      "Total training time: 0.94 seconds.\n",
      "Convergence after 6 epochs took 0.97 seconds\n",
      "[CV 2/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.28658617296069355, clf__eta0=0.03398405924608927, clf__fit_intercept=False, clf__l1_ratio=0.08227014493927165, clf__learning_rate=invscaling, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.5467473202425025, clf__shuffle=True, clf__tol=0.9099604695658384, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.438 total time=  48.1s\n",
      "-- Epoch 1\n",
      "Norm: 1.57, NNZs: 394743, Bias: 0.000000, T: 71040, Avg. loss: 0.813479\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.74, NNZs: 394743, Bias: 0.000000, T: 142080, Avg. loss: 0.830630\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.83, NNZs: 394743, Bias: 0.000000, T: 213120, Avg. loss: 0.819263\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 1.91, NNZs: 394743, Bias: 0.000000, T: 284160, Avg. loss: 0.806853\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.97, NNZs: 394743, Bias: 0.000000, T: 355200, Avg. loss: 0.795793\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.03, NNZs: 394743, Bias: 0.000000, T: 426240, Avg. loss: 0.786512\n",
      "Total training time: 0.92 seconds.\n",
      "Convergence after 6 epochs took 0.96 seconds\n",
      "[CV 3/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.28658617296069355, clf__eta0=0.03398405924608927, clf__fit_intercept=False, clf__l1_ratio=0.08227014493927165, clf__learning_rate=invscaling, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.5467473202425025, clf__shuffle=True, clf__tol=0.9099604695658384, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.450 total time=  48.2s\n",
      "-- Epoch 1\n",
      "Norm: 1.63, NNZs: 395339, Bias: 0.000000, T: 71040, Avg. loss: 0.823935\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.77, NNZs: 395339, Bias: 0.000000, T: 142080, Avg. loss: 0.829330\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.87, NNZs: 395339, Bias: 0.000000, T: 213120, Avg. loss: 0.815590\n",
      "Total training time: 0.43 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.94, NNZs: 395339, Bias: 0.000000, T: 284160, Avg. loss: 0.805963\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.01, NNZs: 395339, Bias: 0.000000, T: 355200, Avg. loss: 0.795743\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.07, NNZs: 395339, Bias: 0.000000, T: 426240, Avg. loss: 0.786223\n",
      "Total training time: 0.90 seconds.\n",
      "Convergence after 6 epochs took 0.93 seconds\n",
      "[CV 4/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.28658617296069355, clf__eta0=0.03398405924608927, clf__fit_intercept=False, clf__l1_ratio=0.08227014493927165, clf__learning_rate=invscaling, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.5467473202425025, clf__shuffle=True, clf__tol=0.9099604695658384, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.454 total time=  47.7s\n",
      "-- Epoch 1\n",
      "Norm: 1.60, NNZs: 393398, Bias: 0.000000, T: 71040, Avg. loss: 0.829149\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.74, NNZs: 393398, Bias: 0.000000, T: 142080, Avg. loss: 0.832330\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.84, NNZs: 393398, Bias: 0.000000, T: 213120, Avg. loss: 0.821884\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.91, NNZs: 393398, Bias: 0.000000, T: 284160, Avg. loss: 0.809581\n",
      "Total training time: 0.61 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.97, NNZs: 393398, Bias: 0.000000, T: 355200, Avg. loss: 0.799673\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.02, NNZs: 393398, Bias: 0.000000, T: 426240, Avg. loss: 0.790480\n",
      "Total training time: 0.93 seconds.\n",
      "Convergence after 6 epochs took 0.96 seconds\n",
      "[CV 5/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.28658617296069355, clf__eta0=0.03398405924608927, clf__fit_intercept=False, clf__l1_ratio=0.08227014493927165, clf__learning_rate=invscaling, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.5467473202425025, clf__shuffle=True, clf__tol=0.9099604695658384, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.442 total time=  47.7s\n",
      "-- Epoch 1\n",
      "Norm: 65.94, NNZs: 395429, Bias: 0.000000, T: 71040, Avg. loss: 0.286613\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 65.04, NNZs: 395429, Bias: 0.000000, T: 142080, Avg. loss: 0.246138\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 65.06, NNZs: 395429, Bias: 0.000000, T: 213120, Avg. loss: 0.246450\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 65.06, NNZs: 395429, Bias: 0.000000, T: 284160, Avg. loss: 0.246444\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 65.06, NNZs: 395429, Bias: 0.000000, T: 355200, Avg. loss: 0.246444\n",
      "Total training time: 0.88 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 65.06, NNZs: 395429, Bias: 0.000000, T: 426240, Avg. loss: 0.246444\n",
      "Total training time: 1.06 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 47.93, NNZs: 395429, Bias: 0.000000, T: 497280, Avg. loss: 0.184545\n",
      "Total training time: 1.25 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 45.77, NNZs: 395429, Bias: 0.000000, T: 568320, Avg. loss: 0.180872\n",
      "Total training time: 1.42 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 45.66, NNZs: 395429, Bias: 0.000000, T: 639360, Avg. loss: 0.182101\n",
      "Total training time: 1.61 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 45.65, NNZs: 395429, Bias: 0.000000, T: 710400, Avg. loss: 0.182308\n",
      "Total training time: 1.79 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 45.65, NNZs: 395429, Bias: 0.000000, T: 781440, Avg. loss: 0.182316\n",
      "Total training time: 1.97 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 44.69, NNZs: 395429, Bias: 0.000000, T: 852480, Avg. loss: 0.167332\n",
      "Total training time: 2.15 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 44.09, NNZs: 395429, Bias: 0.000000, T: 923520, Avg. loss: 0.167138\n",
      "Total training time: 2.33 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 43.72, NNZs: 395429, Bias: 0.000000, T: 994560, Avg. loss: 0.168179\n",
      "Total training time: 2.51 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 43.49, NNZs: 395429, Bias: 0.000000, T: 1065600, Avg. loss: 0.169070\n",
      "Total training time: 2.69 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 43.34, NNZs: 395429, Bias: 0.000000, T: 1136640, Avg. loss: 0.169720\n",
      "Total training time: 2.86 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 43.29, NNZs: 395429, Bias: 0.000000, T: 1207680, Avg. loss: 0.164629\n",
      "Total training time: 3.05 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 43.23, NNZs: 395429, Bias: 0.000000, T: 1278720, Avg. loss: 0.166507\n",
      "Total training time: 3.23 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 43.18, NNZs: 395429, Bias: 0.000000, T: 1349760, Avg. loss: 0.166664\n",
      "Total training time: 3.42 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 43.13, NNZs: 395429, Bias: 0.000000, T: 1420800, Avg. loss: 0.166801\n",
      "Total training time: 3.60 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.42493015701647596, clf__eta0=0.6773009699604285, clf__fit_intercept=False, clf__l1_ratio=0.7301998277223162, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.017782879504616322, clf__shuffle=False, clf__tol=0.19519881462597577, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.679 total time=  50.4s\n",
      "-- Epoch 1\n",
      "Norm: 69.29, NNZs: 395504, Bias: 0.000000, T: 71040, Avg. loss: 0.283130\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 68.22, NNZs: 395504, Bias: 0.000000, T: 142080, Avg. loss: 0.244460\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 68.25, NNZs: 395504, Bias: 0.000000, T: 213120, Avg. loss: 0.244760\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 68.25, NNZs: 395504, Bias: 0.000000, T: 284160, Avg. loss: 0.244751\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 68.25, NNZs: 395504, Bias: 0.000000, T: 355200, Avg. loss: 0.244751\n",
      "Total training time: 0.90 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 68.25, NNZs: 395504, Bias: 0.000000, T: 426240, Avg. loss: 0.244751\n",
      "Total training time: 1.08 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 48.73, NNZs: 395504, Bias: 0.000000, T: 497280, Avg. loss: 0.182552\n",
      "Total training time: 1.29 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 46.26, NNZs: 395504, Bias: 0.000000, T: 568320, Avg. loss: 0.180364\n",
      "Total training time: 1.47 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 46.14, NNZs: 395504, Bias: 0.000000, T: 639360, Avg. loss: 0.181978\n",
      "Total training time: 1.65 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 46.12, NNZs: 395504, Bias: 0.000000, T: 710400, Avg. loss: 0.182354\n",
      "Total training time: 1.83 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 46.13, NNZs: 395504, Bias: 0.000000, T: 781440, Avg. loss: 0.182345\n",
      "Total training time: 2.02 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 45.08, NNZs: 395504, Bias: 0.000000, T: 852480, Avg. loss: 0.166095\n",
      "Total training time: 2.21 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 44.36, NNZs: 395504, Bias: 0.000000, T: 923520, Avg. loss: 0.165684\n",
      "Total training time: 2.39 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 43.91, NNZs: 395504, Bias: 0.000000, T: 994560, Avg. loss: 0.167220\n",
      "Total training time: 2.58 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 43.63, NNZs: 395504, Bias: 0.000000, T: 1065600, Avg. loss: 0.168503\n",
      "Total training time: 2.76 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 43.45, NNZs: 395504, Bias: 0.000000, T: 1136640, Avg. loss: 0.169406\n",
      "Total training time: 2.95 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 43.40, NNZs: 395504, Bias: 0.000000, T: 1207680, Avg. loss: 0.165957\n",
      "Total training time: 3.14 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 43.34, NNZs: 395504, Bias: 0.000000, T: 1278720, Avg. loss: 0.166856\n",
      "Total training time: 3.32 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 43.29, NNZs: 395504, Bias: 0.000000, T: 1349760, Avg. loss: 0.166689\n",
      "Total training time: 3.50 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 43.24, NNZs: 395504, Bias: 0.000000, T: 1420800, Avg. loss: 0.166654\n",
      "Total training time: 3.68 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.42493015701647596, clf__eta0=0.6773009699604285, clf__fit_intercept=False, clf__l1_ratio=0.7301998277223162, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.017782879504616322, clf__shuffle=False, clf__tol=0.19519881462597577, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.684 total time=  50.4s\n",
      "-- Epoch 1\n",
      "Norm: 69.10, NNZs: 394756, Bias: 0.000000, T: 71040, Avg. loss: 0.277659\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 68.03, NNZs: 394756, Bias: 0.000000, T: 142080, Avg. loss: 0.240206\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 68.06, NNZs: 394756, Bias: 0.000000, T: 213120, Avg. loss: 0.240451\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 68.06, NNZs: 394756, Bias: 0.000000, T: 284160, Avg. loss: 0.240447\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 68.06, NNZs: 394756, Bias: 0.000000, T: 355200, Avg. loss: 0.240447\n",
      "Total training time: 0.98 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 68.06, NNZs: 394756, Bias: 0.000000, T: 426240, Avg. loss: 0.240447\n",
      "Total training time: 1.16 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 48.37, NNZs: 394756, Bias: 0.000000, T: 497280, Avg. loss: 0.180714\n",
      "Total training time: 1.34 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 45.77, NNZs: 394756, Bias: 0.000000, T: 568320, Avg. loss: 0.176893\n",
      "Total training time: 1.52 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 45.63, NNZs: 394756, Bias: 0.000000, T: 639360, Avg. loss: 0.178730\n",
      "Total training time: 1.70 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 45.62, NNZs: 394756, Bias: 0.000000, T: 710400, Avg. loss: 0.178993\n",
      "Total training time: 1.89 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 45.62, NNZs: 394756, Bias: 0.000000, T: 781440, Avg. loss: 0.178993\n",
      "Total training time: 2.08 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 44.65, NNZs: 394756, Bias: 0.000000, T: 852480, Avg. loss: 0.163831\n",
      "Total training time: 2.27 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 44.00, NNZs: 394756, Bias: 0.000000, T: 923520, Avg. loss: 0.163113\n",
      "Total training time: 2.47 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 43.58, NNZs: 394756, Bias: 0.000000, T: 994560, Avg. loss: 0.164501\n",
      "Total training time: 2.66 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 43.33, NNZs: 394756, Bias: 0.000000, T: 1065600, Avg. loss: 0.165650\n",
      "Total training time: 2.85 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 43.16, NNZs: 394756, Bias: 0.000000, T: 1136640, Avg. loss: 0.166449\n",
      "Total training time: 3.05 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 43.12, NNZs: 394756, Bias: 0.000000, T: 1207680, Avg. loss: 0.162892\n",
      "Total training time: 3.26 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 43.07, NNZs: 394756, Bias: 0.000000, T: 1278720, Avg. loss: 0.163780\n",
      "Total training time: 3.45 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 43.02, NNZs: 394756, Bias: 0.000000, T: 1349760, Avg. loss: 0.163673\n",
      "Total training time: 3.63 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 42.98, NNZs: 394756, Bias: 0.000000, T: 1420800, Avg. loss: 0.163659\n",
      "Total training time: 3.83 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.42493015701647596, clf__eta0=0.6773009699604285, clf__fit_intercept=False, clf__l1_ratio=0.7301998277223162, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.017782879504616322, clf__shuffle=False, clf__tol=0.19519881462597577, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.684 total time=  50.2s\n",
      "-- Epoch 1\n",
      "Norm: 68.87, NNZs: 395339, Bias: 0.000000, T: 71040, Avg. loss: 0.278261\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 67.91, NNZs: 395339, Bias: 0.000000, T: 142080, Avg. loss: 0.242255\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 67.93, NNZs: 395339, Bias: 0.000000, T: 213120, Avg. loss: 0.242294\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 67.93, NNZs: 395339, Bias: 0.000000, T: 284160, Avg. loss: 0.242297\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 67.93, NNZs: 395339, Bias: 0.000000, T: 355200, Avg. loss: 0.242297\n",
      "Total training time: 1.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 67.93, NNZs: 395339, Bias: 0.000000, T: 426240, Avg. loss: 0.242297\n",
      "Total training time: 1.21 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 48.14, NNZs: 395339, Bias: 0.000000, T: 497280, Avg. loss: 0.179898\n",
      "Total training time: 1.41 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 45.61, NNZs: 395339, Bias: 0.000000, T: 568320, Avg. loss: 0.176289\n",
      "Total training time: 1.61 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 45.46, NNZs: 395339, Bias: 0.000000, T: 639360, Avg. loss: 0.178192\n",
      "Total training time: 1.80 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 45.44, NNZs: 395339, Bias: 0.000000, T: 710400, Avg. loss: 0.178511\n",
      "Total training time: 1.99 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 45.45, NNZs: 395339, Bias: 0.000000, T: 781440, Avg. loss: 0.178522\n",
      "Total training time: 2.17 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 44.54, NNZs: 395339, Bias: 0.000000, T: 852480, Avg. loss: 0.163379\n",
      "Total training time: 2.35 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 43.93, NNZs: 395339, Bias: 0.000000, T: 923520, Avg. loss: 0.163371\n",
      "Total training time: 2.55 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 43.54, NNZs: 395339, Bias: 0.000000, T: 994560, Avg. loss: 0.164616\n",
      "Total training time: 2.74 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 43.30, NNZs: 395339, Bias: 0.000000, T: 1065600, Avg. loss: 0.165648\n",
      "Total training time: 2.94 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 43.15, NNZs: 395339, Bias: 0.000000, T: 1136640, Avg. loss: 0.166381\n",
      "Total training time: 3.14 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 43.09, NNZs: 395339, Bias: 0.000000, T: 1207680, Avg. loss: 0.162873\n",
      "Total training time: 3.34 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 43.04, NNZs: 395339, Bias: 0.000000, T: 1278720, Avg. loss: 0.163326\n",
      "Total training time: 3.54 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 42.99, NNZs: 395339, Bias: 0.000000, T: 1349760, Avg. loss: 0.163411\n",
      "Total training time: 3.73 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 42.94, NNZs: 395339, Bias: 0.000000, T: 1420800, Avg. loss: 0.163520\n",
      "Total training time: 3.92 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.42493015701647596, clf__eta0=0.6773009699604285, clf__fit_intercept=False, clf__l1_ratio=0.7301998277223162, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.017782879504616322, clf__shuffle=False, clf__tol=0.19519881462597577, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.691 total time=  51.3s\n",
      "-- Epoch 1\n",
      "Norm: 72.96, NNZs: 393403, Bias: 0.000000, T: 71040, Avg. loss: 0.290988\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 72.00, NNZs: 393403, Bias: 0.000000, T: 142080, Avg. loss: 0.255921\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 72.02, NNZs: 393403, Bias: 0.000000, T: 213120, Avg. loss: 0.255833\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 72.02, NNZs: 393403, Bias: 0.000000, T: 284160, Avg. loss: 0.255842\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 72.02, NNZs: 393403, Bias: 0.000000, T: 355200, Avg. loss: 0.255842\n",
      "Total training time: 0.97 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 72.02, NNZs: 393403, Bias: 0.000000, T: 426240, Avg. loss: 0.255842\n",
      "Total training time: 1.16 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 49.55, NNZs: 393403, Bias: 0.000000, T: 497280, Avg. loss: 0.191558\n",
      "Total training time: 1.35 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 46.62, NNZs: 393403, Bias: 0.000000, T: 568320, Avg. loss: 0.181461\n",
      "Total training time: 1.54 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 46.41, NNZs: 393403, Bias: 0.000000, T: 639360, Avg. loss: 0.182887\n",
      "Total training time: 1.73 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 46.39, NNZs: 393403, Bias: 0.000000, T: 710400, Avg. loss: 0.183159\n",
      "Total training time: 1.92 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 46.39, NNZs: 393403, Bias: 0.000000, T: 781440, Avg. loss: 0.183197\n",
      "Total training time: 2.13 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 45.31, NNZs: 393403, Bias: 0.000000, T: 852480, Avg. loss: 0.173785\n",
      "Total training time: 2.33 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 44.61, NNZs: 393403, Bias: 0.000000, T: 923520, Avg. loss: 0.166255\n",
      "Total training time: 2.52 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 44.16, NNZs: 393403, Bias: 0.000000, T: 994560, Avg. loss: 0.167913\n",
      "Total training time: 2.72 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 43.88, NNZs: 393403, Bias: 0.000000, T: 1065600, Avg. loss: 0.169264\n",
      "Total training time: 2.93 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 43.70, NNZs: 393403, Bias: 0.000000, T: 1136640, Avg. loss: 0.170183\n",
      "Total training time: 3.15 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 43.63, NNZs: 393403, Bias: 0.000000, T: 1207680, Avg. loss: 0.170249\n",
      "Total training time: 3.34 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 43.58, NNZs: 393403, Bias: 0.000000, T: 1278720, Avg. loss: 0.167462\n",
      "Total training time: 3.54 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 43.52, NNZs: 393403, Bias: 0.000000, T: 1349760, Avg. loss: 0.167266\n",
      "Total training time: 3.74 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 43.47, NNZs: 393403, Bias: 0.000000, T: 1420800, Avg. loss: 0.167269\n",
      "Total training time: 3.94 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.42493015701647596, clf__eta0=0.6773009699604285, clf__fit_intercept=False, clf__l1_ratio=0.7301998277223162, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.017782879504616322, clf__shuffle=False, clf__tol=0.19519881462597577, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.697 total time=  51.8s\n",
      "-- Epoch 1\n",
      "Norm: 50.09, NNZs: 228745, Bias: 2.038632, T: 71040, Avg. loss: 0.245609\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 30.71, NNZs: 242307, Bias: 1.783376, T: 142080, Avg. loss: 0.008862\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 22.75, NNZs: 246170, Bias: 1.649319, T: 213120, Avg. loss: 0.002793\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 18.52, NNZs: 247586, Bias: 1.553333, T: 284160, Avg. loss: 0.000979\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 16.03, NNZs: 248620, Bias: 1.478441, T: 355200, Avg. loss: 0.000742\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 13.86, NNZs: 248958, Bias: 1.448149, T: 426240, Avg. loss: 0.000349\n",
      "Total training time: 0.71 seconds.\n",
      "Convergence after 6 epochs took 0.75 seconds\n",
      "[CV 1/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.21123614325601048, clf__eta0=0.32979731781585486, clf__fit_intercept=True, clf__l1_ratio=0.4775095579144826, clf__learning_rate=optimal, clf__loss=perceptron, clf__max_iter=30, clf__penalty=l2, clf__power_t=0.6427671735097384, clf__shuffle=False, clf__tol=0.2651165400908262, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.946 total time=  48.0s\n",
      "-- Epoch 1\n",
      "Norm: 53.33, NNZs: 227628, Bias: 2.600506, T: 71040, Avg. loss: 0.288347\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 32.57, NNZs: 237073, Bias: 2.240110, T: 142080, Avg. loss: 0.008736\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 24.11, NNZs: 239468, Bias: 2.081054, T: 213120, Avg. loss: 0.002454\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 19.84, NNZs: 240194, Bias: 1.973106, T: 284160, Avg. loss: 0.001116\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 17.38, NNZs: 241522, Bias: 1.889325, T: 355200, Avg. loss: 0.001115\n",
      "Total training time: 0.54 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 15.06, NNZs: 242206, Bias: 1.862918, T: 426240, Avg. loss: 0.000696\n",
      "Total training time: 0.65 seconds.\n",
      "Convergence after 6 epochs took 0.69 seconds\n",
      "[CV 2/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.21123614325601048, clf__eta0=0.32979731781585486, clf__fit_intercept=True, clf__l1_ratio=0.4775095579144826, clf__learning_rate=optimal, clf__loss=perceptron, clf__max_iter=30, clf__penalty=l2, clf__power_t=0.6427671735097384, clf__shuffle=False, clf__tol=0.2651165400908262, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.883 total time=  47.5s\n",
      "-- Epoch 1\n",
      "Norm: 49.93, NNZs: 207076, Bias: 2.008908, T: 71040, Avg. loss: 0.334368\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 29.86, NNZs: 223740, Bias: 1.752017, T: 142080, Avg. loss: 0.007013\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 22.74, NNZs: 230919, Bias: 1.587724, T: 213120, Avg. loss: 0.002977\n",
      "Total training time: 0.30 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 18.56, NNZs: 234560, Bias: 1.499477, T: 284160, Avg. loss: 0.001528\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 15.80, NNZs: 235598, Bias: 1.444366, T: 355200, Avg. loss: 0.000657\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 13.89, NNZs: 236457, Bias: 1.403903, T: 426240, Avg. loss: 0.000642\n",
      "Total training time: 0.62 seconds.\n",
      "Convergence after 6 epochs took 0.66 seconds\n",
      "[CV 3/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.21123614325601048, clf__eta0=0.32979731781585486, clf__fit_intercept=True, clf__l1_ratio=0.4775095579144826, clf__learning_rate=optimal, clf__loss=perceptron, clf__max_iter=30, clf__penalty=l2, clf__power_t=0.6427671735097384, clf__shuffle=False, clf__tol=0.2651165400908262, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.892 total time=  47.3s\n",
      "-- Epoch 1\n",
      "Norm: 51.62, NNZs: 220934, Bias: 2.072691, T: 71040, Avg. loss: 0.318624\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 30.79, NNZs: 237690, Bias: 1.794383, T: 142080, Avg. loss: 0.006377\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 22.68, NNZs: 243314, Bias: 1.702026, T: 213120, Avg. loss: 0.003006\n",
      "Total training time: 0.30 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 18.48, NNZs: 245405, Bias: 1.608536, T: 284160, Avg. loss: 0.001081\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 15.83, NNZs: 246312, Bias: 1.544066, T: 355200, Avg. loss: 0.000466\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 13.89, NNZs: 246661, Bias: 1.504369, T: 426240, Avg. loss: 0.000469\n",
      "Total training time: 0.63 seconds.\n",
      "Convergence after 6 epochs took 0.66 seconds\n",
      "[CV 4/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.21123614325601048, clf__eta0=0.32979731781585486, clf__fit_intercept=True, clf__l1_ratio=0.4775095579144826, clf__learning_rate=optimal, clf__loss=perceptron, clf__max_iter=30, clf__penalty=l2, clf__power_t=0.6427671735097384, clf__shuffle=False, clf__tol=0.2651165400908262, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.926 total time=  47.1s\n",
      "-- Epoch 1\n",
      "Norm: 51.23, NNZs: 222079, Bias: 2.205495, T: 71040, Avg. loss: 0.318318\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 31.91, NNZs: 241636, Bias: 1.921509, T: 142080, Avg. loss: 0.010044\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 23.59, NNZs: 243769, Bias: 1.758898, T: 213120, Avg. loss: 0.001629\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 19.36, NNZs: 246095, Bias: 1.664143, T: 284160, Avg. loss: 0.001331\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 16.59, NNZs: 247128, Bias: 1.598390, T: 355200, Avg. loss: 0.000709\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 14.43, NNZs: 247676, Bias: 1.564870, T: 426240, Avg. loss: 0.000395\n",
      "Total training time: 0.64 seconds.\n",
      "Convergence after 6 epochs took 0.67 seconds\n",
      "[CV 5/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.21123614325601048, clf__eta0=0.32979731781585486, clf__fit_intercept=True, clf__l1_ratio=0.4775095579144826, clf__learning_rate=optimal, clf__loss=perceptron, clf__max_iter=30, clf__penalty=l2, clf__power_t=0.6427671735097384, clf__shuffle=False, clf__tol=0.2651165400908262, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.922 total time=  47.2s\n",
      "-- Epoch 1\n",
      "Norm: 90.07, NNZs: 209, Bias: 0.000000, T: 88800, Avg. loss: 0.019347\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 118.35, NNZs: 104, Bias: 0.000000, T: 177600, Avg. loss: 0.012324\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 139.48, NNZs: 93, Bias: 0.000000, T: 266400, Avg. loss: 0.011059\n",
      "Total training time: 0.91 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 156.93, NNZs: 87, Bias: 0.000000, T: 355200, Avg. loss: 0.010546\n",
      "Total training time: 1.21 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 172.17, NNZs: 84, Bias: 0.000000, T: 444000, Avg. loss: 0.010145\n",
      "Total training time: 1.53 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 185.95, NNZs: 88, Bias: 0.000000, T: 532800, Avg. loss: 0.010008\n",
      "Total training time: 1.85 seconds.\n",
      "Convergence after 6 epochs took 1.90 seconds\n",
      "0.9991891891891892\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          Ja       0.99      0.93      0.96       291\n",
      "         Nee       1.00      1.00      1.00     29309\n",
      "\n",
      "    accuracy                           1.00     29600\n",
      "   macro avg       0.99      0.97      0.98     29600\n",
      "weighted avg       1.00      1.00      1.00     29600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ngram 2 Less stopwords\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1,2), lowercase=True, token_pattern=r\"(?u)\\b\\w\\w+\\b|\\+|\\-\")),\n",
    "    ('clf', SGDClassifier(early_stopping=True, n_iter_no_change=5, validation_fraction = 0.25, verbose=3)),\n",
    "])\n",
    "random_search = RandomizedSearchCV(estimator=pipeline, param_distributions=parameter_grid, random_state=500, verbose=3, scoring='f1_macro')\n",
    "random_search.fit(X_train, y_train)  \n",
    "predicted_nb = random_search.predict(X_test)\n",
    "print(np.mean(predicted_nb == y_test))\n",
    "cm = confusion_matrix(y_test, predicted_nb)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=random_search.classes_)\n",
    "disp.plot()\n",
    "\n",
    "plt.show()\n",
    "print(metrics.classification_report(y_test, predicted_nb,\n",
    "    target_names=random_search.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12a779f",
   "metadata": {},
   "source": [
    "# No stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd3b8699",
   "metadata": {},
   "outputs": [],
   "source": [
    "Corpus[\"text\"] = Corpus[\"text\"].apply(no_stopwords)\n",
    "X_train, X_test, y_train, y_test = train_test_split(Corpus['text'], Corpus['label'], test_size=0.2, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a48f492d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "-- Epoch 1\n",
      "Norm: 88.59, NNZs: 309, Bias: 0.000000, T: 71040, Avg. loss: 0.082622\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 119.05, NNZs: 117, Bias: 0.000000, T: 142080, Avg. loss: 0.057881\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 141.91, NNZs: 90, Bias: 0.000000, T: 213120, Avg. loss: 0.053001\n",
      "Total training time: 1.17 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 160.90, NNZs: 80, Bias: 0.000000, T: 284160, Avg. loss: 0.050142\n",
      "Total training time: 1.57 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 177.38, NNZs: 75, Bias: 0.000000, T: 355200, Avg. loss: 0.048463\n",
      "Total training time: 1.99 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 192.30, NNZs: 67, Bias: 0.000000, T: 426240, Avg. loss: 0.047736\n",
      "Total training time: 2.41 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 194.98, NNZs: 67, Bias: 0.000000, T: 497280, Avg. loss: 0.047121\n",
      "Total training time: 2.83 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 197.62, NNZs: 67, Bias: 0.000000, T: 568320, Avg. loss: 0.047078\n",
      "Total training time: 3.21 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 200.24, NNZs: 66, Bias: 0.000000, T: 639360, Avg. loss: 0.046958\n",
      "Total training time: 3.60 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 202.78, NNZs: 63, Bias: 0.000000, T: 710400, Avg. loss: 0.046843\n",
      "Total training time: 3.97 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 205.31, NNZs: 63, Bias: 0.000000, T: 781440, Avg. loss: 0.046749\n",
      "Total training time: 4.33 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 205.80, NNZs: 63, Bias: 0.000000, T: 852480, Avg. loss: 0.046661\n",
      "Total training time: 4.72 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 206.29, NNZs: 63, Bias: 0.000000, T: 923520, Avg. loss: 0.046655\n",
      "Total training time: 5.10 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 206.77, NNZs: 63, Bias: 0.000000, T: 994560, Avg. loss: 0.046623\n",
      "Total training time: 5.49 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 207.26, NNZs: 63, Bias: 0.000000, T: 1065600, Avg. loss: 0.046630\n",
      "Total training time: 5.88 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 207.75, NNZs: 63, Bias: 0.000000, T: 1136640, Avg. loss: 0.046610\n",
      "Total training time: 6.29 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 207.85, NNZs: 63, Bias: 0.000000, T: 1207680, Avg. loss: 0.046600\n",
      "Total training time: 6.68 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 207.94, NNZs: 63, Bias: 0.000000, T: 1278720, Avg. loss: 0.046597\n",
      "Total training time: 7.09 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 208.04, NNZs: 63, Bias: 0.000000, T: 1349760, Avg. loss: 0.046594\n",
      "Total training time: 7.50 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 208.14, NNZs: 63, Bias: 0.000000, T: 1420800, Avg. loss: 0.046590\n",
      "Total training time: 7.90 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.06171699256249541, clf__eta0=0.6666115972798587, clf__fit_intercept=False, clf__l1_ratio=0.9792901432894962, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.15075392531110676, clf__shuffle=True, clf__tol=0.365636830734297, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.183 total time=  56.0s\n",
      "-- Epoch 1\n",
      "Norm: 88.19, NNZs: 312, Bias: 0.000000, T: 71040, Avg. loss: 0.082957\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 118.22, NNZs: 115, Bias: 0.000000, T: 142080, Avg. loss: 0.059081\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 141.28, NNZs: 94, Bias: 0.000000, T: 213120, Avg. loss: 0.053909\n",
      "Total training time: 1.06 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 160.18, NNZs: 80, Bias: 0.000000, T: 284160, Avg. loss: 0.051067\n",
      "Total training time: 1.42 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 176.77, NNZs: 75, Bias: 0.000000, T: 355200, Avg. loss: 0.049572\n",
      "Total training time: 1.77 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 191.64, NNZs: 68, Bias: 0.000000, T: 426240, Avg. loss: 0.048571\n",
      "Total training time: 2.13 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 194.30, NNZs: 66, Bias: 0.000000, T: 497280, Avg. loss: 0.048126\n",
      "Total training time: 2.49 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 196.97, NNZs: 65, Bias: 0.000000, T: 568320, Avg. loss: 0.047999\n",
      "Total training time: 2.87 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 199.56, NNZs: 65, Bias: 0.000000, T: 639360, Avg. loss: 0.047860\n",
      "Total training time: 3.25 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 202.09, NNZs: 65, Bias: 0.000000, T: 710400, Avg. loss: 0.047740\n",
      "Total training time: 3.63 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 204.64, NNZs: 65, Bias: 0.000000, T: 781440, Avg. loss: 0.047641\n",
      "Total training time: 4.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 205.13, NNZs: 65, Bias: 0.000000, T: 852480, Avg. loss: 0.047592\n",
      "Total training time: 4.40 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 205.62, NNZs: 65, Bias: 0.000000, T: 923520, Avg. loss: 0.047584\n",
      "Total training time: 4.77 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 206.10, NNZs: 65, Bias: 0.000000, T: 994560, Avg. loss: 0.047570\n",
      "Total training time: 5.15 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 206.59, NNZs: 65, Bias: 0.000000, T: 1065600, Avg. loss: 0.047556\n",
      "Total training time: 5.54 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 207.08, NNZs: 65, Bias: 0.000000, T: 1136640, Avg. loss: 0.047537\n",
      "Total training time: 5.91 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 207.18, NNZs: 65, Bias: 0.000000, T: 1207680, Avg. loss: 0.047537\n",
      "Total training time: 6.29 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 207.27, NNZs: 65, Bias: 0.000000, T: 1278720, Avg. loss: 0.047532\n",
      "Total training time: 6.67 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 207.37, NNZs: 65, Bias: 0.000000, T: 1349760, Avg. loss: 0.047530\n",
      "Total training time: 7.02 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 207.47, NNZs: 65, Bias: 0.000000, T: 1420800, Avg. loss: 0.047527\n",
      "Total training time: 7.37 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.06171699256249541, clf__eta0=0.6666115972798587, clf__fit_intercept=False, clf__l1_ratio=0.9792901432894962, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.15075392531110676, clf__shuffle=True, clf__tol=0.365636830734297, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.185 total time=  55.6s\n",
      "-- Epoch 1\n",
      "Norm: 87.99, NNZs: 288, Bias: 0.000000, T: 71040, Avg. loss: 0.083294\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 118.27, NNZs: 119, Bias: 0.000000, T: 142080, Avg. loss: 0.059643\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 141.07, NNZs: 93, Bias: 0.000000, T: 213120, Avg. loss: 0.053849\n",
      "Total training time: 1.09 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 159.97, NNZs: 85, Bias: 0.000000, T: 284160, Avg. loss: 0.051505\n",
      "Total training time: 1.47 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 176.51, NNZs: 77, Bias: 0.000000, T: 355200, Avg. loss: 0.049819\n",
      "Total training time: 1.84 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 191.23, NNZs: 69, Bias: 0.000000, T: 426240, Avg. loss: 0.049180\n",
      "Total training time: 2.21 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 193.99, NNZs: 69, Bias: 0.000000, T: 497280, Avg. loss: 0.048654\n",
      "Total training time: 2.63 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 196.63, NNZs: 68, Bias: 0.000000, T: 568320, Avg. loss: 0.048470\n",
      "Total training time: 3.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 199.23, NNZs: 66, Bias: 0.000000, T: 639360, Avg. loss: 0.048325\n",
      "Total training time: 3.41 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 201.77, NNZs: 66, Bias: 0.000000, T: 710400, Avg. loss: 0.048263\n",
      "Total training time: 3.82 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 204.27, NNZs: 66, Bias: 0.000000, T: 781440, Avg. loss: 0.048120\n",
      "Total training time: 4.20 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 204.77, NNZs: 66, Bias: 0.000000, T: 852480, Avg. loss: 0.048089\n",
      "Total training time: 4.59 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 205.26, NNZs: 65, Bias: 0.000000, T: 923520, Avg. loss: 0.048072\n",
      "Total training time: 4.94 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 205.75, NNZs: 64, Bias: 0.000000, T: 994560, Avg. loss: 0.048050\n",
      "Total training time: 5.29 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 206.24, NNZs: 64, Bias: 0.000000, T: 1065600, Avg. loss: 0.048032\n",
      "Total training time: 5.65 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 206.72, NNZs: 64, Bias: 0.000000, T: 1136640, Avg. loss: 0.048014\n",
      "Total training time: 6.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 206.82, NNZs: 64, Bias: 0.000000, T: 1207680, Avg. loss: 0.048003\n",
      "Total training time: 6.37 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 206.92, NNZs: 64, Bias: 0.000000, T: 1278720, Avg. loss: 0.048001\n",
      "Total training time: 6.74 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 207.01, NNZs: 64, Bias: 0.000000, T: 1349760, Avg. loss: 0.047997\n",
      "Total training time: 7.10 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 207.11, NNZs: 64, Bias: 0.000000, T: 1420800, Avg. loss: 0.047994\n",
      "Total training time: 7.47 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.06171699256249541, clf__eta0=0.6666115972798587, clf__fit_intercept=False, clf__l1_ratio=0.9792901432894962, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.15075392531110676, clf__shuffle=True, clf__tol=0.365636830734297, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.186 total time=  54.6s\n",
      "-- Epoch 1\n",
      "Norm: 88.05, NNZs: 264, Bias: 0.000000, T: 71040, Avg. loss: 0.083431\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 118.34, NNZs: 121, Bias: 0.000000, T: 142080, Avg. loss: 0.059230\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 141.27, NNZs: 92, Bias: 0.000000, T: 213120, Avg. loss: 0.053730\n",
      "Total training time: 1.12 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 160.23, NNZs: 82, Bias: 0.000000, T: 284160, Avg. loss: 0.050990\n",
      "Total training time: 1.51 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 176.86, NNZs: 74, Bias: 0.000000, T: 355200, Avg. loss: 0.049719\n",
      "Total training time: 1.88 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 191.73, NNZs: 69, Bias: 0.000000, T: 426240, Avg. loss: 0.048591\n",
      "Total training time: 2.25 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 194.35, NNZs: 67, Bias: 0.000000, T: 497280, Avg. loss: 0.048218\n",
      "Total training time: 2.61 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 197.00, NNZs: 66, Bias: 0.000000, T: 568320, Avg. loss: 0.048098\n",
      "Total training time: 2.97 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 199.62, NNZs: 65, Bias: 0.000000, T: 639360, Avg. loss: 0.047962\n",
      "Total training time: 3.35 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 202.13, NNZs: 65, Bias: 0.000000, T: 710400, Avg. loss: 0.047839\n",
      "Total training time: 3.73 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 204.69, NNZs: 64, Bias: 0.000000, T: 781440, Avg. loss: 0.047796\n",
      "Total training time: 4.09 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 205.19, NNZs: 64, Bias: 0.000000, T: 852480, Avg. loss: 0.047671\n",
      "Total training time: 4.48 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 205.68, NNZs: 64, Bias: 0.000000, T: 923520, Avg. loss: 0.047649\n",
      "Total training time: 4.85 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 206.17, NNZs: 63, Bias: 0.000000, T: 994560, Avg. loss: 0.047635\n",
      "Total training time: 5.22 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 206.66, NNZs: 63, Bias: 0.000000, T: 1065600, Avg. loss: 0.047618\n",
      "Total training time: 5.62 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 207.15, NNZs: 63, Bias: 0.000000, T: 1136640, Avg. loss: 0.047597\n",
      "Total training time: 5.99 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 207.24, NNZs: 63, Bias: 0.000000, T: 1207680, Avg. loss: 0.047578\n",
      "Total training time: 6.35 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 207.34, NNZs: 63, Bias: 0.000000, T: 1278720, Avg. loss: 0.047575\n",
      "Total training time: 6.72 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 207.44, NNZs: 63, Bias: 0.000000, T: 1349760, Avg. loss: 0.047570\n",
      "Total training time: 7.12 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 207.53, NNZs: 63, Bias: 0.000000, T: 1420800, Avg. loss: 0.047567\n",
      "Total training time: 7.51 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.06171699256249541, clf__eta0=0.6666115972798587, clf__fit_intercept=False, clf__l1_ratio=0.9792901432894962, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.15075392531110676, clf__shuffle=True, clf__tol=0.365636830734297, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.179 total time=  55.1s\n",
      "-- Epoch 1\n",
      "Norm: 88.02, NNZs: 295, Bias: 0.000000, T: 71040, Avg. loss: 0.083401\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 118.48, NNZs: 118, Bias: 0.000000, T: 142080, Avg. loss: 0.059064\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 141.34, NNZs: 96, Bias: 0.000000, T: 213120, Avg. loss: 0.053520\n",
      "Total training time: 1.19 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 160.40, NNZs: 80, Bias: 0.000000, T: 284160, Avg. loss: 0.050691\n",
      "Total training time: 1.58 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 176.91, NNZs: 73, Bias: 0.000000, T: 355200, Avg. loss: 0.049327\n",
      "Total training time: 1.95 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 191.82, NNZs: 69, Bias: 0.000000, T: 426240, Avg. loss: 0.048273\n",
      "Total training time: 2.33 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 194.52, NNZs: 66, Bias: 0.000000, T: 497280, Avg. loss: 0.047851\n",
      "Total training time: 2.71 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 197.20, NNZs: 64, Bias: 0.000000, T: 568320, Avg. loss: 0.047694\n",
      "Total training time: 3.09 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 199.81, NNZs: 64, Bias: 0.000000, T: 639360, Avg. loss: 0.047497\n",
      "Total training time: 3.47 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 202.32, NNZs: 64, Bias: 0.000000, T: 710400, Avg. loss: 0.047408\n",
      "Total training time: 3.84 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 204.87, NNZs: 62, Bias: 0.000000, T: 781440, Avg. loss: 0.047327\n",
      "Total training time: 4.23 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 205.37, NNZs: 62, Bias: 0.000000, T: 852480, Avg. loss: 0.047201\n",
      "Total training time: 4.62 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 205.86, NNZs: 62, Bias: 0.000000, T: 923520, Avg. loss: 0.047174\n",
      "Total training time: 5.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 206.35, NNZs: 61, Bias: 0.000000, T: 994560, Avg. loss: 0.047152\n",
      "Total training time: 5.40 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 206.84, NNZs: 61, Bias: 0.000000, T: 1065600, Avg. loss: 0.047127\n",
      "Total training time: 5.77 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 207.33, NNZs: 60, Bias: 0.000000, T: 1136640, Avg. loss: 0.047118\n",
      "Total training time: 6.14 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 207.43, NNZs: 60, Bias: 0.000000, T: 1207680, Avg. loss: 0.047094\n",
      "Total training time: 6.53 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 207.53, NNZs: 60, Bias: 0.000000, T: 1278720, Avg. loss: 0.047088\n",
      "Total training time: 6.91 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 207.62, NNZs: 60, Bias: 0.000000, T: 1349760, Avg. loss: 0.047083\n",
      "Total training time: 7.31 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 207.72, NNZs: 60, Bias: 0.000000, T: 1420800, Avg. loss: 0.047076\n",
      "Total training time: 7.73 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.06171699256249541, clf__eta0=0.6666115972798587, clf__fit_intercept=False, clf__l1_ratio=0.9792901432894962, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.15075392531110676, clf__shuffle=True, clf__tol=0.365636830734297, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.183 total time=  55.0s\n",
      "-- Epoch 1\n",
      "Norm: 119206172009120.28, NNZs: 393895, Bias: 0.000000, T: 71040, Avg. loss: 137835144452841161097216.000000\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 112588723728507.36, NNZs: 393895, Bias: 0.000000, T: 142080, Avg. loss: 119320075638963651477504.000000\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 109221548206647.45, NNZs: 393895, Bias: 0.000000, T: 213120, Avg. loss: 98974199811005017489408.000000\n",
      "Total training time: 1.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 106996807467761.23, NNZs: 393895, Bias: 0.000000, T: 284160, Avg. loss: 89535250782530350088192.000000\n",
      "Total training time: 1.34 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 105353155119339.30, NNZs: 393895, Bias: 0.000000, T: 355200, Avg. loss: 83709018612574378262528.000000\n",
      "Total training time: 1.69 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 104055963745069.09, NNZs: 393895, Bias: 0.000000, T: 426240, Avg. loss: 79627974546193918197760.000000\n",
      "Total training time: 2.04 seconds.\n",
      "Convergence after 6 epochs took 2.07 seconds\n",
      "[CV 1/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.7915127974877743, clf__eta0=0.05539740212799926, clf__fit_intercept=False, clf__l1_ratio=0.9152680641407671, clf__learning_rate=optimal, clf__loss=squared_epsilon_insensitive, clf__max_iter=80, clf__penalty=l1, clf__power_t=0.6359093112142983, clf__shuffle=True, clf__tol=0.9361199211609239, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.340 total time=  48.8s\n",
      "-- Epoch 1\n",
      "Norm: 114898090363608.50, NNZs: 393685, Bias: 0.000000, T: 71040, Avg. loss: 134122936875952436674560.000000\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 108333850263025.95, NNZs: 393688, Bias: 0.000000, T: 142080, Avg. loss: 110340001023017277718528.000000\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 104969227857529.81, NNZs: 393688, Bias: 0.000000, T: 213120, Avg. loss: 91167885259290223575040.000000\n",
      "Total training time: 1.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 102752951922044.12, NNZs: 393688, Bias: 0.000000, T: 284160, Avg. loss: 82207148813901287653376.000000\n",
      "Total training time: 1.35 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 101117246646647.52, NNZs: 393688, Bias: 0.000000, T: 355200, Avg. loss: 76673371877219789438976.000000\n",
      "Total training time: 1.70 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 99829224730982.50, NNZs: 393688, Bias: 0.000000, T: 426240, Avg. loss: 72792739190889093529600.000000\n",
      "Total training time: 2.04 seconds.\n",
      "Convergence after 6 epochs took 2.07 seconds\n",
      "[CV 2/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.7915127974877743, clf__eta0=0.05539740212799926, clf__fit_intercept=False, clf__l1_ratio=0.9152680641407671, clf__learning_rate=optimal, clf__loss=squared_epsilon_insensitive, clf__max_iter=80, clf__penalty=l1, clf__power_t=0.6359093112142983, clf__shuffle=True, clf__tol=0.9361199211609239, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.340 total time=  48.4s\n",
      "-- Epoch 1\n",
      "Norm: 115002339372019.20, NNZs: 393094, Bias: 0.000000, T: 71040, Avg. loss: 131154479368692987592704.000000\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 108492940549292.30, NNZs: 393097, Bias: 0.000000, T: 142080, Avg. loss: 110310362876573724442624.000000\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 105174714258283.03, NNZs: 393097, Bias: 0.000000, T: 213120, Avg. loss: 91269085664638742298624.000000\n",
      "Total training time: 1.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 102982500528935.09, NNZs: 393097, Bias: 0.000000, T: 284160, Avg. loss: 82442759921743662415872.000000\n",
      "Total training time: 1.35 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 101363029530446.41, NNZs: 393097, Bias: 0.000000, T: 355200, Avg. loss: 76988381118335780126720.000000\n",
      "Total training time: 1.69 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 100084990422363.00, NNZs: 393097, Bias: 0.000000, T: 426240, Avg. loss: 73176621206368776355840.000000\n",
      "Total training time: 2.04 seconds.\n",
      "Convergence after 6 epochs took 2.08 seconds\n",
      "[CV 3/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.7915127974877743, clf__eta0=0.05539740212799926, clf__fit_intercept=False, clf__l1_ratio=0.9152680641407671, clf__learning_rate=optimal, clf__loss=squared_epsilon_insensitive, clf__max_iter=80, clf__penalty=l1, clf__power_t=0.6359093112142983, clf__shuffle=True, clf__tol=0.9361199211609239, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.343 total time=  49.1s\n",
      "-- Epoch 1\n",
      "Norm: 122677910253929.27, NNZs: 393663, Bias: 0.000000, T: 71040, Avg. loss: 151213168223980986826752.000000\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 115941693987979.48, NNZs: 393663, Bias: 0.000000, T: 142080, Avg. loss: 126022121654326520709120.000000\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 112507587897234.94, NNZs: 393663, Bias: 0.000000, T: 213120, Avg. loss: 104609317805532144205824.000000\n",
      "Total training time: 0.96 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 110249083263936.34, NNZs: 393663, Bias: 0.000000, T: 284160, Avg. loss: 94548510671149889224704.000000\n",
      "Total training time: 1.29 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 108582188285866.89, NNZs: 393663, Bias: 0.000000, T: 355200, Avg. loss: 88416087736607964135424.000000\n",
      "Total training time: 1.63 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 107267816705134.28, NNZs: 393663, Bias: 0.000000, T: 426240, Avg. loss: 84076916016570580336640.000000\n",
      "Total training time: 1.97 seconds.\n",
      "Convergence after 6 epochs took 2.00 seconds\n",
      "[CV 4/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.7915127974877743, clf__eta0=0.05539740212799926, clf__fit_intercept=False, clf__l1_ratio=0.9152680641407671, clf__learning_rate=optimal, clf__loss=squared_epsilon_insensitive, clf__max_iter=80, clf__penalty=l1, clf__power_t=0.6359093112142983, clf__shuffle=True, clf__tol=0.9361199211609239, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.339 total time=  48.0s\n",
      "-- Epoch 1\n",
      "Norm: 92141154749967.59, NNZs: 391613, Bias: 0.000000, T: 71040, Avg. loss: 85109921746220388188160.000000\n",
      "Total training time: 0.30 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 86277532865627.28, NNZs: 391617, Bias: 0.000000, T: 142080, Avg. loss: 67784032778174498603008.000000\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 83290883132938.33, NNZs: 391617, Bias: 0.000000, T: 213120, Avg. loss: 54860399477613012189184.000000\n",
      "Total training time: 0.97 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 81317219284806.31, NNZs: 391617, Bias: 0.000000, T: 284160, Avg. loss: 48955838834108002205696.000000\n",
      "Total training time: 1.31 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 79859489137420.16, NNZs: 391617, Bias: 0.000000, T: 355200, Avg. loss: 45343118365172680359936.000000\n",
      "Total training time: 1.65 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 78710041150444.73, NNZs: 391617, Bias: 0.000000, T: 426240, Avg. loss: 42800901133113193660416.000000\n",
      "Total training time: 1.98 seconds.\n",
      "Convergence after 6 epochs took 2.02 seconds\n",
      "[CV 5/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.7915127974877743, clf__eta0=0.05539740212799926, clf__fit_intercept=False, clf__l1_ratio=0.9152680641407671, clf__learning_rate=optimal, clf__loss=squared_epsilon_insensitive, clf__max_iter=80, clf__penalty=l1, clf__power_t=0.6359093112142983, clf__shuffle=True, clf__tol=0.9361199211609239, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.337 total time=  48.6s\n",
      "-- Epoch 1\n",
      "Norm: 88.24, NNZs: 260, Bias: 0.000000, T: 71040, Avg. loss: 0.028273\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 118.02, NNZs: 132, Bias: 0.000000, T: 142080, Avg. loss: 0.022703\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 140.93, NNZs: 121, Bias: 0.000000, T: 213120, Avg. loss: 0.022073\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 160.49, NNZs: 117, Bias: 0.000000, T: 284160, Avg. loss: 0.021804\n",
      "Total training time: 1.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 177.85, NNZs: 112, Bias: 0.000000, T: 355200, Avg. loss: 0.021667\n",
      "Total training time: 1.28 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 193.71, NNZs: 112, Bias: 0.000000, T: 426240, Avg. loss: 0.021563\n",
      "Total training time: 1.53 seconds.\n",
      "Convergence after 6 epochs took 1.56 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.03646223783802971, clf__eta0=0.7491267567674796, clf__fit_intercept=False, clf__l1_ratio=0.775818217437024, clf__learning_rate=constant, clf__loss=squared_hinge, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.4028006727705291, clf__shuffle=True, clf__tol=0.1730703028465106, clf__warm_start=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.838 total time=  49.3s\n",
      "-- Epoch 1\n",
      "Norm: 88.23, NNZs: 282, Bias: 0.000000, T: 71040, Avg. loss: 0.028388\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 117.68, NNZs: 140, Bias: 0.000000, T: 142080, Avg. loss: 0.022461\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 140.95, NNZs: 130, Bias: 0.000000, T: 213120, Avg. loss: 0.022462\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 160.48, NNZs: 126, Bias: 0.000000, T: 284160, Avg. loss: 0.021790\n",
      "Total training time: 0.99 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 177.94, NNZs: 121, Bias: 0.000000, T: 355200, Avg. loss: 0.021699\n",
      "Total training time: 1.24 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 193.53, NNZs: 117, Bias: 0.000000, T: 426240, Avg. loss: 0.021548\n",
      "Total training time: 1.48 seconds.\n",
      "Convergence after 6 epochs took 1.51 seconds\n",
      "[CV 2/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.03646223783802971, clf__eta0=0.7491267567674796, clf__fit_intercept=False, clf__l1_ratio=0.775818217437024, clf__learning_rate=constant, clf__loss=squared_hinge, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.4028006727705291, clf__shuffle=True, clf__tol=0.1730703028465106, clf__warm_start=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.850 total time=  49.8s\n",
      "-- Epoch 1\n",
      "Norm: 87.73, NNZs: 241, Bias: 0.000000, T: 71040, Avg. loss: 0.027919\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 117.38, NNZs: 133, Bias: 0.000000, T: 142080, Avg. loss: 0.022270\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 140.44, NNZs: 122, Bias: 0.000000, T: 213120, Avg. loss: 0.021931\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 159.72, NNZs: 117, Bias: 0.000000, T: 284160, Avg. loss: 0.021682\n",
      "Total training time: 1.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 177.03, NNZs: 112, Bias: 0.000000, T: 355200, Avg. loss: 0.021437\n",
      "Total training time: 1.26 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 192.62, NNZs: 113, Bias: 0.000000, T: 426240, Avg. loss: 0.021164\n",
      "Total training time: 1.51 seconds.\n",
      "Convergence after 6 epochs took 1.55 seconds\n",
      "[CV 3/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.03646223783802971, clf__eta0=0.7491267567674796, clf__fit_intercept=False, clf__l1_ratio=0.775818217437024, clf__learning_rate=constant, clf__loss=squared_hinge, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.4028006727705291, clf__shuffle=True, clf__tol=0.1730703028465106, clf__warm_start=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.875 total time=  49.6s\n",
      "-- Epoch 1\n",
      "Norm: 87.67, NNZs: 279, Bias: 0.000000, T: 71040, Avg. loss: 0.027583\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 117.21, NNZs: 132, Bias: 0.000000, T: 142080, Avg. loss: 0.022459\n",
      "Total training time: 0.54 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 140.19, NNZs: 125, Bias: 0.000000, T: 213120, Avg. loss: 0.021678\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 159.60, NNZs: 114, Bias: 0.000000, T: 284160, Avg. loss: 0.021594\n",
      "Total training time: 1.14 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 176.94, NNZs: 113, Bias: 0.000000, T: 355200, Avg. loss: 0.021468\n",
      "Total training time: 1.40 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 192.59, NNZs: 110, Bias: 0.000000, T: 426240, Avg. loss: 0.021355\n",
      "Total training time: 1.67 seconds.\n",
      "Convergence after 6 epochs took 1.71 seconds\n",
      "[CV 4/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.03646223783802971, clf__eta0=0.7491267567674796, clf__fit_intercept=False, clf__l1_ratio=0.775818217437024, clf__learning_rate=constant, clf__loss=squared_hinge, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.4028006727705291, clf__shuffle=True, clf__tol=0.1730703028465106, clf__warm_start=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.892 total time=  50.5s\n",
      "-- Epoch 1\n",
      "Norm: 88.10, NNZs: 258, Bias: 0.000000, T: 71040, Avg. loss: 0.028215\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 117.75, NNZs: 132, Bias: 0.000000, T: 142080, Avg. loss: 0.022704\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 140.69, NNZs: 121, Bias: 0.000000, T: 213120, Avg. loss: 0.022435\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 160.17, NNZs: 115, Bias: 0.000000, T: 284160, Avg. loss: 0.021975\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 177.44, NNZs: 113, Bias: 0.000000, T: 355200, Avg. loss: 0.021770\n",
      "Total training time: 1.19 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 193.20, NNZs: 116, Bias: 0.000000, T: 426240, Avg. loss: 0.021730\n",
      "Total training time: 1.45 seconds.\n",
      "Convergence after 6 epochs took 1.49 seconds\n",
      "[CV 5/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.03646223783802971, clf__eta0=0.7491267567674796, clf__fit_intercept=False, clf__l1_ratio=0.775818217437024, clf__learning_rate=constant, clf__loss=squared_hinge, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.4028006727705291, clf__shuffle=True, clf__tol=0.1730703028465106, clf__warm_start=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.855 total time=  49.3s\n",
      "-- Epoch 1\n",
      "Norm: 270754049733502.69, NNZs: 393906, Bias: 0.000000, T: 71040, Avg. loss: 1407513342287928400805888.000000\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 220428640630951.94, NNZs: 393537, Bias: 0.000000, T: 142080, Avg. loss: 3640236215767076228300800.000000\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 264694875439422.50, NNZs: 393910, Bias: 0.000000, T: 213120, Avg. loss: 2584072235802672121249792.000000\n",
      "Total training time: 1.17 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 223566531683976.75, NNZs: 393824, Bias: 0.000000, T: 284160, Avg. loss: 3493360343400155531182080.000000\n",
      "Total training time: 1.57 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 265185322412953.25, NNZs: 393913, Bias: 0.000000, T: 355200, Avg. loss: 2673185911632878559559680.000000\n",
      "Total training time: 1.97 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 221688153189649.12, NNZs: 393881, Bias: 0.000000, T: 426240, Avg. loss: 3523339471888169062891520.000000\n",
      "Total training time: 2.36 seconds.\n",
      "Convergence after 6 epochs took 2.39 seconds\n",
      "[CV 1/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.24457156361183285, clf__eta0=0.332929742792607, clf__fit_intercept=False, clf__l1_ratio=0.920539731041378, clf__learning_rate=constant, clf__loss=squared_error, clf__max_iter=100, clf__penalty=l1, clf__power_t=0.5734177157821045, clf__shuffle=True, clf__tol=0.6492274795888617, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.342 total time=  49.6s\n",
      "-- Epoch 1\n",
      "Norm: 271071562225766.91, NNZs: 393689, Bias: 0.000000, T: 71040, Avg. loss: 1360681217854675821264896.000000\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 213106332754091.91, NNZs: 393348, Bias: 0.000000, T: 142080, Avg. loss: 3515036800543464940896256.000000\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 265270612094353.34, NNZs: 393694, Bias: 0.000000, T: 213120, Avg. loss: 2635811096244449454325760.000000\n",
      "Total training time: 1.15 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 223531796217064.75, NNZs: 393605, Bias: 0.000000, T: 284160, Avg. loss: 3572149361562815305875456.000000\n",
      "Total training time: 1.55 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 266409914042303.88, NNZs: 393693, Bias: 0.000000, T: 355200, Avg. loss: 2775653698498583028826112.000000\n",
      "Total training time: 1.94 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 219682534719573.34, NNZs: 393657, Bias: 0.000000, T: 426240, Avg. loss: 3540811966362860658884608.000000\n",
      "Total training time: 2.34 seconds.\n",
      "Convergence after 6 epochs took 2.37 seconds\n",
      "[CV 2/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.24457156361183285, clf__eta0=0.332929742792607, clf__fit_intercept=False, clf__l1_ratio=0.920539731041378, clf__learning_rate=constant, clf__loss=squared_error, clf__max_iter=100, clf__penalty=l1, clf__power_t=0.5734177157821045, clf__shuffle=True, clf__tol=0.6492274795888617, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.338 total time=  49.3s\n",
      "-- Epoch 1\n",
      "Norm: 261504138336654.81, NNZs: 393046, Bias: 0.000000, T: 71040, Avg. loss: 1192165531896997943967744.000000\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 213361934215848.81, NNZs: 392768, Bias: 0.000000, T: 142080, Avg. loss: 3514787172486623854067712.000000\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 265228646307035.69, NNZs: 393079, Bias: 0.000000, T: 213120, Avg. loss: 2764110759145304162828288.000000\n",
      "Total training time: 1.21 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 225971455452349.97, NNZs: 393016, Bias: 0.000000, T: 284160, Avg. loss: 3299641876266887111770112.000000\n",
      "Total training time: 1.62 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 257437214386945.78, NNZs: 393082, Bias: 0.000000, T: 355200, Avg. loss: 2602615620734457254772736.000000\n",
      "Total training time: 2.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 225332166197445.44, NNZs: 393053, Bias: 0.000000, T: 426240, Avg. loss: 3273614405008877370212352.000000\n",
      "Total training time: 2.45 seconds.\n",
      "Convergence after 6 epochs took 2.48 seconds\n",
      "[CV 3/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.24457156361183285, clf__eta0=0.332929742792607, clf__fit_intercept=False, clf__l1_ratio=0.920539731041378, clf__learning_rate=constant, clf__loss=squared_error, clf__max_iter=100, clf__penalty=l1, clf__power_t=0.5734177157821045, clf__shuffle=True, clf__tol=0.6492274795888617, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.333 total time=  49.5s\n",
      "-- Epoch 1\n",
      "Norm: 273679421539959.69, NNZs: 393663, Bias: 0.000000, T: 71040, Avg. loss: 1355548821433527094476800.000000\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 209041658159593.84, NNZs: 393277, Bias: 0.000000, T: 142080, Avg. loss: 3643944994958866575785984.000000\n",
      "Total training time: 0.81 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 265704019986807.00, NNZs: 393662, Bias: 0.000000, T: 213120, Avg. loss: 2544148554225777549246464.000000\n",
      "Total training time: 1.20 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 214243927735380.47, NNZs: 393602, Bias: 0.000000, T: 284160, Avg. loss: 3207048891728888565071872.000000\n",
      "Total training time: 1.59 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 262954591610641.94, NNZs: 393663, Bias: 0.000000, T: 355200, Avg. loss: 2616110857290237842817024.000000\n",
      "Total training time: 2.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 227560666126220.88, NNZs: 393630, Bias: 0.000000, T: 426240, Avg. loss: 3247530454521252457480192.000000\n",
      "Total training time: 2.43 seconds.\n",
      "Convergence after 6 epochs took 2.46 seconds\n",
      "[CV 4/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.24457156361183285, clf__eta0=0.332929742792607, clf__fit_intercept=False, clf__l1_ratio=0.920539731041378, clf__learning_rate=constant, clf__loss=squared_error, clf__max_iter=100, clf__penalty=l1, clf__power_t=0.5734177157821045, clf__shuffle=True, clf__tol=0.6492274795888617, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.342 total time=  48.4s\n",
      "-- Epoch 1\n",
      "Norm: 268678512726950.12, NNZs: 391627, Bias: 0.000000, T: 71040, Avg. loss: 1307941742633571349168128.000000\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 204004796724163.78, NNZs: 391290, Bias: 0.000000, T: 142080, Avg. loss: 3590071998488459612258304.000000\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 269108188212211.25, NNZs: 391633, Bias: 0.000000, T: 213120, Avg. loss: 2593500854805836525993984.000000\n",
      "Total training time: 1.33 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 231248719865342.56, NNZs: 391570, Bias: 0.000000, T: 284160, Avg. loss: 3501040491959364119166976.000000\n",
      "Total training time: 1.79 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 262732748474174.06, NNZs: 391642, Bias: 0.000000, T: 355200, Avg. loss: 2987759404811172628660224.000000\n",
      "Total training time: 2.22 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 227488829454125.06, NNZs: 391616, Bias: 0.000000, T: 426240, Avg. loss: 3278160971535755828527104.000000\n",
      "Total training time: 2.64 seconds.\n",
      "Convergence after 6 epochs took 2.68 seconds\n",
      "[CV 5/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.24457156361183285, clf__eta0=0.332929742792607, clf__fit_intercept=False, clf__l1_ratio=0.920539731041378, clf__learning_rate=constant, clf__loss=squared_error, clf__max_iter=100, clf__penalty=l1, clf__power_t=0.5734177157821045, clf__shuffle=True, clf__tol=0.6492274795888617, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.342 total time=  50.0s\n",
      "-- Epoch 1\n",
      "Norm: 4.12, NNZs: 679523, Bias: 0.432864, T: 71040, Avg. loss: 0.041150\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 4.19, NNZs: 679523, Bias: 0.492719, T: 142080, Avg. loss: 0.015438\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.18, NNZs: 679523, Bias: 0.524961, T: 213120, Avg. loss: 0.011896\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.16, NNZs: 679523, Bias: 0.546912, T: 284160, Avg. loss: 0.010337\n",
      "Total training time: 0.82 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.12, NNZs: 679523, Bias: 0.563491, T: 355200, Avg. loss: 0.009439\n",
      "Total training time: 1.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 4.09, NNZs: 679523, Bias: 0.576801, T: 426240, Avg. loss: 0.008842\n",
      "Total training time: 1.24 seconds.\n",
      "Convergence after 6 epochs took 1.27 seconds\n",
      "[CV 1/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.2527955528897454, clf__eta0=0.4377192284389271, clf__fit_intercept=True, clf__l1_ratio=0.6515110441465675, clf__learning_rate=invscaling, clf__loss=huber, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.47239053945705856, clf__shuffle=False, clf__tol=0.9089234089706554, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.498 total time=  48.9s\n",
      "-- Epoch 1\n",
      "Norm: 4.12, NNZs: 678800, Bias: 0.432418, T: 71040, Avg. loss: 0.041106\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 4.19, NNZs: 678800, Bias: 0.492187, T: 142080, Avg. loss: 0.015457\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.18, NNZs: 678800, Bias: 0.524406, T: 213120, Avg. loss: 0.011935\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.16, NNZs: 678800, Bias: 0.546380, T: 284160, Avg. loss: 0.010379\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.12, NNZs: 678800, Bias: 0.563001, T: 355200, Avg. loss: 0.009479\n",
      "Total training time: 1.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 4.09, NNZs: 678800, Bias: 0.576357, T: 426240, Avg. loss: 0.008879\n",
      "Total training time: 1.22 seconds.\n",
      "Convergence after 6 epochs took 1.25 seconds\n",
      "[CV 2/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.2527955528897454, clf__eta0=0.4377192284389271, clf__fit_intercept=True, clf__l1_ratio=0.6515110441465675, clf__learning_rate=invscaling, clf__loss=huber, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.47239053945705856, clf__shuffle=False, clf__tol=0.9089234089706554, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.498 total time=  49.3s\n",
      "-- Epoch 1\n",
      "Norm: 4.11, NNZs: 678713, Bias: 0.432476, T: 71040, Avg. loss: 0.041270\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 4.19, NNZs: 678713, Bias: 0.492679, T: 142080, Avg. loss: 0.015438\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.18, NNZs: 678713, Bias: 0.524987, T: 213120, Avg. loss: 0.011883\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.16, NNZs: 678713, Bias: 0.546947, T: 284160, Avg. loss: 0.010328\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.13, NNZs: 678713, Bias: 0.563523, T: 355200, Avg. loss: 0.009434\n",
      "Total training time: 1.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 4.09, NNZs: 678713, Bias: 0.576825, T: 426240, Avg. loss: 0.008840\n",
      "Total training time: 1.22 seconds.\n",
      "Convergence after 6 epochs took 1.25 seconds\n",
      "[CV 3/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.2527955528897454, clf__eta0=0.4377192284389271, clf__fit_intercept=True, clf__l1_ratio=0.6515110441465675, clf__learning_rate=invscaling, clf__loss=huber, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.47239053945705856, clf__shuffle=False, clf__tol=0.9089234089706554, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.498 total time=  48.9s\n",
      "-- Epoch 1\n",
      "Norm: 4.13, NNZs: 678259, Bias: 0.431958, T: 71040, Avg. loss: 0.041086\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 4.20, NNZs: 678259, Bias: 0.491680, T: 142080, Avg. loss: 0.015394\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.19, NNZs: 678259, Bias: 0.523779, T: 213120, Avg. loss: 0.011853\n",
      "Total training time: 0.61 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.17, NNZs: 678259, Bias: 0.545617, T: 284160, Avg. loss: 0.010299\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.13, NNZs: 678259, Bias: 0.562103, T: 355200, Avg. loss: 0.009407\n",
      "Total training time: 1.04 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 6\n",
      "Norm: 4.10, NNZs: 678259, Bias: 0.575331, T: 426240, Avg. loss: 0.008814\n",
      "Total training time: 1.28 seconds.\n",
      "Convergence after 6 epochs took 1.31 seconds\n",
      "[CV 4/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.2527955528897454, clf__eta0=0.4377192284389271, clf__fit_intercept=True, clf__l1_ratio=0.6515110441465675, clf__learning_rate=invscaling, clf__loss=huber, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.47239053945705856, clf__shuffle=False, clf__tol=0.9089234089706554, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.498 total time=  50.5s\n",
      "-- Epoch 1\n",
      "Norm: 4.12, NNZs: 674837, Bias: 0.432103, T: 71040, Avg. loss: 0.041177\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 4.20, NNZs: 674837, Bias: 0.491880, T: 142080, Avg. loss: 0.015416\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.19, NNZs: 674837, Bias: 0.524000, T: 213120, Avg. loss: 0.011891\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.16, NNZs: 674837, Bias: 0.545871, T: 284160, Avg. loss: 0.010341\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.13, NNZs: 674837, Bias: 0.562398, T: 355200, Avg. loss: 0.009448\n",
      "Total training time: 1.08 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 4.09, NNZs: 674837, Bias: 0.575673, T: 426240, Avg. loss: 0.008854\n",
      "Total training time: 1.32 seconds.\n",
      "Convergence after 6 epochs took 1.36 seconds\n",
      "[CV 5/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.2527955528897454, clf__eta0=0.4377192284389271, clf__fit_intercept=True, clf__l1_ratio=0.6515110441465675, clf__learning_rate=invscaling, clf__loss=huber, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.47239053945705856, clf__shuffle=False, clf__tol=0.9089234089706554, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.498 total time=  50.4s\n",
      "-- Epoch 1\n",
      "Norm: 9.18, NNZs: 218952, Bias: 0.933903, T: 71040, Avg. loss: 0.028094\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 7.55, NNZs: 228483, Bias: 0.911048, T: 142080, Avg. loss: 0.009301\n",
      "Total training time: 0.43 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 7.18, NNZs: 235362, Bias: 0.897252, T: 213120, Avg. loss: 0.009023\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 7.04, NNZs: 240275, Bias: 0.886140, T: 284160, Avg. loss: 0.008840\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 6.96, NNZs: 244168, Bias: 0.879337, T: 355200, Avg. loss: 0.008809\n",
      "Total training time: 1.08 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 6.93, NNZs: 246847, Bias: 0.872121, T: 426240, Avg. loss: 0.008766\n",
      "Total training time: 1.31 seconds.\n",
      "Convergence after 6 epochs took 1.35 seconds\n",
      "[CV 1/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.3241670976844645, clf__eta0=0.9631840511405841, clf__fit_intercept=True, clf__l1_ratio=0.5912641309775509, clf__learning_rate=optimal, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.6710686638981408, clf__shuffle=True, clf__tol=0.09654933943827881, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.612 total time=  50.6s\n",
      "-- Epoch 1\n",
      "Norm: 9.27, NNZs: 212906, Bias: 0.955539, T: 71040, Avg. loss: 0.028244\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 7.67, NNZs: 223815, Bias: 0.930278, T: 142080, Avg. loss: 0.009064\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 7.31, NNZs: 231571, Bias: 0.916190, T: 213120, Avg. loss: 0.008801\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 7.18, NNZs: 236653, Bias: 0.902087, T: 284160, Avg. loss: 0.008701\n",
      "Total training time: 0.84 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 7.11, NNZs: 240365, Bias: 0.894929, T: 355200, Avg. loss: 0.008618\n",
      "Total training time: 1.05 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 7.07, NNZs: 243006, Bias: 0.889389, T: 426240, Avg. loss: 0.008556\n",
      "Total training time: 1.26 seconds.\n",
      "Convergence after 6 epochs took 1.30 seconds\n",
      "[CV 2/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.3241670976844645, clf__eta0=0.9631840511405841, clf__fit_intercept=True, clf__l1_ratio=0.5912641309775509, clf__learning_rate=optimal, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.6710686638981408, clf__shuffle=True, clf__tol=0.09654933943827881, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.633 total time=  50.5s\n",
      "-- Epoch 1\n",
      "Norm: 8.96, NNZs: 207051, Bias: 0.936146, T: 71040, Avg. loss: 0.028148\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 7.41, NNZs: 218039, Bias: 0.908799, T: 142080, Avg. loss: 0.009467\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 7.06, NNZs: 225687, Bias: 0.890563, T: 213120, Avg. loss: 0.009168\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 6.93, NNZs: 230731, Bias: 0.880669, T: 284160, Avg. loss: 0.009080\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 6.86, NNZs: 234085, Bias: 0.872258, T: 355200, Avg. loss: 0.008967\n",
      "Total training time: 1.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 6.82, NNZs: 237365, Bias: 0.869028, T: 426240, Avg. loss: 0.008934\n",
      "Total training time: 1.21 seconds.\n",
      "Convergence after 6 epochs took 1.25 seconds\n",
      "[CV 3/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.3241670976844645, clf__eta0=0.9631840511405841, clf__fit_intercept=True, clf__l1_ratio=0.5912641309775509, clf__learning_rate=optimal, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.6710686638981408, clf__shuffle=True, clf__tol=0.09654933943827881, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.613 total time=  49.9s\n",
      "-- Epoch 1\n",
      "Norm: 9.02, NNZs: 211775, Bias: 0.934008, T: 71040, Avg. loss: 0.028330\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 7.44, NNZs: 222918, Bias: 0.908659, T: 142080, Avg. loss: 0.009394\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 7.10, NNZs: 230686, Bias: 0.891608, T: 213120, Avg. loss: 0.009081\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 6.98, NNZs: 236005, Bias: 0.879650, T: 284160, Avg. loss: 0.008960\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 6.91, NNZs: 240034, Bias: 0.873365, T: 355200, Avg. loss: 0.008867\n",
      "Total training time: 1.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 6.87, NNZs: 243048, Bias: 0.866008, T: 426240, Avg. loss: 0.008823\n",
      "Total training time: 1.20 seconds.\n",
      "Convergence after 6 epochs took 1.24 seconds\n",
      "[CV 4/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.3241670976844645, clf__eta0=0.9631840511405841, clf__fit_intercept=True, clf__l1_ratio=0.5912641309775509, clf__learning_rate=optimal, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.6710686638981408, clf__shuffle=True, clf__tol=0.09654933943827881, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.620 total time=  49.0s\n",
      "-- Epoch 1\n",
      "Norm: 9.10, NNZs: 213712, Bias: 0.948827, T: 71040, Avg. loss: 0.028617\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 7.49, NNZs: 224331, Bias: 0.922829, T: 142080, Avg. loss: 0.009443\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 7.14, NNZs: 231915, Bias: 0.902775, T: 213120, Avg. loss: 0.009111\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 6.99, NNZs: 237115, Bias: 0.894255, T: 284160, Avg. loss: 0.008996\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 6.91, NNZs: 241624, Bias: 0.888271, T: 355200, Avg. loss: 0.008900\n",
      "Total training time: 1.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 6.87, NNZs: 244368, Bias: 0.880799, T: 426240, Avg. loss: 0.008849\n",
      "Total training time: 1.23 seconds.\n",
      "Convergence after 6 epochs took 1.26 seconds\n",
      "[CV 5/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.3241670976844645, clf__eta0=0.9631840511405841, clf__fit_intercept=True, clf__l1_ratio=0.5912641309775509, clf__learning_rate=optimal, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.6710686638981408, clf__shuffle=True, clf__tol=0.09654933943827881, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.609 total time=  49.7s\n",
      "-- Epoch 1\n",
      "Norm: 493.77, NNZs: 815, Bias: 0.000000, T: 71040, Avg. loss: 0.337649\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 664.32, NNZs: 384, Bias: 0.000000, T: 142080, Avg. loss: 0.145476\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 797.40, NNZs: 299, Bias: 0.000000, T: 213120, Avg. loss: 0.123474\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 908.84, NNZs: 270, Bias: 0.000000, T: 284160, Avg. loss: 0.110976\n",
      "Total training time: 0.78 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 5\n",
      "Norm: 1008.52, NNZs: 236, Bias: 0.000000, T: 355200, Avg. loss: 0.101515\n",
      "Total training time: 0.97 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1098.19, NNZs: 220, Bias: 0.000000, T: 426240, Avg. loss: 0.108135\n",
      "Total training time: 1.16 seconds.\n",
      "Convergence after 6 epochs took 1.19 seconds\n",
      "[CV 1/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.3509613152086368, clf__eta0=0.9934401124631351, clf__fit_intercept=False, clf__l1_ratio=0.5204998682261415, clf__learning_rate=constant, clf__loss=hinge, clf__max_iter=40, clf__penalty=l1, clf__power_t=0.5098574122392232, clf__shuffle=False, clf__tol=0.5563103350645606, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.777 total time=  47.3s\n",
      "-- Epoch 1\n",
      "Norm: 482.65, NNZs: 763, Bias: 0.000000, T: 71040, Avg. loss: 0.368839\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 655.93, NNZs: 348, Bias: 0.000000, T: 142080, Avg. loss: 0.156075\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 787.74, NNZs: 299, Bias: 0.000000, T: 213120, Avg. loss: 0.130158\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 903.92, NNZs: 264, Bias: 0.000000, T: 284160, Avg. loss: 0.131175\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 997.97, NNZs: 221, Bias: 0.000000, T: 355200, Avg. loss: 0.114253\n",
      "Total training time: 1.07 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1086.21, NNZs: 227, Bias: 0.000000, T: 426240, Avg. loss: 0.119923\n",
      "Total training time: 1.30 seconds.\n",
      "Convergence after 6 epochs took 1.34 seconds\n",
      "[CV 2/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.3509613152086368, clf__eta0=0.9934401124631351, clf__fit_intercept=False, clf__l1_ratio=0.5204998682261415, clf__learning_rate=constant, clf__loss=hinge, clf__max_iter=40, clf__penalty=l1, clf__power_t=0.5098574122392232, clf__shuffle=False, clf__tol=0.5563103350645606, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.828 total time=  48.2s\n",
      "-- Epoch 1\n",
      "Norm: 480.95, NNZs: 774, Bias: 0.000000, T: 71040, Avg. loss: 0.346856\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 648.72, NNZs: 376, Bias: 0.000000, T: 142080, Avg. loss: 0.134237\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 766.20, NNZs: 298, Bias: 0.000000, T: 213120, Avg. loss: 0.112295\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 877.43, NNZs: 271, Bias: 0.000000, T: 284160, Avg. loss: 0.108474\n",
      "Total training time: 0.82 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 973.55, NNZs: 248, Bias: 0.000000, T: 355200, Avg. loss: 0.099983\n",
      "Total training time: 1.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1060.67, NNZs: 233, Bias: 0.000000, T: 426240, Avg. loss: 0.103355\n",
      "Total training time: 1.22 seconds.\n",
      "Convergence after 6 epochs took 1.26 seconds\n",
      "[CV 3/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.3509613152086368, clf__eta0=0.9934401124631351, clf__fit_intercept=False, clf__l1_ratio=0.5204998682261415, clf__learning_rate=constant, clf__loss=hinge, clf__max_iter=40, clf__penalty=l1, clf__power_t=0.5098574122392232, clf__shuffle=False, clf__tol=0.5563103350645606, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.784 total time=  47.8s\n",
      "-- Epoch 1\n",
      "Norm: 507.24, NNZs: 861, Bias: 0.000000, T: 71040, Avg. loss: 0.385458\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 678.55, NNZs: 369, Bias: 0.000000, T: 142080, Avg. loss: 0.140177\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 820.36, NNZs: 320, Bias: 0.000000, T: 213120, Avg. loss: 0.130632\n",
      "Total training time: 0.61 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 930.52, NNZs: 281, Bias: 0.000000, T: 284160, Avg. loss: 0.118723\n",
      "Total training time: 0.81 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1032.91, NNZs: 251, Bias: 0.000000, T: 355200, Avg. loss: 0.113920\n",
      "Total training time: 1.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1122.43, NNZs: 228, Bias: 0.000000, T: 426240, Avg. loss: 0.114801\n",
      "Total training time: 1.21 seconds.\n",
      "Convergence after 6 epochs took 1.24 seconds\n",
      "[CV 4/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.3509613152086368, clf__eta0=0.9934401124631351, clf__fit_intercept=False, clf__l1_ratio=0.5204998682261415, clf__learning_rate=constant, clf__loss=hinge, clf__max_iter=40, clf__penalty=l1, clf__power_t=0.5098574122392232, clf__shuffle=False, clf__tol=0.5563103350645606, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.741 total time=  48.4s\n",
      "-- Epoch 1\n",
      "Norm: 490.35, NNZs: 817, Bias: 0.000000, T: 71040, Avg. loss: 0.347655\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 649.63, NNZs: 360, Bias: 0.000000, T: 142080, Avg. loss: 0.128338\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 787.85, NNZs: 305, Bias: 0.000000, T: 213120, Avg. loss: 0.107591\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 900.07, NNZs: 270, Bias: 0.000000, T: 284160, Avg. loss: 0.095770\n",
      "Total training time: 0.85 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 998.89, NNZs: 239, Bias: 0.000000, T: 355200, Avg. loss: 0.092019\n",
      "Total training time: 1.05 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1088.57, NNZs: 217, Bias: 0.000000, T: 426240, Avg. loss: 0.092176\n",
      "Total training time: 1.25 seconds.\n",
      "Convergence after 6 epochs took 1.29 seconds\n",
      "[CV 5/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.3509613152086368, clf__eta0=0.9934401124631351, clf__fit_intercept=False, clf__l1_ratio=0.5204998682261415, clf__learning_rate=constant, clf__loss=hinge, clf__max_iter=40, clf__penalty=l1, clf__power_t=0.5098574122392232, clf__shuffle=False, clf__tol=0.5563103350645606, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.729 total time=  47.8s\n",
      "-- Epoch 1\n",
      "Norm: 1.49, NNZs: 393891, Bias: 0.000000, T: 71040, Avg. loss: 0.800077\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.67, NNZs: 393891, Bias: 0.000000, T: 142080, Avg. loss: 0.827408\n",
      "Total training time: 0.30 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.78, NNZs: 393891, Bias: 0.000000, T: 213120, Avg. loss: 0.821663\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.85, NNZs: 393891, Bias: 0.000000, T: 284160, Avg. loss: 0.813250\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.91, NNZs: 393891, Bias: 0.000000, T: 355200, Avg. loss: 0.804227\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.96, NNZs: 393891, Bias: 0.000000, T: 426240, Avg. loss: 0.795716\n",
      "Total training time: 0.94 seconds.\n",
      "Convergence after 6 epochs took 0.98 seconds\n",
      "[CV 1/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.28658617296069355, clf__eta0=0.03398405924608927, clf__fit_intercept=False, clf__l1_ratio=0.08227014493927165, clf__learning_rate=invscaling, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.5467473202425025, clf__shuffle=True, clf__tol=0.9099604695658384, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.432 total time=  47.8s\n",
      "-- Epoch 1\n",
      "Norm: 1.52, NNZs: 393679, Bias: 0.000000, T: 71040, Avg. loss: 0.808223\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.70, NNZs: 393679, Bias: 0.000000, T: 142080, Avg. loss: 0.833001\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.79, NNZs: 393679, Bias: 0.000000, T: 213120, Avg. loss: 0.822840\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.86, NNZs: 393679, Bias: 0.000000, T: 284160, Avg. loss: 0.813146\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.92, NNZs: 393679, Bias: 0.000000, T: 355200, Avg. loss: 0.804063\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.98, NNZs: 393679, Bias: 0.000000, T: 426240, Avg. loss: 0.796264\n",
      "Total training time: 0.96 seconds.\n",
      "Convergence after 6 epochs took 1.00 seconds\n",
      "[CV 2/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.28658617296069355, clf__eta0=0.03398405924608927, clf__fit_intercept=False, clf__l1_ratio=0.08227014493927165, clf__learning_rate=invscaling, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.5467473202425025, clf__shuffle=True, clf__tol=0.9099604695658384, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.432 total time=  46.9s\n",
      "-- Epoch 1\n",
      "Norm: 1.73, NNZs: 393089, Bias: 0.000000, T: 71040, Avg. loss: 0.842086\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.84, NNZs: 393089, Bias: 0.000000, T: 142080, Avg. loss: 0.837550\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.91, NNZs: 393089, Bias: 0.000000, T: 213120, Avg. loss: 0.826108\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 1.97, NNZs: 393089, Bias: 0.000000, T: 284160, Avg. loss: 0.814365\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.03, NNZs: 393089, Bias: 0.000000, T: 355200, Avg. loss: 0.804148\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.08, NNZs: 393089, Bias: 0.000000, T: 426240, Avg. loss: 0.795873\n",
      "Total training time: 0.92 seconds.\n",
      "Convergence after 6 epochs took 0.96 seconds\n",
      "[CV 3/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.28658617296069355, clf__eta0=0.03398405924608927, clf__fit_intercept=False, clf__l1_ratio=0.08227014493927165, clf__learning_rate=invscaling, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.5467473202425025, clf__shuffle=True, clf__tol=0.9099604695658384, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.432 total time=  47.1s\n",
      "-- Epoch 1\n",
      "Norm: 1.49, NNZs: 393680, Bias: 0.000000, T: 71040, Avg. loss: 0.796200\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.69, NNZs: 393680, Bias: 0.000000, T: 142080, Avg. loss: 0.826299\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.79, NNZs: 393680, Bias: 0.000000, T: 213120, Avg. loss: 0.820416\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.87, NNZs: 393680, Bias: 0.000000, T: 284160, Avg. loss: 0.812465\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.94, NNZs: 393680, Bias: 0.000000, T: 355200, Avg. loss: 0.802521\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.99, NNZs: 393680, Bias: 0.000000, T: 426240, Avg. loss: 0.795321\n",
      "Total training time: 0.90 seconds.\n",
      "Convergence after 6 epochs took 0.94 seconds\n",
      "[CV 4/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.28658617296069355, clf__eta0=0.03398405924608927, clf__fit_intercept=False, clf__l1_ratio=0.08227014493927165, clf__learning_rate=invscaling, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.5467473202425025, clf__shuffle=True, clf__tol=0.9099604695658384, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.445 total time=  46.8s\n",
      "-- Epoch 1\n",
      "Norm: 1.57, NNZs: 391616, Bias: 0.000000, T: 71040, Avg. loss: 0.811647\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.74, NNZs: 391616, Bias: 0.000000, T: 142080, Avg. loss: 0.834977\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.83, NNZs: 391616, Bias: 0.000000, T: 213120, Avg. loss: 0.827043\n",
      "Total training time: 0.43 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.90, NNZs: 391616, Bias: 0.000000, T: 284160, Avg. loss: 0.816737\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.95, NNZs: 391616, Bias: 0.000000, T: 355200, Avg. loss: 0.808592\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.01, NNZs: 391616, Bias: 0.000000, T: 426240, Avg. loss: 0.800745\n",
      "Total training time: 0.90 seconds.\n",
      "Convergence after 6 epochs took 0.93 seconds\n",
      "[CV 5/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.28658617296069355, clf__eta0=0.03398405924608927, clf__fit_intercept=False, clf__l1_ratio=0.08227014493927165, clf__learning_rate=invscaling, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.5467473202425025, clf__shuffle=True, clf__tol=0.9099604695658384, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.431 total time=  47.5s\n",
      "-- Epoch 1\n",
      "Norm: 77.10, NNZs: 393910, Bias: 0.000000, T: 71040, Avg. loss: 0.368815\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 75.88, NNZs: 393910, Bias: 0.000000, T: 142080, Avg. loss: 0.325958\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 75.91, NNZs: 393910, Bias: 0.000000, T: 213120, Avg. loss: 0.326329\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 75.91, NNZs: 393910, Bias: 0.000000, T: 284160, Avg. loss: 0.326323\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 75.91, NNZs: 393910, Bias: 0.000000, T: 355200, Avg. loss: 0.326323\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 75.91, NNZs: 393910, Bias: 0.000000, T: 426240, Avg. loss: 0.326323\n",
      "Total training time: 1.05 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 50.48, NNZs: 393910, Bias: 0.000000, T: 497280, Avg. loss: 0.222270\n",
      "Total training time: 1.24 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 46.80, NNZs: 393910, Bias: 0.000000, T: 568320, Avg. loss: 0.214414\n",
      "Total training time: 1.42 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 46.51, NNZs: 393910, Bias: 0.000000, T: 639360, Avg. loss: 0.216899\n",
      "Total training time: 1.60 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 46.47, NNZs: 393910, Bias: 0.000000, T: 710400, Avg. loss: 0.217379\n",
      "Total training time: 1.78 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 46.47, NNZs: 393910, Bias: 0.000000, T: 781440, Avg. loss: 0.217420\n",
      "Total training time: 1.96 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 45.37, NNZs: 393910, Bias: 0.000000, T: 852480, Avg. loss: 0.196400\n",
      "Total training time: 2.14 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 44.60, NNZs: 393910, Bias: 0.000000, T: 923520, Avg. loss: 0.195301\n",
      "Total training time: 2.33 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 44.11, NNZs: 393910, Bias: 0.000000, T: 994560, Avg. loss: 0.196498\n",
      "Total training time: 2.51 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 43.79, NNZs: 393910, Bias: 0.000000, T: 1065600, Avg. loss: 0.197669\n",
      "Total training time: 2.69 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 43.58, NNZs: 393910, Bias: 0.000000, T: 1136640, Avg. loss: 0.198569\n",
      "Total training time: 2.87 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 43.52, NNZs: 393910, Bias: 0.000000, T: 1207680, Avg. loss: 0.192393\n",
      "Total training time: 3.05 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 43.46, NNZs: 393910, Bias: 0.000000, T: 1278720, Avg. loss: 0.194408\n",
      "Total training time: 3.24 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 43.39, NNZs: 393910, Bias: 0.000000, T: 1349760, Avg. loss: 0.194533\n",
      "Total training time: 3.42 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 43.34, NNZs: 393910, Bias: 0.000000, T: 1420800, Avg. loss: 0.194674\n",
      "Total training time: 3.60 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.42493015701647596, clf__eta0=0.6773009699604285, clf__fit_intercept=False, clf__l1_ratio=0.7301998277223162, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.017782879504616322, clf__shuffle=False, clf__tol=0.19519881462597577, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.604 total time=  50.2s\n",
      "-- Epoch 1\n",
      "Norm: 76.78, NNZs: 393673, Bias: 0.000000, T: 71040, Avg. loss: 0.362234\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 75.77, NNZs: 393673, Bias: 0.000000, T: 142080, Avg. loss: 0.326387\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 75.79, NNZs: 393673, Bias: 0.000000, T: 213120, Avg. loss: 0.326456\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 75.79, NNZs: 393673, Bias: 0.000000, T: 284160, Avg. loss: 0.326453\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 75.79, NNZs: 393673, Bias: 0.000000, T: 355200, Avg. loss: 0.326453\n",
      "Total training time: 0.88 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 75.79, NNZs: 393673, Bias: 0.000000, T: 426240, Avg. loss: 0.326453\n",
      "Total training time: 1.07 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 50.05, NNZs: 393673, Bias: 0.000000, T: 497280, Avg. loss: 0.224312\n",
      "Total training time: 1.25 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 46.34, NNZs: 393673, Bias: 0.000000, T: 568320, Avg. loss: 0.212840\n",
      "Total training time: 1.43 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 46.03, NNZs: 393673, Bias: 0.000000, T: 639360, Avg. loss: 0.215257\n",
      "Total training time: 1.61 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 45.99, NNZs: 393673, Bias: 0.000000, T: 710400, Avg. loss: 0.215885\n",
      "Total training time: 1.80 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 45.99, NNZs: 393673, Bias: 0.000000, T: 781440, Avg. loss: 0.215900\n",
      "Total training time: 2.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 44.92, NNZs: 393673, Bias: 0.000000, T: 852480, Avg. loss: 0.196625\n",
      "Total training time: 2.18 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 44.20, NNZs: 393673, Bias: 0.000000, T: 923520, Avg. loss: 0.195167\n",
      "Total training time: 2.37 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 43.74, NNZs: 393673, Bias: 0.000000, T: 994560, Avg. loss: 0.196074\n",
      "Total training time: 2.56 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 43.44, NNZs: 393673, Bias: 0.000000, T: 1065600, Avg. loss: 0.197064\n",
      "Total training time: 2.75 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 43.24, NNZs: 393673, Bias: 0.000000, T: 1136640, Avg. loss: 0.197843\n",
      "Total training time: 2.95 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 43.19, NNZs: 393673, Bias: 0.000000, T: 1207680, Avg. loss: 0.192814\n",
      "Total training time: 3.14 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 43.13, NNZs: 393673, Bias: 0.000000, T: 1278720, Avg. loss: 0.194009\n",
      "Total training time: 3.32 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 43.07, NNZs: 393673, Bias: 0.000000, T: 1349760, Avg. loss: 0.194000\n",
      "Total training time: 3.51 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 43.02, NNZs: 393673, Bias: 0.000000, T: 1420800, Avg. loss: 0.194051\n",
      "Total training time: 3.69 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.42493015701647596, clf__eta0=0.6773009699604285, clf__fit_intercept=False, clf__l1_ratio=0.7301998277223162, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.017782879504616322, clf__shuffle=False, clf__tol=0.19519881462597577, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.595 total time=  51.0s\n",
      "-- Epoch 1\n",
      "Norm: 76.24, NNZs: 393106, Bias: 0.000000, T: 71040, Avg. loss: 0.371272\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 74.98, NNZs: 393106, Bias: 0.000000, T: 142080, Avg. loss: 0.330733\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 75.01, NNZs: 393106, Bias: 0.000000, T: 213120, Avg. loss: 0.331016\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 75.01, NNZs: 393106, Bias: 0.000000, T: 284160, Avg. loss: 0.331007\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 75.01, NNZs: 393106, Bias: 0.000000, T: 355200, Avg. loss: 0.331007\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 75.01, NNZs: 393106, Bias: 0.000000, T: 426240, Avg. loss: 0.331007\n",
      "Total training time: 1.05 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 50.12, NNZs: 393106, Bias: 0.000000, T: 497280, Avg. loss: 0.223073\n",
      "Total training time: 1.23 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 46.63, NNZs: 393106, Bias: 0.000000, T: 568320, Avg. loss: 0.214789\n",
      "Total training time: 1.41 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 46.39, NNZs: 393106, Bias: 0.000000, T: 639360, Avg. loss: 0.216814\n",
      "Total training time: 1.59 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 46.35, NNZs: 393106, Bias: 0.000000, T: 710400, Avg. loss: 0.217358\n",
      "Total training time: 1.76 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 46.35, NNZs: 393106, Bias: 0.000000, T: 781440, Avg. loss: 0.217385\n",
      "Total training time: 1.94 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 45.19, NNZs: 393106, Bias: 0.000000, T: 852480, Avg. loss: 0.196063\n",
      "Total training time: 2.12 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 44.42, NNZs: 393106, Bias: 0.000000, T: 923520, Avg. loss: 0.194951\n",
      "Total training time: 2.30 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 43.94, NNZs: 393106, Bias: 0.000000, T: 994560, Avg. loss: 0.196273\n",
      "Total training time: 2.48 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 43.63, NNZs: 393106, Bias: 0.000000, T: 1065600, Avg. loss: 0.197498\n",
      "Total training time: 2.66 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 43.43, NNZs: 393106, Bias: 0.000000, T: 1136640, Avg. loss: 0.198406\n",
      "Total training time: 2.84 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 43.38, NNZs: 393106, Bias: 0.000000, T: 1207680, Avg. loss: 0.192897\n",
      "Total training time: 3.02 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 43.32, NNZs: 393106, Bias: 0.000000, T: 1278720, Avg. loss: 0.194701\n",
      "Total training time: 3.20 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 43.26, NNZs: 393106, Bias: 0.000000, T: 1349760, Avg. loss: 0.194579\n",
      "Total training time: 3.38 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 43.20, NNZs: 393106, Bias: 0.000000, T: 1420800, Avg. loss: 0.194563\n",
      "Total training time: 3.56 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.42493015701647596, clf__eta0=0.6773009699604285, clf__fit_intercept=False, clf__l1_ratio=0.7301998277223162, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.017782879504616322, clf__shuffle=False, clf__tol=0.19519881462597577, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.600 total time=  49.9s\n",
      "-- Epoch 1\n",
      "Norm: 74.96, NNZs: 393671, Bias: 0.000000, T: 71040, Avg. loss: 0.380493\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 73.96, NNZs: 393671, Bias: 0.000000, T: 142080, Avg. loss: 0.337192\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 73.99, NNZs: 393671, Bias: 0.000000, T: 213120, Avg. loss: 0.337524\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 73.99, NNZs: 393671, Bias: 0.000000, T: 284160, Avg. loss: 0.337504\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 73.99, NNZs: 393671, Bias: 0.000000, T: 355200, Avg. loss: 0.337506\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 73.99, NNZs: 393671, Bias: 0.000000, T: 426240, Avg. loss: 0.337506\n",
      "Total training time: 1.14 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 49.89, NNZs: 393671, Bias: 0.000000, T: 497280, Avg. loss: 0.228289\n",
      "Total training time: 1.32 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 46.40, NNZs: 393671, Bias: 0.000000, T: 568320, Avg. loss: 0.218761\n",
      "Total training time: 1.53 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 46.15, NNZs: 393671, Bias: 0.000000, T: 639360, Avg. loss: 0.221156\n",
      "Total training time: 1.72 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 46.11, NNZs: 393671, Bias: 0.000000, T: 710400, Avg. loss: 0.221577\n",
      "Total training time: 1.91 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 46.11, NNZs: 393671, Bias: 0.000000, T: 781440, Avg. loss: 0.221574\n",
      "Total training time: 2.11 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 45.04, NNZs: 393671, Bias: 0.000000, T: 852480, Avg. loss: 0.198546\n",
      "Total training time: 2.31 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 44.32, NNZs: 393671, Bias: 0.000000, T: 923520, Avg. loss: 0.198698\n",
      "Total training time: 2.50 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 43.85, NNZs: 393671, Bias: 0.000000, T: 994560, Avg. loss: 0.199852\n",
      "Total training time: 2.70 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 43.55, NNZs: 393671, Bias: 0.000000, T: 1065600, Avg. loss: 0.200954\n",
      "Total training time: 2.88 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 43.36, NNZs: 393671, Bias: 0.000000, T: 1136640, Avg. loss: 0.201799\n",
      "Total training time: 3.07 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 43.32, NNZs: 393671, Bias: 0.000000, T: 1207680, Avg. loss: 0.194529\n",
      "Total training time: 3.26 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 43.26, NNZs: 393671, Bias: 0.000000, T: 1278720, Avg. loss: 0.197553\n",
      "Total training time: 3.46 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 43.20, NNZs: 393671, Bias: 0.000000, T: 1349760, Avg. loss: 0.197624\n",
      "Total training time: 3.66 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 43.15, NNZs: 393671, Bias: 0.000000, T: 1420800, Avg. loss: 0.197705\n",
      "Total training time: 3.85 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.42493015701647596, clf__eta0=0.6773009699604285, clf__fit_intercept=False, clf__l1_ratio=0.7301998277223162, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.017782879504616322, clf__shuffle=False, clf__tol=0.19519881462597577, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.596 total time=  50.8s\n",
      "-- Epoch 1\n",
      "Norm: 76.40, NNZs: 391616, Bias: 0.000000, T: 71040, Avg. loss: 0.375807\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 75.56, NNZs: 391616, Bias: 0.000000, T: 142080, Avg. loss: 0.342465\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 75.58, NNZs: 391616, Bias: 0.000000, T: 213120, Avg. loss: 0.342202\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 75.57, NNZs: 391616, Bias: 0.000000, T: 284160, Avg. loss: 0.342223\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 75.57, NNZs: 391616, Bias: 0.000000, T: 355200, Avg. loss: 0.342221\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 75.57, NNZs: 391616, Bias: 0.000000, T: 426240, Avg. loss: 0.342221\n",
      "Total training time: 1.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 50.50, NNZs: 391616, Bias: 0.000000, T: 497280, Avg. loss: 0.229482\n",
      "Total training time: 1.21 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 47.00, NNZs: 391616, Bias: 0.000000, T: 568320, Avg. loss: 0.218399\n",
      "Total training time: 1.39 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 46.72, NNZs: 391616, Bias: 0.000000, T: 639360, Avg. loss: 0.220132\n",
      "Total training time: 1.57 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 46.69, NNZs: 391616, Bias: 0.000000, T: 710400, Avg. loss: 0.220497\n",
      "Total training time: 1.74 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 46.69, NNZs: 391616, Bias: 0.000000, T: 781440, Avg. loss: 0.220508\n",
      "Total training time: 1.92 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 45.40, NNZs: 391616, Bias: 0.000000, T: 852480, Avg. loss: 0.201939\n",
      "Total training time: 2.09 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 44.60, NNZs: 391616, Bias: 0.000000, T: 923520, Avg. loss: 0.196545\n",
      "Total training time: 2.27 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 44.08, NNZs: 391616, Bias: 0.000000, T: 994560, Avg. loss: 0.198258\n",
      "Total training time: 2.46 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 43.74, NNZs: 391616, Bias: 0.000000, T: 1065600, Avg. loss: 0.199698\n",
      "Total training time: 2.63 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 43.52, NNZs: 391616, Bias: 0.000000, T: 1136640, Avg. loss: 0.200741\n",
      "Total training time: 2.82 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 43.43, NNZs: 391616, Bias: 0.000000, T: 1207680, Avg. loss: 0.200108\n",
      "Total training time: 3.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 43.37, NNZs: 391616, Bias: 0.000000, T: 1278720, Avg. loss: 0.196568\n",
      "Total training time: 3.20 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 43.30, NNZs: 391616, Bias: 0.000000, T: 1349760, Avg. loss: 0.196515\n",
      "Total training time: 3.40 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 43.24, NNZs: 391616, Bias: 0.000000, T: 1420800, Avg. loss: 0.196592\n",
      "Total training time: 3.58 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.42493015701647596, clf__eta0=0.6773009699604285, clf__fit_intercept=False, clf__l1_ratio=0.7301998277223162, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.017782879504616322, clf__shuffle=False, clf__tol=0.19519881462597577, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.601 total time=  49.7s\n",
      "-- Epoch 1\n",
      "Norm: 57.13, NNZs: 238082, Bias: 2.157876, T: 71040, Avg. loss: 0.431575\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 34.90, NNZs: 254564, Bias: 1.870889, T: 142080, Avg. loss: 0.017077\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 26.49, NNZs: 261307, Bias: 1.698457, T: 213120, Avg. loss: 0.007161\n",
      "Total training time: 0.30 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 21.44, NNZs: 263744, Bias: 1.624121, T: 284160, Avg. loss: 0.003868\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 18.45, NNZs: 264462, Bias: 1.540834, T: 355200, Avg. loss: 0.001640\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 15.92, NNZs: 265079, Bias: 1.517438, T: 426240, Avg. loss: 0.001120\n",
      "Total training time: 0.62 seconds.\n",
      "Convergence after 6 epochs took 0.65 seconds\n",
      "[CV 1/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.21123614325601048, clf__eta0=0.32979731781585486, clf__fit_intercept=True, clf__l1_ratio=0.4775095579144826, clf__learning_rate=optimal, clf__loss=perceptron, clf__max_iter=30, clf__penalty=l2, clf__power_t=0.6427671735097384, clf__shuffle=False, clf__tol=0.2651165400908262, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.798 total time=  46.9s\n",
      "-- Epoch 1\n",
      "Norm: 55.29, NNZs: 224890, Bias: 2.484104, T: 71040, Avg. loss: 0.343847\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 34.85, NNZs: 238901, Bias: 2.169093, T: 142080, Avg. loss: 0.020600\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 26.36, NNZs: 243508, Bias: 2.040118, T: 213120, Avg. loss: 0.008746\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 22.03, NNZs: 245331, Bias: 1.917871, T: 284160, Avg. loss: 0.003997\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 18.78, NNZs: 245757, Bias: 1.851746, T: 355200, Avg. loss: 0.001582\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 16.67, NNZs: 246006, Bias: 1.788721, T: 426240, Avg. loss: 0.000988\n",
      "Total training time: 0.64 seconds.\n",
      "Convergence after 6 epochs took 0.67 seconds\n",
      "[CV 2/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.21123614325601048, clf__eta0=0.32979731781585486, clf__fit_intercept=True, clf__l1_ratio=0.4775095579144826, clf__learning_rate=optimal, clf__loss=perceptron, clf__max_iter=30, clf__penalty=l2, clf__power_t=0.6427671735097384, clf__shuffle=False, clf__tol=0.2651165400908262, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.791 total time=  47.0s\n",
      "-- Epoch 1\n",
      "Norm: 57.41, NNZs: 238612, Bias: 2.434884, T: 71040, Avg. loss: 0.383656\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 36.51, NNZs: 256554, Bias: 2.057999, T: 142080, Avg. loss: 0.024659\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 27.58, NNZs: 260084, Bias: 1.906125, T: 213120, Avg. loss: 0.007901\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 22.40, NNZs: 261755, Bias: 1.815761, T: 284160, Avg. loss: 0.003375\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 19.07, NNZs: 262787, Bias: 1.757469, T: 355200, Avg. loss: 0.002261\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 16.71, NNZs: 263071, Bias: 1.714172, T: 426240, Avg. loss: 0.001456\n",
      "Total training time: 0.66 seconds.\n",
      "Convergence after 6 epochs took 0.69 seconds\n",
      "[CV 3/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.21123614325601048, clf__eta0=0.32979731781585486, clf__fit_intercept=True, clf__l1_ratio=0.4775095579144826, clf__learning_rate=optimal, clf__loss=perceptron, clf__max_iter=30, clf__penalty=l2, clf__power_t=0.6427671735097384, clf__shuffle=False, clf__tol=0.2651165400908262, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.788 total time=  47.9s\n",
      "-- Epoch 1\n",
      "Norm: 55.90, NNZs: 231086, Bias: 1.814658, T: 71040, Avg. loss: 0.417473\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 34.86, NNZs: 249174, Bias: 1.537390, T: 142080, Avg. loss: 0.019999\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 25.77, NNZs: 252760, Bias: 1.446869, T: 213120, Avg. loss: 0.006813\n",
      "Total training time: 0.30 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 20.98, NNZs: 254437, Bias: 1.360248, T: 284160, Avg. loss: 0.002988\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 17.75, NNZs: 255141, Bias: 1.311707, T: 355200, Avg. loss: 0.001467\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 15.37, NNZs: 255487, Bias: 1.278211, T: 426240, Avg. loss: 0.000817\n",
      "Total training time: 0.62 seconds.\n",
      "Convergence after 6 epochs took 0.66 seconds\n",
      "[CV 4/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.21123614325601048, clf__eta0=0.32979731781585486, clf__fit_intercept=True, clf__l1_ratio=0.4775095579144826, clf__learning_rate=optimal, clf__loss=perceptron, clf__max_iter=30, clf__penalty=l2, clf__power_t=0.6427671735097384, clf__shuffle=False, clf__tol=0.2651165400908262, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.706 total time=  47.1s\n",
      "-- Epoch 1\n",
      "Norm: 57.88, NNZs: 250479, Bias: 1.875689, T: 71040, Avg. loss: 0.341596\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 35.79, NNZs: 263536, Bias: 1.588969, T: 142080, Avg. loss: 0.020198\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 26.68, NNZs: 266420, Bias: 1.474467, T: 213120, Avg. loss: 0.006882\n",
      "Total training time: 0.30 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 21.20, NNZs: 267541, Bias: 1.433786, T: 284160, Avg. loss: 0.003122\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 18.05, NNZs: 268087, Bias: 1.360767, T: 355200, Avg. loss: 0.001355\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 15.79, NNZs: 268531, Bias: 1.318351, T: 426240, Avg. loss: 0.001229\n",
      "Total training time: 0.62 seconds.\n",
      "Convergence after 6 epochs took 0.66 seconds\n",
      "[CV 5/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.21123614325601048, clf__eta0=0.32979731781585486, clf__fit_intercept=True, clf__l1_ratio=0.4775095579144826, clf__learning_rate=optimal, clf__loss=perceptron, clf__max_iter=30, clf__penalty=l2, clf__power_t=0.6427671735097384, clf__shuffle=False, clf__tol=0.2651165400908262, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.710 total time=  47.3s\n",
      "-- Epoch 1\n",
      "Norm: 97.60, NNZs: 232, Bias: 0.000000, T: 88800, Avg. loss: 0.027866\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 130.90, NNZs: 118, Bias: 0.000000, T: 177600, Avg. loss: 0.022786\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 157.07, NNZs: 119, Bias: 0.000000, T: 266400, Avg. loss: 0.022646\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 179.27, NNZs: 114, Bias: 0.000000, T: 355200, Avg. loss: 0.022207\n",
      "Total training time: 1.19 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 198.82, NNZs: 110, Bias: 0.000000, T: 444000, Avg. loss: 0.022206\n",
      "Total training time: 1.52 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 216.79, NNZs: 113, Bias: 0.000000, T: 532800, Avg. loss: 0.022193\n",
      "Total training time: 1.84 seconds.\n",
      "Convergence after 6 epochs took 1.89 seconds\n",
      "0.9960135135135135\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGwCAYAAAAJ/wd3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABDPElEQVR4nO3deVxVdf7H8fcFZFE2N0AUt3DNNSulSctixLImy2bKnNJSmxyp3JcWcikpyynN0rLSmp/mMlM2aWmMpmWSpYXkRooWmqKWAoKy3Xt+fyC37qjF6Vwu4H09H4/zmO453/M9n8MgfPh8v+d7bIZhGAIAAPAQn6oOAAAAeBeSDwAA4FEkHwAAwKNIPgAAgEeRfAAAAI8i+QAAAB5F8gEAADzKr6oDqC4cDocOHz6skJAQ2Wy2qg4HAGCCYRg6deqUoqOj5eNTeX9XFxYWqri42C19+fv7KzAw0C191TQkH2cdPnxYMTExVR0GAMCCgwcPqkmTJpXSd2FhoVo0C1b2Mbtb+ouKitKBAwe8MgEh+TgrJCREknS1+snPVquKowEqCQsa4yJVqhJt0gfOn+WVobi4WNnH7Pp+W3OFhlirruSdcqhZt+9UXFxM8uHNyoda/Gy1SD5wESP5wEXq7Le2J4bNg0NsCg6xdh2HvHt4n+QDAAAT7IZDdot5vN1wuCeYGorkAwAAExwy5LBYRbR6fk3Ho7YAAMCjqHwAAGCCQw5ZHTSx3kPNRvIBAIAJdsOQ3eKTY1bPr+kYdgEAAB5F5QMAABOYcGodyQcAACY4ZMhO8mEJwy4AAMCjqHwAAGACwy7WkXwAAGACT7tYx7ALAADwKCofAACY4Di7We3Dm5F8AABggt0NT7tYPb+mI/kAAMAEuyE3vNXWPbHUVMz5AAAAHkXlAwAAE5jzYR3JBwAAJjhkk102y314M4ZdAACAR1H5AADABIdRtlntw5uRfAAAYILdDcMuVs+v6Rh2AQAAHkXlAwAAE6h8WEfyAQCACQ7DJodh8WkXi+fXdAy7AAAAj6LyAQCACQy7WEfyAQCACXb5yG5x4MDuplhqKpIPAABMMNww58NgzgcAAIDnUPkAAMAE5nxYR/IBAIAJdsNHdsPinA8vX16dYRcAAOBRVD4AADDBIZscFv92d8i7Sx8kHwAAmMCcD+sYdgEAAB5F5QMAABPcM+GUYRcAAFBBZXM+LL5YjmEXAAAAz6HyAQCACQ43vNuFp10AAECFMefDOpIPAABMcMiHdT4sYs4HAADwKCofAACYYDdsshsWFxmzeH5NR/IBAIAJdjdMOLUz7AIAAOA5VD4AADDBYfjIYfFpFwdPuwAAgIpi2MU6hl0AAIBHkXwAAGCCQz8/8fJ7N4eJ6yUnJ+uKK65QSEiIIiIi1L9/f2VkZLi0ufbaa2Wz2Vy2Bx54wKVNVlaW+vXrp9q1aysiIkLjx49XaWmpS5sNGzbosssuU0BAgGJjY7Vo0aJz4nnppZfUvHlzBQYGqnv37vriiy9M3E0Zkg8AAEwoX2TM6lZRGzdu1MiRI/X5558rJSVFJSUl6tOnjwoKClzaDR8+XEeOHHFuM2fOdB6z2+3q16+fiouLtXnzZr355ptatGiRkpKSnG0OHDigfv36qXfv3kpLS9OoUaM0bNgwrV271tlm2bJlGjNmjJ544gl99dVX6ty5sxISEnTs2DFTX0ObYXj5rJez8vLyFBYWpmtt/eVnq1XV4QCVg3/uuEiVGiXaoPeUm5ur0NDQSrlG+e+JeV9doaBga1Mmz+SXasRlX+rgwYMu8QYEBCggIOBXzz1+/LgiIiK0ceNG9erVS1JZ5aNLly564YUXznvOhx9+qJtuukmHDx9WZGSkJGn+/PmaOHGijh8/Ln9/f02cOFGrV6/Wjh07nOfdeeedysnJ0Zo1ayRJ3bt31xVXXKG5c+dKkhwOh2JiYvTggw9q0qRJFb5/Kh8AAJhQ/m4Xq5skxcTEKCwszLklJyf/5vVzc3MlSfXq1XPZv3jxYjVo0EAdOnTQ5MmTdfr0aeex1NRUdezY0Zl4SFJCQoLy8vK0c+dOZ5v4+HiXPhMSEpSamipJKi4u1rZt21za+Pj4KD4+3tmmonjaBQAAExyyySFrK5SWn3++ysevnudwaNSoUfrDH/6gDh06OPffddddatasmaKjo5Wenq6JEycqIyND77zzjiQpOzvbJfGQ5PycnZ39q23y8vJ05swZnTx5Una7/bxt9uzZY+b2ST4AADDDPW+1LTs/NDTU1DDRyJEjtWPHDm3atMll//333+/8744dO6pRo0a6/vrrlZmZqUsuucRSrJWBYRcAAGqAxMRErVq1Sh9//LGaNGnyq227d+8uSdq3b58kKSoqSkePHnVpU/45KirqV9uEhoYqKChIDRo0kK+v73nblPdRUSQfAACYUL7ImNWtogzDUGJiot59912tX79eLVq0+M1z0tLSJEmNGjWSJMXFxembb75xeSolJSVFoaGhat++vbPNunXrXPpJSUlRXFycJMnf31/dunVzaeNwOLRu3Tpnm4pi2AUAABMchk0Oi2+lNXP+yJEjtWTJEr333nsKCQlxztEICwtTUFCQMjMztWTJEt14442qX7++0tPTNXr0aPXq1UudOnWSJPXp00ft27fX3XffrZkzZyo7O1uPPfaYRo4c6Zxn8sADD2ju3LmaMGGC7rvvPq1fv17Lly/X6tWrnbGMGTNGgwcP1uWXX64rr7xSL7zwggoKCnTvvfeaun+SDwAAqrF58+ZJKnuc9pcWLlyoIUOGyN/fX//973+diUBMTIwGDBigxx57zNnW19dXq1at0ogRIxQXF6c6depo8ODBmjZtmrNNixYttHr1ao0ePVqzZ89WkyZN9NprrykhIcHZ5o477tDx48eVlJSk7OxsdenSRWvWrDlnEupvYZ2Ps1jnA16Bf+64SHlynY+nv7xGgRbX+SjML9WkKzZWarzVGZUPAABMcM9bbb17yqV33z0AAPA4Kh8AAJhgl012i4uMWT2/piP5AADABIZdrPPuuwcAAB5H5QMAABPssj5sYndPKDUWyQcAACYw7GIdyQcAACa488Vy3sq77x4AAHgclQ8AAEwwZJPD4pwPg0dtAQBARTHsYp133z0AAPA4Kh8AAJjgMGxyGNaGTayeX9ORfAAAYIJdPrJbHDiwen5N5913DwAAPI7KBwAAJjDsYh3JBwAAJjjkI4fFgQOr59d03n33AADA46h8AABggt2wyW5x2MTq+TUdyQcAACYw58M6kg8AAEww3PBWW4MVTgEAADyHygcAACbYZZPd4ovhrJ5f05F8AABggsOwPmfDYbgpmBqKYRcAAOBRVD7gNh265+vPI46pVcfTqh9Vqin3NVfq2nDn8fAGJRr66GF163VKdcLs2vF5sF56vIkOHwhwtpm5Yq86X1Xg0u/qf9bXnEkxnroNwJSgOnYNnpCtq27IVXj9UmXuDNK8xxvr2+21nW1iYgs19LEj6tQjX75+0vffBmj68OY6/oN/FUaO38vhhgmnVs+v6Ug+4DaBtR3avytIa5fW0xOvf/c/Rw098cYB2UtsmnJfS53O99Ft9x/X00v3afi1bVV0xtfZ8oP/q6+3notyfi46493/SFG9jZ51UM3bFGrmg0114mgtXTfgpJ5elqnh17bVT9m11KhZkf6xcp/WLK2nfz4XqdOnfNWsTaGKC717zL8mc8gmh8U5G1bPr+lqbPIxZMgQ5eTkaOXKlVUdCs7a+nGotn4cet5jjVsWqX2307q/dxt9/22QJOnFSU20NG2nevfP0Zq36zvbFhXadPJ4LY/EDFjhH+jQ1Tfmasq9LbRjS7Ak6f9mRanHH/N00z0/6s2ZjTRkUra+WB+q15+Mdp535PuAC3UJeAX+pIRH1PIvm11VXPTzt5xh2FRSbNOlV+a7tO1960kt/+YbvbJuj+6ddFgBgQ6PxgpUlK+vIV8/qbjI9a/YokKbLr2yQDaboSuvz9MP+wP01JJMLUvfqdmr9iqub24VRQx3KF/h1OrmzS6K5GPNmjW6+uqrFR4ervr16+umm25SZmZmVYeFXzi4L1BHD9XSfZOPKDisVH61HPrL34+qYXSJ6kWUOtt9vLKuZj7YTBP+HKulcyN0/e0nNeHF76swcuDCzhT4atfW2rpr1FHViyyRj4+h6247qXbdTqteZKnCG5SqdrBDdyQe09aPQzV5YEt9tiZUSa99p4498n/7AqiWyud8WN28WY0ddvmlgoICjRkzRp06dVJ+fr6SkpJ06623Ki0tTT4+5/8/uKioSEVFRc7PeXl5ngrXK9lLbZo2rIXGzMrSv3ftkL1U+vrTEH2xLkS2X/wB8OHiBs7//m5PkE4cq6WZyzPVqFkRpWpUSzMfbKox/ziot7/eJXuptO+bIG1YGa5Wnc7IdvbHT+raUL27oKEkaf/OILW//LT63fOTvvk8uAojB6rORZF8DBgwwOXzG2+8oYYNG2rXrl3q0KHDec9JTk7W1KlTPREeztr3TW39vU9b1Q6xq1YtQ7kn/DT7/W/1bXrtC56z56uyY9HNST5QPR35PkDjB8QqIMiuOiEOnThWS4/M/05HvvdX3glflZZI338b6HLOwb0BuvTKggv0iOrOITe828XLJ5xeFHWfvXv3auDAgWrZsqVCQ0PVvHlzSVJWVtYFz5k8ebJyc3Od28GDBz0ULU6f8lXuCT9FtyhSq86nlbr2/JNUJemSS89Ikk4cYwIqqreiM746cayWgsNK1e2aU0pdG6bSEh99u722mlxS5NK2ccsiHTvEY7Y1lXH2aRcrm+HlycdFUfm4+eab1axZMy1YsEDR0dFyOBzq0KGDiouLL3hOQECAAgL4S9qdAmvbFd3i5x+yUU2L1fLS0zp10k/HD/ur5005yv3JV8d+8FeLtoV6YNohpa4J01eflCUfjZoVqfetJ/XFulCdOumrFu0K9bcpPyg9tY4O7A6qqtsCflW3a/Jks0kHMwPUuEWxhj1+WAf3BeqjZfUkSStejtAj87/Xjs/raPvmYF3e+5R6/DFP42+/pIojx+/FW22tq/HJx08//aSMjAwtWLBAPXv2lCRt2rSpiqPyTq07n9az//p5ou8DUw5Lkj5aXlezRjdTvYgS/e2JHxTeoFQnjvnpv/+qpyUvRDrbl5bY1PXqU7p12HEFBjl0/EgtbfogXG/PjjznWkB1USfUoXsnH1GDRiU6leOrzz4I08KnG8leWvbLZfOaMM2Z1Fh3Jh7TiOk/6ND+sgXGdn7BfA94rxqffNStW1f169fXq6++qkaNGikrK0uTJk2q6rC8UnpqiBIad7ng8ffeaKj33mh4wePHD/tr/O2tKiEyoPJ88n64Pnk//FfbfLS0vj5aWv9X26DmYIVT62rs3TscDvn5+cnHx0dLly7Vtm3b1KFDB40ePVrPPvtsVYcHALhIlQ+7WN28WY2tfBw7dkyxsbGSpPj4eO3atcvluGF4+SsDAQCopmpc5ePkyZNatWqVNmzYoPj4+KoOBwDgZaw+6eKOd8PUdDWu8nHffffpyy+/1NixY3XLLbdUdTgAAC/D0y7W1bjk4913363qEAAAgAU1LvkAAKAqUfmwjuQDAAATSD6sq3ETTgEAQM1G5QMAABOofFhH8gEAgAmGrL+V1ttXoiL5AADABCof1jHnAwAAeBSVDwAATKDyYR3JBwAAJpB8WMewCwAA8CgqHwAAmEDlwzoqHwAAmGAYNrdsFZWcnKwrrrhCISEhioiIUP/+/ZWRkeHSprCwUCNHjlT9+vUVHBysAQMG6OjRoy5tsrKy1K9fP9WuXVsREREaP368SktLXdps2LBBl112mQICAhQbG6tFixadE89LL72k5s2bKzAwUN27d9cXX3xR8S/eWSQfAABUYxs3btTIkSP1+eefKyUlRSUlJerTp48KCgqcbUaPHq33339fK1as0MaNG3X48GHddtttzuN2u139+vVTcXGxNm/erDfffFOLFi1SUlKSs82BAwfUr18/9e7dW2lpaRo1apSGDRumtWvXOtssW7ZMY8aM0RNPPKGvvvpKnTt3VkJCgo4dO2bqnmyGYXj7WieSpLy8PIWFhelaW3/52WpVdThA5eCfOy5SpUaJNug95ebmKjQ0tFKuUf57Iu69B+VXJ8BSX6UFRUq95UUdPHjQJd6AgAAFBPx638ePH1dERIQ2btyoXr16KTc3Vw0bNtSSJUt0++23S5L27Nmjdu3aKTU1VT169NCHH36om266SYcPH1ZkZKQkaf78+Zo4caKOHz8uf39/TZw4UatXr9aOHTuc17rzzjuVk5OjNWvWSJK6d++uK664QnPnzpUkORwOxcTE6MEHH9SkSZMqfP9UPgAAMKF8zofVTZJiYmIUFhbm3JKTk3/z+rm5uZKkevXqSZK2bdumkpISxcfHO9u0bdtWTZs2VWpqqiQpNTVVHTt2dCYekpSQkKC8vDzt3LnT2eaXfZS3Ke+juLhY27Ztc2nj4+Oj+Ph4Z5uKYsIpAABV5HyVj1/jcDg0atQo/eEPf1CHDh0kSdnZ2fL391d4eLhL28jISGVnZzvb/DLxKD9efuzX2uTl5enMmTM6efKk7Hb7edvs2bOngndchuQDAAATzE4YvVAfkhQaGmpqmGjkyJHasWOHNm3aZOn6VY1hFwAATHDnsIsZiYmJWrVqlT7++GM1adLEuT8qKkrFxcXKyclxaX/06FFFRUU52/zv0y/ln3+rTWhoqIKCgtSgQQP5+vqet015HxVF8gEAgAmeftTWMAwlJibq3Xff1fr169WiRQuX4926dVOtWrW0bt06576MjAxlZWUpLi5OkhQXF6dvvvnG5amUlJQUhYaGqn379s42v+yjvE15H/7+/urWrZtLG4fDoXXr1jnbVBTDLgAAVGMjR47UkiVL9N577ykkJMQ5RyMsLExBQUEKCwvT0KFDNWbMGNWrV0+hoaF68MEHFRcXpx49ekiS+vTpo/bt2+vuu+/WzJkzlZ2drccee0wjR450zjN54IEHNHfuXE2YMEH33Xef1q9fr+XLl2v16tXOWMaMGaPBgwfr8ssv15VXXqkXXnhBBQUFuvfee03dE8kHAAAmGG5Y4dRM5WPevHmSpGuvvdZl/8KFCzVkyBBJ0vPPPy8fHx8NGDBARUVFSkhI0Msvv+xs6+vrq1WrVmnEiBGKi4tTnTp1NHjwYE2bNs3ZpkWLFlq9erVGjx6t2bNnq0mTJnrttdeUkJDgbHPHHXfo+PHjSkpKUnZ2trp06aI1a9acMwn1t7DOx1ms8wGvwD93XKQ8uc5H13+NkW9ta+t82E8X6evb/1Gp8VZnzPkAAAAexbALAAAmOGSTTRZfLGfx/JqO5AMAABPcuc6Ht2LYBQAAeBSVDwAATHAYNtksVi6sPi1T05F8AABggmFYf3DM2x88Y9gFAAB4FJUPAABMYMKpdSQfAACYQPJhHckHAAAmMOHUOuZ8AAAAj6LyAQCACTztYh3JBwAAJpQlH1bnfLgpmBqKYRcAAOBRVD4AADCBp12sI/kAAMAE4+xmtQ9vxrALAADwKCofAACYwLCLdSQfAACYwbiLZSQfAACY4YbKh7y88sGcDwAA4FFUPgAAMIEVTq0j+QAAwAQmnFrHsAsAAPAoKh8AAJhh2KxPGPXyygfJBwAAJjDnwzqGXQAAgEdR+QAAwAwWGbOM5AMAABN42sW6CiUf//nPfyrc4Z/+9KffHQwAALj4VSj56N+/f4U6s9lsstvtVuIBAKD68/JhE6sqlHw4HI7KjgMAgBqBYRfrLD3tUlhY6K44AACoGQw3bV7MdPJht9s1ffp0NW7cWMHBwdq/f78k6fHHH9frr7/u9gABAMDFxXTy8dRTT2nRokWaOXOm/P39nfs7dOig1157za3BAQBQ/djctHkv08nHW2+9pVdffVWDBg2Sr6+vc3/nzp21Z88etwYHAEC1w7CLZaaTjx9++EGxsbHn7Hc4HCopKXFLUAAA4OJlOvlo3769Pv3003P2/+tf/1LXrl3dEhQAANUWlQ/LTK9wmpSUpMGDB+uHH36Qw+HQO++8o4yMDL311ltatWpVZcQIAED1wVttLTNd+bjlllv0/vvv67///a/q1KmjpKQk7d69W++//77++Mc/VkaMAADgIvK73u3Ss2dPpaSkuDsWAACqPcMo26z24c1+94vltm7dqt27d0sqmwfSrVs3twUFAEC1xVttLTOdfBw6dEgDBw7UZ599pvDwcElSTk6OrrrqKi1dulRNmjRxd4wAAOAiYnrOx7Bhw1RSUqLdu3frxIkTOnHihHbv3i2Hw6Fhw4ZVRowAAFQf5RNOrW5ezHTlY+PGjdq8ebPatGnj3NemTRu9+OKL6tmzp1uDAwCgurEZZZvVPryZ6eQjJibmvIuJ2e12RUdHuyUoAACqLeZ8WGZ62OXZZ5/Vgw8+qK1btzr3bd26VQ8//LCee+45twYHAAAuPhWqfNStW1c228/jUwUFBerevbv8/MpOLy0tlZ+fn+677z7179+/UgIFAKBaYJExyyqUfLzwwguVHAYAADUEwy6WVSj5GDx4cGXHAQAAvMTvXmRMkgoLC1VcXOyyLzQ01FJAAABUa1Q+LDM94bSgoECJiYmKiIhQnTp1VLduXZcNAICLGm+1tcx08jFhwgStX79e8+bNU0BAgF577TVNnTpV0dHReuuttyojRgAAvNonn3yim2++WdHR0bLZbFq5cqXL8SFDhshms7lsffv2dWlz4sQJDRo0SKGhoQoPD9fQoUOVn5/v0iY9PV09e/ZUYGCgYmJiNHPmzHNiWbFihdq2bavAwEB17NhRH3zwgen7MZ18vP/++3r55Zc1YMAA+fn5qWfPnnrsscc0Y8YMLV682HQAAADUKFWwwmlBQYE6d+6sl1566YJt+vbtqyNHjji3t99+2+X4oEGDtHPnTqWkpGjVqlX65JNPdP/99zuP5+XlqU+fPmrWrJm2bdumZ599VlOmTNGrr77qbLN582YNHDhQQ4cO1ddff63+/furf//+2rFjh6n7MT3n48SJE2rZsqWksvkdJ06ckCRdffXVGjFihNnuAACoUapihdMbbrhBN9xww6+2CQgIUFRU1HmP7d69W2vWrNGXX36pyy+/XJL04osv6sYbb9Rzzz2n6OhoLV68WMXFxXrjjTfk7++vSy+9VGlpafrHP/7hTFJmz56tvn37avz48ZKk6dOnKyUlRXPnztX8+fMrfD+mKx8tW7bUgQMHJElt27bV8uXLJZVVRMpfNAcAAH5bXl6ey1ZUVPS7+9qwYYMiIiLUpk0bjRgxQj/99JPzWGpqqsLDw52JhyTFx8fLx8dHW7Zscbbp1auX/P39nW0SEhKUkZGhkydPOtvEx8e7XDchIUGpqammYjWdfNx7773avn27JGnSpEl66aWXFBgYqNGjRzszIQAALlpunHAaExOjsLAw55acnPy7Qurbt6/eeustrVu3Ts8884w2btyoG264QXa7XZKUnZ2tiIgIl3P8/PxUr149ZWdnO9tERka6tCn//Fttyo9XlOlhl9GjRzv/Oz4+Xnv27NG2bdsUGxurTp06me0OAACvdfDgQZclKgICAn5XP3feeafzvzt27KhOnTrpkksu0YYNG3T99ddbjtPdLK3zIUnNmjVTs2bN3BELAADVnk1umPNx9n9DQ0MrZX2sli1bqkGDBtq3b5+uv/56RUVF6dixYy5tSktLdeLECec8kaioKB09etSlTfnn32pzobkmF1Kh5GPOnDkV7vChhx4yFQAAAHCvQ4cO6aefflKjRo0kSXFxccrJydG2bdvUrVs3SdL69evlcDjUvXt3Z5tHH31UJSUlqlWrliQpJSVFbdq0ca7jFRcXp3Xr1mnUqFHOa6WkpCguLs5UfBVKPp5//vkKdWaz2Wp+8mGw+gsuXmsPp1V1CEClyDvlUN3WHrpYFbxYLj8/X/v27XN+PnDggNLS0lSvXj3Vq1dPU6dO1YABAxQVFaXMzExNmDBBsbGxSkhIkCS1a9dOffv21fDhwzV//nyVlJQoMTFRd955p6KjoyVJd911l6ZOnaqhQ4dq4sSJ2rFjh2bPnu2SAzz88MO65pprNGvWLPXr109Lly7V1q1bXR7HrYgKJR/lT7cAAOD1qmB59a1bt6p3797Oz2PGjJFU9u61efPmKT09XW+++aZycnIUHR2tPn36aPr06S5zSBYvXqzExERdf/318vHx0YABA1xGNsLCwvTRRx9p5MiR6tatmxo0aKCkpCSXtUCuuuoqLVmyRI899pgeeeQRtWrVSitXrlSHDh1M3Y/NMAz+zFfZ405hYWG6VrfIz1arqsMBKgWVD1ysyiof+5Wbm1tp7xgr/z3RLPkp+QQGWurLUVio7yc/WqnxVmeWJ5wCAOBVeLGcZSQfAACYUBUrnF5sTC8yBgAAYAWVDwAAzGDYxbLfVfn49NNP9de//lVxcXH64YcfJEn//Oc/tWnTJrcGBwBAtePG5dW9lenk49///rcSEhIUFBSkr7/+2vkSnNzcXM2YMcPtAQIAgIuL6eTjySef1Pz587VgwQLnCmiS9Ic//EFfffWVW4MDAKC6KZ9wanXzZqbnfGRkZKhXr17n7A8LC1NOTo47YgIAoPqqghVOLzamKx9RUVEuS7yW27Rpk1q2bOmWoAAAqLaY82GZ6eRj+PDhevjhh7VlyxbZbDYdPnxYixcv1rhx4zRixIjKiBEAAFxETA+7TJo0SQ6HQ9dff71Onz6tXr16KSAgQOPGjdODDz5YGTECAFBtsMiYdaaTD5vNpkcffVTjx4/Xvn37lJ+fr/bt2ys4OLgy4gMAoHphnQ/LfvciY/7+/mrfvr07YwEAAF7AdPLRu3dv2WwXnqW7fv16SwEBAFCtueNRWSof5nTp0sXlc0lJidLS0rRjxw4NHjzYXXEBAFA9Meximenk4/nnnz/v/ilTpig/P99yQAAA4OLmtrfa/vWvf9Ubb7zhru4AAKieWOfDMre91TY1NVWBgYHu6g4AgGqJR22tM5183HbbbS6fDcPQkSNHtHXrVj3++ONuCwwAAFycTCcfYWFhLp99fHzUpk0bTZs2TX369HFbYAAA4OJkKvmw2+2699571bFjR9WtW7eyYgIAoPriaRfLTE049fX1VZ8+fXh7LQDAa5XP+bC6eTPTT7t06NBB+/fvr4xYAACAFzCdfDz55JMaN26cVq1apSNHjigvL89lAwDgosdjtpZUeM7HtGnTNHbsWN14442SpD/96U8uy6wbhiGbzSa73e7+KAEAqC6Y82FZhZOPqVOn6oEHHtDHH39cmfEAAICLXIWTD8MoS9OuueaaSgsGAIDqjkXGrDP1qO2vvc0WAACvwLCLZaaSj9atW/9mAnLixAlLAQEAgIubqeRj6tSp56xwCgCAN2HYxTpTycedd96piIiIyooFAIDqj2EXyyq8zgfzPQAAgDuYftoFAACvRuXDsgonHw6HozLjAACgRmDOh3Wm5nwAAOD1qHxYZvrdLgAAAFZQ+QAAwAwqH5aRfAAAYAJzPqxj2AUAAHgUlQ8AAMxg2MUykg8AAExg2MU6hl0AAIBHUfkAAMAMhl0sI/kAAMAMkg/LGHYBAAAeReUDAAATbGc3q314M5IPAADMYNjFMpIPAABM4FFb65jzAQAAPIrKBwAAZjDsYhnJBwAAZnl58mAVwy4AAMCjSD4AADChfMKp1c2MTz75RDfffLOio6Nls9m0cuVKl+OGYSgpKUmNGjVSUFCQ4uPjtXfvXpc2J06c0KBBgxQaGqrw8HANHTpU+fn5Lm3S09PVs2dPBQYGKiYmRjNnzjwnlhUrVqht27YKDAxUx44d9cEHH5i7GZF8AABgjuGmzYSCggJ17txZL7300nmPz5w5U3PmzNH8+fO1ZcsW1alTRwkJCSosLHS2GTRokHbu3KmUlBStWrVKn3zyie6//37n8by8PPXp00fNmjXTtm3b9Oyzz2rKlCl69dVXnW02b96sgQMHaujQofr666/Vv39/9e/fXzt27DB1PzbDMBi5UtkXPSwsTNfqFvnZalV1OEClWHs4rapDACpF3imH6rber9zcXIWGhlbONc7+nugwfIZ8/QMt9WUvLtSOBY/8rnhtNpveffdd9e/fX1JZ1SM6Olpjx47VuHHjJEm5ubmKjIzUokWLdOedd2r37t1q3769vvzyS11++eWSpDVr1ujGG2/UoUOHFB0drXnz5unRRx9Vdna2/P39JUmTJk3SypUrtWfPHknSHXfcoYKCAq1atcoZT48ePdSlSxfNnz+/wvdA5QMAABPcOeySl5fnshUVFZmO58CBA8rOzlZ8fLxzX1hYmLp3767U1FRJUmpqqsLDw52JhyTFx8fLx8dHW7Zscbbp1auXM/GQpISEBGVkZOjkyZPONr+8Tnmb8utUFMkHAABmuHHYJSYmRmFhYc4tOTnZdDjZ2dmSpMjISJf9kZGRzmPZ2dmKiIhwOe7n56d69eq5tDlfH7+8xoXalB+vKB61BQCgihw8eNBl2CUgIKAKo/EcKh8AAJjgzmGX0NBQl+33JB9RUVGSpKNHj7rsP3r0qPNYVFSUjh075nK8tLRUJ06ccGlzvj5+eY0LtSk/XlEkHwAAmFEFT7v8mhYtWigqKkrr1q1z7svLy9OWLVsUFxcnSYqLi1NOTo62bdvmbLN+/Xo5HA51797d2eaTTz5RSUmJs01KSoratGmjunXrOtv88jrlbcqvU1EkHwAAmFEFyUd+fr7S0tKUlpYmqWySaVpamrKysmSz2TRq1Cg9+eST+s9//qNvvvlG99xzj6Kjo51PxLRr1059+/bV8OHD9cUXX+izzz5TYmKi7rzzTkVHR0uS7rrrLvn7+2vo0KHauXOnli1bptmzZ2vMmDHOOB5++GGtWbNGs2bN0p49ezRlyhRt3bpViYmJpu6HOR8AAFRzW7duVe/evZ2fyxOCwYMHa9GiRZowYYIKCgp0//33KycnR1dffbXWrFmjwMCfHwlevHixEhMTdf3118vHx0cDBgzQnDlznMfDwsL00UcfaeTIkerWrZsaNGigpKQkl7VArrrqKi1ZskSPPfaYHnnkEbVq1UorV65Uhw4dTN0P63ycxTof8Aas84GLlSfX+eg82D3rfGx/8/et83ExoPIBAIAZ7piz4eV/9jPnAwAAeBSVDwAATLAZhmwWZyxYPb+mI/kAAMAMhl0sY9gFAAB4FJUPAABM+OUKpVb68GYkHwAAmMGwi2UMuwAAAI+i8gEAgAkMu1hH8gEAgBkMu1hG8gEAgAlUPqxjzgcAAPAoKh8AAJjBsItlJB8AAJjk7cMmVjHsAgAAPIrKBwAAZhhG2Wa1Dy9G8gEAgAk87WIdwy4AAMCjqHwAAGAGT7tYRvIBAIAJNkfZZrUPb8awCwAA8CgqH6g0dyQe1R9uzFVMbJGKC320a2ttvf5UIx3KDJQkhYSX6u5x2brsmnxFRBcr94SfNq8J05szo3T6lG8VRw9vs/TFCH32QbgO7guQf6BD7S8/raGPHlZMbJGzzeHv/LVgWrR2fhGskmKbuvXO08gnf1DdhqWSpOyD/lryfKTSPgvWyeO1VD+yRNfddlIDHz6qWv4/19m3bgjRP5+L0vcZgfIPMNShR77uf+KwomKKJUnPjWqqlOX1zomxaeszWrAho5K/EvhNDLtYRuUDlaZTXIHeX9RAo25qpcl3tpSvn6EZb+9XQJBdklQvskT1I0u1YFoj/e26NnpuVIwuvzZPY2YdrOLI4Y3SU4N185Af9cKqvUpemil7qfTIwEtUeLrsx2ThaR89MvAS2WzSMyv26R/v7VVpsY+SBreQ42wJ/eC+ADkc0sPPHNKrH+/R36b8oNX/rK+FyY2c18nO8teUe1uo8x/y9XJKhp5akqm8E36aPrS5s82IaYf0dtoO5/Z/W3cqpG6pet2U68kvCS6g/GkXq5s3q9LkY8iQIbLZbHr66add9q9cuVI2m62KooK7PDqopVKW19P33wZq/64gzRrVVJFNStSq0xlJ0vcZQZo+vLm2pITpyPcB2v5ZiBY900jd/5gnH18v/5cJj5uxZL/63HFCzdsU6pJLCzX2hSwd+8Ffe9ODJEk7v6ijowf9NfaFLLVoV6gW7Qo1fvb32ru9ttI2BUuSruh9SuNeOKhu155So2bFikvI0+0PHNNnH4Y5r7M3PUgOu01DJh5RdPNitep0Rrc/cEyZO4NUWlLWpk6oQ/UiSp3b3u21lZ/jqz53/uTxrwvOo3ydD6ubF6vyykdgYKCeeeYZnTx5sqpDQSWrE1pW8TiVc+EhlTqhdp3O95HDTvKJqlWQV/Z9GhJe9n1bUmyTbHIZPqkVYMjmI+38IvjC/ZzydfYhSa06nZGPj6GPltaT3S4V5Pnov/+uq649T8mv1vn7WPN2PXXteUqRTUrccGdA1avy5CM+Pl5RUVFKTk6+YJtNmzapZ8+eCgoKUkxMjB566CEVFBQ4jxcVFWncuHFq3Lix6tSpo+7du2vDhg2/et2ioiLl5eW5bKg8NpuhB6b+oB1f1Nb3GUHnbRNar1R3jTqqD/+vvoejA1w5HNL8Jxrr0ivy1bxtoSSpbbcCBdZ26PWnolV42qbC0z5aMC1aDrtNJ46df/rcDwf89d4bDXXj3T8690U1LdaMtzO18OlGuql5Z93WtpN+POyvR1/5/rx9/JTtpy8/DlXfu064/0bxuzDsYl2VJx++vr6aMWOGXnzxRR06dOic45mZmerbt68GDBig9PR0LVu2TJs2bVJiYqKzTWJiolJTU7V06VKlp6frz3/+s/r27au9e/de8LrJyckKCwtzbjExMZVyfyiTOOMHNWtbqOQRzc57vHawXdPfOqCsbwP1z1lRHo4OcDX3kSb6fk+QJs/7OSEIr2/XY698py0poerfqpNubdNRBXm+iu14Wrbz/CT98UgtPTroEvW6KUc3Dvo5cThxzE8vjI/RH/98Qi9+8K2ee2evavkbmj68+Xkr8Skr6ik41K6r+jLfo9ow3LR5sSpPPiTp1ltvVZcuXfTEE0+ccyw5OVmDBg3SqFGj1KpVK1111VWaM2eO3nrrLRUWFiorK0sLFy7UihUr1LNnT11yySUaN26crr76ai1cuPCC15w8ebJyc3Od28GDTHKsLCOfOqTuf8zThNsv0Y9H/M85HlTHrqeW7NeZAh9NHdpc9lKGXFB15j7SWFtSQjXzX/vUMNp1mKPbtae0KHW3lqXv0IodOzThxSz9lF1LjZoWubT7KdtPE/58idpfXqCHn3X92fL+ogaqE+LQsMePKLbjGXXsUaAJL36vtE0h2vNVbZe2hiGtXVpf199+wmW4B6jpqs2jts8884yuu+46jRs3zmX/9u3blZ6ersWLFzv3GYYhh8OhAwcOaP/+/bLb7WrdurXLeUVFRapf/8Ll+4CAAAUEBLj3JvA/DI186gdd1TdX42+P1dGD5369aweXJR4lxTY9MaSFSoqqRT4ML2QY0kuPNtbmNWF69l/7FNW0+IJtw+qXzeFI2xSsnB/91KPPz8O2Px6ppQl/vkStOp7R2Oez5PM/39KFZ3xk83FNJMonWDv+Z+Gp9NRgHT4QoL4DGXKpTni3i3XVJvno1auXEhISNHnyZA0ZMsS5Pz8/X3/729/00EMPnXNO06ZNlZ6eLl9fX23btk2+vq4TGYODLzwJDJUvccYP6n3rSU25t4XO5PuobsOyvyILTvmquNBHtYPtZx+9dWjmg81VO9iu2sFlP9Rzf/KTw0EFBJ4z95Em+vjdupqycL+Cgh3OeRx1QuwKCCr7TbF2aT01bVWosPql2r2tjuYlNdat9x93rgXy45FaGn97rCIaF2t40mHl/vTzj9h6EWVrgXS/Pk/vvtpQ//ePSPXuf1Kn83218OlGimxSrNgOZ1xiWvt2PbW9rMA57wTVBG+1tazaJB+S9PTTT6tLly5q06aNc99ll12mXbt2KTY29rzndO3aVXa7XceOHVPPnj09FSoq4OYhZY8FPvdOpsv+50bFKGV5PcV2PKN23U5Lkhal7nFpc8+V7XT00LlDNEBlWfVmA0nS+AGtXPaPfT5Lfe4oqzwcygzQwuRGOpXjq8iYYg186Khuu/+4s+1Xn4To8IEAHT4QoEHdLnXpZ+3hNElSl6vzNeml77Xi5QiteDlCAUEOtet2Wk8uznQmOVLZUzCbVofrgennzoUDajqbYVRd+jVkyBDl5ORo5cqVzn333HOPVqxYocLCQhmGofT0dPXo0UP33Xefhg0bpjp16mjXrl1KSUnR3LlzJUl//etf9dlnn2nWrFnq2rWrjh8/rnXr1qlTp07q169fhWLJy8tTWFiYrtUt8rNd4Hk3oIYr/wUIXGzyTjlUt/V+5ebmKjQ0tHKucfb3RNwN0+RXK9BSX6UlhUr9MKlS463Oqt0A+7Rp0+T4xcBnp06dtHHjRn377bfq2bOnunbtqqSkJEVHRzvbLFy4UPfcc4/Gjh2rNm3aqH///vryyy/VtGnTqrgFAMDFjKddLKvSykd1QuUD3oDKBy5WHq189HVT5WON91Y+qtWcDwAAqjuedrGO5AMAADMcRtlmtQ8vRvIBAIAZ7piz4d25R/WbcAoAAC5uVD4AADDBJjfM+XBLJDUXyQcAAGawwqllDLsAAACPovIBAIAJPGprHckHAABm8LSLZQy7AAAAj6LyAQCACTbDkM3ihFGr59d0JB8AAJjhOLtZ7cOLMewCAAA8isoHAAAmMOxiHckHAABm8LSLZSQfAACYwQqnljHnAwAAeBSVDwAATGCFU+uofAAAYEb5sIvVrYKmTJkim83msrVt29Z5vLCwUCNHjlT9+vUVHBysAQMG6OjRoy59ZGVlqV+/fqpdu7YiIiI0fvx4lZaWurTZsGGDLrvsMgUEBCg2NlaLFi2y9GX6NSQfAABUc5deeqmOHDni3DZt2uQ8Nnr0aL3//vtasWKFNm7cqMOHD+u2225zHrfb7erXr5+Ki4u1efNmvfnmm1q0aJGSkpKcbQ4cOKB+/fqpd+/eSktL06hRozRs2DCtXbu2Uu6HYRcAAEywOco2q32Y4efnp6ioqHP25+bm6vXXX9eSJUt03XXXSZIWLlyodu3a6fPPP1ePHj300UcfadeuXfrvf/+ryMhIdenSRdOnT9fEiRM1ZcoU+fv7a/78+WrRooVmzZolSWrXrp02bdqk559/XgkJCdZu9jyofAAAYIYbh13y8vJctqKiovNecu/evYqOjlbLli01aNAgZWVlSZK2bdumkpISxcfHO9u2bdtWTZs2VWpqqiQpNTVVHTt2VGRkpLNNQkKC8vLytHPnTmebX/ZR3qa8D3cj+QAAoIrExMQoLCzMuSUnJ5/Tpnv37lq0aJHWrFmjefPm6cCBA+rZs6dOnTql7Oxs+fv7Kzw83OWcyMhIZWdnS5Kys7NdEo/y4+XHfq1NXl6ezpw5467bdWLYBQAAM9y4yNjBgwcVGhrq3B0QEHBO0xtuuMH53506dVL37t3VrFkzLV++XEFBQRYDqRpUPgAAMKF8eXWrmySFhoa6bOdLPv5XeHi4WrdurX379ikqKkrFxcXKyclxaXP06FHnHJGoqKhznn4p//xbbUJDQyslwSH5AACgBsnPz1dmZqYaNWqkbt26qVatWlq3bp3zeEZGhrKyshQXFydJiouL0zfffKNjx44526SkpCg0NFTt27d3tvllH+VtyvtwN5IPAADM8PA6H+PGjdPGjRv13XffafPmzbr11lvl6+urgQMHKiwsTEOHDtWYMWP08ccfa9u2bbr33nsVFxenHj16SJL69Omj9u3b6+6779b27du1du1aPfbYYxo5cqSz0vLAAw9o//79mjBhgvbs2aOXX35Zy5cv1+jRoyvlS8icDwAAzDAkWXzU1syckUOHDmngwIH66aef1LBhQ1199dX6/PPP1bBhQ0nS888/Lx8fHw0YMEBFRUVKSEjQyy+/7Dzf19dXq1at0ogRIxQXF6c6depo8ODBmjZtmrNNixYttHr1ao0ePVqzZ89WkyZN9Nprr1XKY7aSZDMML3+7zVl5eXkKCwvTtbpFfrZaVR0OUCnWHk6r6hCASpF3yqG6rfcrNzfXZQKnW69x9vfEdV0nyc830FJfpfZCrf/66UqNtzpj2AUAAHgUwy4AAJhhyNScjQv24cVIPgAAMMPkhNEL9uHFGHYBAAAeReUDAAAzHJJsbujDi5F8AABgwi9XKLXShzdj2AUAAHgUlQ8AAMxgwqllJB8AAJhB8mEZwy4AAMCjqHwAAGAGlQ/LSD4AADCDR20tI/kAAMAEHrW1jjkfAADAo6h8AABgBnM+LCP5AADADIch2SwmDw7vTj4YdgEAAB5F5QMAADMYdrGM5AMAAFPckHzIu5MPhl0AAIBHUfkAAMAMhl0sI/kAAMAMhyHLwyY87QIAAOA5VD4AADDDcJRtVvvwYiQfAACYwZwPy0g+AAAwgzkfljHnAwAAeBSVDwAAzGDYxTKSDwAAzDDkhuTDLZHUWAy7AAAAj6LyAQCAGQy7WEbyAQCAGQ6HJIvrdDi8e50Phl0AAIBHUfkAAMAMhl0sI/kAAMAMkg/LGHYBAAAeReUDAAAzWF7dMpIPAABMMAyHDItvpbV6fk1H8gEAgBmGYb1ywZwPAAAAz6HyAQCAGYYb5nx4eeWD5AMAADMcDslmcc6Gl8/5YNgFAAB4FJUPAADMYNjFMpIPAABMMBwOGRaHXbz9UVuGXQAAgEdR+QAAwAyGXSwj+QAAwAyHIdlIPqxg2AUAAHgUlQ8AAMwwDElW1/nw7soHyQcAACYYDkOGxWEXg+QDAABUmOGQ9coHj9oCAAB4DJUPAABMYNjFOpIPAADMYNjFMpKPs8qz0FKVWF47Bqiu8k559w88XLzy8su+tz1RUXDH74lSlbgnmBqK5OOsU6dOSZI26YMqjgSoPHVbV3UEQOU6deqUwsLCKqVvf39/RUVFaVO2e35PREVFyd/f3y191TQ2w9sHns5yOBw6fPiwQkJCZLPZqjqci15eXp5iYmJ08OBBhYaGVnU4gNvxPe5ZhmHo1KlTio6Olo9P5T1LUVhYqOLiYrf05e/vr8DAQLf0VdNQ+TjLx8dHTZo0qeowvE5oaCg/mHFR43vccyqr4vFLgYGBXpswuBOP2gIAAI8i+QAAAB5F8oEqERAQoCeeeEIBAQFVHQpQKfgeBy6MCacAAMCjqHwAAACPIvkAAAAeRfIBAAA8iuQDAAB4FMkHPGLIkCHq379/VYcBWDJkyBDZbDY9/fTTLvtXrlzJysiACSQfAGBCYGCgnnnmGZ08ebKqQwFqLJIPeNyaNWt09dVXKzw8XPXr19dNN92kzMzMqg4LqJD4+HhFRUUpOTn5gm02bdqknj17KigoSDExMXrooYdUUFDgPF5UVKRx48apcePGqlOnjrp3764NGzZ4IHqgeiD5gMcVFBRozJgx2rp1q9atWycfHx/deuutcjh43TuqP19fX82YMUMvvviiDh06dM7xzMxM9e3bVwMGDFB6erqWLVumTZs2KTEx0dkmMTFRqampWrp0qdLT0/XnP/9Zffv21d69ez15K0CVYZExeMSQIUOUk5OjlStXnnPsxx9/VMOGDfXNN9+oQ4cOng8OqKBffh/HxcWpffv2ev3117Vy5UrdeuutMgxDw4YNk6+vr1555RXneZs2bdI111yjgoICHTt2TC1btlRWVpaio6OdbeLj43XllVdqxowZVXFrgEfxVlt43N69e5WUlKQtW7boxx9/dFY8srKySD5QYzzzzDO67rrrNG7cOJf927dvV3p6uhYvXuzcZxiGHA6HDhw4oP3798tut6t169Yu5xUVFal+/foeiR2oaiQf8Libb75ZzZo104IFCxQdHS2Hw6EOHTqouLi4qkMDKqxXr15KSEjQ5MmTNWTIEOf+/Px8/e1vf9NDDz10zjlNmzZVenq6fH19tW3bNvn6+rocDw4OruywgWqB5AMe9dNPPykjI0MLFixQz549JZWVpIGa6Omnn1aXLl3Upk0b577LLrtMu3btUmxs7HnP6dq1q+x2u44dO+b8NwB4GyacwqPq1q2r+vXr69VXX9W+ffu0fv16jRkzpqrDAn6Xjh07atCgQZozZ45z38SJE7V582YlJiYqLS1Ne/fu1XvvveeccNq6dWsNGjRI99xzj9555x0dOHBAX3zxhZKTk7V69eqquhXAo0g+4BEOh0N+fn7y8fHR0qVLtW3bNnXo0EGjR4/Ws88+W9XhAb/btGnTXJ7U6tSpkzZu3Khvv/1WPXv2VNeuXZWUlOQyuXThwoW65557NHbsWLVp00b9+/fXl19+qaZNm1bFLQAex9Mu8Ii+ffsqNjZWc+fOrepQAABVjMoHKtXJkye1atUqbdiwQfHx8VUdDgCgGmDCKSrVfffdpy+//FJjx47VLbfcUtXhAACqAYZdAACARzHsAgAAPIrkAwAAeBTJBwAA8CiSDwAA4FEkHwAAwKNIPoBqZMiQIerfv7/z87XXXqtRo0Z5PI4NGzbIZrMpJyfngm1sNptWrlxZ4T6nTJmiLl26WIrru+++k81mU1pamqV+AFQtkg/gNwwZMkQ2m002m03+/v6KjY3VtGnTVFpaWunXfueddzR9+vQKta1IwgAA1QGLjAEV0LdvXy1cuFBFRUX64IMPNHLkSNWqVUuTJ08+p21xcbH8/f3dct169eq5pR8AqE6ofAAVEBAQoKioKDVr1kwjRoxQfHy8/vOf/0j6eajkqaeeUnR0tPP16gcPHtRf/vIXhYeHq169errlllv03XffOfu02+0aM2aMwsPDVb9+fU2YMEH/u+bf/w67FBUVaeLEiYqJiVFAQIBiY2P1+uuv67vvvlPv3r0llb052GazaciQIZLKXuqXnJysFi1aKCgoSJ07d9a//vUvl+t88MEHat26tYKCgtS7d2+XOCtq4sSJat26tWrXrq2WLVvq8ccfV0lJyTntXnnlFcXExKh27dr6y1/+otzcXJfjr732mtq1a6fAwEC1bdtWL7/8sulYAFRvJB/A7xAUFKTi4mLn53Xr1ikjI0MpKSlatWqVSkpKlJCQoJCQEH366af67LPPFBwcrL59+zrPmzVrlhYtWqQ33nhDmzZt0okTJ/Tuu+/+6nXvuecevf3225ozZ452796tV155RcHBwYqJidG///1vSVJGRoaOHDmi2bNnS5KSk5P11ltvaf78+dq5c6dGjx6tv/71r9q4caOksiTptttu080336y0tDQNGzZMkyZNMv01CQkJ0aJFi7Rr1y7Nnj1bCxYs0PPPP+/SZt++fVq+fLnef/99rVmzRl9//bX+/ve/O48vXrxYSUlJeuqpp7R7927NmDFDjz/+uN58803T8QCoxgwAv2rw4MHGLbfcYhiGYTgcDiMlJcUICAgwxo0b5zweGRlpFBUVOc/55z//abRp08ZwOBzOfUVFRUZQUJCxdu1awzAMo1GjRsbMmTOdx0tKSowmTZo4r2UYhnHNNdcYDz/8sGEYhpGRkWFIMlJSUs4b58cff2xIMk6ePOncV1hYaNSuXdvYvHmzS9uhQ4caAwcONAzDMCZPnmy0b9/e5fjEiRPP6et/STLefffdCx5/9tlnjW7dujk/P/HEE4avr69x6NAh574PP/zQ8PHxMY4cOWIYhmFccsklxpIlS1z6mT59uhEXF2cYhmEcOHDAkGR8/fXXF7wugOqPOR9ABaxatUrBwcEqKSmRw+HQXXfdpSlTpjiPd+zY0WWex/bt27Vv3z6FhIS49FNYWKjMzEzl5ubqyJEj6t69u/OYn5+fLr/88nOGXsqlpaXJ19dX11xzTYXj3rdvn06fPq0//vGPLvuLi4vVtWtXSdLu3btd4pCkuLi4Cl+j3LJlyzRnzhxlZmYqPz9fpaWlCg0NdWnTtGlTNW7c2OU6DodDGRkZCgkJUWZmpoYOHarhw4c725SWliosLMx0PACqL5IPoAJ69+6tefPmyd/fX9HR0fLzc/2nU6dOHZfP+fn56tatmxYvXnxOXw0bNvxdMQQFBZk+Jz8/X5K0evVql1/6Utk8FndJTU3VoEGDNHXqVCUkJCgsLExLly7VrFmzTMe6YMGCc5IhX19ft8UKoOqRfAAVUKdOHcXGxla4/WWXXaZly5YpIiLinL/+yzVq1EhbtmxRr169JJX9hb9t2zZddtll523fsWNHORwObdy4UfHx8eccL6+82O1257727dsrICBAWVlZF6yYtGvXzjl5ttznn3/+2zf5C5s3b1azZs306KOPOvd9//3357TLysrS4cOHFR0d7byOj4+P2rRpo8jISEVHR2v//v0aNGiQqesDqFmYcApUgkGDBqlBgwa65ZZb9Omnn+rAgQPasGGDHnroIR06dEiS9PDDD+vpp5/WypUrtWfPHv3973//1TU6mjdvrsGDB+u+++7TypUrnX0uX75cktSsWTPZbDatWrVKx48fV35+vkJCQjRu3DiNHj1ab775pjIzM/XVV1/pxRdfdE7ifOCBB7R3716NHz9eGRkZWrJkiRYtWmTqflu1aqWsrCwtXbpUmZmZmjNnznknzwYGBmrw4MHavn27Pv30Uz300EP6y1/+oqioKEnS1KlTlZycrDlz5ujbb7/VN998o4ULF+of//iHqXgAVG8kH0AlqF27tj755BM1bdpUt912m9q1a6ehQ4eqsLDQWQkZO3as7r77bg0ePFhxcXEKCQnRrbfe+qv9zps3T7fffrv+/ve/q23btho+fLgKCgokSY0bN9bUqVM1adIkRUZGKjExUZI0ffp0Pf7440pOTla7du3Ut29frV69Wi1atJBUNg/j3//+t1auXKnOnTtr/vz5mjFjhqn7/dOf/qTRo0crMTFRXbp00ebNm/X444+f0y42Nla33XabbrzxRvXp00edOnVyeZR22LBheu2117Rw4UJ17NhR11xzjRYtWuSMFcDFwWZcaHYbAABAJaDyAQAAPIrkAwAAeBTJBwAA8CiSDwAA4FEkHwAAwKNIPgAAgEeRfAAAAI8i+QAAAB5F8gEAADyK5AMAAHgUyQcAAPCo/weSMK5kD/JQRwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          Ja       0.90      0.67      0.77       291\n",
      "         Nee       1.00      1.00      1.00     29309\n",
      "\n",
      "    accuracy                           1.00     29600\n",
      "   macro avg       0.95      0.83      0.88     29600\n",
      "weighted avg       1.00      1.00      1.00     29600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ngram 2 No stopwords\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1,2), lowercase=True, token_pattern=r\"(?u)\\b\\w\\w+\\b|\\+|\\-\")),\n",
    "    ('clf', SGDClassifier(early_stopping=True, n_iter_no_change=5, validation_fraction = 0.25, verbose=3)),\n",
    "])\n",
    "random_search = RandomizedSearchCV(estimator=pipeline, param_distributions=parameter_grid, random_state=500, verbose=3, scoring='f1_macro')\n",
    "random_search.fit(X_train, y_train)  \n",
    "predicted_nb = random_search.predict(X_test)\n",
    "print(np.mean(predicted_nb == y_test))\n",
    "cm = confusion_matrix(y_test, predicted_nb)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=random_search.classes_)\n",
    "disp.plot()\n",
    "\n",
    "plt.show()\n",
    "print(metrics.classification_report(y_test, predicted_nb,\n",
    "    target_names=random_search.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb127a2",
   "metadata": {},
   "source": [
    "# BEST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50737463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESET CORPUS\n",
    "Corpus = Corpus_backup.copy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(Corpus['text'], Corpus['label'], test_size=0.2, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6819f54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = {'clf__loss':              ['hinge', 'log_loss', 'log', 'modified_huber', 'squared_hinge', 'perceptron', 'squared_error', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "                  'clf__penalty':           ['l2', 'l1'],\n",
    "                  'clf__l1_ratio':          sp_randFloat(),\n",
    "                  'clf__fit_intercept':     [True, False],\n",
    "                  'clf__max_iter':          [int(x) for x in np.linspace(start = 10, stop = 100, num = 10)],\n",
    "                  'clf__tol':               sp_randFloat(),\n",
    "                  'clf__shuffle':           [True, False],\n",
    "                  'clf__epsilon':           sp_randFloat(),\n",
    "                  'clf__learning_rate':     ['constant', 'optimal', 'invscaling', 'adaptive'],\n",
    "                  'clf__eta0':              sp_randFloat(),\n",
    "                  'clf__power_t':           sp_randFloat(),\n",
    "                  'clf__class_weight':      ['balanced', None],\n",
    "                  'clf__warm_start':        [True, False],\n",
    "                  'clf__average':           [True, False],\n",
    "                  'tfidf__max_df':          [0.90, 0.95],\n",
    "                  'tfidf__min_df':          [3, 5]\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cbe0cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "-- Epoch 1\n",
      "Norm: 82.06, NNZs: 296, Bias: 0.000000, T: 71040, Avg. loss: 0.073459\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 110.67, NNZs: 87, Bias: 0.000000, T: 142080, Avg. loss: 0.051392\n",
      "Total training time: 0.93 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 132.37, NNZs: 67, Bias: 0.000000, T: 213120, Avg. loss: 0.045295\n",
      "Total training time: 1.47 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 150.59, NNZs: 58, Bias: 0.000000, T: 284160, Avg. loss: 0.042234\n",
      "Total training time: 2.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 166.72, NNZs: 54, Bias: 0.000000, T: 355200, Avg. loss: 0.039995\n",
      "Total training time: 2.61 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 181.20, NNZs: 49, Bias: 0.000000, T: 426240, Avg. loss: 0.038496\n",
      "Total training time: 3.18 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 183.85, NNZs: 49, Bias: 0.000000, T: 497280, Avg. loss: 0.037617\n",
      "Total training time: 3.70 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 186.46, NNZs: 49, Bias: 0.000000, T: 568320, Avg. loss: 0.037417\n",
      "Total training time: 4.18 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 189.02, NNZs: 49, Bias: 0.000000, T: 639360, Avg. loss: 0.037194\n",
      "Total training time: 4.72 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 191.57, NNZs: 49, Bias: 0.000000, T: 710400, Avg. loss: 0.036966\n",
      "Total training time: 5.25 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 194.06, NNZs: 48, Bias: 0.000000, T: 781440, Avg. loss: 0.036769\n",
      "Total training time: 5.75 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 194.55, NNZs: 48, Bias: 0.000000, T: 852480, Avg. loss: 0.036684\n",
      "Total training time: 6.23 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 195.05, NNZs: 48, Bias: 0.000000, T: 923520, Avg. loss: 0.036638\n",
      "Total training time: 6.70 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 195.53, NNZs: 48, Bias: 0.000000, T: 994560, Avg. loss: 0.036590\n",
      "Total training time: 7.17 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 196.02, NNZs: 48, Bias: 0.000000, T: 1065600, Avg. loss: 0.036568\n",
      "Total training time: 7.63 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 196.51, NNZs: 47, Bias: 0.000000, T: 1136640, Avg. loss: 0.036536\n",
      "Total training time: 8.10 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 196.61, NNZs: 47, Bias: 0.000000, T: 1207680, Avg. loss: 0.036510\n",
      "Total training time: 8.60 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 196.71, NNZs: 47, Bias: 0.000000, T: 1278720, Avg. loss: 0.036502\n",
      "Total training time: 9.11 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 196.80, NNZs: 47, Bias: 0.000000, T: 1349760, Avg. loss: 0.036496\n",
      "Total training time: 9.59 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 196.90, NNZs: 47, Bias: 0.000000, T: 1420800, Avg. loss: 0.036487\n",
      "Total training time: 10.06 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.06171699256249541, clf__eta0=0.6666115972798587, clf__fit_intercept=False, clf__l1_ratio=0.9792901432894962, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.15075392531110676, clf__shuffle=True, clf__tol=0.365636830734297, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.198 total time= 1.1min\n",
      "-- Epoch 1\n",
      "Norm: 81.60, NNZs: 253, Bias: 0.000000, T: 71040, Avg. loss: 0.073763\n",
      "Total training time: 0.43 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 110.63, NNZs: 93, Bias: 0.000000, T: 142080, Avg. loss: 0.050780\n",
      "Total training time: 0.91 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 132.56, NNZs: 67, Bias: 0.000000, T: 213120, Avg. loss: 0.044806\n",
      "Total training time: 1.37 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 150.89, NNZs: 57, Bias: 0.000000, T: 284160, Avg. loss: 0.041424\n",
      "Total training time: 1.85 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 167.00, NNZs: 53, Bias: 0.000000, T: 355200, Avg. loss: 0.039199\n",
      "Total training time: 2.33 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 181.51, NNZs: 50, Bias: 0.000000, T: 426240, Avg. loss: 0.037752\n",
      "Total training time: 2.81 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 184.17, NNZs: 49, Bias: 0.000000, T: 497280, Avg. loss: 0.036724\n",
      "Total training time: 3.30 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 186.77, NNZs: 49, Bias: 0.000000, T: 568320, Avg. loss: 0.036546\n",
      "Total training time: 3.78 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 189.35, NNZs: 49, Bias: 0.000000, T: 639360, Avg. loss: 0.036345\n",
      "Total training time: 4.26 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 191.89, NNZs: 49, Bias: 0.000000, T: 710400, Avg. loss: 0.036107\n",
      "Total training time: 4.74 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 194.41, NNZs: 49, Bias: 0.000000, T: 781440, Avg. loss: 0.035957\n",
      "Total training time: 5.22 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 194.90, NNZs: 49, Bias: 0.000000, T: 852480, Avg. loss: 0.035818\n",
      "Total training time: 5.72 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 195.39, NNZs: 49, Bias: 0.000000, T: 923520, Avg. loss: 0.035793\n",
      "Total training time: 6.22 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 195.88, NNZs: 49, Bias: 0.000000, T: 994560, Avg. loss: 0.035758\n",
      "Total training time: 6.72 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 196.37, NNZs: 49, Bias: 0.000000, T: 1065600, Avg. loss: 0.035717\n",
      "Total training time: 7.23 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 196.86, NNZs: 49, Bias: 0.000000, T: 1136640, Avg. loss: 0.035691\n",
      "Total training time: 7.72 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 196.95, NNZs: 49, Bias: 0.000000, T: 1207680, Avg. loss: 0.035663\n",
      "Total training time: 8.21 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 197.05, NNZs: 49, Bias: 0.000000, T: 1278720, Avg. loss: 0.035658\n",
      "Total training time: 8.71 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 197.15, NNZs: 49, Bias: 0.000000, T: 1349760, Avg. loss: 0.035650\n",
      "Total training time: 9.24 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 197.24, NNZs: 49, Bias: 0.000000, T: 1420800, Avg. loss: 0.035646\n",
      "Total training time: 9.76 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.06171699256249541, clf__eta0=0.6666115972798587, clf__fit_intercept=False, clf__l1_ratio=0.9792901432894962, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.15075392531110676, clf__shuffle=True, clf__tol=0.365636830734297, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.195 total time= 1.1min\n",
      "-- Epoch 1\n",
      "Norm: 82.03, NNZs: 241, Bias: 0.000000, T: 71040, Avg. loss: 0.073916\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 110.71, NNZs: 92, Bias: 0.000000, T: 142080, Avg. loss: 0.051338\n",
      "Total training time: 0.90 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 132.56, NNZs: 72, Bias: 0.000000, T: 213120, Avg. loss: 0.045196\n",
      "Total training time: 1.37 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 151.04, NNZs: 58, Bias: 0.000000, T: 284160, Avg. loss: 0.041865\n",
      "Total training time: 1.82 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 167.02, NNZs: 52, Bias: 0.000000, T: 355200, Avg. loss: 0.039529\n",
      "Total training time: 2.27 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 181.61, NNZs: 49, Bias: 0.000000, T: 426240, Avg. loss: 0.038015\n",
      "Total training time: 2.75 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 184.31, NNZs: 49, Bias: 0.000000, T: 497280, Avg. loss: 0.037122\n",
      "Total training time: 3.25 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 186.94, NNZs: 49, Bias: 0.000000, T: 568320, Avg. loss: 0.036872\n",
      "Total training time: 3.73 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 189.50, NNZs: 48, Bias: 0.000000, T: 639360, Avg. loss: 0.036596\n",
      "Total training time: 4.24 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 192.06, NNZs: 48, Bias: 0.000000, T: 710400, Avg. loss: 0.036436\n",
      "Total training time: 4.78 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 194.58, NNZs: 48, Bias: 0.000000, T: 781440, Avg. loss: 0.036212\n",
      "Total training time: 5.30 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 195.08, NNZs: 48, Bias: 0.000000, T: 852480, Avg. loss: 0.036077\n",
      "Total training time: 5.82 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 195.58, NNZs: 48, Bias: 0.000000, T: 923520, Avg. loss: 0.036034\n",
      "Total training time: 6.34 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 196.07, NNZs: 47, Bias: 0.000000, T: 994560, Avg. loss: 0.035983\n",
      "Total training time: 6.84 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 196.56, NNZs: 47, Bias: 0.000000, T: 1065600, Avg. loss: 0.035961\n",
      "Total training time: 7.29 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 197.05, NNZs: 47, Bias: 0.000000, T: 1136640, Avg. loss: 0.035913\n",
      "Total training time: 7.76 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 197.15, NNZs: 47, Bias: 0.000000, T: 1207680, Avg. loss: 0.035885\n",
      "Total training time: 8.23 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 197.25, NNZs: 47, Bias: 0.000000, T: 1278720, Avg. loss: 0.035879\n",
      "Total training time: 8.69 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 197.34, NNZs: 47, Bias: 0.000000, T: 1349760, Avg. loss: 0.035871\n",
      "Total training time: 9.17 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 197.44, NNZs: 47, Bias: 0.000000, T: 1420800, Avg. loss: 0.035861\n",
      "Total training time: 9.63 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.06171699256249541, clf__eta0=0.6666115972798587, clf__fit_intercept=False, clf__l1_ratio=0.9792901432894962, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.15075392531110676, clf__shuffle=True, clf__tol=0.365636830734297, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.195 total time= 1.1min\n",
      "-- Epoch 1\n",
      "Norm: 81.85, NNZs: 262, Bias: 0.000000, T: 71040, Avg. loss: 0.073042\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 110.73, NNZs: 95, Bias: 0.000000, T: 142080, Avg. loss: 0.050815\n",
      "Total training time: 0.99 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 132.52, NNZs: 70, Bias: 0.000000, T: 213120, Avg. loss: 0.044825\n",
      "Total training time: 1.46 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 150.88, NNZs: 59, Bias: 0.000000, T: 284160, Avg. loss: 0.041505\n",
      "Total training time: 1.93 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 167.02, NNZs: 51, Bias: 0.000000, T: 355200, Avg. loss: 0.039157\n",
      "Total training time: 2.39 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 181.52, NNZs: 49, Bias: 0.000000, T: 426240, Avg. loss: 0.037766\n",
      "Total training time: 2.91 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 184.18, NNZs: 49, Bias: 0.000000, T: 497280, Avg. loss: 0.036603\n",
      "Total training time: 3.42 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 186.79, NNZs: 49, Bias: 0.000000, T: 568320, Avg. loss: 0.036436\n",
      "Total training time: 3.89 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 189.35, NNZs: 49, Bias: 0.000000, T: 639360, Avg. loss: 0.036221\n",
      "Total training time: 4.36 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 191.89, NNZs: 49, Bias: 0.000000, T: 710400, Avg. loss: 0.036080\n",
      "Total training time: 4.82 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 194.41, NNZs: 49, Bias: 0.000000, T: 781440, Avg. loss: 0.035860\n",
      "Total training time: 5.27 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 194.90, NNZs: 49, Bias: 0.000000, T: 852480, Avg. loss: 0.035761\n",
      "Total training time: 5.72 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 195.40, NNZs: 49, Bias: 0.000000, T: 923520, Avg. loss: 0.035728\n",
      "Total training time: 6.20 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 195.89, NNZs: 49, Bias: 0.000000, T: 994560, Avg. loss: 0.035699\n",
      "Total training time: 6.68 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 196.38, NNZs: 49, Bias: 0.000000, T: 1065600, Avg. loss: 0.035669\n",
      "Total training time: 7.16 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 196.86, NNZs: 49, Bias: 0.000000, T: 1136640, Avg. loss: 0.035627\n",
      "Total training time: 7.66 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 196.96, NNZs: 49, Bias: 0.000000, T: 1207680, Avg. loss: 0.035609\n",
      "Total training time: 8.15 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 197.06, NNZs: 49, Bias: 0.000000, T: 1278720, Avg. loss: 0.035602\n",
      "Total training time: 8.64 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 197.16, NNZs: 49, Bias: 0.000000, T: 1349760, Avg. loss: 0.035594\n",
      "Total training time: 9.12 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 197.25, NNZs: 49, Bias: 0.000000, T: 1420800, Avg. loss: 0.035590\n",
      "Total training time: 9.61 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.06171699256249541, clf__eta0=0.6666115972798587, clf__fit_intercept=False, clf__l1_ratio=0.9792901432894962, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.15075392531110676, clf__shuffle=True, clf__tol=0.365636830734297, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.195 total time= 1.1min\n",
      "-- Epoch 1\n",
      "Norm: 81.96, NNZs: 241, Bias: 0.000000, T: 71040, Avg. loss: 0.073779\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 110.92, NNZs: 97, Bias: 0.000000, T: 142080, Avg. loss: 0.050951\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 132.70, NNZs: 74, Bias: 0.000000, T: 213120, Avg. loss: 0.044961\n",
      "Total training time: 1.44 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 151.11, NNZs: 57, Bias: 0.000000, T: 284160, Avg. loss: 0.041672\n",
      "Total training time: 1.92 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 167.19, NNZs: 53, Bias: 0.000000, T: 355200, Avg. loss: 0.039362\n",
      "Total training time: 2.44 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 181.66, NNZs: 49, Bias: 0.000000, T: 426240, Avg. loss: 0.037869\n",
      "Total training time: 2.93 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 184.27, NNZs: 49, Bias: 0.000000, T: 497280, Avg. loss: 0.036930\n",
      "Total training time: 3.41 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 186.89, NNZs: 48, Bias: 0.000000, T: 568320, Avg. loss: 0.036764\n",
      "Total training time: 3.90 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 189.44, NNZs: 48, Bias: 0.000000, T: 639360, Avg. loss: 0.036573\n",
      "Total training time: 4.38 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 191.98, NNZs: 48, Bias: 0.000000, T: 710400, Avg. loss: 0.036363\n",
      "Total training time: 4.83 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 194.47, NNZs: 48, Bias: 0.000000, T: 781440, Avg. loss: 0.036140\n",
      "Total training time: 5.29 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 194.97, NNZs: 48, Bias: 0.000000, T: 852480, Avg. loss: 0.036049\n",
      "Total training time: 5.74 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 195.46, NNZs: 48, Bias: 0.000000, T: 923520, Avg. loss: 0.036010\n",
      "Total training time: 6.21 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 195.95, NNZs: 48, Bias: 0.000000, T: 994560, Avg. loss: 0.035976\n",
      "Total training time: 6.68 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 196.44, NNZs: 48, Bias: 0.000000, T: 1065600, Avg. loss: 0.035919\n",
      "Total training time: 7.16 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 196.93, NNZs: 48, Bias: 0.000000, T: 1136640, Avg. loss: 0.035901\n",
      "Total training time: 7.64 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 197.02, NNZs: 48, Bias: 0.000000, T: 1207680, Avg. loss: 0.035874\n",
      "Total training time: 8.11 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 197.12, NNZs: 48, Bias: 0.000000, T: 1278720, Avg. loss: 0.035869\n",
      "Total training time: 8.60 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 197.22, NNZs: 48, Bias: 0.000000, T: 1349760, Avg. loss: 0.035865\n",
      "Total training time: 9.08 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 197.32, NNZs: 48, Bias: 0.000000, T: 1420800, Avg. loss: 0.035856\n",
      "Total training time: 9.56 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.06171699256249541, clf__eta0=0.6666115972798587, clf__fit_intercept=False, clf__l1_ratio=0.9792901432894962, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.15075392531110676, clf__shuffle=True, clf__tol=0.365636830734297, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.193 total time= 1.1min\n",
      "-- Epoch 1\n",
      "Norm: 104465896571351.62, NNZs: 444219, Bias: 0.000000, T: 71040, Avg. loss: 101445913655355975401472.000000\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 98363755017342.47, NNZs: 444220, Bias: 0.000000, T: 142080, Avg. loss: 89493904388737101463552.000000\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 95235822734454.81, NNZs: 444220, Bias: 0.000000, T: 213120, Avg. loss: 73939594834050713387008.000000\n",
      "Total training time: 1.15 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 93163842659720.62, NNZs: 444220, Bias: 0.000000, T: 284160, Avg. loss: 66644013770035712491520.000000\n",
      "Total training time: 1.55 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 91631492421277.84, NNZs: 444220, Bias: 0.000000, T: 355200, Avg. loss: 62158685545787732000768.000000\n",
      "Total training time: 1.95 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 90422300295319.38, NNZs: 444220, Bias: 0.000000, T: 426240, Avg. loss: 58990644337833414754304.000000\n",
      "Total training time: 2.36 seconds.\n",
      "Convergence after 6 epochs took 2.40 seconds\n",
      "[CV 1/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.7915127974877743, clf__eta0=0.05539740212799926, clf__fit_intercept=False, clf__l1_ratio=0.9152680641407671, clf__learning_rate=optimal, clf__loss=squared_epsilon_insensitive, clf__max_iter=80, clf__penalty=l1, clf__power_t=0.6359093112142983, clf__shuffle=True, clf__tol=0.9361199211609239, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.334 total time=  57.3s\n",
      "-- Epoch 1\n",
      "Norm: 131493296442987.25, NNZs: 444370, Bias: 0.000000, T: 71040, Avg. loss: 159097066460160825753600.000000\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 124718090184087.05, NNZs: 444372, Bias: 0.000000, T: 142080, Avg. loss: 147353468919192951455744.000000\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 121253356411586.00, NNZs: 444372, Bias: 0.000000, T: 213120, Avg. loss: 124097469671243643879424.000000\n",
      "Total training time: 1.14 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 118971956344955.62, NNZs: 444372, Bias: 0.000000, T: 284160, Avg. loss: 113106227094757916540928.000000\n",
      "Total training time: 1.55 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 117283346337260.95, NNZs: 444372, Bias: 0.000000, T: 355200, Avg. loss: 106235229080585337044992.000000\n",
      "Total training time: 1.95 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 115950474449262.61, NNZs: 444372, Bias: 0.000000, T: 426240, Avg. loss: 101410026084417558020096.000000\n",
      "Total training time: 2.34 seconds.\n",
      "Convergence after 6 epochs took 2.38 seconds\n",
      "[CV 2/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.7915127974877743, clf__eta0=0.05539740212799926, clf__fit_intercept=False, clf__l1_ratio=0.9152680641407671, clf__learning_rate=optimal, clf__loss=squared_epsilon_insensitive, clf__max_iter=80, clf__penalty=l1, clf__power_t=0.6359093112142983, clf__shuffle=True, clf__tol=0.9361199211609239, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.339 total time=  56.4s\n",
      "-- Epoch 1\n",
      "Norm: 125210155884644.64, NNZs: 443341, Bias: 0.000000, T: 71040, Avg. loss: 144576959104939513085952.000000\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 118499796396098.61, NNZs: 443341, Bias: 0.000000, T: 142080, Avg. loss: 133854126276265493135360.000000\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 115065759799513.31, NNZs: 443341, Bias: 0.000000, T: 213120, Avg. loss: 112061395497958489718784.000000\n",
      "Total training time: 1.13 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 112795100620847.48, NNZs: 443341, Bias: 0.000000, T: 284160, Avg. loss: 101852613043773480370176.000000\n",
      "Total training time: 1.51 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 111115045090770.19, NNZs: 443341, Bias: 0.000000, T: 355200, Avg. loss: 95517503568967230291968.000000\n",
      "Total training time: 1.90 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 109791000964424.88, NNZs: 443341, Bias: 0.000000, T: 426240, Avg. loss: 91012282258247638843392.000000\n",
      "Total training time: 2.29 seconds.\n",
      "Convergence after 6 epochs took 2.33 seconds\n",
      "[CV 3/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.7915127974877743, clf__eta0=0.05539740212799926, clf__fit_intercept=False, clf__l1_ratio=0.9152680641407671, clf__learning_rate=optimal, clf__loss=squared_epsilon_insensitive, clf__max_iter=80, clf__penalty=l1, clf__power_t=0.6359093112142983, clf__shuffle=True, clf__tol=0.9361199211609239, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.343 total time=  57.2s\n",
      "-- Epoch 1\n",
      "Norm: 75785557747981.94, NNZs: 443699, Bias: 0.000000, T: 71040, Avg. loss: 52909571682532918820864.000000\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 70616121666362.39, NNZs: 443708, Bias: 0.000000, T: 142080, Avg. loss: 45799439839880441495552.000000\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 67973071444376.03, NNZs: 443708, Bias: 0.000000, T: 213120, Avg. loss: 36791417346492840542208.000000\n",
      "Total training time: 1.18 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 66222487382264.23, NNZs: 443708, Bias: 0.000000, T: 284160, Avg. loss: 32686431218164853374976.000000\n",
      "Total training time: 1.59 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 64924425619196.72, NNZs: 443708, Bias: 0.000000, T: 355200, Avg. loss: 30151104217124314284032.000000\n",
      "Total training time: 1.99 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 63900162704108.52, NNZs: 443708, Bias: 0.000000, T: 426240, Avg. loss: 28381975105834649124864.000000\n",
      "Total training time: 2.40 seconds.\n",
      "Convergence after 6 epochs took 2.44 seconds\n",
      "[CV 4/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.7915127974877743, clf__eta0=0.05539740212799926, clf__fit_intercept=False, clf__l1_ratio=0.9152680641407671, clf__learning_rate=optimal, clf__loss=squared_epsilon_insensitive, clf__max_iter=80, clf__penalty=l1, clf__power_t=0.6359093112142983, clf__shuffle=True, clf__tol=0.9361199211609239, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.345 total time=  57.2s\n",
      "-- Epoch 1\n",
      "Norm: 114186064774457.16, NNZs: 441696, Bias: 0.000000, T: 71040, Avg. loss: 119921315616983672160256.000000\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 107843543420768.94, NNZs: 441698, Bias: 0.000000, T: 142080, Avg. loss: 108845468136996966760448.000000\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 104600170214196.20, NNZs: 441698, Bias: 0.000000, T: 213120, Avg. loss: 90705053281035418075136.000000\n",
      "Total training time: 1.19 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 102445776703474.98, NNZs: 441698, Bias: 0.000000, T: 284160, Avg. loss: 82215408491668451622912.000000\n",
      "Total training time: 1.60 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 100853508005699.36, NNZs: 441698, Bias: 0.000000, T: 355200, Avg. loss: 76927047164111387361280.000000\n",
      "Total training time: 2.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 99597402149572.86, NNZs: 441698, Bias: 0.000000, T: 426240, Avg. loss: 73190236702504986345472.000000\n",
      "Total training time: 2.43 seconds.\n",
      "Convergence after 6 epochs took 2.47 seconds\n",
      "[CV 5/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.7915127974877743, clf__eta0=0.05539740212799926, clf__fit_intercept=False, clf__l1_ratio=0.9152680641407671, clf__learning_rate=optimal, clf__loss=squared_epsilon_insensitive, clf__max_iter=80, clf__penalty=l1, clf__power_t=0.6359093112142983, clf__shuffle=True, clf__tol=0.9361199211609239, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.347 total time=  57.4s\n",
      "-- Epoch 1\n",
      "Norm: 80.30, NNZs: 212, Bias: 0.000000, T: 71040, Avg. loss: 0.020532\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 105.21, NNZs: 100, Bias: 0.000000, T: 142080, Avg. loss: 0.012716\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 123.94, NNZs: 88, Bias: 0.000000, T: 213120, Avg. loss: 0.011291\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 139.39, NNZs: 82, Bias: 0.000000, T: 284160, Avg. loss: 0.010345\n",
      "Total training time: 1.17 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 152.85, NNZs: 79, Bias: 0.000000, T: 355200, Avg. loss: 0.009941\n",
      "Total training time: 1.47 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 164.89, NNZs: 76, Bias: 0.000000, T: 426240, Avg. loss: 0.009558\n",
      "Total training time: 1.76 seconds.\n",
      "Convergence after 6 epochs took 1.81 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.03646223783802971, clf__eta0=0.7491267567674796, clf__fit_intercept=False, clf__l1_ratio=0.775818217437024, clf__learning_rate=constant, clf__loss=squared_hinge, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.4028006727705291, clf__shuffle=True, clf__tol=0.1730703028465106, clf__warm_start=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.974 total time=  58.1s\n",
      "-- Epoch 1\n",
      "Norm: 80.67, NNZs: 226, Bias: 0.000000, T: 71040, Avg. loss: 0.020850\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 105.54, NNZs: 101, Bias: 0.000000, T: 142080, Avg. loss: 0.012842\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 124.29, NNZs: 86, Bias: 0.000000, T: 213120, Avg. loss: 0.011318\n",
      "Total training time: 0.82 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 139.59, NNZs: 85, Bias: 0.000000, T: 284160, Avg. loss: 0.010473\n",
      "Total training time: 1.11 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 152.90, NNZs: 77, Bias: 0.000000, T: 355200, Avg. loss: 0.009999\n",
      "Total training time: 1.40 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 164.85, NNZs: 72, Bias: 0.000000, T: 426240, Avg. loss: 0.009782\n",
      "Total training time: 1.69 seconds.\n",
      "Convergence after 6 epochs took 1.73 seconds\n",
      "[CV 2/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.03646223783802971, clf__eta0=0.7491267567674796, clf__fit_intercept=False, clf__l1_ratio=0.775818217437024, clf__learning_rate=constant, clf__loss=squared_hinge, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.4028006727705291, clf__shuffle=True, clf__tol=0.1730703028465106, clf__warm_start=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.966 total time=  57.1s\n",
      "-- Epoch 1\n",
      "Norm: 80.69, NNZs: 210, Bias: 0.000000, T: 71040, Avg. loss: 0.020666\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 105.84, NNZs: 101, Bias: 0.000000, T: 142080, Avg. loss: 0.012724\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 124.49, NNZs: 87, Bias: 0.000000, T: 213120, Avg. loss: 0.011116\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 139.97, NNZs: 83, Bias: 0.000000, T: 284160, Avg. loss: 0.010470\n",
      "Total training time: 1.18 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 153.44, NNZs: 79, Bias: 0.000000, T: 355200, Avg. loss: 0.009949\n",
      "Total training time: 1.49 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 165.34, NNZs: 76, Bias: 0.000000, T: 426240, Avg. loss: 0.009540\n",
      "Total training time: 1.79 seconds.\n",
      "Convergence after 6 epochs took 1.83 seconds\n",
      "[CV 3/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.03646223783802971, clf__eta0=0.7491267567674796, clf__fit_intercept=False, clf__l1_ratio=0.775818217437024, clf__learning_rate=constant, clf__loss=squared_hinge, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.4028006727705291, clf__shuffle=True, clf__tol=0.1730703028465106, clf__warm_start=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.969 total time=  57.7s\n",
      "-- Epoch 1\n",
      "Norm: 80.64, NNZs: 220, Bias: 0.000000, T: 71040, Avg. loss: 0.020885\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 105.47, NNZs: 96, Bias: 0.000000, T: 142080, Avg. loss: 0.012568\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 124.21, NNZs: 88, Bias: 0.000000, T: 213120, Avg. loss: 0.011304\n",
      "Total training time: 0.92 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 139.48, NNZs: 80, Bias: 0.000000, T: 284160, Avg. loss: 0.010408\n",
      "Total training time: 1.23 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 152.81, NNZs: 75, Bias: 0.000000, T: 355200, Avg. loss: 0.009957\n",
      "Total training time: 1.53 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 164.74, NNZs: 69, Bias: 0.000000, T: 426240, Avg. loss: 0.009633\n",
      "Total training time: 1.83 seconds.\n",
      "Convergence after 6 epochs took 1.87 seconds\n",
      "[CV 4/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.03646223783802971, clf__eta0=0.7491267567674796, clf__fit_intercept=False, clf__l1_ratio=0.775818217437024, clf__learning_rate=constant, clf__loss=squared_hinge, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.4028006727705291, clf__shuffle=True, clf__tol=0.1730703028465106, clf__warm_start=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.959 total time=  59.0s\n",
      "-- Epoch 1\n",
      "Norm: 80.21, NNZs: 212, Bias: 0.000000, T: 71040, Avg. loss: 0.020370\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 105.31, NNZs: 103, Bias: 0.000000, T: 142080, Avg. loss: 0.012490\n",
      "Total training time: 0.54 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 123.75, NNZs: 92, Bias: 0.000000, T: 213120, Avg. loss: 0.010928\n",
      "Total training time: 0.81 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 139.10, NNZs: 89, Bias: 0.000000, T: 284160, Avg. loss: 0.010255\n",
      "Total training time: 1.10 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 152.43, NNZs: 81, Bias: 0.000000, T: 355200, Avg. loss: 0.009802\n",
      "Total training time: 1.41 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 164.39, NNZs: 76, Bias: 0.000000, T: 426240, Avg. loss: 0.009581\n",
      "Total training time: 1.70 seconds.\n",
      "Convergence after 6 epochs took 1.74 seconds\n",
      "[CV 5/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.03646223783802971, clf__eta0=0.7491267567674796, clf__fit_intercept=False, clf__l1_ratio=0.775818217437024, clf__learning_rate=constant, clf__loss=squared_hinge, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.4028006727705291, clf__shuffle=True, clf__tol=0.1730703028465106, clf__warm_start=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.970 total time=  57.1s\n",
      "-- Epoch 1\n",
      "Norm: 271755352913725.12, NNZs: 444229, Bias: 0.000000, T: 71040, Avg. loss: 1286051905462241519992832.000000\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 195202611889774.94, NNZs: 443928, Bias: 0.000000, T: 142080, Avg. loss: 3291653184327411335954432.000000\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 265408183587079.62, NNZs: 444253, Bias: 0.000000, T: 213120, Avg. loss: 2413967079340324113350656.000000\n",
      "Total training time: 1.41 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 222549145320894.38, NNZs: 444179, Bias: 0.000000, T: 284160, Avg. loss: 3503854976454291378667520.000000\n",
      "Total training time: 1.90 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 265109966894787.84, NNZs: 444251, Bias: 0.000000, T: 355200, Avg. loss: 2770690000024085458845696.000000\n",
      "Total training time: 2.39 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 235801795076167.94, NNZs: 444226, Bias: 0.000000, T: 426240, Avg. loss: 3380561923242983440777216.000000\n",
      "Total training time: 2.88 seconds.\n",
      "Convergence after 6 epochs took 2.92 seconds\n",
      "[CV 1/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.24457156361183285, clf__eta0=0.332929742792607, clf__fit_intercept=False, clf__l1_ratio=0.920539731041378, clf__learning_rate=constant, clf__loss=squared_error, clf__max_iter=100, clf__penalty=l1, clf__power_t=0.5734177157821045, clf__shuffle=True, clf__tol=0.6492274795888617, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.347 total time=  58.6s\n",
      "-- Epoch 1\n",
      "Norm: 269542993161886.91, NNZs: 444369, Bias: 0.000000, T: 71040, Avg. loss: 1256755328965954062254080.000000\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 203284654711039.97, NNZs: 443965, Bias: 0.000000, T: 142080, Avg. loss: 3482825099762558184718336.000000\n",
      "Total training time: 0.92 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 267200532337215.25, NNZs: 444365, Bias: 0.000000, T: 213120, Avg. loss: 2357726355882450758926336.000000\n",
      "Total training time: 1.41 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 226857544984382.66, NNZs: 444272, Bias: 0.000000, T: 284160, Avg. loss: 3587029228629295605219328.000000\n",
      "Total training time: 1.89 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 262236951017792.53, NNZs: 444367, Bias: 0.000000, T: 355200, Avg. loss: 2764414098243573245804544.000000\n",
      "Total training time: 2.35 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 227636174723634.22, NNZs: 444330, Bias: 0.000000, T: 426240, Avg. loss: 3270031693523770687881216.000000\n",
      "Total training time: 2.83 seconds.\n",
      "Convergence after 6 epochs took 2.87 seconds\n",
      "[CV 2/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.24457156361183285, clf__eta0=0.332929742792607, clf__fit_intercept=False, clf__l1_ratio=0.920539731041378, clf__learning_rate=constant, clf__loss=squared_error, clf__max_iter=100, clf__penalty=l1, clf__power_t=0.5734177157821045, clf__shuffle=True, clf__tol=0.6492274795888617, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.342 total time=  57.8s\n",
      "-- Epoch 1\n",
      "Norm: 263280924895603.12, NNZs: 443315, Bias: 0.000000, T: 71040, Avg. loss: 1175162755600130494169088.000000\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 211683486631067.03, NNZs: 442954, Bias: 0.000000, T: 142080, Avg. loss: 3422971257699987020054528.000000\n",
      "Total training time: 0.96 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 262383788543553.53, NNZs: 443324, Bias: 0.000000, T: 213120, Avg. loss: 2573568346070816355516416.000000\n",
      "Total training time: 1.46 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 218055181331415.59, NNZs: 443222, Bias: 0.000000, T: 284160, Avg. loss: 3537566121741740423512064.000000\n",
      "Total training time: 1.95 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 256256172644143.09, NNZs: 443326, Bias: 0.000000, T: 355200, Avg. loss: 2633163649027409751048192.000000\n",
      "Total training time: 2.45 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 235383224019141.28, NNZs: 443291, Bias: 0.000000, T: 426240, Avg. loss: 3209641320547143448002560.000000\n",
      "Total training time: 2.99 seconds.\n",
      "Convergence after 6 epochs took 3.03 seconds\n",
      "[CV 3/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.24457156361183285, clf__eta0=0.332929742792607, clf__fit_intercept=False, clf__l1_ratio=0.920539731041378, clf__learning_rate=constant, clf__loss=squared_error, clf__max_iter=100, clf__penalty=l1, clf__power_t=0.5734177157821045, clf__shuffle=True, clf__tol=0.6492274795888617, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.347 total time=  58.7s\n",
      "-- Epoch 1\n",
      "Norm: 268564913161348.34, NNZs: 443724, Bias: 0.000000, T: 71040, Avg. loss: 1250284044742729796681728.000000\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 217064106262491.44, NNZs: 443400, Bias: 0.000000, T: 142080, Avg. loss: 3293303630234426563100672.000000\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 270094434835778.75, NNZs: 443740, Bias: 0.000000, T: 213120, Avg. loss: 2634174455375933705551872.000000\n",
      "Total training time: 1.45 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 220996846024493.41, NNZs: 443672, Bias: 0.000000, T: 284160, Avg. loss: 3418528777035235895279616.000000\n",
      "Total training time: 1.95 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 262345922636982.38, NNZs: 443746, Bias: 0.000000, T: 355200, Avg. loss: 2786770805700216970280960.000000\n",
      "Total training time: 2.43 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 227532172111843.47, NNZs: 443718, Bias: 0.000000, T: 426240, Avg. loss: 3426989765445154909454336.000000\n",
      "Total training time: 2.90 seconds.\n",
      "Convergence after 6 epochs took 2.94 seconds\n",
      "[CV 4/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.24457156361183285, clf__eta0=0.332929742792607, clf__fit_intercept=False, clf__l1_ratio=0.920539731041378, clf__learning_rate=constant, clf__loss=squared_error, clf__max_iter=100, clf__penalty=l1, clf__power_t=0.5734177157821045, clf__shuffle=True, clf__tol=0.6492274795888617, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.346 total time=  57.6s\n",
      "-- Epoch 1\n",
      "Norm: 269296789027572.34, NNZs: 441676, Bias: 0.000000, T: 71040, Avg. loss: 1275161751445718836445184.000000\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 215634629860672.91, NNZs: 441327, Bias: 0.000000, T: 142080, Avg. loss: 3477805252809457387175936.000000\n",
      "Total training time: 0.93 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 263249277483272.91, NNZs: 441686, Bias: 0.000000, T: 213120, Avg. loss: 2477308329144655680634880.000000\n",
      "Total training time: 1.43 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 227067588755832.59, NNZs: 441600, Bias: 0.000000, T: 284160, Avg. loss: 3463095107185560782897152.000000\n",
      "Total training time: 1.93 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 260695788755102.69, NNZs: 441695, Bias: 0.000000, T: 355200, Avg. loss: 2735008139060657248010240.000000\n",
      "Total training time: 2.42 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 225579991488369.34, NNZs: 441660, Bias: 0.000000, T: 426240, Avg. loss: 3471417394441921553760256.000000\n",
      "Total training time: 2.91 seconds.\n",
      "Convergence after 6 epochs took 2.95 seconds\n",
      "[CV 5/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.24457156361183285, clf__eta0=0.332929742792607, clf__fit_intercept=False, clf__l1_ratio=0.920539731041378, clf__learning_rate=constant, clf__loss=squared_error, clf__max_iter=100, clf__penalty=l1, clf__power_t=0.5734177157821045, clf__shuffle=True, clf__tol=0.6492274795888617, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.347 total time=  57.5s\n",
      "-- Epoch 1\n",
      "Norm: 3.97, NNZs: 728335, Bias: 0.389701, T: 71040, Avg. loss: 0.038095\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 4.04, NNZs: 728335, Bias: 0.449418, T: 142080, Avg. loss: 0.016769\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.05, NNZs: 728335, Bias: 0.483969, T: 213120, Avg. loss: 0.013099\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.03, NNZs: 728335, Bias: 0.508336, T: 284160, Avg. loss: 0.011347\n",
      "Total training time: 1.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.01, NNZs: 728335, Bias: 0.527114, T: 355200, Avg. loss: 0.010297\n",
      "Total training time: 1.30 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.99, NNZs: 728335, Bias: 0.542358, T: 426240, Avg. loss: 0.009584\n",
      "Total training time: 1.60 seconds.\n",
      "Convergence after 6 epochs took 1.65 seconds\n",
      "[CV 1/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.2527955528897454, clf__eta0=0.4377192284389271, clf__fit_intercept=True, clf__l1_ratio=0.6515110441465675, clf__learning_rate=invscaling, clf__loss=huber, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.47239053945705856, clf__shuffle=False, clf__tol=0.9089234089706554, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.498 total time=  57.6s\n",
      "-- Epoch 1\n",
      "Norm: 3.97, NNZs: 727797, Bias: 0.387537, T: 71040, Avg. loss: 0.037984\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 4.05, NNZs: 727797, Bias: 0.447014, T: 142080, Avg. loss: 0.016791\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.05, NNZs: 727797, Bias: 0.481522, T: 213120, Avg. loss: 0.013152\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.04, NNZs: 727797, Bias: 0.505888, T: 284160, Avg. loss: 0.011408\n",
      "Total training time: 1.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.02, NNZs: 727797, Bias: 0.524685, T: 355200, Avg. loss: 0.010359\n",
      "Total training time: 1.25 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.99, NNZs: 727797, Bias: 0.539959, T: 426240, Avg. loss: 0.009644\n",
      "Total training time: 1.50 seconds.\n",
      "Convergence after 6 epochs took 1.55 seconds\n",
      "[CV 2/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.2527955528897454, clf__eta0=0.4377192284389271, clf__fit_intercept=True, clf__l1_ratio=0.6515110441465675, clf__learning_rate=invscaling, clf__loss=huber, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.47239053945705856, clf__shuffle=False, clf__tol=0.9089234089706554, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.498 total time=  58.1s\n",
      "-- Epoch 1\n",
      "Norm: 3.97, NNZs: 727918, Bias: 0.388171, T: 71040, Avg. loss: 0.037918\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 4.04, NNZs: 727918, Bias: 0.447624, T: 142080, Avg. loss: 0.016854\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.04, NNZs: 727918, Bias: 0.482243, T: 213120, Avg. loss: 0.013218\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.03, NNZs: 727918, Bias: 0.506735, T: 284160, Avg. loss: 0.011459\n",
      "Total training time: 1.07 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.01, NNZs: 727918, Bias: 0.525643, T: 355200, Avg. loss: 0.010397\n",
      "Total training time: 1.31 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.98, NNZs: 727918, Bias: 0.541013, T: 426240, Avg. loss: 0.009673\n",
      "Total training time: 1.55 seconds.\n",
      "Convergence after 6 epochs took 1.59 seconds\n",
      "[CV 3/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.2527955528897454, clf__eta0=0.4377192284389271, clf__fit_intercept=True, clf__l1_ratio=0.6515110441465675, clf__learning_rate=invscaling, clf__loss=huber, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.47239053945705856, clf__shuffle=False, clf__tol=0.9089234089706554, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.498 total time=  56.9s\n",
      "-- Epoch 1\n",
      "Norm: 3.97, NNZs: 727599, Bias: 0.388239, T: 71040, Avg. loss: 0.038088\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 4.04, NNZs: 727599, Bias: 0.447853, T: 142080, Avg. loss: 0.016791\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.05, NNZs: 727599, Bias: 0.482420, T: 213120, Avg. loss: 0.013127\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.04, NNZs: 727599, Bias: 0.506812, T: 284160, Avg. loss: 0.011375\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.02, NNZs: 727599, Bias: 0.525615, T: 355200, Avg. loss: 0.010323\n",
      "Total training time: 1.20 seconds.\n",
      "-- Epoch 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 3.99, NNZs: 727599, Bias: 0.540883, T: 426240, Avg. loss: 0.009608\n",
      "Total training time: 1.45 seconds.\n",
      "Convergence after 6 epochs took 1.50 seconds\n",
      "[CV 4/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.2527955528897454, clf__eta0=0.4377192284389271, clf__fit_intercept=True, clf__l1_ratio=0.6515110441465675, clf__learning_rate=invscaling, clf__loss=huber, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.47239053945705856, clf__shuffle=False, clf__tol=0.9089234089706554, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.498 total time=  57.1s\n",
      "-- Epoch 1\n",
      "Norm: 3.98, NNZs: 724493, Bias: 0.388451, T: 71040, Avg. loss: 0.037927\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 4.05, NNZs: 724493, Bias: 0.447742, T: 142080, Avg. loss: 0.016755\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.05, NNZs: 724493, Bias: 0.482124, T: 213120, Avg. loss: 0.013137\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.04, NNZs: 724493, Bias: 0.506421, T: 284160, Avg. loss: 0.011399\n",
      "Total training time: 0.97 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.02, NNZs: 724493, Bias: 0.525174, T: 355200, Avg. loss: 0.010352\n",
      "Total training time: 1.21 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.99, NNZs: 724493, Bias: 0.540417, T: 426240, Avg. loss: 0.009638\n",
      "Total training time: 1.44 seconds.\n",
      "Convergence after 6 epochs took 1.49 seconds\n",
      "[CV 5/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.2527955528897454, clf__eta0=0.4377192284389271, clf__fit_intercept=True, clf__l1_ratio=0.6515110441465675, clf__learning_rate=invscaling, clf__loss=huber, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.47239053945705856, clf__shuffle=False, clf__tol=0.9089234089706554, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.498 total time=  56.3s\n",
      "-- Epoch 1\n",
      "Norm: 9.93, NNZs: 243791, Bias: 0.920648, T: 71040, Avg. loss: 0.026778\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 8.53, NNZs: 256210, Bias: 0.889419, T: 142080, Avg. loss: 0.007688\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 8.22, NNZs: 265535, Bias: 0.873191, T: 213120, Avg. loss: 0.007331\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 8.09, NNZs: 271650, Bias: 0.859243, T: 284160, Avg. loss: 0.007229\n",
      "Total training time: 0.93 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 8.04, NNZs: 276896, Bias: 0.850202, T: 355200, Avg. loss: 0.007152\n",
      "Total training time: 1.18 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 8.00, NNZs: 281013, Bias: 0.845891, T: 426240, Avg. loss: 0.007096\n",
      "Total training time: 1.43 seconds.\n",
      "Convergence after 6 epochs took 1.47 seconds\n",
      "[CV 1/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.3241670976844645, clf__eta0=0.9631840511405841, clf__fit_intercept=True, clf__l1_ratio=0.5912641309775509, clf__learning_rate=optimal, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.6710686638981408, clf__shuffle=True, clf__tol=0.09654933943827881, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.763 total time=  57.1s\n",
      "-- Epoch 1\n",
      "Norm: 10.00, NNZs: 242995, Bias: 0.916448, T: 71040, Avg. loss: 0.026791\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 8.55, NNZs: 254630, Bias: 0.887837, T: 142080, Avg. loss: 0.007594\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 8.20, NNZs: 263884, Bias: 0.872777, T: 213120, Avg. loss: 0.007307\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 8.07, NNZs: 271368, Bias: 0.862444, T: 284160, Avg. loss: 0.007194\n",
      "Total training time: 0.96 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 8.03, NNZs: 276857, Bias: 0.854084, T: 355200, Avg. loss: 0.007178\n",
      "Total training time: 1.21 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 7.99, NNZs: 280501, Bias: 0.848273, T: 426240, Avg. loss: 0.007082\n",
      "Total training time: 1.47 seconds.\n",
      "Convergence after 6 epochs took 1.51 seconds\n",
      "[CV 2/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.3241670976844645, clf__eta0=0.9631840511405841, clf__fit_intercept=True, clf__l1_ratio=0.5912641309775509, clf__learning_rate=optimal, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.6710686638981408, clf__shuffle=True, clf__tol=0.09654933943827881, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.771 total time=  56.8s\n",
      "-- Epoch 1\n",
      "Norm: 9.99, NNZs: 246022, Bias: 0.916717, T: 71040, Avg. loss: 0.027134\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 8.48, NNZs: 259292, Bias: 0.893365, T: 142080, Avg. loss: 0.007867\n",
      "Total training time: 0.43 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 8.15, NNZs: 267923, Bias: 0.872410, T: 213120, Avg. loss: 0.007557\n",
      "Total training time: 0.67 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 8.02, NNZs: 274223, Bias: 0.860300, T: 284160, Avg. loss: 0.007430\n",
      "Total training time: 0.91 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 7.96, NNZs: 278726, Bias: 0.851323, T: 355200, Avg. loss: 0.007331\n",
      "Total training time: 1.15 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 7.92, NNZs: 282171, Bias: 0.844685, T: 426240, Avg. loss: 0.007289\n",
      "Total training time: 1.40 seconds.\n",
      "Convergence after 6 epochs took 1.44 seconds\n",
      "[CV 3/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.3241670976844645, clf__eta0=0.9631840511405841, clf__fit_intercept=True, clf__l1_ratio=0.5912641309775509, clf__learning_rate=optimal, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.6710686638981408, clf__shuffle=True, clf__tol=0.09654933943827881, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.749 total time=  57.5s\n",
      "-- Epoch 1\n",
      "Norm: 9.95, NNZs: 248544, Bias: 0.922907, T: 71040, Avg. loss: 0.026002\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 8.50, NNZs: 259985, Bias: 0.892103, T: 142080, Avg. loss: 0.007757\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 8.17, NNZs: 269834, Bias: 0.873510, T: 213120, Avg. loss: 0.007454\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 8.05, NNZs: 275396, Bias: 0.859794, T: 284160, Avg. loss: 0.007320\n",
      "Total training time: 0.96 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 7.99, NNZs: 279911, Bias: 0.850895, T: 355200, Avg. loss: 0.007228\n",
      "Total training time: 1.21 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 7.95, NNZs: 283741, Bias: 0.844454, T: 426240, Avg. loss: 0.007161\n",
      "Total training time: 1.45 seconds.\n",
      "Convergence after 6 epochs took 1.49 seconds\n",
      "[CV 4/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.3241670976844645, clf__eta0=0.9631840511405841, clf__fit_intercept=True, clf__l1_ratio=0.5912641309775509, clf__learning_rate=optimal, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.6710686638981408, clf__shuffle=True, clf__tol=0.09654933943827881, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.758 total time=  56.9s\n",
      "-- Epoch 1\n",
      "Norm: 9.86, NNZs: 238695, Bias: 0.922664, T: 71040, Avg. loss: 0.026955\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 8.42, NNZs: 251248, Bias: 0.888009, T: 142080, Avg. loss: 0.007867\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 8.12, NNZs: 260476, Bias: 0.870952, T: 213120, Avg. loss: 0.007579\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 8.00, NNZs: 267209, Bias: 0.860016, T: 284160, Avg. loss: 0.007369\n",
      "Total training time: 0.93 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 7.94, NNZs: 273011, Bias: 0.851625, T: 355200, Avg. loss: 0.007283\n",
      "Total training time: 1.19 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 7.91, NNZs: 276748, Bias: 0.844348, T: 426240, Avg. loss: 0.007280\n",
      "Total training time: 1.44 seconds.\n",
      "Convergence after 6 epochs took 1.48 seconds\n",
      "[CV 5/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.3241670976844645, clf__eta0=0.9631840511405841, clf__fit_intercept=True, clf__l1_ratio=0.5912641309775509, clf__learning_rate=optimal, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.6710686638981408, clf__shuffle=True, clf__tol=0.09654933943827881, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.756 total time=  58.3s\n",
      "-- Epoch 1\n",
      "Norm: 403.46, NNZs: 367, Bias: 0.000000, T: 71040, Avg. loss: 0.198373\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 483.94, NNZs: 115, Bias: 0.000000, T: 142080, Avg. loss: 0.027578\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 543.50, NNZs: 88, Bias: 0.000000, T: 213120, Avg. loss: 0.021167\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 590.20, NNZs: 73, Bias: 0.000000, T: 284160, Avg. loss: 0.020090\n",
      "Total training time: 0.92 seconds.\n",
      "-- Epoch 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 629.03, NNZs: 65, Bias: 0.000000, T: 355200, Avg. loss: 0.015867\n",
      "Total training time: 1.15 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 667.79, NNZs: 62, Bias: 0.000000, T: 426240, Avg. loss: 0.016684\n",
      "Total training time: 1.37 seconds.\n",
      "Convergence after 6 epochs took 1.41 seconds\n",
      "[CV 1/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.3509613152086368, clf__eta0=0.9934401124631351, clf__fit_intercept=False, clf__l1_ratio=0.5204998682261415, clf__learning_rate=constant, clf__loss=hinge, clf__max_iter=40, clf__penalty=l1, clf__power_t=0.5098574122392232, clf__shuffle=False, clf__tol=0.5563103350645606, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.975 total time=  56.2s\n",
      "-- Epoch 1\n",
      "Norm: 397.68, NNZs: 391, Bias: 0.000000, T: 71040, Avg. loss: 0.219437\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 478.73, NNZs: 132, Bias: 0.000000, T: 142080, Avg. loss: 0.031856\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 538.22, NNZs: 90, Bias: 0.000000, T: 213120, Avg. loss: 0.023932\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 589.94, NNZs: 80, Bias: 0.000000, T: 284160, Avg. loss: 0.019571\n",
      "Total training time: 1.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 637.38, NNZs: 75, Bias: 0.000000, T: 355200, Avg. loss: 0.021407\n",
      "Total training time: 1.24 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 675.23, NNZs: 66, Bias: 0.000000, T: 426240, Avg. loss: 0.018676\n",
      "Total training time: 1.48 seconds.\n",
      "Convergence after 6 epochs took 1.53 seconds\n",
      "[CV 2/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.3509613152086368, clf__eta0=0.9934401124631351, clf__fit_intercept=False, clf__l1_ratio=0.5204998682261415, clf__learning_rate=constant, clf__loss=hinge, clf__max_iter=40, clf__penalty=l1, clf__power_t=0.5098574122392232, clf__shuffle=False, clf__tol=0.5563103350645606, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.985 total time=  56.8s\n",
      "-- Epoch 1\n",
      "Norm: 400.56, NNZs: 392, Bias: 0.000000, T: 71040, Avg. loss: 0.223759\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 479.11, NNZs: 112, Bias: 0.000000, T: 142080, Avg. loss: 0.026371\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 534.37, NNZs: 90, Bias: 0.000000, T: 213120, Avg. loss: 0.019961\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 577.35, NNZs: 84, Bias: 0.000000, T: 284160, Avg. loss: 0.016858\n",
      "Total training time: 1.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 617.41, NNZs: 77, Bias: 0.000000, T: 355200, Avg. loss: 0.015986\n",
      "Total training time: 1.25 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 652.90, NNZs: 77, Bias: 0.000000, T: 426240, Avg. loss: 0.015740\n",
      "Total training time: 1.50 seconds.\n",
      "Convergence after 6 epochs took 1.54 seconds\n",
      "[CV 3/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.3509613152086368, clf__eta0=0.9934401124631351, clf__fit_intercept=False, clf__l1_ratio=0.5204998682261415, clf__learning_rate=constant, clf__loss=hinge, clf__max_iter=40, clf__penalty=l1, clf__power_t=0.5098574122392232, clf__shuffle=False, clf__tol=0.5563103350645606, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.977 total time=  56.5s\n",
      "-- Epoch 1\n",
      "Norm: 419.58, NNZs: 434, Bias: 0.000000, T: 71040, Avg. loss: 0.203101\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 494.59, NNZs: 148, Bias: 0.000000, T: 142080, Avg. loss: 0.026561\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 550.69, NNZs: 100, Bias: 0.000000, T: 213120, Avg. loss: 0.021538\n",
      "Total training time: 0.67 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 597.03, NNZs: 80, Bias: 0.000000, T: 284160, Avg. loss: 0.017336\n",
      "Total training time: 0.90 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 638.04, NNZs: 74, Bias: 0.000000, T: 355200, Avg. loss: 0.017209\n",
      "Total training time: 1.12 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 674.27, NNZs: 64, Bias: 0.000000, T: 426240, Avg. loss: 0.015034\n",
      "Total training time: 1.33 seconds.\n",
      "Convergence after 6 epochs took 1.37 seconds\n",
      "[CV 4/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.3509613152086368, clf__eta0=0.9934401124631351, clf__fit_intercept=False, clf__l1_ratio=0.5204998682261415, clf__learning_rate=constant, clf__loss=hinge, clf__max_iter=40, clf__penalty=l1, clf__power_t=0.5098574122392232, clf__shuffle=False, clf__tol=0.5563103350645606, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.977 total time=  56.9s\n",
      "-- Epoch 1\n",
      "Norm: 408.59, NNZs: 366, Bias: 0.000000, T: 71040, Avg. loss: 0.217634\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 488.50, NNZs: 121, Bias: 0.000000, T: 142080, Avg. loss: 0.027784\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 545.04, NNZs: 102, Bias: 0.000000, T: 213120, Avg. loss: 0.021044\n",
      "Total training time: 0.67 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 594.19, NNZs: 88, Bias: 0.000000, T: 284160, Avg. loss: 0.019223\n",
      "Total training time: 0.91 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 630.47, NNZs: 70, Bias: 0.000000, T: 355200, Avg. loss: 0.016630\n",
      "Total training time: 1.13 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 671.18, NNZs: 67, Bias: 0.000000, T: 426240, Avg. loss: 0.018378\n",
      "Total training time: 1.35 seconds.\n",
      "Convergence after 6 epochs took 1.39 seconds\n",
      "[CV 5/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.3509613152086368, clf__eta0=0.9934401124631351, clf__fit_intercept=False, clf__l1_ratio=0.5204998682261415, clf__learning_rate=constant, clf__loss=hinge, clf__max_iter=40, clf__penalty=l1, clf__power_t=0.5098574122392232, clf__shuffle=False, clf__tol=0.5563103350645606, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.904 total time=  56.2s\n",
      "-- Epoch 1\n",
      "Norm: 1.52, NNZs: 444257, Bias: 0.000000, T: 71040, Avg. loss: 0.811898\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.69, NNZs: 444257, Bias: 0.000000, T: 142080, Avg. loss: 0.832262\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.79, NNZs: 444257, Bias: 0.000000, T: 213120, Avg. loss: 0.824045\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.87, NNZs: 444257, Bias: 0.000000, T: 284160, Avg. loss: 0.811822\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.94, NNZs: 444257, Bias: 0.000000, T: 355200, Avg. loss: 0.801289\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.00, NNZs: 444257, Bias: 0.000000, T: 426240, Avg. loss: 0.791358\n",
      "Total training time: 1.05 seconds.\n",
      "Convergence after 6 epochs took 1.09 seconds\n",
      "[CV 1/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.28658617296069355, clf__eta0=0.03398405924608927, clf__fit_intercept=False, clf__l1_ratio=0.08227014493927165, clf__learning_rate=invscaling, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.5467473202425025, clf__shuffle=True, clf__tol=0.9099604695658384, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.445 total time=  55.3s\n",
      "-- Epoch 1\n",
      "Norm: 1.69, NNZs: 444369, Bias: 0.000000, T: 71040, Avg. loss: 0.841893\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.80, NNZs: 444369, Bias: 0.000000, T: 142080, Avg. loss: 0.844656\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.87, NNZs: 444369, Bias: 0.000000, T: 213120, Avg. loss: 0.829120\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.94, NNZs: 444369, Bias: 0.000000, T: 284160, Avg. loss: 0.815587\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.00, NNZs: 444369, Bias: 0.000000, T: 355200, Avg. loss: 0.803965\n",
      "Total training time: 1.06 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.06, NNZs: 444369, Bias: 0.000000, T: 426240, Avg. loss: 0.793303\n",
      "Total training time: 1.26 seconds.\n",
      "Convergence after 6 epochs took 1.30 seconds\n",
      "[CV 2/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.28658617296069355, clf__eta0=0.03398405924608927, clf__fit_intercept=False, clf__l1_ratio=0.08227014493927165, clf__learning_rate=invscaling, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.5467473202425025, clf__shuffle=True, clf__tol=0.9099604695658384, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.438 total time= 2.7min\n",
      "-- Epoch 1\n",
      "Norm: 1.54, NNZs: 443330, Bias: 0.000000, T: 71040, Avg. loss: 0.827165\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.70, NNZs: 443330, Bias: 0.000000, T: 142080, Avg. loss: 0.839999\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.80, NNZs: 443330, Bias: 0.000000, T: 213120, Avg. loss: 0.826757\n",
      "Total training time: 0.54 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 4\n",
      "Norm: 1.88, NNZs: 443330, Bias: 0.000000, T: 284160, Avg. loss: 0.815678\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.94, NNZs: 443330, Bias: 0.000000, T: 355200, Avg. loss: 0.804769\n",
      "Total training time: 0.92 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.00, NNZs: 443330, Bias: 0.000000, T: 426240, Avg. loss: 0.793762\n",
      "Total training time: 1.12 seconds.\n",
      "Convergence after 6 epochs took 1.17 seconds\n",
      "[CV 3/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.28658617296069355, clf__eta0=0.03398405924608927, clf__fit_intercept=False, clf__l1_ratio=0.08227014493927165, clf__learning_rate=invscaling, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.5467473202425025, clf__shuffle=True, clf__tol=0.9099604695658384, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.443 total time= 1.0min\n",
      "-- Epoch 1\n",
      "Norm: 1.52, NNZs: 443737, Bias: 0.000000, T: 71040, Avg. loss: 0.817108\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.68, NNZs: 443737, Bias: 0.000000, T: 142080, Avg. loss: 0.837862\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.77, NNZs: 443737, Bias: 0.000000, T: 213120, Avg. loss: 0.826506\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.85, NNZs: 443737, Bias: 0.000000, T: 284160, Avg. loss: 0.813916\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.91, NNZs: 443737, Bias: 0.000000, T: 355200, Avg. loss: 0.804184\n",
      "Total training time: 0.97 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.98, NNZs: 443737, Bias: 0.000000, T: 426240, Avg. loss: 0.793259\n",
      "Total training time: 1.17 seconds.\n",
      "Convergence after 6 epochs took 1.21 seconds\n",
      "[CV 4/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.28658617296069355, clf__eta0=0.03398405924608927, clf__fit_intercept=False, clf__l1_ratio=0.08227014493927165, clf__learning_rate=invscaling, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.5467473202425025, clf__shuffle=True, clf__tol=0.9099604695658384, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.445 total time=  57.9s\n",
      "-- Epoch 1\n",
      "Norm: 1.50, NNZs: 441706, Bias: 0.000000, T: 71040, Avg. loss: 0.819263\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.67, NNZs: 441706, Bias: 0.000000, T: 142080, Avg. loss: 0.839115\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.77, NNZs: 441706, Bias: 0.000000, T: 213120, Avg. loss: 0.827366\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.85, NNZs: 441706, Bias: 0.000000, T: 284160, Avg. loss: 0.815980\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.92, NNZs: 441706, Bias: 0.000000, T: 355200, Avg. loss: 0.805118\n",
      "Total training time: 0.90 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.98, NNZs: 441706, Bias: 0.000000, T: 426240, Avg. loss: 0.795481\n",
      "Total training time: 1.08 seconds.\n",
      "Convergence after 6 epochs took 1.12 seconds\n",
      "[CV 5/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.28658617296069355, clf__eta0=0.03398405924608927, clf__fit_intercept=False, clf__l1_ratio=0.08227014493927165, clf__learning_rate=invscaling, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.5467473202425025, clf__shuffle=True, clf__tol=0.9099604695658384, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.441 total time=  56.7s\n",
      "-- Epoch 1\n",
      "Norm: 72.05, NNZs: 444239, Bias: 0.000000, T: 71040, Avg. loss: 0.302162\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 70.96, NNZs: 444239, Bias: 0.000000, T: 142080, Avg. loss: 0.258887\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 70.99, NNZs: 444239, Bias: 0.000000, T: 213120, Avg. loss: 0.259185\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 70.99, NNZs: 444239, Bias: 0.000000, T: 284160, Avg. loss: 0.259181\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 70.99, NNZs: 444239, Bias: 0.000000, T: 355200, Avg. loss: 0.259181\n",
      "Total training time: 1.13 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 70.99, NNZs: 444239, Bias: 0.000000, T: 426240, Avg. loss: 0.259181\n",
      "Total training time: 1.35 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 49.32, NNZs: 444239, Bias: 0.000000, T: 497280, Avg. loss: 0.187373\n",
      "Total training time: 1.59 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 46.31, NNZs: 444239, Bias: 0.000000, T: 568320, Avg. loss: 0.183821\n",
      "Total training time: 1.82 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 46.09, NNZs: 444239, Bias: 0.000000, T: 639360, Avg. loss: 0.185623\n",
      "Total training time: 2.05 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 46.07, NNZs: 444239, Bias: 0.000000, T: 710400, Avg. loss: 0.185927\n",
      "Total training time: 2.28 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 46.07, NNZs: 444239, Bias: 0.000000, T: 781440, Avg. loss: 0.185931\n",
      "Total training time: 2.50 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 45.12, NNZs: 444239, Bias: 0.000000, T: 852480, Avg. loss: 0.168550\n",
      "Total training time: 2.73 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 44.48, NNZs: 444239, Bias: 0.000000, T: 923520, Avg. loss: 0.169040\n",
      "Total training time: 2.95 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 44.07, NNZs: 444239, Bias: 0.000000, T: 994560, Avg. loss: 0.170428\n",
      "Total training time: 3.18 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 43.81, NNZs: 444239, Bias: 0.000000, T: 1065600, Avg. loss: 0.171535\n",
      "Total training time: 3.40 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 43.65, NNZs: 444239, Bias: 0.000000, T: 1136640, Avg. loss: 0.172315\n",
      "Total training time: 3.63 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 43.60, NNZs: 444239, Bias: 0.000000, T: 1207680, Avg. loss: 0.166191\n",
      "Total training time: 3.86 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 43.54, NNZs: 444239, Bias: 0.000000, T: 1278720, Avg. loss: 0.168860\n",
      "Total training time: 4.09 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 43.49, NNZs: 444239, Bias: 0.000000, T: 1349760, Avg. loss: 0.169017\n",
      "Total training time: 4.32 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 43.44, NNZs: 444239, Bias: 0.000000, T: 1420800, Avg. loss: 0.169159\n",
      "Total training time: 4.56 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.42493015701647596, clf__eta0=0.6773009699604285, clf__fit_intercept=False, clf__l1_ratio=0.7301998277223162, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.017782879504616322, clf__shuffle=False, clf__tol=0.19519881462597577, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.667 total time= 1.0min\n",
      "-- Epoch 1\n",
      "Norm: 66.18, NNZs: 444386, Bias: 0.000000, T: 71040, Avg. loss: 0.293639\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 65.36, NNZs: 444386, Bias: 0.000000, T: 142080, Avg. loss: 0.250804\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 65.37, NNZs: 444386, Bias: 0.000000, T: 213120, Avg. loss: 0.251141\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 65.37, NNZs: 444386, Bias: 0.000000, T: 284160, Avg. loss: 0.251133\n",
      "Total training time: 0.92 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 65.37, NNZs: 444386, Bias: 0.000000, T: 355200, Avg. loss: 0.251134\n",
      "Total training time: 1.17 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 65.37, NNZs: 444386, Bias: 0.000000, T: 426240, Avg. loss: 0.251134\n",
      "Total training time: 1.40 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 48.11, NNZs: 444386, Bias: 0.000000, T: 497280, Avg. loss: 0.184702\n",
      "Total training time: 1.63 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 45.95, NNZs: 444386, Bias: 0.000000, T: 568320, Avg. loss: 0.182222\n",
      "Total training time: 1.85 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 45.86, NNZs: 444386, Bias: 0.000000, T: 639360, Avg. loss: 0.183091\n",
      "Total training time: 2.07 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 45.85, NNZs: 444386, Bias: 0.000000, T: 710400, Avg. loss: 0.183165\n",
      "Total training time: 2.30 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 45.86, NNZs: 444386, Bias: 0.000000, T: 781440, Avg. loss: 0.183143\n",
      "Total training time: 2.54 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 44.83, NNZs: 444386, Bias: 0.000000, T: 852480, Avg. loss: 0.165347\n",
      "Total training time: 2.78 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 44.16, NNZs: 444386, Bias: 0.000000, T: 923520, Avg. loss: 0.166056\n",
      "Total training time: 3.02 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 43.74, NNZs: 444386, Bias: 0.000000, T: 994560, Avg. loss: 0.167585\n",
      "Total training time: 3.26 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 43.47, NNZs: 444386, Bias: 0.000000, T: 1065600, Avg. loss: 0.168755\n",
      "Total training time: 3.50 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 43.31, NNZs: 444386, Bias: 0.000000, T: 1136640, Avg. loss: 0.169555\n",
      "Total training time: 3.75 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 43.26, NNZs: 444386, Bias: 0.000000, T: 1207680, Avg. loss: 0.163238\n",
      "Total training time: 3.97 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 43.20, NNZs: 444386, Bias: 0.000000, T: 1278720, Avg. loss: 0.166013\n",
      "Total training time: 4.20 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 43.15, NNZs: 444386, Bias: 0.000000, T: 1349760, Avg. loss: 0.166175\n",
      "Total training time: 4.42 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 43.10, NNZs: 444386, Bias: 0.000000, T: 1420800, Avg. loss: 0.166321\n",
      "Total training time: 4.66 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.42493015701647596, clf__eta0=0.6773009699604285, clf__fit_intercept=False, clf__l1_ratio=0.7301998277223162, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.017782879504616322, clf__shuffle=False, clf__tol=0.19519881462597577, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.660 total time= 1.0min\n",
      "-- Epoch 1\n",
      "Norm: 68.63, NNZs: 443337, Bias: 0.000000, T: 71040, Avg. loss: 0.290983\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 67.68, NNZs: 443337, Bias: 0.000000, T: 142080, Avg. loss: 0.251159\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 67.70, NNZs: 443337, Bias: 0.000000, T: 213120, Avg. loss: 0.251241\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 67.70, NNZs: 443337, Bias: 0.000000, T: 284160, Avg. loss: 0.251251\n",
      "Total training time: 0.91 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 67.70, NNZs: 443337, Bias: 0.000000, T: 355200, Avg. loss: 0.251250\n",
      "Total training time: 1.18 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 67.70, NNZs: 443337, Bias: 0.000000, T: 426240, Avg. loss: 0.251250\n",
      "Total training time: 1.41 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 48.54, NNZs: 443337, Bias: 0.000000, T: 497280, Avg. loss: 0.183709\n",
      "Total training time: 1.63 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 46.13, NNZs: 443337, Bias: 0.000000, T: 568320, Avg. loss: 0.181293\n",
      "Total training time: 1.94 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 46.01, NNZs: 443337, Bias: 0.000000, T: 639360, Avg. loss: 0.182710\n",
      "Total training time: 2.22 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 46.00, NNZs: 443337, Bias: 0.000000, T: 710400, Avg. loss: 0.182928\n",
      "Total training time: 2.50 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 46.00, NNZs: 443337, Bias: 0.000000, T: 781440, Avg. loss: 0.182933\n",
      "Total training time: 2.78 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 45.02, NNZs: 443337, Bias: 0.000000, T: 852480, Avg. loss: 0.165986\n",
      "Total training time: 3.07 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 44.32, NNZs: 443337, Bias: 0.000000, T: 923520, Avg. loss: 0.165872\n",
      "Total training time: 3.34 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 43.87, NNZs: 443337, Bias: 0.000000, T: 994560, Avg. loss: 0.167382\n",
      "Total training time: 3.59 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 43.59, NNZs: 443337, Bias: 0.000000, T: 1065600, Avg. loss: 0.168642\n",
      "Total training time: 3.89 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 43.41, NNZs: 443337, Bias: 0.000000, T: 1136640, Avg. loss: 0.169526\n",
      "Total training time: 4.13 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 43.36, NNZs: 443337, Bias: 0.000000, T: 1207680, Avg. loss: 0.164308\n",
      "Total training time: 4.36 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 43.31, NNZs: 443337, Bias: 0.000000, T: 1278720, Avg. loss: 0.166448\n",
      "Total training time: 4.61 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 43.26, NNZs: 443337, Bias: 0.000000, T: 1349760, Avg. loss: 0.166453\n",
      "Total training time: 4.85 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 43.21, NNZs: 443337, Bias: 0.000000, T: 1420800, Avg. loss: 0.166510\n",
      "Total training time: 5.17 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.42493015701647596, clf__eta0=0.6773009699604285, clf__fit_intercept=False, clf__l1_ratio=0.7301998277223162, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.017782879504616322, clf__shuffle=False, clf__tol=0.19519881462597577, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.672 total time= 1.0min\n",
      "-- Epoch 1\n",
      "Norm: 72.49, NNZs: 443723, Bias: 0.000000, T: 71040, Avg. loss: 0.299037\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 71.41, NNZs: 443723, Bias: 0.000000, T: 142080, Avg. loss: 0.259229\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 71.44, NNZs: 443723, Bias: 0.000000, T: 213120, Avg. loss: 0.259444\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 71.44, NNZs: 443723, Bias: 0.000000, T: 284160, Avg. loss: 0.259445\n",
      "Total training time: 0.92 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 71.44, NNZs: 443723, Bias: 0.000000, T: 355200, Avg. loss: 0.259445\n",
      "Total training time: 1.15 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 71.44, NNZs: 443723, Bias: 0.000000, T: 426240, Avg. loss: 0.259445\n",
      "Total training time: 1.39 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 49.13, NNZs: 443723, Bias: 0.000000, T: 497280, Avg. loss: 0.185414\n",
      "Total training time: 1.64 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 46.12, NNZs: 443723, Bias: 0.000000, T: 568320, Avg. loss: 0.182155\n",
      "Total training time: 1.88 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 45.92, NNZs: 443723, Bias: 0.000000, T: 639360, Avg. loss: 0.184015\n",
      "Total training time: 2.10 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 45.90, NNZs: 443723, Bias: 0.000000, T: 710400, Avg. loss: 0.184308\n",
      "Total training time: 2.33 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 45.90, NNZs: 443723, Bias: 0.000000, T: 781440, Avg. loss: 0.184306\n",
      "Total training time: 2.56 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 44.95, NNZs: 443723, Bias: 0.000000, T: 852480, Avg. loss: 0.167284\n",
      "Total training time: 2.79 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 44.26, NNZs: 443723, Bias: 0.000000, T: 923520, Avg. loss: 0.166722\n",
      "Total training time: 3.03 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 43.82, NNZs: 443723, Bias: 0.000000, T: 994560, Avg. loss: 0.168185\n",
      "Total training time: 3.26 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 43.54, NNZs: 443723, Bias: 0.000000, T: 1065600, Avg. loss: 0.169418\n",
      "Total training time: 3.49 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 43.36, NNZs: 443723, Bias: 0.000000, T: 1136640, Avg. loss: 0.170293\n",
      "Total training time: 3.73 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 43.31, NNZs: 443723, Bias: 0.000000, T: 1207680, Avg. loss: 0.166243\n",
      "Total training time: 3.96 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 43.25, NNZs: 443723, Bias: 0.000000, T: 1278720, Avg. loss: 0.167092\n",
      "Total training time: 4.20 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 43.20, NNZs: 443723, Bias: 0.000000, T: 1349760, Avg. loss: 0.167130\n",
      "Total training time: 4.43 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 43.15, NNZs: 443723, Bias: 0.000000, T: 1420800, Avg. loss: 0.167208\n",
      "Total training time: 4.65 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.42493015701647596, clf__eta0=0.6773009699604285, clf__fit_intercept=False, clf__l1_ratio=0.7301998277223162, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.017782879504616322, clf__shuffle=False, clf__tol=0.19519881462597577, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.671 total time= 1.0min\n",
      "-- Epoch 1\n",
      "Norm: 72.54, NNZs: 441701, Bias: 0.000000, T: 71040, Avg. loss: 0.292679\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 71.54, NNZs: 441701, Bias: 0.000000, T: 142080, Avg. loss: 0.247823\n",
      "Total training time: 0.43 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 71.57, NNZs: 441701, Bias: 0.000000, T: 213120, Avg. loss: 0.247951\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 71.57, NNZs: 441701, Bias: 0.000000, T: 284160, Avg. loss: 0.247954\n",
      "Total training time: 0.93 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 71.57, NNZs: 441701, Bias: 0.000000, T: 355200, Avg. loss: 0.247954\n",
      "Total training time: 1.18 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 71.57, NNZs: 441701, Bias: 0.000000, T: 426240, Avg. loss: 0.247954\n",
      "Total training time: 1.44 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 49.08, NNZs: 441701, Bias: 0.000000, T: 497280, Avg. loss: 0.192314\n",
      "Total training time: 1.67 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 46.20, NNZs: 441701, Bias: 0.000000, T: 568320, Avg. loss: 0.181436\n",
      "Total training time: 1.91 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 45.97, NNZs: 441701, Bias: 0.000000, T: 639360, Avg. loss: 0.181946\n",
      "Total training time: 2.14 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 45.96, NNZs: 441701, Bias: 0.000000, T: 710400, Avg. loss: 0.182039\n",
      "Total training time: 2.40 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 45.96, NNZs: 441701, Bias: 0.000000, T: 781440, Avg. loss: 0.182051\n",
      "Total training time: 2.64 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 44.93, NNZs: 441701, Bias: 0.000000, T: 852480, Avg. loss: 0.173708\n",
      "Total training time: 2.90 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 44.26, NNZs: 441701, Bias: 0.000000, T: 923520, Avg. loss: 0.166040\n",
      "Total training time: 3.22 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 43.83, NNZs: 441701, Bias: 0.000000, T: 994560, Avg. loss: 0.167472\n",
      "Total training time: 3.47 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 43.57, NNZs: 441701, Bias: 0.000000, T: 1065600, Avg. loss: 0.168637\n",
      "Total training time: 3.71 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 43.40, NNZs: 441701, Bias: 0.000000, T: 1136640, Avg. loss: 0.169417\n",
      "Total training time: 3.96 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 43.34, NNZs: 441701, Bias: 0.000000, T: 1207680, Avg. loss: 0.168203\n",
      "Total training time: 4.18 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 43.28, NNZs: 441701, Bias: 0.000000, T: 1278720, Avg. loss: 0.166320\n",
      "Total training time: 4.43 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 43.23, NNZs: 441701, Bias: 0.000000, T: 1349760, Avg. loss: 0.166255\n",
      "Total training time: 4.66 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 43.18, NNZs: 441701, Bias: 0.000000, T: 1420800, Avg. loss: 0.166311\n",
      "Total training time: 4.91 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.42493015701647596, clf__eta0=0.6773009699604285, clf__fit_intercept=False, clf__l1_ratio=0.7301998277223162, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.017782879504616322, clf__shuffle=False, clf__tol=0.19519881462597577, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.679 total time=  59.2s\n",
      "-- Epoch 1\n",
      "Norm: 51.20, NNZs: 267663, Bias: 1.996836, T: 71040, Avg. loss: 0.308728\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 30.55, NNZs: 287455, Bias: 1.743076, T: 142080, Avg. loss: 0.006972\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 22.98, NNZs: 294318, Bias: 1.604928, T: 213120, Avg. loss: 0.002907\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 18.59, NNZs: 297304, Bias: 1.532337, T: 284160, Avg. loss: 0.001227\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 15.99, NNZs: 298124, Bias: 1.460855, T: 355200, Avg. loss: 0.000583\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 14.11, NNZs: 299119, Bias: 1.415337, T: 426240, Avg. loss: 0.000470\n",
      "Total training time: 0.93 seconds.\n",
      "Convergence after 6 epochs took 0.97 seconds\n",
      "[CV 1/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.21123614325601048, clf__eta0=0.32979731781585486, clf__fit_intercept=True, clf__l1_ratio=0.4775095579144826, clf__learning_rate=optimal, clf__loss=perceptron, clf__max_iter=30, clf__penalty=l2, clf__power_t=0.6427671735097384, clf__shuffle=False, clf__tol=0.2651165400908262, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.858 total time=  56.9s\n",
      "-- Epoch 1\n",
      "Norm: 51.70, NNZs: 267650, Bias: 1.980007, T: 71040, Avg. loss: 0.267388\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 31.04, NNZs: 286442, Bias: 1.780144, T: 142080, Avg. loss: 0.009007\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 23.04, NNZs: 293476, Bias: 1.664339, T: 213120, Avg. loss: 0.002749\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 18.62, NNZs: 295103, Bias: 1.585121, T: 284160, Avg. loss: 0.001014\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 15.94, NNZs: 295906, Bias: 1.522464, T: 355200, Avg. loss: 0.000671\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 14.26, NNZs: 296639, Bias: 1.463391, T: 426240, Avg. loss: 0.000482\n",
      "Total training time: 0.77 seconds.\n",
      "Convergence after 6 epochs took 0.81 seconds\n",
      "[CV 2/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.21123614325601048, clf__eta0=0.32979731781585486, clf__fit_intercept=True, clf__l1_ratio=0.4775095579144826, clf__learning_rate=optimal, clf__loss=perceptron, clf__max_iter=30, clf__penalty=l2, clf__power_t=0.6427671735097384, clf__shuffle=False, clf__tol=0.2651165400908262, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.864 total time=  55.7s\n",
      "-- Epoch 1\n",
      "Norm: 51.37, NNZs: 262072, Bias: 2.254206, T: 71040, Avg. loss: 0.318685\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 31.64, NNZs: 280414, Bias: 1.917042, T: 142080, Avg. loss: 0.007386\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 23.34, NNZs: 283755, Bias: 1.781034, T: 213120, Avg. loss: 0.002371\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 19.09, NNZs: 287103, Bias: 1.691039, T: 284160, Avg. loss: 0.001348\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 16.40, NNZs: 288722, Bias: 1.628755, T: 355200, Avg. loss: 0.000881\n",
      "Total training time: 0.72 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 14.28, NNZs: 289608, Bias: 1.598527, T: 426240, Avg. loss: 0.000516\n",
      "Total training time: 0.86 seconds.\n",
      "Convergence after 6 epochs took 0.90 seconds\n",
      "[CV 3/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.21123614325601048, clf__eta0=0.32979731781585486, clf__fit_intercept=True, clf__l1_ratio=0.4775095579144826, clf__learning_rate=optimal, clf__loss=perceptron, clf__max_iter=30, clf__penalty=l2, clf__power_t=0.6427671735097384, clf__shuffle=False, clf__tol=0.2651165400908262, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.895 total time=  56.8s\n",
      "-- Epoch 1\n",
      "Norm: 53.29, NNZs: 256742, Bias: 2.588917, T: 71040, Avg. loss: 0.353850\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 32.00, NNZs: 277470, Bias: 2.300366, T: 142080, Avg. loss: 0.007834\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 24.10, NNZs: 282393, Bias: 2.121531, T: 213120, Avg. loss: 0.002256\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 20.04, NNZs: 286208, Bias: 2.016851, T: 284160, Avg. loss: 0.001725\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 17.05, NNZs: 287177, Bias: 1.962331, T: 355200, Avg. loss: 0.000806\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 15.37, NNZs: 287661, Bias: 1.890565, T: 426240, Avg. loss: 0.000402\n",
      "Total training time: 0.93 seconds.\n",
      "Convergence after 6 epochs took 0.97 seconds\n",
      "[CV 4/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.21123614325601048, clf__eta0=0.32979731781585486, clf__fit_intercept=True, clf__l1_ratio=0.4775095579144826, clf__learning_rate=optimal, clf__loss=perceptron, clf__max_iter=30, clf__penalty=l2, clf__power_t=0.6427671735097384, clf__shuffle=False, clf__tol=0.2651165400908262, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.849 total time=  56.3s\n",
      "-- Epoch 1\n",
      "Norm: 52.94, NNZs: 270662, Bias: 2.324132, T: 71040, Avg. loss: 0.330324\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 32.06, NNZs: 289824, Bias: 2.027232, T: 142080, Avg. loss: 0.007855\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 24.29, NNZs: 294995, Bias: 1.852712, T: 213120, Avg. loss: 0.002588\n",
      "Total training time: 0.54 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 19.79, NNZs: 296938, Bias: 1.766113, T: 284160, Avg. loss: 0.001311\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 16.91, NNZs: 298084, Bias: 1.705443, T: 355200, Avg. loss: 0.000694\n",
      "Total training time: 0.81 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 15.05, NNZs: 298739, Bias: 1.651291, T: 426240, Avg. loss: 0.000540\n",
      "Total training time: 0.95 seconds.\n",
      "Convergence after 6 epochs took 0.99 seconds\n",
      "[CV 5/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.21123614325601048, clf__eta0=0.32979731781585486, clf__fit_intercept=True, clf__l1_ratio=0.4775095579144826, clf__learning_rate=optimal, clf__loss=perceptron, clf__max_iter=30, clf__penalty=l2, clf__power_t=0.6427671735097384, clf__shuffle=False, clf__tol=0.2651165400908262, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.707 total time=  56.4s\n",
      "-- Epoch 1\n",
      "Norm: 88.13, NNZs: 226, Bias: 0.000000, T: 88800, Avg. loss: 0.019296\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 115.70, NNZs: 93, Bias: 0.000000, T: 177600, Avg. loss: 0.011856\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 136.12, NNZs: 85, Bias: 0.000000, T: 266400, Avg. loss: 0.010482\n",
      "Total training time: 1.21 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 153.11, NNZs: 80, Bias: 0.000000, T: 355200, Avg. loss: 0.009845\n",
      "Total training time: 1.62 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 167.88, NNZs: 72, Bias: 0.000000, T: 444000, Avg. loss: 0.009330\n",
      "Total training time: 2.08 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 181.21, NNZs: 69, Bias: 0.000000, T: 532800, Avg. loss: 0.009257\n",
      "Total training time: 2.51 seconds.\n",
      "Convergence after 6 epochs took 2.56 seconds\n",
      "0.9992905405405406\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          Ja       1.00      0.93      0.96       291\n",
      "         Nee       1.00      1.00      1.00     29309\n",
      "\n",
      "    accuracy                           1.00     29600\n",
      "   macro avg       1.00      0.97      0.98     29600\n",
      "weighted avg       1.00      1.00      1.00     29600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ngram 2 Stopwords kept\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1,2), lowercase=True, token_pattern=r\"(?u)\\b\\w\\w+\\b|\\+|\\-\")),\n",
    "    ('clf', SGDClassifier(early_stopping=True, n_iter_no_change=5, validation_fraction = 0.25, verbose=3)),\n",
    "])\n",
    "random_search = RandomizedSearchCV(estimator=pipeline, param_distributions=parameter_grid, random_state=500, verbose=3, scoring='f1_macro')\n",
    "random_search.fit(X_train, y_train)  \n",
    "predicted_nb = random_search.predict(X_test)\n",
    "print(np.mean(predicted_nb == y_test))\n",
    "cm = confusion_matrix(y_test, predicted_nb)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=random_search.classes_)\n",
    "disp.plot()\n",
    "\n",
    "plt.show()\n",
    "print(metrics.classification_report(y_test, predicted_nb,\n",
    "    target_names=random_search.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae6d0b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump\n",
    "\n",
    "dump(random_search, open('best_models/best_drugs_ex2.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4266a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (thesis_hielke)",
   "language": "python",
   "name": "thesis_hielke"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
