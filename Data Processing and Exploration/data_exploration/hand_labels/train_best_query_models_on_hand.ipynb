{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c73a6a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import sklearn\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy.stats import uniform as sp_randFloat\n",
    "from scipy.stats import randint as sp_randInt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import pickle\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6b81fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_reviewed_data_drop = pd.read_csv('../../input_data/full_datasets/fully_hand_labelled_texts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "985a98f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_reviewed_data_drop.text = full_reviewed_data_drop.text.str.replace(\"_x000D_\\n\", \"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6bc747b",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = pd.read_csv('medrobertanl-haga_smoking_predictions.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02654121",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = full_reviewed_data_drop.loc[indices['index']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b17fc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = full_reviewed_data_drop.loc[~full_reviewed_data_drop.index.isin(test_set.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1d7a892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label_id</th>\n",
       "      <th>text</th>\n",
       "      <th>Roken</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Drugs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Beloop: \\tPatiÃ«nte heeft 10 minuten van te vo...</td>\n",
       "      <td>Niets gevonden</td>\n",
       "      <td>Niets gevonden</td>\n",
       "      <td>Niets gevonden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Beloop: \\tG5P4 36 wkGrav 1e lijnALL geen Hb Pa...</td>\n",
       "      <td>Niets gevonden</td>\n",
       "      <td>Niets gevonden</td>\n",
       "      <td>Niets gevonden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Beleid: \\tAlgemeen: Dagopname voor 3x PC  a 2....</td>\n",
       "      <td>Niets gevonden</td>\n",
       "      <td>Niets gevonden</td>\n",
       "      <td>Niets gevonden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Anamnese: \\t34W4D</td>\n",
       "      <td>Niets gevonden</td>\n",
       "      <td>Niets gevonden</td>\n",
       "      <td>Niets gevonden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Conclusie: \\tMw gebeld, vertelde dat het goed ...</td>\n",
       "      <td>Niets gevonden</td>\n",
       "      <td>Niets gevonden</td>\n",
       "      <td>Niets gevonden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4694</th>\n",
       "      <td>94</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Beloop: \\tVOORBEREIDING:G3P1 // AD 39+0 // B P...</td>\n",
       "      <td>Geen gebruiker</td>\n",
       "      <td>Geen gebruiker</td>\n",
       "      <td>Geen gebruiker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4695</th>\n",
       "      <td>95</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Beloop: \\tCONSULTENKAMERGezien door co-ass Y. ...</td>\n",
       "      <td>Geen gebruiker</td>\n",
       "      <td>Geen gebruiker</td>\n",
       "      <td>Geen gebruiker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4696</th>\n",
       "      <td>96</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Reden van komst / Verwijzing: \\tReden verwijzi...</td>\n",
       "      <td>Geen gebruiker</td>\n",
       "      <td>Geen gebruiker</td>\n",
       "      <td>Geen gebruiker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4697</th>\n",
       "      <td>97</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Beloop: \\tMR CPG7P4M4 //  MI: 4x sectio ia, 1x...</td>\n",
       "      <td>Geen gebruiker</td>\n",
       "      <td>Geen gebruiker</td>\n",
       "      <td>Geen gebruiker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4698</th>\n",
       "      <td>98</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Reden van komst / Verwijzing: \\tReden van koms...</td>\n",
       "      <td>Geen gebruiker</td>\n",
       "      <td>Geen gebruiker</td>\n",
       "      <td>Geen gebruiker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3760 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  label_id                                               text  \\\n",
       "0              0       1.0  Beloop: \\tPatiÃ«nte heeft 10 minuten van te vo...   \n",
       "1              1       1.0  Beloop: \\tG5P4 36 wkGrav 1e lijnALL geen Hb Pa...   \n",
       "3              3       1.0  Beleid: \\tAlgemeen: Dagopname voor 3x PC  a 2....   \n",
       "4              4       1.0                                  Anamnese: \\t34W4D   \n",
       "5              5       1.0  Conclusie: \\tMw gebeld, vertelde dat het goed ...   \n",
       "...          ...       ...                                                ...   \n",
       "4694          94       2.0  Beloop: \\tVOORBEREIDING:G3P1 // AD 39+0 // B P...   \n",
       "4695          95       2.0  Beloop: \\tCONSULTENKAMERGezien door co-ass Y. ...   \n",
       "4696          96       2.0  Reden van komst / Verwijzing: \\tReden verwijzi...   \n",
       "4697          97       2.0  Beloop: \\tMR CPG7P4M4 //  MI: 4x sectio ia, 1x...   \n",
       "4698          98       2.0  Reden van komst / Verwijzing: \\tReden van koms...   \n",
       "\n",
       "               Roken         Alcohol           Drugs  \n",
       "0     Niets gevonden  Niets gevonden  Niets gevonden  \n",
       "1     Niets gevonden  Niets gevonden  Niets gevonden  \n",
       "3     Niets gevonden  Niets gevonden  Niets gevonden  \n",
       "4     Niets gevonden  Niets gevonden  Niets gevonden  \n",
       "5     Niets gevonden  Niets gevonden  Niets gevonden  \n",
       "...              ...             ...             ...  \n",
       "4694  Geen gebruiker  Geen gebruiker  Geen gebruiker  \n",
       "4695  Geen gebruiker  Geen gebruiker  Geen gebruiker  \n",
       "4696  Geen gebruiker  Geen gebruiker  Geen gebruiker  \n",
       "4697  Geen gebruiker  Geen gebruiker  Geen gebruiker  \n",
       "4698  Geen gebruiker  Geen gebruiker  Geen gebruiker  \n",
       "\n",
       "[3760 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b615e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "Corpus = full_reviewed_data_drop.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2dec6e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Corpus['text'] = Corpus['text'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b1702e",
   "metadata": {},
   "source": [
    "# Roken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a4f796",
   "metadata": {},
   "source": [
    "## Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0936906f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rook_corpus = Corpus[[\"text\", \"Roken\"]].rename(columns={\"Roken\":\"label\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "894f79ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beloop: \\tPatiÃ«nte heeft 10 minuten van te vo...</td>\n",
       "      <td>Niets gevonden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beloop: \\tG5P4 36 wkGrav 1e lijnALL geen Hb Pa...</td>\n",
       "      <td>Niets gevonden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Conclusie: \\tNormale nacontrole. Kijkt goed te...</td>\n",
       "      <td>Niets gevonden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beleid: \\tAlgemeen: Dagopname voor 3x PC  a 2....</td>\n",
       "      <td>Niets gevonden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anamnese: \\t34W4D</td>\n",
       "      <td>Niets gevonden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4695</th>\n",
       "      <td>Beloop: \\tCONSULTENKAMERGezien door co-ass Y. ...</td>\n",
       "      <td>Geen gebruiker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4696</th>\n",
       "      <td>Reden van komst / Verwijzing: \\tReden verwijzi...</td>\n",
       "      <td>Geen gebruiker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4697</th>\n",
       "      <td>Beloop: \\tMR CPG7P4M4 //  MI: 4x sectio ia, 1x...</td>\n",
       "      <td>Geen gebruiker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4698</th>\n",
       "      <td>Reden van komst / Verwijzing: \\tReden van koms...</td>\n",
       "      <td>Geen gebruiker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4699</th>\n",
       "      <td>Reden van komst / Verwijzing: \\tReden van koms...</td>\n",
       "      <td>Geen gebruiker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4700 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text           label\n",
       "0     Beloop: \\tPatiÃ«nte heeft 10 minuten van te vo...  Niets gevonden\n",
       "1     Beloop: \\tG5P4 36 wkGrav 1e lijnALL geen Hb Pa...  Niets gevonden\n",
       "2     Conclusie: \\tNormale nacontrole. Kijkt goed te...  Niets gevonden\n",
       "3     Beleid: \\tAlgemeen: Dagopname voor 3x PC  a 2....  Niets gevonden\n",
       "4                                     Anamnese: \\t34W4D  Niets gevonden\n",
       "...                                                 ...             ...\n",
       "4695  Beloop: \\tCONSULTENKAMERGezien door co-ass Y. ...  Geen gebruiker\n",
       "4696  Reden van komst / Verwijzing: \\tReden verwijzi...  Geen gebruiker\n",
       "4697  Beloop: \\tMR CPG7P4M4 //  MI: 4x sectio ia, 1x...  Geen gebruiker\n",
       "4698  Reden van komst / Verwijzing: \\tReden van koms...  Geen gebruiker\n",
       "4699  Reden van komst / Verwijzing: \\tReden van koms...  Geen gebruiker\n",
       "\n",
       "[4700 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rook_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b92ad7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rook_corpus['text'] = rook_corpus['text'].str.replace('\\t',' ')\n",
    "rook_corpus.drop_duplicates(inplace=True)\n",
    "rook_corpus['text'] = rook_corpus['text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "87a70287",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"dutch\")\n",
    "rook_corpus['text'] = rook_corpus['text'].str.lower()\n",
    "rook_corpus['text'] = [stemmer.stem(text) for text in rook_corpus['text']]\n",
    "rook_corpus = rook_corpus.drop(rook_corpus[rook_corpus.label == '--'].index)\n",
    "rook_corpus_backup = rook_corpus.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5d65ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_filter = ['niet', 'niets', 'geen', 'zonder']\n",
    "with open('../../helping_files/stopwords.txt') as file:\n",
    "    full_stopwords = [line.rstrip() for line in file]\n",
    "    filtered_stopwords = [item for item in full_stopwords if item not in stopwords_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1df7f00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = rook_corpus.loc[indices['index']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "624b28e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = rook_corpus.loc[~rook_corpus.index.isin(test_set.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d6ea17ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>beloop:  patiã«nte heeft 10 minuten van te vor...</td>\n",
       "      <td>Niets gevonden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>beloop:  g5p4 36 wkgrav 1e lijnall geen hb pat...</td>\n",
       "      <td>Niets gevonden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>beleid:  algemeen: dagopname voor 3x pc  a 2.5...</td>\n",
       "      <td>Niets gevonden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anamnese:  34w4d</td>\n",
       "      <td>Niets gevonden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>conclusie:  mw gebeld, vertelde dat het goed g...</td>\n",
       "      <td>Niets gevonden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4694</th>\n",
       "      <td>beloop:  voorbereiding:g3p1 // ad 39+0 // b po...</td>\n",
       "      <td>Geen gebruiker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4695</th>\n",
       "      <td>beloop:  consultenkamergezien door co-ass y. t...</td>\n",
       "      <td>Geen gebruiker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4696</th>\n",
       "      <td>reden van komst / verwijzing:  reden verwijzin...</td>\n",
       "      <td>Geen gebruiker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4697</th>\n",
       "      <td>beloop:  mr cpg7p4m4 //  mi: 4x sectio ia, 1x ...</td>\n",
       "      <td>Geen gebruiker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4698</th>\n",
       "      <td>reden van komst / verwijzing:  reden van komst...</td>\n",
       "      <td>Geen gebruiker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3760 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text           label\n",
       "0     beloop:  patiã«nte heeft 10 minuten van te vor...  Niets gevonden\n",
       "1     beloop:  g5p4 36 wkgrav 1e lijnall geen hb pat...  Niets gevonden\n",
       "3     beleid:  algemeen: dagopname voor 3x pc  a 2.5...  Niets gevonden\n",
       "4                                      anamnese:  34w4d  Niets gevonden\n",
       "5     conclusie:  mw gebeld, vertelde dat het goed g...  Niets gevonden\n",
       "...                                                 ...             ...\n",
       "4694  beloop:  voorbereiding:g3p1 // ad 39+0 // b po...  Geen gebruiker\n",
       "4695  beloop:  consultenkamergezien door co-ass y. t...  Geen gebruiker\n",
       "4696  reden van komst / verwijzing:  reden verwijzin...  Geen gebruiker\n",
       "4697  beloop:  mr cpg7p4m4 //  mi: 4x sectio ia, 1x ...  Geen gebruiker\n",
       "4698  reden van komst / verwijzing:  reden van komst...  Geen gebruiker\n",
       "\n",
       "[3760 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5761c853",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = {'clf__loss':              ['hinge', 'log_loss', 'log', 'modified_huber', 'squared_hinge', 'perceptron', 'squared_error', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "                  'clf__penalty':           ['l2', 'l1'],\n",
    "                  'clf__l1_ratio':          sp_randFloat(),\n",
    "                  'clf__fit_intercept':     [True, False],\n",
    "                  'clf__max_iter':          [int(x) for x in np.linspace(start = 10, stop = 100, num = 10)],\n",
    "                  'clf__tol':               sp_randFloat(),\n",
    "                  'clf__shuffle':           [True, False],\n",
    "                  'clf__epsilon':           sp_randFloat(),\n",
    "                  'clf__learning_rate':     ['constant', 'optimal', 'invscaling', 'adaptive'],\n",
    "                  'clf__eta0':              sp_randFloat(),\n",
    "                  'clf__power_t':           sp_randFloat(),\n",
    "                  'clf__class_weight':      ['balanced', None],\n",
    "                  'clf__warm_start':        [True, False],\n",
    "                  'clf__average':           [True, False],\n",
    "                  'tfidf__max_df':          [0.90, 0.95],\n",
    "                  'tfidf__min_df':          [3, 5]\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "767390cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 23.44, NNZs: 4963, Bias: 0.000000, T: 2256, Avg. loss: 0.380919\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 32.92, NNZs: 2591, Bias: 0.000000, T: 4512, Avg. loss: 0.257075\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 39.70, NNZs: 1854, Bias: 0.000000, T: 6768, Avg. loss: 0.221490\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 45.33, NNZs: 1535, Bias: 0.000000, T: 9024, Avg. loss: 0.201711\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 50.14, NNZs: 1328, Bias: 0.000000, T: 11280, Avg. loss: 0.188065\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 54.41, NNZs: 1198, Bias: 0.000000, T: 13536, Avg. loss: 0.178112\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 55.16, NNZs: 1137, Bias: 0.000000, T: 15792, Avg. loss: 0.171522\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 55.90, NNZs: 1106, Bias: 0.000000, T: 18048, Avg. loss: 0.170332\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 56.64, NNZs: 1082, Bias: 0.000000, T: 20304, Avg. loss: 0.168906\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 57.36, NNZs: 1057, Bias: 0.000000, T: 22560, Avg. loss: 0.167605\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 58.07, NNZs: 1038, Bias: 0.000000, T: 24816, Avg. loss: 0.166266\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 58.21, NNZs: 1027, Bias: 0.000000, T: 27072, Avg. loss: 0.165200\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 58.35, NNZs: 1020, Bias: 0.000000, T: 29328, Avg. loss: 0.164991\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 58.48, NNZs: 1020, Bias: 0.000000, T: 31584, Avg. loss: 0.164740\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 58.62, NNZs: 1018, Bias: 0.000000, T: 33840, Avg. loss: 0.164500\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 58.76, NNZs: 1015, Bias: 0.000000, T: 36096, Avg. loss: 0.164269\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 58.79, NNZs: 1010, Bias: 0.000000, T: 38352, Avg. loss: 0.164050\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 58.81, NNZs: 1010, Bias: 0.000000, T: 40608, Avg. loss: 0.164013\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 58.84, NNZs: 1008, Bias: 0.000000, T: 42864, Avg. loss: 0.163966\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 58.87, NNZs: 1008, Bias: 0.000000, T: 45120, Avg. loss: 0.163918\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 24.02, NNZs: 5194, Bias: 0.000000, T: 2256, Avg. loss: 0.350511\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 32.27, NNZs: 2325, Bias: 0.000000, T: 4512, Avg. loss: 0.232562\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 38.46, NNZs: 1678, Bias: 0.000000, T: 6768, Avg. loss: 0.207623\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 43.29, NNZs: 1341, Bias: 0.000000, T: 9024, Avg. loss: 0.192616\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 47.64, NNZs: 1149, Bias: 0.000000, T: 11280, Avg. loss: 0.182446\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 51.36, NNZs: 1037, Bias: 0.000000, T: 13536, Avg. loss: 0.173880\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 52.06, NNZs: 984, Bias: 0.000000, T: 15792, Avg. loss: 0.169107\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 52.75, NNZs: 960, Bias: 0.000000, T: 18048, Avg. loss: 0.168038\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 53.42, NNZs: 952, Bias: 0.000000, T: 20304, Avg. loss: 0.166654\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 54.09, NNZs: 937, Bias: 0.000000, T: 22560, Avg. loss: 0.165509\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 54.74, NNZs: 924, Bias: 0.000000, T: 24816, Avg. loss: 0.164341\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 54.86, NNZs: 913, Bias: 0.000000, T: 27072, Avg. loss: 0.163378\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 54.99, NNZs: 910, Bias: 0.000000, T: 29328, Avg. loss: 0.163208\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 55.12, NNZs: 910, Bias: 0.000000, T: 31584, Avg. loss: 0.162990\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 55.24, NNZs: 907, Bias: 0.000000, T: 33840, Avg. loss: 0.162768\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 55.37, NNZs: 907, Bias: 0.000000, T: 36096, Avg. loss: 0.162560\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 55.39, NNZs: 902, Bias: 0.000000, T: 38352, Avg. loss: 0.162376\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 55.42, NNZs: 902, Bias: 0.000000, T: 40608, Avg. loss: 0.162342\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 55.44, NNZs: 902, Bias: 0.000000, T: 42864, Avg. loss: 0.162298\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 55.47, NNZs: 902, Bias: 0.000000, T: 45120, Avg. loss: 0.162255\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 24.26, NNZs: 5607, Bias: 0.000000, T: 2256, Avg. loss: 0.407102\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 34.35, NNZs: 3124, Bias: 0.000000, T: 4512, Avg. loss: 0.268694\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 41.65, NNZs: 2376, Bias: 0.000000, T: 6768, Avg. loss: 0.231138\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 47.56, NNZs: 1965, Bias: 0.000000, T: 9024, Avg. loss: 0.209694\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 52.70, NNZs: 1708, Bias: 0.000000, T: 11280, Avg. loss: 0.195492\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 57.22, NNZs: 1560, Bias: 0.000000, T: 13536, Avg. loss: 0.185772\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 58.03, NNZs: 1489, Bias: 0.000000, T: 15792, Avg. loss: 0.178643\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 58.82, NNZs: 1464, Bias: 0.000000, T: 18048, Avg. loss: 0.177444\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 59.60, NNZs: 1439, Bias: 0.000000, T: 20304, Avg. loss: 0.176053\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 60.36, NNZs: 1423, Bias: 0.000000, T: 22560, Avg. loss: 0.174724\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 61.12, NNZs: 1404, Bias: 0.000000, T: 24816, Avg. loss: 0.173390\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 61.26, NNZs: 1393, Bias: 0.000000, T: 27072, Avg. loss: 0.172311\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 61.41, NNZs: 1385, Bias: 0.000000, T: 29328, Avg. loss: 0.172103\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 61.56, NNZs: 1382, Bias: 0.000000, T: 31584, Avg. loss: 0.171866\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 61.70, NNZs: 1379, Bias: 0.000000, T: 33840, Avg. loss: 0.171615\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 61.85, NNZs: 1374, Bias: 0.000000, T: 36096, Avg. loss: 0.171390\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 61.88, NNZs: 1373, Bias: 0.000000, T: 38352, Avg. loss: 0.171164\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 61.91, NNZs: 1370, Bias: 0.000000, T: 40608, Avg. loss: 0.171130\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 61.94, NNZs: 1371, Bias: 0.000000, T: 42864, Avg. loss: 0.171081\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 61.97, NNZs: 1370, Bias: 0.000000, T: 45120, Avg. loss: 0.171035\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 24.80, NNZs: 5875, Bias: 0.000000, T: 2256, Avg. loss: 0.377867\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 34.24, NNZs: 3014, Bias: 0.000000, T: 4512, Avg. loss: 0.244677\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 40.96, NNZs: 2252, Bias: 0.000000, T: 6768, Avg. loss: 0.213215\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 46.53, NNZs: 1780, Bias: 0.000000, T: 9024, Avg. loss: 0.195131\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 51.25, NNZs: 1503, Bias: 0.000000, T: 11280, Avg. loss: 0.183076\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 55.49, NNZs: 1342, Bias: 0.000000, T: 13536, Avg. loss: 0.174139\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 56.25, NNZs: 1279, Bias: 0.000000, T: 15792, Avg. loss: 0.167982\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 57.00, NNZs: 1255, Bias: 0.000000, T: 18048, Avg. loss: 0.166914\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 57.74, NNZs: 1228, Bias: 0.000000, T: 20304, Avg. loss: 0.165571\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 58.46, NNZs: 1203, Bias: 0.000000, T: 22560, Avg. loss: 0.164474\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 59.17, NNZs: 1189, Bias: 0.000000, T: 24816, Avg. loss: 0.163202\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 59.31, NNZs: 1183, Bias: 0.000000, T: 27072, Avg. loss: 0.162206\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 59.44, NNZs: 1179, Bias: 0.000000, T: 29328, Avg. loss: 0.162033\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 59.58, NNZs: 1173, Bias: 0.000000, T: 31584, Avg. loss: 0.161818\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 59.72, NNZs: 1170, Bias: 0.000000, T: 33840, Avg. loss: 0.161600\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 59.86, NNZs: 1161, Bias: 0.000000, T: 36096, Avg. loss: 0.161363\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 59.88, NNZs: 1158, Bias: 0.000000, T: 38352, Avg. loss: 0.161181\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 59.91, NNZs: 1158, Bias: 0.000000, T: 40608, Avg. loss: 0.161145\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 59.94, NNZs: 1154, Bias: 0.000000, T: 42864, Avg. loss: 0.161100\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 59.97, NNZs: 1156, Bias: 0.000000, T: 45120, Avg. loss: 0.161061\n",
      "Total training time: 0.08 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.3s finished\n",
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.06171699256249541, clf__eta0=0.6666115972798587, clf__fit_intercept=False, clf__l1_ratio=0.9792901432894962, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.15075392531110676, clf__shuffle=True, clf__tol=0.365636830734297, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.549 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 23.15, NNZs: 5069, Bias: 0.000000, T: 2256, Avg. loss: 0.393031\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 32.44, NNZs: 2565, Bias: 0.000000, T: 4512, Avg. loss: 0.272809\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 39.35, NNZs: 1931, Bias: 0.000000, T: 6768, Avg. loss: 0.237768\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 44.98, NNZs: 1610, Bias: 0.000000, T: 9024, Avg. loss: 0.217403\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 49.84, NNZs: 1412, Bias: 0.000000, T: 11280, Avg. loss: 0.203140\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 54.24, NNZs: 1260, Bias: 0.000000, T: 13536, Avg. loss: 0.192888\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 55.01, NNZs: 1187, Bias: 0.000000, T: 15792, Avg. loss: 0.185897\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 55.77, NNZs: 1166, Bias: 0.000000, T: 18048, Avg. loss: 0.184605\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 56.51, NNZs: 1150, Bias: 0.000000, T: 20304, Avg. loss: 0.183185\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 57.25, NNZs: 1129, Bias: 0.000000, T: 22560, Avg. loss: 0.181804\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 57.97, NNZs: 1101, Bias: 0.000000, T: 24816, Avg. loss: 0.180428\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 58.12, NNZs: 1090, Bias: 0.000000, T: 27072, Avg. loss: 0.179267\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 58.26, NNZs: 1083, Bias: 0.000000, T: 29328, Avg. loss: 0.179080\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 58.40, NNZs: 1078, Bias: 0.000000, T: 31584, Avg. loss: 0.178812\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 58.54, NNZs: 1070, Bias: 0.000000, T: 33840, Avg. loss: 0.178548\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 58.68, NNZs: 1066, Bias: 0.000000, T: 36096, Avg. loss: 0.178311\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 58.70, NNZs: 1064, Bias: 0.000000, T: 38352, Avg. loss: 0.178090\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 58.73, NNZs: 1063, Bias: 0.000000, T: 40608, Avg. loss: 0.178052\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 58.76, NNZs: 1063, Bias: 0.000000, T: 42864, Avg. loss: 0.177998\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 58.79, NNZs: 1062, Bias: 0.000000, T: 45120, Avg. loss: 0.177951\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 23.69, NNZs: 5090, Bias: 0.000000, T: 2256, Avg. loss: 0.359760\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 32.30, NNZs: 2432, Bias: 0.000000, T: 4512, Avg. loss: 0.243408\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 38.41, NNZs: 1802, Bias: 0.000000, T: 6768, Avg. loss: 0.216953\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 43.40, NNZs: 1426, Bias: 0.000000, T: 9024, Avg. loss: 0.201536\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 47.77, NNZs: 1228, Bias: 0.000000, T: 11280, Avg. loss: 0.191193\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 51.71, NNZs: 1113, Bias: 0.000000, T: 13536, Avg. loss: 0.182475\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 52.40, NNZs: 1060, Bias: 0.000000, T: 15792, Avg. loss: 0.176322\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 53.08, NNZs: 1045, Bias: 0.000000, T: 18048, Avg. loss: 0.175433\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 53.75, NNZs: 1028, Bias: 0.000000, T: 20304, Avg. loss: 0.174277\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 54.42, NNZs: 1013, Bias: 0.000000, T: 22560, Avg. loss: 0.173140\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 55.07, NNZs: 996, Bias: 0.000000, T: 24816, Avg. loss: 0.172007\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 55.20, NNZs: 986, Bias: 0.000000, T: 27072, Avg. loss: 0.170989\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 55.33, NNZs: 978, Bias: 0.000000, T: 29328, Avg. loss: 0.170815\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 55.45, NNZs: 976, Bias: 0.000000, T: 31584, Avg. loss: 0.170612\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 55.58, NNZs: 976, Bias: 0.000000, T: 33840, Avg. loss: 0.170394\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 55.71, NNZs: 970, Bias: 0.000000, T: 36096, Avg. loss: 0.170165\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 55.73, NNZs: 967, Bias: 0.000000, T: 38352, Avg. loss: 0.169992\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 55.76, NNZs: 965, Bias: 0.000000, T: 40608, Avg. loss: 0.169961\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 55.78, NNZs: 964, Bias: 0.000000, T: 42864, Avg. loss: 0.169920\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 55.81, NNZs: 964, Bias: 0.000000, T: 45120, Avg. loss: 0.169876\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 23.91, NNZs: 5589, Bias: 0.000000, T: 2256, Avg. loss: 0.422472\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 34.03, NNZs: 3097, Bias: 0.000000, T: 4512, Avg. loss: 0.286709\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 41.50, NNZs: 2369, Bias: 0.000000, T: 6768, Avg. loss: 0.247066\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 47.58, NNZs: 1987, Bias: 0.000000, T: 9024, Avg. loss: 0.224297\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 52.81, NNZs: 1749, Bias: 0.000000, T: 11280, Avg. loss: 0.208965\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 57.53, NNZs: 1586, Bias: 0.000000, T: 13536, Avg. loss: 0.198209\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 58.36, NNZs: 1515, Bias: 0.000000, T: 15792, Avg. loss: 0.190911\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 59.17, NNZs: 1490, Bias: 0.000000, T: 18048, Avg. loss: 0.189574\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 59.97, NNZs: 1470, Bias: 0.000000, T: 20304, Avg. loss: 0.188098\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 60.76, NNZs: 1451, Bias: 0.000000, T: 22560, Avg. loss: 0.186629\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 61.53, NNZs: 1427, Bias: 0.000000, T: 24816, Avg. loss: 0.185243\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 61.68, NNZs: 1396, Bias: 0.000000, T: 27072, Avg. loss: 0.184039\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 61.83, NNZs: 1393, Bias: 0.000000, T: 29328, Avg. loss: 0.183837\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 61.99, NNZs: 1386, Bias: 0.000000, T: 31584, Avg. loss: 0.183569\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 62.14, NNZs: 1382, Bias: 0.000000, T: 33840, Avg. loss: 0.183318\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 62.29, NNZs: 1379, Bias: 0.000000, T: 36096, Avg. loss: 0.183068\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 62.32, NNZs: 1377, Bias: 0.000000, T: 38352, Avg. loss: 0.182835\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 62.35, NNZs: 1377, Bias: 0.000000, T: 40608, Avg. loss: 0.182793\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 62.38, NNZs: 1376, Bias: 0.000000, T: 42864, Avg. loss: 0.182741\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 62.40, NNZs: 1375, Bias: 0.000000, T: 45120, Avg. loss: 0.182694\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 24.44, NNZs: 5795, Bias: 0.000000, T: 2256, Avg. loss: 0.392621\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 34.17, NNZs: 3017, Bias: 0.000000, T: 4512, Avg. loss: 0.259752\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 40.95, NNZs: 2237, Bias: 0.000000, T: 6768, Avg. loss: 0.225078\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 46.59, NNZs: 1818, Bias: 0.000000, T: 9024, Avg. loss: 0.206248\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 51.43, NNZs: 1559, Bias: 0.000000, T: 11280, Avg. loss: 0.193445\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 55.82, NNZs: 1406, Bias: 0.000000, T: 13536, Avg. loss: 0.183661\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 56.59, NNZs: 1329, Bias: 0.000000, T: 15792, Avg. loss: 0.177474\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 57.34, NNZs: 1298, Bias: 0.000000, T: 18048, Avg. loss: 0.176345\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 58.09, NNZs: 1277, Bias: 0.000000, T: 20304, Avg. loss: 0.174835\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 58.82, NNZs: 1254, Bias: 0.000000, T: 22560, Avg. loss: 0.173605\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 59.55, NNZs: 1239, Bias: 0.000000, T: 24816, Avg. loss: 0.172508\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 59.70, NNZs: 1233, Bias: 0.000000, T: 27072, Avg. loss: 0.171435\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 59.84, NNZs: 1225, Bias: 0.000000, T: 29328, Avg. loss: 0.171237\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 59.98, NNZs: 1222, Bias: 0.000000, T: 31584, Avg. loss: 0.171010\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 60.12, NNZs: 1218, Bias: 0.000000, T: 33840, Avg. loss: 0.170780\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 60.26, NNZs: 1213, Bias: 0.000000, T: 36096, Avg. loss: 0.170543\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 60.29, NNZs: 1211, Bias: 0.000000, T: 38352, Avg. loss: 0.170339\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 60.32, NNZs: 1209, Bias: 0.000000, T: 40608, Avg. loss: 0.170302\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 60.35, NNZs: 1207, Bias: 0.000000, T: 42864, Avg. loss: 0.170258\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 60.38, NNZs: 1208, Bias: 0.000000, T: 45120, Avg. loss: 0.170209\n",
      "Total training time: 0.09 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.3s finished\n",
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.06171699256249541, clf__eta0=0.6666115972798587, clf__fit_intercept=False, clf__l1_ratio=0.9792901432894962, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.15075392531110676, clf__shuffle=True, clf__tol=0.365636830734297, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.626 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 23.38, NNZs: 5035, Bias: 0.000000, T: 2256, Avg. loss: 0.389871\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 32.56, NNZs: 2518, Bias: 0.000000, T: 4512, Avg. loss: 0.269872\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 39.38, NNZs: 1913, Bias: 0.000000, T: 6768, Avg. loss: 0.235908\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 44.96, NNZs: 1572, Bias: 0.000000, T: 9024, Avg. loss: 0.216051\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 49.77, NNZs: 1395, Bias: 0.000000, T: 11280, Avg. loss: 0.202296\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 54.08, NNZs: 1258, Bias: 0.000000, T: 13536, Avg. loss: 0.192163\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 54.82, NNZs: 1183, Bias: 0.000000, T: 15792, Avg. loss: 0.185447\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 55.56, NNZs: 1158, Bias: 0.000000, T: 18048, Avg. loss: 0.184427\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 56.28, NNZs: 1148, Bias: 0.000000, T: 20304, Avg. loss: 0.183029\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 56.99, NNZs: 1126, Bias: 0.000000, T: 22560, Avg. loss: 0.181747\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 57.69, NNZs: 1107, Bias: 0.000000, T: 24816, Avg. loss: 0.180525\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 57.83, NNZs: 1099, Bias: 0.000000, T: 27072, Avg. loss: 0.179417\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 57.97, NNZs: 1098, Bias: 0.000000, T: 29328, Avg. loss: 0.179231\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 58.10, NNZs: 1098, Bias: 0.000000, T: 31584, Avg. loss: 0.179002\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 58.24, NNZs: 1094, Bias: 0.000000, T: 33840, Avg. loss: 0.178765\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 58.37, NNZs: 1091, Bias: 0.000000, T: 36096, Avg. loss: 0.178540\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 58.40, NNZs: 1090, Bias: 0.000000, T: 38352, Avg. loss: 0.178332\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 58.43, NNZs: 1090, Bias: 0.000000, T: 40608, Avg. loss: 0.178291\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 58.45, NNZs: 1089, Bias: 0.000000, T: 42864, Avg. loss: 0.178251\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 58.48, NNZs: 1089, Bias: 0.000000, T: 45120, Avg. loss: 0.178204\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 23.73, NNZs: 4984, Bias: 0.000000, T: 2256, Avg. loss: 0.354796\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 32.11, NNZs: 2387, Bias: 0.000000, T: 4512, Avg. loss: 0.239780\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 38.13, NNZs: 1769, Bias: 0.000000, T: 6768, Avg. loss: 0.214597\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 43.12, NNZs: 1443, Bias: 0.000000, T: 9024, Avg. loss: 0.199962\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 47.31, NNZs: 1234, Bias: 0.000000, T: 11280, Avg. loss: 0.189689\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 51.19, NNZs: 1126, Bias: 0.000000, T: 13536, Avg. loss: 0.182431\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 51.86, NNZs: 1069, Bias: 0.000000, T: 15792, Avg. loss: 0.176436\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 52.53, NNZs: 1054, Bias: 0.000000, T: 18048, Avg. loss: 0.175523\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 53.18, NNZs: 1032, Bias: 0.000000, T: 20304, Avg. loss: 0.174327\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 53.83, NNZs: 1011, Bias: 0.000000, T: 22560, Avg. loss: 0.173307\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 54.47, NNZs: 996, Bias: 0.000000, T: 24816, Avg. loss: 0.172151\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 54.59, NNZs: 990, Bias: 0.000000, T: 27072, Avg. loss: 0.171169\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 54.72, NNZs: 989, Bias: 0.000000, T: 29328, Avg. loss: 0.171031\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 54.84, NNZs: 984, Bias: 0.000000, T: 31584, Avg. loss: 0.170838\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 54.97, NNZs: 979, Bias: 0.000000, T: 33840, Avg. loss: 0.170597\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 55.09, NNZs: 977, Bias: 0.000000, T: 36096, Avg. loss: 0.170396\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 55.12, NNZs: 976, Bias: 0.000000, T: 38352, Avg. loss: 0.170216\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 55.14, NNZs: 976, Bias: 0.000000, T: 40608, Avg. loss: 0.170187\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 55.16, NNZs: 975, Bias: 0.000000, T: 42864, Avg. loss: 0.170148\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 55.19, NNZs: 975, Bias: 0.000000, T: 45120, Avg. loss: 0.170103\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 23.89, NNZs: 5550, Bias: 0.000000, T: 2256, Avg. loss: 0.421315\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 33.99, NNZs: 3135, Bias: 0.000000, T: 4512, Avg. loss: 0.286591\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 41.32, NNZs: 2433, Bias: 0.000000, T: 6768, Avg. loss: 0.248789\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 47.28, NNZs: 2001, Bias: 0.000000, T: 9024, Avg. loss: 0.227126\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 52.46, NNZs: 1772, Bias: 0.000000, T: 11280, Avg. loss: 0.212745\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 57.06, NNZs: 1633, Bias: 0.000000, T: 13536, Avg. loss: 0.202425\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 57.87, NNZs: 1558, Bias: 0.000000, T: 15792, Avg. loss: 0.194210\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 58.66, NNZs: 1534, Bias: 0.000000, T: 18048, Avg. loss: 0.193180\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 59.44, NNZs: 1503, Bias: 0.000000, T: 20304, Avg. loss: 0.191754\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 60.22, NNZs: 1486, Bias: 0.000000, T: 22560, Avg. loss: 0.190325\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 60.98, NNZs: 1458, Bias: 0.000000, T: 24816, Avg. loss: 0.189022\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 61.13, NNZs: 1450, Bias: 0.000000, T: 27072, Avg. loss: 0.187830\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 61.27, NNZs: 1444, Bias: 0.000000, T: 29328, Avg. loss: 0.187637\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 61.42, NNZs: 1441, Bias: 0.000000, T: 31584, Avg. loss: 0.187386\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 61.57, NNZs: 1439, Bias: 0.000000, T: 33840, Avg. loss: 0.187139\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 61.72, NNZs: 1436, Bias: 0.000000, T: 36096, Avg. loss: 0.186896\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 61.75, NNZs: 1433, Bias: 0.000000, T: 38352, Avg. loss: 0.186670\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 61.77, NNZs: 1433, Bias: 0.000000, T: 40608, Avg. loss: 0.186631\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 61.80, NNZs: 1433, Bias: 0.000000, T: 42864, Avg. loss: 0.186582\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 61.83, NNZs: 1432, Bias: 0.000000, T: 45120, Avg. loss: 0.186533\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 24.22, NNZs: 5719, Bias: 0.000000, T: 2256, Avg. loss: 0.392507\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 33.80, NNZs: 3021, Bias: 0.000000, T: 4512, Avg. loss: 0.260718\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 40.63, NNZs: 2254, Bias: 0.000000, T: 6768, Avg. loss: 0.228184\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 46.17, NNZs: 1822, Bias: 0.000000, T: 9024, Avg. loss: 0.210375\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 51.01, NNZs: 1582, Bias: 0.000000, T: 11280, Avg. loss: 0.198544\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 55.23, NNZs: 1408, Bias: 0.000000, T: 13536, Avg. loss: 0.189292\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 55.99, NNZs: 1350, Bias: 0.000000, T: 15792, Avg. loss: 0.182976\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 56.73, NNZs: 1326, Bias: 0.000000, T: 18048, Avg. loss: 0.181875\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 57.46, NNZs: 1305, Bias: 0.000000, T: 20304, Avg. loss: 0.180645\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 58.18, NNZs: 1287, Bias: 0.000000, T: 22560, Avg. loss: 0.179506\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 58.89, NNZs: 1270, Bias: 0.000000, T: 24816, Avg. loss: 0.178315\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 59.03, NNZs: 1260, Bias: 0.000000, T: 27072, Avg. loss: 0.177292\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 59.17, NNZs: 1254, Bias: 0.000000, T: 29328, Avg. loss: 0.177121\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 59.31, NNZs: 1249, Bias: 0.000000, T: 31584, Avg. loss: 0.176930\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 59.44, NNZs: 1245, Bias: 0.000000, T: 33840, Avg. loss: 0.176701\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 59.58, NNZs: 1240, Bias: 0.000000, T: 36096, Avg. loss: 0.176498\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 59.61, NNZs: 1237, Bias: 0.000000, T: 38352, Avg. loss: 0.176296\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 59.63, NNZs: 1235, Bias: 0.000000, T: 40608, Avg. loss: 0.176263\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 59.66, NNZs: 1235, Bias: 0.000000, T: 42864, Avg. loss: 0.176224\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 59.69, NNZs: 1236, Bias: 0.000000, T: 45120, Avg. loss: 0.176181\n",
      "Total training time: 0.09 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.4s finished\n",
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.06171699256249541, clf__eta0=0.6666115972798587, clf__fit_intercept=False, clf__l1_ratio=0.9792901432894962, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.15075392531110676, clf__shuffle=True, clf__tol=0.365636830734297, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.649 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 23.65, NNZs: 5224, Bias: 0.000000, T: 2256, Avg. loss: 0.380205\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 32.70, NNZs: 2586, Bias: 0.000000, T: 4512, Avg. loss: 0.260202\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 39.55, NNZs: 1914, Bias: 0.000000, T: 6768, Avg. loss: 0.225809\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 45.20, NNZs: 1573, Bias: 0.000000, T: 9024, Avg. loss: 0.206057\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 49.99, NNZs: 1364, Bias: 0.000000, T: 11280, Avg. loss: 0.192469\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 54.31, NNZs: 1210, Bias: 0.000000, T: 13536, Avg. loss: 0.182812\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 55.05, NNZs: 1154, Bias: 0.000000, T: 15792, Avg. loss: 0.175754\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 55.79, NNZs: 1136, Bias: 0.000000, T: 18048, Avg. loss: 0.174749\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 56.51, NNZs: 1100, Bias: 0.000000, T: 20304, Avg. loss: 0.173367\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 57.22, NNZs: 1090, Bias: 0.000000, T: 22560, Avg. loss: 0.172149\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 57.92, NNZs: 1065, Bias: 0.000000, T: 24816, Avg. loss: 0.170891\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 58.05, NNZs: 1060, Bias: 0.000000, T: 27072, Avg. loss: 0.169765\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 58.19, NNZs: 1057, Bias: 0.000000, T: 29328, Avg. loss: 0.169586\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 58.33, NNZs: 1053, Bias: 0.000000, T: 31584, Avg. loss: 0.169351\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 58.46, NNZs: 1049, Bias: 0.000000, T: 33840, Avg. loss: 0.169109\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 58.60, NNZs: 1044, Bias: 0.000000, T: 36096, Avg. loss: 0.168882\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 58.62, NNZs: 1043, Bias: 0.000000, T: 38352, Avg. loss: 0.168680\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 58.65, NNZs: 1041, Bias: 0.000000, T: 40608, Avg. loss: 0.168649\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 58.68, NNZs: 1041, Bias: 0.000000, T: 42864, Avg. loss: 0.168599\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 58.70, NNZs: 1041, Bias: 0.000000, T: 45120, Avg. loss: 0.168552\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 23.75, NNZs: 5201, Bias: 0.000000, T: 2256, Avg. loss: 0.351441\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 32.50, NNZs: 2362, Bias: 0.000000, T: 4512, Avg. loss: 0.234679\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 38.39, NNZs: 1681, Bias: 0.000000, T: 6768, Avg. loss: 0.208588\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 43.22, NNZs: 1324, Bias: 0.000000, T: 9024, Avg. loss: 0.194173\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 47.40, NNZs: 1140, Bias: 0.000000, T: 11280, Avg. loss: 0.184711\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 51.28, NNZs: 1021, Bias: 0.000000, T: 13536, Avg. loss: 0.177258\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 51.95, NNZs: 957, Bias: 0.000000, T: 15792, Avg. loss: 0.171520\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 52.61, NNZs: 942, Bias: 0.000000, T: 18048, Avg. loss: 0.170630\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 53.26, NNZs: 925, Bias: 0.000000, T: 20304, Avg. loss: 0.169395\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 53.90, NNZs: 915, Bias: 0.000000, T: 22560, Avg. loss: 0.168416\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 54.53, NNZs: 902, Bias: 0.000000, T: 24816, Avg. loss: 0.167326\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 54.65, NNZs: 893, Bias: 0.000000, T: 27072, Avg. loss: 0.166393\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 54.78, NNZs: 890, Bias: 0.000000, T: 29328, Avg. loss: 0.166219\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 54.90, NNZs: 884, Bias: 0.000000, T: 31584, Avg. loss: 0.166026\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 55.02, NNZs: 879, Bias: 0.000000, T: 33840, Avg. loss: 0.165816\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 55.14, NNZs: 876, Bias: 0.000000, T: 36096, Avg. loss: 0.165624\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 55.17, NNZs: 873, Bias: 0.000000, T: 38352, Avg. loss: 0.165436\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 55.19, NNZs: 873, Bias: 0.000000, T: 40608, Avg. loss: 0.165406\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 55.21, NNZs: 872, Bias: 0.000000, T: 42864, Avg. loss: 0.165370\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 55.24, NNZs: 871, Bias: 0.000000, T: 45120, Avg. loss: 0.165327\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 23.97, NNZs: 5701, Bias: 0.000000, T: 2256, Avg. loss: 0.418653\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 34.03, NNZs: 2983, Bias: 0.000000, T: 4512, Avg. loss: 0.284378\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 41.35, NNZs: 2302, Bias: 0.000000, T: 6768, Avg. loss: 0.245718\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 47.28, NNZs: 1924, Bias: 0.000000, T: 9024, Avg. loss: 0.224433\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 52.44, NNZs: 1691, Bias: 0.000000, T: 11280, Avg. loss: 0.210239\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 57.01, NNZs: 1502, Bias: 0.000000, T: 13536, Avg. loss: 0.199370\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 57.81, NNZs: 1451, Bias: 0.000000, T: 15792, Avg. loss: 0.192440\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 58.60, NNZs: 1431, Bias: 0.000000, T: 18048, Avg. loss: 0.191265\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 59.37, NNZs: 1415, Bias: 0.000000, T: 20304, Avg. loss: 0.189711\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 60.14, NNZs: 1391, Bias: 0.000000, T: 22560, Avg. loss: 0.188296\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 60.89, NNZs: 1370, Bias: 0.000000, T: 24816, Avg. loss: 0.187036\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 61.04, NNZs: 1364, Bias: 0.000000, T: 27072, Avg. loss: 0.185820\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 61.18, NNZs: 1358, Bias: 0.000000, T: 29328, Avg. loss: 0.185638\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 61.33, NNZs: 1353, Bias: 0.000000, T: 31584, Avg. loss: 0.185384\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 61.47, NNZs: 1348, Bias: 0.000000, T: 33840, Avg. loss: 0.185142\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 61.62, NNZs: 1347, Bias: 0.000000, T: 36096, Avg. loss: 0.184889\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 61.65, NNZs: 1344, Bias: 0.000000, T: 38352, Avg. loss: 0.184667\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 61.68, NNZs: 1344, Bias: 0.000000, T: 40608, Avg. loss: 0.184631\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 61.71, NNZs: 1342, Bias: 0.000000, T: 42864, Avg. loss: 0.184583\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 61.74, NNZs: 1341, Bias: 0.000000, T: 45120, Avg. loss: 0.184534\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 24.82, NNZs: 5870, Bias: 0.000000, T: 2256, Avg. loss: 0.379772\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 34.35, NNZs: 2877, Bias: 0.000000, T: 4512, Avg. loss: 0.245147\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 41.19, NNZs: 2175, Bias: 0.000000, T: 6768, Avg. loss: 0.211418\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 46.66, NNZs: 1698, Bias: 0.000000, T: 9024, Avg. loss: 0.194192\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 51.49, NNZs: 1454, Bias: 0.000000, T: 11280, Avg. loss: 0.181730\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 55.69, NNZs: 1277, Bias: 0.000000, T: 13536, Avg. loss: 0.172459\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 56.45, NNZs: 1214, Bias: 0.000000, T: 15792, Avg. loss: 0.166500\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 57.20, NNZs: 1196, Bias: 0.000000, T: 18048, Avg. loss: 0.165413\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 57.93, NNZs: 1169, Bias: 0.000000, T: 20304, Avg. loss: 0.164200\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 58.64, NNZs: 1150, Bias: 0.000000, T: 22560, Avg. loss: 0.162841\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 59.35, NNZs: 1129, Bias: 0.000000, T: 24816, Avg. loss: 0.161791\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 59.49, NNZs: 1121, Bias: 0.000000, T: 27072, Avg. loss: 0.160807\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 59.62, NNZs: 1117, Bias: 0.000000, T: 29328, Avg. loss: 0.160650\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 59.76, NNZs: 1115, Bias: 0.000000, T: 31584, Avg. loss: 0.160424\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 59.90, NNZs: 1111, Bias: 0.000000, T: 33840, Avg. loss: 0.160211\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 60.03, NNZs: 1107, Bias: 0.000000, T: 36096, Avg. loss: 0.160009\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 60.06, NNZs: 1106, Bias: 0.000000, T: 38352, Avg. loss: 0.159804\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 60.09, NNZs: 1106, Bias: 0.000000, T: 40608, Avg. loss: 0.159771\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 60.11, NNZs: 1104, Bias: 0.000000, T: 42864, Avg. loss: 0.159727\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 60.14, NNZs: 1104, Bias: 0.000000, T: 45120, Avg. loss: 0.159688\n",
      "Total training time: 0.09 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.4s finished\n",
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.06171699256249541, clf__eta0=0.6666115972798587, clf__fit_intercept=False, clf__l1_ratio=0.9792901432894962, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.15075392531110676, clf__shuffle=True, clf__tol=0.365636830734297, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.593 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 23.16, NNZs: 5013, Bias: 0.000000, T: 2256, Avg. loss: 0.390913\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 32.43, NNZs: 2571, Bias: 0.000000, T: 4512, Avg. loss: 0.271505\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 39.21, NNZs: 1931, Bias: 0.000000, T: 6768, Avg. loss: 0.236849\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 44.85, NNZs: 1533, Bias: 0.000000, T: 9024, Avg. loss: 0.216533\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 49.67, NNZs: 1322, Bias: 0.000000, T: 11280, Avg. loss: 0.202564\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 54.00, NNZs: 1183, Bias: 0.000000, T: 13536, Avg. loss: 0.192371\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 54.78, NNZs: 1126, Bias: 0.000000, T: 15792, Avg. loss: 0.185541\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 55.54, NNZs: 1110, Bias: 0.000000, T: 18048, Avg. loss: 0.184218\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 56.28, NNZs: 1092, Bias: 0.000000, T: 20304, Avg. loss: 0.182650\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 57.02, NNZs: 1079, Bias: 0.000000, T: 22560, Avg. loss: 0.181166\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 57.74, NNZs: 1063, Bias: 0.000000, T: 24816, Avg. loss: 0.179822\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 57.88, NNZs: 1053, Bias: 0.000000, T: 27072, Avg. loss: 0.178641\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 58.02, NNZs: 1047, Bias: 0.000000, T: 29328, Avg. loss: 0.178411\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 58.16, NNZs: 1045, Bias: 0.000000, T: 31584, Avg. loss: 0.178160\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 58.30, NNZs: 1044, Bias: 0.000000, T: 33840, Avg. loss: 0.177902\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 58.44, NNZs: 1044, Bias: 0.000000, T: 36096, Avg. loss: 0.177645\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 58.47, NNZs: 1042, Bias: 0.000000, T: 38352, Avg. loss: 0.177415\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 58.50, NNZs: 1042, Bias: 0.000000, T: 40608, Avg. loss: 0.177371\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 58.52, NNZs: 1042, Bias: 0.000000, T: 42864, Avg. loss: 0.177321\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 58.55, NNZs: 1042, Bias: 0.000000, T: 45120, Avg. loss: 0.177270\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 23.77, NNZs: 5084, Bias: 0.000000, T: 2256, Avg. loss: 0.354555\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 32.16, NNZs: 2271, Bias: 0.000000, T: 4512, Avg. loss: 0.238819\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 38.20, NNZs: 1658, Bias: 0.000000, T: 6768, Avg. loss: 0.213837\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 43.10, NNZs: 1320, Bias: 0.000000, T: 9024, Avg. loss: 0.198827\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 47.41, NNZs: 1151, Bias: 0.000000, T: 11280, Avg. loss: 0.188892\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 51.18, NNZs: 1028, Bias: 0.000000, T: 13536, Avg. loss: 0.180854\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 51.85, NNZs: 982, Bias: 0.000000, T: 15792, Avg. loss: 0.175542\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 52.51, NNZs: 971, Bias: 0.000000, T: 18048, Avg. loss: 0.174471\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 53.16, NNZs: 951, Bias: 0.000000, T: 20304, Avg. loss: 0.173371\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 53.81, NNZs: 934, Bias: 0.000000, T: 22560, Avg. loss: 0.172265\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 54.44, NNZs: 916, Bias: 0.000000, T: 24816, Avg. loss: 0.171194\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 54.56, NNZs: 909, Bias: 0.000000, T: 27072, Avg. loss: 0.170331\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 54.68, NNZs: 906, Bias: 0.000000, T: 29328, Avg. loss: 0.170150\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 54.81, NNZs: 906, Bias: 0.000000, T: 31584, Avg. loss: 0.169939\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 54.93, NNZs: 905, Bias: 0.000000, T: 33840, Avg. loss: 0.169740\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 55.05, NNZs: 904, Bias: 0.000000, T: 36096, Avg. loss: 0.169536\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 55.08, NNZs: 903, Bias: 0.000000, T: 38352, Avg. loss: 0.169363\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 55.10, NNZs: 902, Bias: 0.000000, T: 40608, Avg. loss: 0.169330\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 55.12, NNZs: 901, Bias: 0.000000, T: 42864, Avg. loss: 0.169291\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 55.15, NNZs: 901, Bias: 0.000000, T: 45120, Avg. loss: 0.169251\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 23.92, NNZs: 5553, Bias: 0.000000, T: 2256, Avg. loss: 0.417168\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 34.05, NNZs: 2989, Bias: 0.000000, T: 4512, Avg. loss: 0.281324\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 41.41, NNZs: 2296, Bias: 0.000000, T: 6768, Avg. loss: 0.242680\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 47.43, NNZs: 1934, Bias: 0.000000, T: 9024, Avg. loss: 0.220280\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 52.64, NNZs: 1684, Bias: 0.000000, T: 11280, Avg. loss: 0.205871\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 57.28, NNZs: 1492, Bias: 0.000000, T: 13536, Avg. loss: 0.194443\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 58.10, NNZs: 1428, Bias: 0.000000, T: 15792, Avg. loss: 0.187322\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 58.91, NNZs: 1410, Bias: 0.000000, T: 18048, Avg. loss: 0.186016\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 59.70, NNZs: 1391, Bias: 0.000000, T: 20304, Avg. loss: 0.184443\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 60.48, NNZs: 1374, Bias: 0.000000, T: 22560, Avg. loss: 0.183038\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 61.24, NNZs: 1341, Bias: 0.000000, T: 24816, Avg. loss: 0.181614\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 61.39, NNZs: 1334, Bias: 0.000000, T: 27072, Avg. loss: 0.180439\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 61.54, NNZs: 1331, Bias: 0.000000, T: 29328, Avg. loss: 0.180242\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 61.69, NNZs: 1329, Bias: 0.000000, T: 31584, Avg. loss: 0.179971\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 61.84, NNZs: 1326, Bias: 0.000000, T: 33840, Avg. loss: 0.179731\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 61.99, NNZs: 1322, Bias: 0.000000, T: 36096, Avg. loss: 0.179459\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 62.02, NNZs: 1320, Bias: 0.000000, T: 38352, Avg. loss: 0.179236\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 62.05, NNZs: 1319, Bias: 0.000000, T: 40608, Avg. loss: 0.179197\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 62.08, NNZs: 1319, Bias: 0.000000, T: 42864, Avg. loss: 0.179146\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 62.11, NNZs: 1319, Bias: 0.000000, T: 45120, Avg. loss: 0.179093\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 24.53, NNZs: 5588, Bias: 0.000000, T: 2256, Avg. loss: 0.386957\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 33.95, NNZs: 2838, Bias: 0.000000, T: 4512, Avg. loss: 0.254560\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 40.82, NNZs: 2198, Bias: 0.000000, T: 6768, Avg. loss: 0.222685\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 46.35, NNZs: 1734, Bias: 0.000000, T: 9024, Avg. loss: 0.203238\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 51.13, NNZs: 1475, Bias: 0.000000, T: 11280, Avg. loss: 0.190943\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 55.41, NNZs: 1266, Bias: 0.000000, T: 13536, Avg. loss: 0.181682\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 56.19, NNZs: 1213, Bias: 0.000000, T: 15792, Avg. loss: 0.175671\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 56.94, NNZs: 1195, Bias: 0.000000, T: 18048, Avg. loss: 0.174192\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 57.69, NNZs: 1174, Bias: 0.000000, T: 20304, Avg. loss: 0.172874\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 58.41, NNZs: 1148, Bias: 0.000000, T: 22560, Avg. loss: 0.171568\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 59.12, NNZs: 1133, Bias: 0.000000, T: 24816, Avg. loss: 0.170328\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 59.26, NNZs: 1121, Bias: 0.000000, T: 27072, Avg. loss: 0.169315\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 59.40, NNZs: 1112, Bias: 0.000000, T: 29328, Avg. loss: 0.169132\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 59.54, NNZs: 1110, Bias: 0.000000, T: 31584, Avg. loss: 0.168905\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 59.67, NNZs: 1106, Bias: 0.000000, T: 33840, Avg. loss: 0.168689\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 59.81, NNZs: 1100, Bias: 0.000000, T: 36096, Avg. loss: 0.168450\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 59.84, NNZs: 1098, Bias: 0.000000, T: 38352, Avg. loss: 0.168249\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 59.87, NNZs: 1098, Bias: 0.000000, T: 40608, Avg. loss: 0.168213\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 59.89, NNZs: 1096, Bias: 0.000000, T: 42864, Avg. loss: 0.168171\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.4s finished\n",
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 59.92, NNZs: 1096, Bias: 0.000000, T: 45120, Avg. loss: 0.168126\n",
      "Total training time: 0.08 seconds.\n",
      "[CV 5/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.06171699256249541, clf__eta0=0.6666115972798587, clf__fit_intercept=False, clf__l1_ratio=0.9792901432894962, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.15075392531110676, clf__shuffle=True, clf__tol=0.365636830734297, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.650 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 129601285387603.66, NNZs: 12896, Bias: 0.000000, T: 2256, Avg. loss: 2679321727511991500668928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 83553662237219.39, NNZs: 12898, Bias: 0.000000, T: 4512, Avg. loss: 5963598203761059516383232.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 58215279776672.65, NNZs: 12898, Bias: 0.000000, T: 6768, Avg. loss: 2149670939892447749079040.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 42636578916650.61, NNZs: 12898, Bias: 0.000000, T: 9024, Avg. loss: 925956764668081324687360.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 31603125622082.79, NNZs: 12898, Bias: 0.000000, T: 11280, Avg. loss: 454855404101630267752448.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 24007593559791.59, NNZs: 12898, Bias: 0.000000, T: 13536, Avg. loss: 220806907674073816367104.000000\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 127778156103177.31, NNZs: 12898, Bias: 0.000000, T: 2256, Avg. loss: 2684969404484804226842624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 83743843349300.59, NNZs: 12898, Bias: 0.000000, T: 4512, Avg. loss: 5776207181594757068488704.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 59707168937625.76, NNZs: 12898, Bias: 0.000000, T: 6768, Avg. loss: 2128695490046568880406528.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 43594123148377.41, NNZs: 12898, Bias: 0.000000, T: 9024, Avg. loss: 971376049460895394299904.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 32811745281423.92, NNZs: 12898, Bias: 0.000000, T: 11280, Avg. loss: 462366030188688432955392.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 24979653048258.88, NNZs: 12898, Bias: 0.000000, T: 13536, Avg. loss: 241159829339987689603072.000000\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 137362981096094.77, NNZs: 12898, Bias: 0.000000, T: 2256, Avg. loss: 3081366014421047330209792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 92312710792093.42, NNZs: 12898, Bias: 0.000000, T: 4512, Avg. loss: 6512145223609249188282368.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 65890848696671.23, NNZs: 12898, Bias: 0.000000, T: 6768, Avg. loss: 2555409509802545436950528.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 47787284432383.81, NNZs: 12898, Bias: 0.000000, T: 9024, Avg. loss: 1187384055678865944608768.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 35372807721878.91, NNZs: 12898, Bias: 0.000000, T: 11280, Avg. loss: 573515281357703663845376.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 26851457492925.57, NNZs: 12898, Bias: 0.000000, T: 13536, Avg. loss: 282011524468524965691392.000000\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 131586240731406.86, NNZs: 12897, Bias: 0.000000, T: 2256, Avg. loss: 2865028577229413816467456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 86614680729999.38, NNZs: 12898, Bias: 0.000000, T: 4512, Avg. loss: 6115173752206609711366144.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 61841321379663.37, NNZs: 12898, Bias: 0.000000, T: 6768, Avg. loss: 2293986934459134377984000.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 45064336322995.21, NNZs: 12898, Bias: 0.000000, T: 9024, Avg. loss: 1067770445764978425200640.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 33950886250695.35, NNZs: 12898, Bias: 0.000000, T: 11280, Avg. loss: 500582563707551865634816.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 25872418066065.69, NNZs: 12898, Bias: 0.000000, T: 13536, Avg. loss: 256645393134076603400192.000000\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 1/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.7915127974877743, clf__eta0=0.05539740212799926, clf__fit_intercept=False, clf__l1_ratio=0.9152680641407671, clf__learning_rate=optimal, clf__loss=squared_epsilon_insensitive, clf__max_iter=80, clf__penalty=l1, clf__power_t=0.6359093112142983, clf__shuffle=True, clf__tol=0.9361199211609239, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.166 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 129131613919610.88, NNZs: 12717, Bias: 0.000000, T: 2256, Avg. loss: 2799117296214975501565952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 85817281100182.38, NNZs: 12717, Bias: 0.000000, T: 4512, Avg. loss: 5820118283143014676168704.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 59790275312887.24, NNZs: 12717, Bias: 0.000000, T: 6768, Avg. loss: 2317610525913137067065344.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 43682586035637.78, NNZs: 12717, Bias: 0.000000, T: 9024, Avg. loss: 989380565819587894968320.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 32593155085827.16, NNZs: 12717, Bias: 0.000000, T: 11280, Avg. loss: 476690485507326753112064.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 24676461646134.09, NNZs: 12717, Bias: 0.000000, T: 13536, Avg. loss: 238843345069914474938368.000000\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 132265979431939.00, NNZs: 12717, Bias: 0.000000, T: 2256, Avg. loss: 2810513673340021731491840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 87834959586837.95, NNZs: 12717, Bias: 0.000000, T: 4512, Avg. loss: 6118096646333638593478656.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 62632962597646.99, NNZs: 12717, Bias: 0.000000, T: 6768, Avg. loss: 2331997479998027947048960.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 45320472809971.18, NNZs: 12717, Bias: 0.000000, T: 9024, Avg. loss: 1104006846917660458876928.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 33430327159905.36, NNZs: 12717, Bias: 0.000000, T: 11280, Avg. loss: 524880316521098713759744.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 25434498761163.50, NNZs: 12717, Bias: 0.000000, T: 13536, Avg. loss: 250074959057086712905728.000000\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 117722650667104.61, NNZs: 12717, Bias: 0.000000, T: 2256, Avg. loss: 2277902564210671823618048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 76750620572524.08, NNZs: 12717, Bias: 0.000000, T: 4512, Avg. loss: 5018900718689616381607936.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 52776360392456.37, NNZs: 12717, Bias: 0.000000, T: 6768, Avg. loss: 1884278816828305098932224.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 37603436276194.59, NNZs: 12717, Bias: 0.000000, T: 9024, Avg. loss: 790522261194543462350848.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 27294322371514.93, NNZs: 12717, Bias: 0.000000, T: 11280, Avg. loss: 369558355677084215410688.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 20563266953356.64, NNZs: 12717, Bias: 0.000000, T: 13536, Avg. loss: 168167832999607863869440.000000\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 133234527465580.97, NNZs: 12717, Bias: 0.000000, T: 2256, Avg. loss: 2874921322092975695593472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 87687978143072.16, NNZs: 12717, Bias: 0.000000, T: 4512, Avg. loss: 6255632391578874862895104.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 62191712743055.44, NNZs: 12717, Bias: 0.000000, T: 6768, Avg. loss: 2327614338896643808559104.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 45930090556507.55, NNZs: 12717, Bias: 0.000000, T: 9024, Avg. loss: 1053209965898652364832768.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 34122809371901.20, NNZs: 12717, Bias: 0.000000, T: 11280, Avg. loss: 528831390585273549062144.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 26000945979645.38, NNZs: 12717, Bias: 0.000000, T: 13536, Avg. loss: 256643971648909511491584.000000\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 2/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.7915127974877743, clf__eta0=0.05539740212799926, clf__fit_intercept=False, clf__l1_ratio=0.9152680641407671, clf__learning_rate=optimal, clf__loss=squared_epsilon_insensitive, clf__max_iter=80, clf__penalty=l1, clf__power_t=0.6359093112142983, clf__shuffle=True, clf__tol=0.9361199211609239, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.151 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 120531382668769.45, NNZs: 13143, Bias: 0.000000, T: 2256, Avg. loss: 2182651184528505629048832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 78670365096867.72, NNZs: 13143, Bias: 0.000000, T: 4512, Avg. loss: 5216237036067638764109824.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 54190250009985.29, NNZs: 13143, Bias: 0.000000, T: 6768, Avg. loss: 1982282133708120216567808.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 39422357024919.84, NNZs: 13143, Bias: 0.000000, T: 9024, Avg. loss: 813432465519038485757952.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 29112791848889.59, NNZs: 13143, Bias: 0.000000, T: 11280, Avg. loss: 396228251926560757514240.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 21722025270335.03, NNZs: 13143, Bias: 0.000000, T: 13536, Avg. loss: 200344152550098920800256.000000\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 128860219063171.22, NNZs: 13143, Bias: 0.000000, T: 2256, Avg. loss: 2632771172155746443853824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 84637724564957.17, NNZs: 13143, Bias: 0.000000, T: 4512, Avg. loss: 5807962744911021249396736.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 59562721292925.41, NNZs: 13143, Bias: 0.000000, T: 6768, Avg. loss: 2190908986915698973343744.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 43171643100633.95, NNZs: 13143, Bias: 0.000000, T: 9024, Avg. loss: 986456363098324353417216.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 32268093210260.45, NNZs: 13143, Bias: 0.000000, T: 11280, Avg. loss: 468969418289554110021632.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 24545753409576.44, NNZs: 13143, Bias: 0.000000, T: 13536, Avg. loss: 235848971868218494812160.000000\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 121411225431035.19, NNZs: 13141, Bias: 0.000000, T: 2256, Avg. loss: 2357406348643110995623936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 80807104546810.12, NNZs: 13143, Bias: 0.000000, T: 4512, Avg. loss: 5137504765502491935637504.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 56485053097725.19, NNZs: 13143, Bias: 0.000000, T: 6768, Avg. loss: 2024626189761926760759296.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 41158764539241.96, NNZs: 13143, Bias: 0.000000, T: 9024, Avg. loss: 881720390179124626325504.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 30162830348465.27, NNZs: 13143, Bias: 0.000000, T: 11280, Avg. loss: 439256557249885756194816.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 22945439090875.32, NNZs: 13143, Bias: 0.000000, T: 13536, Avg. loss: 203263093348321802059776.000000\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 129546108930932.56, NNZs: 13143, Bias: 0.000000, T: 2256, Avg. loss: 2868381671600267907301376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 85289133096983.31, NNZs: 13143, Bias: 0.000000, T: 4512, Avg. loss: 5900817622044961329381376.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 59948657434336.52, NNZs: 13143, Bias: 0.000000, T: 6768, Avg. loss: 2246339998864472646090752.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 43296694960093.63, NNZs: 13143, Bias: 0.000000, T: 9024, Avg. loss: 1007810410284418779316224.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 32189844861596.39, NNZs: 13143, Bias: 0.000000, T: 11280, Avg. loss: 465151591609135970385920.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 24177365666544.49, NNZs: 13143, Bias: 0.000000, T: 13536, Avg. loss: 236257523010592523157504.000000\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 3/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.7915127974877743, clf__eta0=0.05539740212799926, clf__fit_intercept=False, clf__l1_ratio=0.9152680641407671, clf__learning_rate=optimal, clf__loss=squared_epsilon_insensitive, clf__max_iter=80, clf__penalty=l1, clf__power_t=0.6359093112142983, clf__shuffle=True, clf__tol=0.9361199211609239, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.184 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 114433093760032.41, NNZs: 13618, Bias: 0.000000, T: 2256, Avg. loss: 1900733399140429488717824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 74629569786210.61, NNZs: 13618, Bias: 0.000000, T: 4512, Avg. loss: 4840614778028044020875264.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 50275192139326.80, NNZs: 13618, Bias: 0.000000, T: 6768, Avg. loss: 1816811322003461836374016.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 35740393740014.23, NNZs: 13618, Bias: 0.000000, T: 9024, Avg. loss: 720182834500364465602560.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 25986758981906.52, NNZs: 13618, Bias: 0.000000, T: 11280, Avg. loss: 333268795794861624131584.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 19599076447364.38, NNZs: 13618, Bias: 0.000000, T: 13536, Avg. loss: 151864266339316104429568.000000\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 127900788686109.03, NNZs: 13614, Bias: 0.000000, T: 2256, Avg. loss: 2598759607012464936353792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 82363288426280.02, NNZs: 13618, Bias: 0.000000, T: 4512, Avg. loss: 5957095787306894514716672.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 56918721107627.31, NNZs: 13618, Bias: 0.000000, T: 6768, Avg. loss: 2144713310330727348305920.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 41748002727795.16, NNZs: 13618, Bias: 0.000000, T: 9024, Avg. loss: 887102902234287888662528.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 30484675442895.96, NNZs: 13618, Bias: 0.000000, T: 11280, Avg. loss: 449176770724887594532864.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 22843678298086.12, NNZs: 13618, Bias: 0.000000, T: 13536, Avg. loss: 211979905877408181387264.000000\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 134488404318699.27, NNZs: 13617, Bias: 0.000000, T: 2256, Avg. loss: 2779686362394005778464768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 86870559266606.88, NNZs: 13618, Bias: 0.000000, T: 4512, Avg. loss: 6387753730819621275041792.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 60947852665348.03, NNZs: 13618, Bias: 0.000000, T: 6768, Avg. loss: 2336035162198971670069248.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 44370779860817.32, NNZs: 13618, Bias: 0.000000, T: 9024, Avg. loss: 1032818313521330089099264.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 32553818283223.22, NNZs: 13618, Bias: 0.000000, T: 11280, Avg. loss: 508396099971457027670016.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 24380048631682.21, NNZs: 13618, Bias: 0.000000, T: 13536, Avg. loss: 243257286249795582689280.000000\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 128564873017980.73, NNZs: 13614, Bias: 0.000000, T: 2256, Avg. loss: 2642242405442671645556736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 86397710072813.11, NNZs: 13618, Bias: 0.000000, T: 4512, Avg. loss: 5638143201263405638877184.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 60426122638809.27, NNZs: 13618, Bias: 0.000000, T: 6768, Avg. loss: 2291809397105718393307136.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 43467784153353.01, NNZs: 13618, Bias: 0.000000, T: 9024, Avg. loss: 1018574743964208907419648.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 32071422129833.14, NNZs: 13618, Bias: 0.000000, T: 11280, Avg. loss: 478752517198626645082112.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 24102967925606.34, NNZs: 13618, Bias: 0.000000, T: 13536, Avg. loss: 237880311474193598251008.000000\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 4/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.7915127974877743, clf__eta0=0.05539740212799926, clf__fit_intercept=False, clf__l1_ratio=0.9152680641407671, clf__learning_rate=optimal, clf__loss=squared_epsilon_insensitive, clf__max_iter=80, clf__penalty=l1, clf__power_t=0.6359093112142983, clf__shuffle=True, clf__tol=0.9361199211609239, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.140 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 124409239880952.70, NNZs: 13465, Bias: 0.000000, T: 2256, Avg. loss: 2356747052498280872148992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 81864182149230.03, NNZs: 13465, Bias: 0.000000, T: 4512, Avg. loss: 5414918379169723715682304.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 56854121071262.46, NNZs: 13465, Bias: 0.000000, T: 6768, Avg. loss: 2095270885898111802146816.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 41008006468574.98, NNZs: 13465, Bias: 0.000000, T: 9024, Avg. loss: 907134404938537990356992.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 30172146973543.06, NNZs: 13465, Bias: 0.000000, T: 11280, Avg. loss: 429541196408694316728320.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 22611843121903.42, NNZs: 13465, Bias: 0.000000, T: 13536, Avg. loss: 207661415080468521418752.000000\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 126343860820005.92, NNZs: 13465, Bias: 0.000000, T: 2256, Avg. loss: 2412661032650506460200960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 81867243304174.75, NNZs: 13465, Bias: 0.000000, T: 4512, Avg. loss: 5767881772619614058971136.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 56893738785844.96, NNZs: 13465, Bias: 0.000000, T: 6768, Avg. loss: 2104313810582761692463104.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 41101748757091.66, NNZs: 13465, Bias: 0.000000, T: 9024, Avg. loss: 907920470145397986164736.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 30367591588284.78, NNZs: 13465, Bias: 0.000000, T: 11280, Avg. loss: 429222597854347416043520.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 22655544636916.50, NNZs: 13465, Bias: 0.000000, T: 13536, Avg. loss: 213154533518277620006912.000000\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 131955055546340.59, NNZs: 13464, Bias: 0.000000, T: 2256, Avg. loss: 2609117529452261205344256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 86889396754535.27, NNZs: 13465, Bias: 0.000000, T: 4512, Avg. loss: 6182083071522729661300736.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 60071393449281.91, NNZs: 13465, Bias: 0.000000, T: 6768, Avg. loss: 2355598460851948871483392.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 43572854845069.18, NNZs: 13465, Bias: 0.000000, T: 9024, Avg. loss: 1008409300669081189351424.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 32266866612646.58, NNZs: 13465, Bias: 0.000000, T: 11280, Avg. loss: 476074739893861523390464.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 24395735502600.48, NNZs: 13465, Bias: 0.000000, T: 13536, Avg. loss: 234948374224593930420224.000000\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 120545620823275.50, NNZs: 13462, Bias: 0.000000, T: 2256, Avg. loss: 2266324858965194577018880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 78655142380405.25, NNZs: 13465, Bias: 0.000000, T: 4512, Avg. loss: 5175391287702204727689216.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 53808806649062.91, NNZs: 13465, Bias: 0.000000, T: 6768, Avg. loss: 1981442110606012703571968.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 38691221226185.21, NNZs: 13465, Bias: 0.000000, T: 9024, Avg. loss: 820472293692419996647424.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 28151266226454.50, NNZs: 13465, Bias: 0.000000, T: 11280, Avg. loss: 388229772098585311051776.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 21299376373377.39, NNZs: 13465, Bias: 0.000000, T: 13536, Avg. loss: 177441230471916574212096.000000\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 5/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.7915127974877743, clf__eta0=0.05539740212799926, clf__fit_intercept=False, clf__l1_ratio=0.9152680641407671, clf__learning_rate=optimal, clf__loss=squared_epsilon_insensitive, clf__max_iter=80, clf__penalty=l1, clf__power_t=0.6359093112142983, clf__shuffle=True, clf__tol=0.9361199211609239, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.274 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 38.07, NNZs: 9673, Bias: 0.000000, T: 2256, Avg. loss: 0.242309\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 43.44, NNZs: 4921, Bias: 0.000000, T: 4512, Avg. loss: 0.037537\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 48.97, NNZs: 3464, Bias: 0.000000, T: 6768, Avg. loss: 0.040268\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 53.51, NNZs: 2729, Bias: 0.000000, T: 9024, Avg. loss: 0.032546\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 57.54, NNZs: 2306, Bias: 0.000000, T: 11280, Avg. loss: 0.029855\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 61.16, NNZs: 2030, Bias: 0.000000, T: 13536, Avg. loss: 0.028765\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 35.30, NNZs: 8730, Bias: 0.000000, T: 2256, Avg. loss: 0.211304\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 40.69, NNZs: 4349, Bias: 0.000000, T: 4512, Avg. loss: 0.036879\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 45.95, NNZs: 2999, Bias: 0.000000, T: 6768, Avg. loss: 0.034388\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 50.33, NNZs: 2419, Bias: 0.000000, T: 9024, Avg. loss: 0.030138\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 54.23, NNZs: 2060, Bias: 0.000000, T: 11280, Avg. loss: 0.028173\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 57.67, NNZs: 1808, Bias: 0.000000, T: 13536, Avg. loss: 0.026413\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 39.09, NNZs: 9819, Bias: 0.000000, T: 2256, Avg. loss: 0.249168\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 44.58, NNZs: 5324, Bias: 0.000000, T: 4512, Avg. loss: 0.039020\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 49.97, NNZs: 3730, Bias: 0.000000, T: 6768, Avg. loss: 0.036455\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 54.69, NNZs: 3007, Bias: 0.000000, T: 9024, Avg. loss: 0.032968\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 58.84, NNZs: 2553, Bias: 0.000000, T: 11280, Avg. loss: 0.031917\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 62.58, NNZs: 2262, Bias: 0.000000, T: 13536, Avg. loss: 0.029514\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 35.92, NNZs: 9609, Bias: 0.000000, T: 2256, Avg. loss: 0.209859\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 41.22, NNZs: 4762, Bias: 0.000000, T: 4512, Avg. loss: 0.038322\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 46.85, NNZs: 3377, Bias: 0.000000, T: 6768, Avg. loss: 0.040280\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 51.37, NNZs: 2660, Bias: 0.000000, T: 9024, Avg. loss: 0.034236\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 55.37, NNZs: 2238, Bias: 0.000000, T: 11280, Avg. loss: 0.030116\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 58.73, NNZs: 1919, Bias: 0.000000, T: 13536, Avg. loss: 0.028859\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 1/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.03646223783802971, clf__eta0=0.7491267567674796, clf__fit_intercept=False, clf__l1_ratio=0.775818217437024, clf__learning_rate=constant, clf__loss=squared_hinge, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.4028006727705291, clf__shuffle=True, clf__tol=0.1730703028465106, clf__warm_start=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.723 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 39.21, NNZs: 10023, Bias: 0.000000, T: 2256, Avg. loss: 0.249784\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 44.39, NNZs: 5246, Bias: 0.000000, T: 4512, Avg. loss: 0.038717\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 49.87, NNZs: 3663, Bias: 0.000000, T: 6768, Avg. loss: 0.039173\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 54.73, NNZs: 3009, Bias: 0.000000, T: 9024, Avg. loss: 0.036272\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 58.91, NNZs: 2530, Bias: 0.000000, T: 11280, Avg. loss: 0.031905\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 62.60, NNZs: 2166, Bias: 0.000000, T: 13536, Avg. loss: 0.030317\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 36.34, NNZs: 9287, Bias: 0.000000, T: 2256, Avg. loss: 0.228724\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 42.19, NNZs: 4744, Bias: 0.000000, T: 4512, Avg. loss: 0.044135\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 47.48, NNZs: 3364, Bias: 0.000000, T: 6768, Avg. loss: 0.038934\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 52.20, NNZs: 2758, Bias: 0.000000, T: 9024, Avg. loss: 0.036921\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 56.35, NNZs: 2359, Bias: 0.000000, T: 11280, Avg. loss: 0.033488\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 60.00, NNZs: 2115, Bias: 0.000000, T: 13536, Avg. loss: 0.031139\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 40.45, NNZs: 10277, Bias: 0.000000, T: 2256, Avg. loss: 0.261619\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 45.68, NNZs: 5530, Bias: 0.000000, T: 4512, Avg. loss: 0.039651\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 51.31, NNZs: 3881, Bias: 0.000000, T: 6768, Avg. loss: 0.040452\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 56.03, NNZs: 3123, Bias: 0.000000, T: 9024, Avg. loss: 0.034266\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 60.30, NNZs: 2693, Bias: 0.000000, T: 11280, Avg. loss: 0.034053\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 64.20, NNZs: 2406, Bias: 0.000000, T: 13536, Avg. loss: 0.033911\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 37.12, NNZs: 9683, Bias: 0.000000, T: 2256, Avg. loss: 0.234109\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 42.93, NNZs: 5005, Bias: 0.000000, T: 4512, Avg. loss: 0.048000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 48.51, NNZs: 3589, Bias: 0.000000, T: 6768, Avg. loss: 0.042683\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 53.32, NNZs: 2792, Bias: 0.000000, T: 9024, Avg. loss: 0.039680\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 57.49, NNZs: 2416, Bias: 0.000000, T: 11280, Avg. loss: 0.036684\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 61.26, NNZs: 2143, Bias: 0.000000, T: 13536, Avg. loss: 0.035057\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 2/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.03646223783802971, clf__eta0=0.7491267567674796, clf__fit_intercept=False, clf__l1_ratio=0.775818217437024, clf__learning_rate=constant, clf__loss=squared_hinge, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.4028006727705291, clf__shuffle=True, clf__tol=0.1730703028465106, clf__warm_start=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.811 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 39.24, NNZs: 10304, Bias: 0.000000, T: 2256, Avg. loss: 0.265387\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 45.01, NNZs: 5371, Bias: 0.000000, T: 4512, Avg. loss: 0.045836\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 50.65, NNZs: 3822, Bias: 0.000000, T: 6768, Avg. loss: 0.041369\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 55.45, NNZs: 3066, Bias: 0.000000, T: 9024, Avg. loss: 0.038052\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 59.69, NNZs: 2550, Bias: 0.000000, T: 11280, Avg. loss: 0.035602\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 63.51, NNZs: 2224, Bias: 0.000000, T: 13536, Avg. loss: 0.032471\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 36.58, NNZs: 9319, Bias: 0.000000, T: 2256, Avg. loss: 0.224680\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 41.99, NNZs: 4552, Bias: 0.000000, T: 4512, Avg. loss: 0.040861\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 47.47, NNZs: 3276, Bias: 0.000000, T: 6768, Avg. loss: 0.039431\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 51.94, NNZs: 2643, Bias: 0.000000, T: 9024, Avg. loss: 0.033126\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 55.90, NNZs: 2274, Bias: 0.000000, T: 11280, Avg. loss: 0.031220\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 59.47, NNZs: 1980, Bias: 0.000000, T: 13536, Avg. loss: 0.029631\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 40.81, NNZs: 10855, Bias: 0.000000, T: 2256, Avg. loss: 0.272201\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 46.03, NNZs: 5570, Bias: 0.000000, T: 4512, Avg. loss: 0.036952\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 51.78, NNZs: 4033, Bias: 0.000000, T: 6768, Avg. loss: 0.040772\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 56.68, NNZs: 3216, Bias: 0.000000, T: 9024, Avg. loss: 0.036297\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 60.98, NNZs: 2774, Bias: 0.000000, T: 11280, Avg. loss: 0.032951\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 64.86, NNZs: 2425, Bias: 0.000000, T: 13536, Avg. loss: 0.031664\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 37.34, NNZs: 10119, Bias: 0.000000, T: 2256, Avg. loss: 0.230562\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 43.04, NNZs: 4996, Bias: 0.000000, T: 4512, Avg. loss: 0.041271\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 48.73, NNZs: 3595, Bias: 0.000000, T: 6768, Avg. loss: 0.041770\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 53.45, NNZs: 2878, Bias: 0.000000, T: 9024, Avg. loss: 0.036514\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 57.63, NNZs: 2453, Bias: 0.000000, T: 11280, Avg. loss: 0.034163\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 61.26, NNZs: 2199, Bias: 0.000000, T: 13536, Avg. loss: 0.031290\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 3/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.03646223783802971, clf__eta0=0.7491267567674796, clf__fit_intercept=False, clf__l1_ratio=0.775818217437024, clf__learning_rate=constant, clf__loss=squared_hinge, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.4028006727705291, clf__shuffle=True, clf__tol=0.1730703028465106, clf__warm_start=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.882 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 38.01, NNZs: 10136, Bias: 0.000000, T: 2256, Avg. loss: 0.237250\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 43.45, NNZs: 5152, Bias: 0.000000, T: 4512, Avg. loss: 0.038283\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 49.10, NNZs: 3598, Bias: 0.000000, T: 6768, Avg. loss: 0.037862\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 53.66, NNZs: 2839, Bias: 0.000000, T: 9024, Avg. loss: 0.033495\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 57.82, NNZs: 2409, Bias: 0.000000, T: 11280, Avg. loss: 0.031696\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 61.53, NNZs: 2075, Bias: 0.000000, T: 13536, Avg. loss: 0.030126\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 35.30, NNZs: 9445, Bias: 0.000000, T: 2256, Avg. loss: 0.211882\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 41.26, NNZs: 4691, Bias: 0.000000, T: 4512, Avg. loss: 0.039713\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 46.63, NNZs: 3359, Bias: 0.000000, T: 6768, Avg. loss: 0.037435\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 51.25, NNZs: 2640, Bias: 0.000000, T: 9024, Avg. loss: 0.033791\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 55.23, NNZs: 2276, Bias: 0.000000, T: 11280, Avg. loss: 0.030902\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 58.79, NNZs: 1991, Bias: 0.000000, T: 13536, Avg. loss: 0.028558\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 39.89, NNZs: 11014, Bias: 0.000000, T: 2256, Avg. loss: 0.260077\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 45.55, NNZs: 5659, Bias: 0.000000, T: 4512, Avg. loss: 0.043109\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 51.30, NNZs: 4032, Bias: 0.000000, T: 6768, Avg. loss: 0.042592\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 56.25, NNZs: 3170, Bias: 0.000000, T: 9024, Avg. loss: 0.040196\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 60.58, NNZs: 2710, Bias: 0.000000, T: 11280, Avg. loss: 0.036477\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 64.47, NNZs: 2414, Bias: 0.000000, T: 13536, Avg. loss: 0.033654\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 35.55, NNZs: 9829, Bias: 0.000000, T: 2256, Avg. loss: 0.212583\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 41.71, NNZs: 4923, Bias: 0.000000, T: 4512, Avg. loss: 0.050263\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 47.33, NNZs: 3469, Bias: 0.000000, T: 6768, Avg. loss: 0.043899\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 52.03, NNZs: 2719, Bias: 0.000000, T: 9024, Avg. loss: 0.038758\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 56.22, NNZs: 2354, Bias: 0.000000, T: 11280, Avg. loss: 0.036417\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 59.88, NNZs: 2093, Bias: 0.000000, T: 13536, Avg. loss: 0.032717\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 4/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.03646223783802971, clf__eta0=0.7491267567674796, clf__fit_intercept=False, clf__l1_ratio=0.775818217437024, clf__learning_rate=constant, clf__loss=squared_hinge, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.4028006727705291, clf__shuffle=True, clf__tol=0.1730703028465106, clf__warm_start=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.803 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 39.19, NNZs: 10779, Bias: 0.000000, T: 2256, Avg. loss: 0.258709\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 45.05, NNZs: 5511, Bias: 0.000000, T: 4512, Avg. loss: 0.044043\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 50.55, NNZs: 3814, Bias: 0.000000, T: 6768, Avg. loss: 0.039071\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 55.49, NNZs: 2968, Bias: 0.000000, T: 9024, Avg. loss: 0.037516\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 59.67, NNZs: 2485, Bias: 0.000000, T: 11280, Avg. loss: 0.034420\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 63.42, NNZs: 2180, Bias: 0.000000, T: 13536, Avg. loss: 0.031094\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 36.05, NNZs: 9381, Bias: 0.000000, T: 2256, Avg. loss: 0.223322\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 41.60, NNZs: 4578, Bias: 0.000000, T: 4512, Avg. loss: 0.036463\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 47.18, NNZs: 3299, Bias: 0.000000, T: 6768, Avg. loss: 0.038916\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 51.68, NNZs: 2688, Bias: 0.000000, T: 9024, Avg. loss: 0.034365\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 55.77, NNZs: 2315, Bias: 0.000000, T: 11280, Avg. loss: 0.030374\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 59.38, NNZs: 2030, Bias: 0.000000, T: 13536, Avg. loss: 0.029998\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 40.62, NNZs: 11056, Bias: 0.000000, T: 2256, Avg. loss: 0.274565\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 46.11, NNZs: 5699, Bias: 0.000000, T: 4512, Avg. loss: 0.041336\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 51.95, NNZs: 3977, Bias: 0.000000, T: 6768, Avg. loss: 0.044450\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 56.95, NNZs: 3215, Bias: 0.000000, T: 9024, Avg. loss: 0.040944\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 61.24, NNZs: 2673, Bias: 0.000000, T: 11280, Avg. loss: 0.036839\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 65.13, NNZs: 2360, Bias: 0.000000, T: 13536, Avg. loss: 0.033078\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 36.96, NNZs: 10084, Bias: 0.000000, T: 2256, Avg. loss: 0.237695\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 42.83, NNZs: 4949, Bias: 0.000000, T: 4512, Avg. loss: 0.049086\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 48.51, NNZs: 3496, Bias: 0.000000, T: 6768, Avg. loss: 0.044672\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 53.12, NNZs: 2774, Bias: 0.000000, T: 9024, Avg. loss: 0.038339\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 57.31, NNZs: 2379, Bias: 0.000000, T: 11280, Avg. loss: 0.037663\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 61.09, NNZs: 2099, Bias: 0.000000, T: 13536, Avg. loss: 0.034828\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 5/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.03646223783802971, clf__eta0=0.7491267567674796, clf__fit_intercept=False, clf__l1_ratio=0.775818217437024, clf__learning_rate=constant, clf__loss=squared_hinge, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.4028006727705291, clf__shuffle=True, clf__tol=0.1730703028465106, clf__warm_start=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.847 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 16.97, NNZs: 6596, Bias: 0.000000, T: 2256, Avg. loss: 0.170875\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 21.91, NNZs: 4707, Bias: 0.000000, T: 4512, Avg. loss: 0.076292\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 25.34, NNZs: 3802, Bias: 0.000000, T: 6768, Avg. loss: 0.058598\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 28.36, NNZs: 3304, Bias: 0.000000, T: 9024, Avg. loss: 0.051062\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 30.93, NNZs: 2953, Bias: 0.000000, T: 11280, Avg. loss: 0.045683\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 33.25, NNZs: 2716, Bias: 0.000000, T: 13536, Avg. loss: 0.043129\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 24.42, NNZs: 9189, Bias: 0.000000, T: 2256, Avg. loss: 0.199222\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 26.12, NNZs: 5530, Bias: 0.000000, T: 4512, Avg. loss: 0.054784\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 30.14, NNZs: 4378, Bias: 0.000000, T: 6768, Avg. loss: 0.045840\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 32.65, NNZs: 3636, Bias: 0.000000, T: 9024, Avg. loss: 0.036713\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 35.07, NNZs: 3235, Bias: 0.000000, T: 11280, Avg. loss: 0.034359\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 37.19, NNZs: 2900, Bias: 0.000000, T: 13536, Avg. loss: 0.031964\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 10.50, NNZs: 4208, Bias: 0.000000, T: 2256, Avg. loss: 0.249336\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14.12, NNZs: 2642, Bias: 0.000000, T: 4512, Avg. loss: 0.152650\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 16.79, NNZs: 2110, Bias: 0.000000, T: 6768, Avg. loss: 0.129791\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 18.94, NNZs: 1806, Bias: 0.000000, T: 9024, Avg. loss: 0.117179\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 20.81, NNZs: 1589, Bias: 0.000000, T: 11280, Avg. loss: 0.110953\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 22.53, NNZs: 1448, Bias: 0.000000, T: 13536, Avg. loss: 0.105218\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 13.95, NNZs: 5726, Bias: 0.000000, T: 2256, Avg. loss: 0.148026\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 17.96, NNZs: 3946, Bias: 0.000000, T: 4512, Avg. loss: 0.077660\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 21.23, NNZs: 3250, Bias: 0.000000, T: 6768, Avg. loss: 0.063656\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 23.83, NNZs: 2794, Bias: 0.000000, T: 9024, Avg. loss: 0.057416\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 26.16, NNZs: 2529, Bias: 0.000000, T: 11280, Avg. loss: 0.053711\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 28.26, NNZs: 2256, Bias: 0.000000, T: 13536, Avg. loss: 0.050898\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 1/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.24457156361183285, clf__eta0=0.332929742792607, clf__fit_intercept=False, clf__l1_ratio=0.920539731041378, clf__learning_rate=constant, clf__loss=squared_error, clf__max_iter=100, clf__penalty=l1, clf__power_t=0.5734177157821045, clf__shuffle=True, clf__tol=0.6492274795888617, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.394 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 17.30, NNZs: 6783, Bias: 0.000000, T: 2256, Avg. loss: 0.173333\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 21.86, NNZs: 4659, Bias: 0.000000, T: 4512, Avg. loss: 0.076547\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 25.55, NNZs: 3820, Bias: 0.000000, T: 6768, Avg. loss: 0.058085\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 28.55, NNZs: 3320, Bias: 0.000000, T: 9024, Avg. loss: 0.048775\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 31.15, NNZs: 2951, Bias: 0.000000, T: 11280, Avg. loss: 0.045399\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 33.42, NNZs: 2695, Bias: 0.000000, T: 13536, Avg. loss: 0.041797\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 24.90, NNZs: 9200, Bias: 0.000000, T: 2256, Avg. loss: 0.208305\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 26.99, NNZs: 5992, Bias: 0.000000, T: 4512, Avg. loss: 0.065658\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 30.84, NNZs: 4634, Bias: 0.000000, T: 6768, Avg. loss: 0.049749\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 33.54, NNZs: 3912, Bias: 0.000000, T: 9024, Avg. loss: 0.041949\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 36.02, NNZs: 3426, Bias: 0.000000, T: 11280, Avg. loss: 0.038548\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 38.16, NNZs: 3072, Bias: 0.000000, T: 13536, Avg. loss: 0.035776\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 10.50, NNZs: 4209, Bias: 0.000000, T: 2256, Avg. loss: 0.257702\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14.02, NNZs: 2744, Bias: 0.000000, T: 4512, Avg. loss: 0.158843\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 16.78, NNZs: 2237, Bias: 0.000000, T: 6768, Avg. loss: 0.137079\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 19.11, NNZs: 1917, Bias: 0.000000, T: 9024, Avg. loss: 0.124512\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 20.99, NNZs: 1713, Bias: 0.000000, T: 11280, Avg. loss: 0.116757\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 22.81, NNZs: 1561, Bias: 0.000000, T: 13536, Avg. loss: 0.110812\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 14.11, NNZs: 5870, Bias: 0.000000, T: 2256, Avg. loss: 0.156774\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 18.42, NNZs: 4038, Bias: 0.000000, T: 4512, Avg. loss: 0.080731\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 21.77, NNZs: 3247, Bias: 0.000000, T: 6768, Avg. loss: 0.065742\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 24.55, NNZs: 2852, Bias: 0.000000, T: 9024, Avg. loss: 0.057968\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 26.97, NNZs: 2567, Bias: 0.000000, T: 11280, Avg. loss: 0.053213\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 29.00, NNZs: 2345, Bias: 0.000000, T: 13536, Avg. loss: 0.050509\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 2/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.24457156361183285, clf__eta0=0.332929742792607, clf__fit_intercept=False, clf__l1_ratio=0.920539731041378, clf__learning_rate=constant, clf__loss=squared_error, clf__max_iter=100, clf__penalty=l1, clf__power_t=0.5734177157821045, clf__shuffle=True, clf__tol=0.6492274795888617, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.500 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 17.37, NNZs: 6849, Bias: 0.000000, T: 2256, Avg. loss: 0.182140\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 22.12, NNZs: 4851, Bias: 0.000000, T: 4512, Avg. loss: 0.083370\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 25.92, NNZs: 3948, Bias: 0.000000, T: 6768, Avg. loss: 0.064143\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 29.11, NNZs: 3433, Bias: 0.000000, T: 9024, Avg. loss: 0.055379\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 31.77, NNZs: 3066, Bias: 0.000000, T: 11280, Avg. loss: 0.050195\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 34.19, NNZs: 2815, Bias: 0.000000, T: 13536, Avg. loss: 0.046708\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 25.46, NNZs: 9382, Bias: 0.000000, T: 2256, Avg. loss: 0.227534\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 27.83, NNZs: 6053, Bias: 0.000000, T: 4512, Avg. loss: 0.065590\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 31.98, NNZs: 4704, Bias: 0.000000, T: 6768, Avg. loss: 0.051899\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 34.70, NNZs: 3939, Bias: 0.000000, T: 9024, Avg. loss: 0.042188\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 37.20, NNZs: 3421, Bias: 0.000000, T: 11280, Avg. loss: 0.038785\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 39.49, NNZs: 3130, Bias: 0.000000, T: 13536, Avg. loss: 0.036925\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 10.58, NNZs: 4311, Bias: 0.000000, T: 2256, Avg. loss: 0.263267\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14.33, NNZs: 2756, Bias: 0.000000, T: 4512, Avg. loss: 0.166691\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 17.05, NNZs: 2142, Bias: 0.000000, T: 6768, Avg. loss: 0.142516\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 19.32, NNZs: 1843, Bias: 0.000000, T: 9024, Avg. loss: 0.128665\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 21.31, NNZs: 1641, Bias: 0.000000, T: 11280, Avg. loss: 0.122557\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 23.14, NNZs: 1525, Bias: 0.000000, T: 13536, Avg. loss: 0.115891\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 14.42, NNZs: 6082, Bias: 0.000000, T: 2256, Avg. loss: 0.160388\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 18.63, NNZs: 4159, Bias: 0.000000, T: 4512, Avg. loss: 0.084171\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 21.95, NNZs: 3327, Bias: 0.000000, T: 6768, Avg. loss: 0.069589\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 24.69, NNZs: 2937, Bias: 0.000000, T: 9024, Avg. loss: 0.062079\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 27.09, NNZs: 2638, Bias: 0.000000, T: 11280, Avg. loss: 0.057650\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 29.29, NNZs: 2400, Bias: 0.000000, T: 13536, Avg. loss: 0.054394\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 3/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.24457156361183285, clf__eta0=0.332929742792607, clf__fit_intercept=False, clf__l1_ratio=0.920539731041378, clf__learning_rate=constant, clf__loss=squared_error, clf__max_iter=100, clf__penalty=l1, clf__power_t=0.5734177157821045, clf__shuffle=True, clf__tol=0.6492274795888617, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.537 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 17.19, NNZs: 7048, Bias: 0.000000, T: 2256, Avg. loss: 0.177114\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 22.32, NNZs: 4908, Bias: 0.000000, T: 4512, Avg. loss: 0.078138\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 26.07, NNZs: 3978, Bias: 0.000000, T: 6768, Avg. loss: 0.060203\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 29.12, NNZs: 3486, Bias: 0.000000, T: 9024, Avg. loss: 0.051495\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 31.74, NNZs: 3137, Bias: 0.000000, T: 11280, Avg. loss: 0.046637\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 34.04, NNZs: 2859, Bias: 0.000000, T: 13536, Avg. loss: 0.043768\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 25.19, NNZs: 9647, Bias: 0.000000, T: 2256, Avg. loss: 0.212613\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 27.52, NNZs: 6261, Bias: 0.000000, T: 4512, Avg. loss: 0.063924\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 31.45, NNZs: 4831, Bias: 0.000000, T: 6768, Avg. loss: 0.047939\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 34.03, NNZs: 3941, Bias: 0.000000, T: 9024, Avg. loss: 0.039924\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 36.34, NNZs: 3373, Bias: 0.000000, T: 11280, Avg. loss: 0.036337\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 38.53, NNZs: 3029, Bias: 0.000000, T: 13536, Avg. loss: 0.035181\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 10.59, NNZs: 4418, Bias: 0.000000, T: 2256, Avg. loss: 0.260818\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14.28, NNZs: 2762, Bias: 0.000000, T: 4512, Avg. loss: 0.160973\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 16.98, NNZs: 2129, Bias: 0.000000, T: 6768, Avg. loss: 0.137908\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 19.30, NNZs: 1843, Bias: 0.000000, T: 9024, Avg. loss: 0.126287\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 21.28, NNZs: 1638, Bias: 0.000000, T: 11280, Avg. loss: 0.118112\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 22.99, NNZs: 1494, Bias: 0.000000, T: 13536, Avg. loss: 0.112116\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 14.03, NNZs: 5976, Bias: 0.000000, T: 2256, Avg. loss: 0.150153\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 18.14, NNZs: 4002, Bias: 0.000000, T: 4512, Avg. loss: 0.079575\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 21.35, NNZs: 3198, Bias: 0.000000, T: 6768, Avg. loss: 0.066139\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 23.99, NNZs: 2799, Bias: 0.000000, T: 9024, Avg. loss: 0.060420\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 26.36, NNZs: 2512, Bias: 0.000000, T: 11280, Avg. loss: 0.055829\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 28.36, NNZs: 2285, Bias: 0.000000, T: 13536, Avg. loss: 0.052887\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 4/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.24457156361183285, clf__eta0=0.332929742792607, clf__fit_intercept=False, clf__l1_ratio=0.920539731041378, clf__learning_rate=constant, clf__loss=squared_error, clf__max_iter=100, clf__penalty=l1, clf__power_t=0.5734177157821045, clf__shuffle=True, clf__tol=0.6492274795888617, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.453 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 17.45, NNZs: 7015, Bias: 0.000000, T: 2256, Avg. loss: 0.180763\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 22.45, NNZs: 4916, Bias: 0.000000, T: 4512, Avg. loss: 0.079336\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 26.16, NNZs: 3988, Bias: 0.000000, T: 6768, Avg. loss: 0.059515\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 29.27, NNZs: 3435, Bias: 0.000000, T: 9024, Avg. loss: 0.051270\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 31.83, NNZs: 3029, Bias: 0.000000, T: 11280, Avg. loss: 0.046403\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 34.19, NNZs: 2773, Bias: 0.000000, T: 13536, Avg. loss: 0.043484\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 25.28, NNZs: 9724, Bias: 0.000000, T: 2256, Avg. loss: 0.215505\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 27.55, NNZs: 6351, Bias: 0.000000, T: 4512, Avg. loss: 0.064804\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 31.67, NNZs: 5048, Bias: 0.000000, T: 6768, Avg. loss: 0.049465\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 34.16, NNZs: 4113, Bias: 0.000000, T: 9024, Avg. loss: 0.040826\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 36.81, NNZs: 3591, Bias: 0.000000, T: 11280, Avg. loss: 0.038532\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 38.87, NNZs: 3151, Bias: 0.000000, T: 13536, Avg. loss: 0.035359\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 10.49, NNZs: 4313, Bias: 0.000000, T: 2256, Avg. loss: 0.264736\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14.27, NNZs: 2804, Bias: 0.000000, T: 4512, Avg. loss: 0.163649\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 17.01, NNZs: 2178, Bias: 0.000000, T: 6768, Avg. loss: 0.139340\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 19.30, NNZs: 1902, Bias: 0.000000, T: 9024, Avg. loss: 0.127917\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 21.36, NNZs: 1701, Bias: 0.000000, T: 11280, Avg. loss: 0.118150\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 23.11, NNZs: 1534, Bias: 0.000000, T: 13536, Avg. loss: 0.114091\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 14.11, NNZs: 5936, Bias: 0.000000, T: 2256, Avg. loss: 0.153195\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 18.29, NNZs: 4052, Bias: 0.000000, T: 4512, Avg. loss: 0.082879\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 21.35, NNZs: 3159, Bias: 0.000000, T: 6768, Avg. loss: 0.068108\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 24.16, NNZs: 2744, Bias: 0.000000, T: 9024, Avg. loss: 0.061625\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 26.47, NNZs: 2504, Bias: 0.000000, T: 11280, Avg. loss: 0.057243\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 28.67, NNZs: 2265, Bias: 0.000000, T: 13536, Avg. loss: 0.053642\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 5/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.24457156361183285, clf__eta0=0.332929742792607, clf__fit_intercept=False, clf__l1_ratio=0.920539731041378, clf__learning_rate=constant, clf__loss=squared_error, clf__max_iter=100, clf__penalty=l1, clf__power_t=0.5734177157821045, clf__shuffle=True, clf__tol=0.6492274795888617, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.438 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 1.23, NNZs: 25006, Bias: -0.106250, T: 2256, Avg. loss: 0.187681\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.78, NNZs: 25006, Bias: -0.150897, T: 4512, Avg. loss: 0.154882\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.13, NNZs: 25006, Bias: -0.183442, T: 6768, Avg. loss: 0.135819\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.37, NNZs: 25006, Bias: -0.209186, T: 9024, Avg. loss: 0.124184\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.56, NNZs: 25006, Bias: -0.230972, T: 11280, Avg. loss: 0.115764\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.72, NNZs: 25006, Bias: -0.250174, T: 13536, Avg. loss: 0.108807\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.28, NNZs: 25006, Bias: -0.115990, T: 2256, Avg. loss: 0.182572\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.85, NNZs: 25006, Bias: -0.166483, T: 4512, Avg. loss: 0.145304\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.23, NNZs: 25006, Bias: -0.203893, T: 6768, Avg. loss: 0.122718\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.50, NNZs: 25006, Bias: -0.233827, T: 9024, Avg. loss: 0.108004\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.72, NNZs: 25006, Bias: -0.259312, T: 11280, Avg. loss: 0.096971\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.90, NNZs: 25006, Bias: -0.281729, T: 13536, Avg. loss: 0.087793\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.07, NNZs: 25006, Bias: 0.067013, T: 2256, Avg. loss: 0.203692\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.55, NNZs: 25006, Bias: 0.088023, T: 4512, Avg. loss: 0.184533\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.93, NNZs: 25006, Bias: 0.103712, T: 6768, Avg. loss: 0.172268\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.25, NNZs: 25006, Bias: 0.117113, T: 9024, Avg. loss: 0.162489\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.50, NNZs: 25006, Bias: 0.129501, T: 11280, Avg. loss: 0.154961\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.71, NNZs: 25006, Bias: 0.141244, T: 13536, Avg. loss: 0.149160\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.10, NNZs: 25006, Bias: -0.088365, T: 2256, Avg. loss: 0.197799\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.56, NNZs: 25006, Bias: -0.122709, T: 4512, Avg. loss: 0.175426\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.93, NNZs: 25006, Bias: -0.149106, T: 6768, Avg. loss: 0.161075\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.25, NNZs: 25006, Bias: -0.171447, T: 9024, Avg. loss: 0.149391\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.53, NNZs: 25006, Bias: -0.191209, T: 11280, Avg. loss: 0.139248\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.78, NNZs: 25006, Bias: -0.209188, T: 13536, Avg. loss: 0.130180\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 1/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.2527955528897454, clf__eta0=0.4377192284389271, clf__fit_intercept=True, clf__l1_ratio=0.6515110441465675, clf__learning_rate=invscaling, clf__loss=huber, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.47239053945705856, clf__shuffle=False, clf__tol=0.9089234089706554, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.426 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 1.22, NNZs: 25109, Bias: -0.103941, T: 2256, Avg. loss: 0.187308\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.75, NNZs: 25109, Bias: -0.147725, T: 4512, Avg. loss: 0.155344\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.06, NNZs: 25109, Bias: -0.179218, T: 6768, Avg. loss: 0.138423\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.27, NNZs: 25109, Bias: -0.204344, T: 9024, Avg. loss: 0.127956\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.44, NNZs: 25109, Bias: -0.225760, T: 11280, Avg. loss: 0.120020\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.59, NNZs: 25109, Bias: -0.244699, T: 13536, Avg. loss: 0.113341\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.26, NNZs: 25109, Bias: -0.114124, T: 2256, Avg. loss: 0.182687\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.81, NNZs: 25109, Bias: -0.163999, T: 4512, Avg. loss: 0.146106\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.15, NNZs: 25109, Bias: -0.200478, T: 6768, Avg. loss: 0.125455\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.40, NNZs: 25109, Bias: -0.229866, T: 9024, Avg. loss: 0.111930\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.60, NNZs: 25109, Bias: -0.254984, T: 11280, Avg. loss: 0.101445\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.76, NNZs: 25109, Bias: -0.277118, T: 13536, Avg. loss: 0.092661\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.05, NNZs: 25109, Bias: 0.052832, T: 2256, Avg. loss: 0.203679\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.53, NNZs: 25109, Bias: 0.073170, T: 4512, Avg. loss: 0.185469\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.91, NNZs: 25109, Bias: 0.088769, T: 6768, Avg. loss: 0.173682\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.19, NNZs: 25109, Bias: 0.102640, T: 9024, Avg. loss: 0.165080\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.41, NNZs: 25109, Bias: 0.115565, T: 11280, Avg. loss: 0.158835\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.59, NNZs: 25109, Bias: 0.127739, T: 13536, Avg. loss: 0.153887\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.03, NNZs: 25109, Bias: -0.078359, T: 2256, Avg. loss: 0.199631\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.50, NNZs: 25109, Bias: -0.112334, T: 4512, Avg. loss: 0.177920\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.87, NNZs: 25109, Bias: -0.138580, T: 6768, Avg. loss: 0.163775\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.19, NNZs: 25109, Bias: -0.160836, T: 9024, Avg. loss: 0.152242\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.47, NNZs: 25109, Bias: -0.180636, T: 11280, Avg. loss: 0.142285\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.71, NNZs: 25109, Bias: -0.198861, T: 13536, Avg. loss: 0.133616\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 2/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.2527955528897454, clf__eta0=0.4377192284389271, clf__fit_intercept=True, clf__l1_ratio=0.6515110441465675, clf__learning_rate=invscaling, clf__loss=huber, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.47239053945705856, clf__shuffle=False, clf__tol=0.9089234089706554, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.439 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 1.20, NNZs: 25958, Bias: -0.103567, T: 2256, Avg. loss: 0.188208\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.72, NNZs: 25958, Bias: -0.147439, T: 4512, Avg. loss: 0.156953\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.04, NNZs: 25958, Bias: -0.179311, T: 6768, Avg. loss: 0.139684\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.27, NNZs: 25958, Bias: -0.204736, T: 9024, Avg. loss: 0.128939\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.44, NNZs: 25958, Bias: -0.226374, T: 11280, Avg. loss: 0.120891\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.58, NNZs: 25958, Bias: -0.245506, T: 13536, Avg. loss: 0.114148\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.25, NNZs: 25958, Bias: -0.114722, T: 2256, Avg. loss: 0.182967\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.80, NNZs: 25958, Bias: -0.164672, T: 4512, Avg. loss: 0.146541\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.15, NNZs: 25958, Bias: -0.201370, T: 6768, Avg. loss: 0.125593\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.40, NNZs: 25958, Bias: -0.230901, T: 9024, Avg. loss: 0.111876\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.61, NNZs: 25958, Bias: -0.256117, T: 11280, Avg. loss: 0.101318\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.78, NNZs: 25958, Bias: -0.278337, T: 13536, Avg. loss: 0.092489\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.02, NNZs: 25958, Bias: 0.051643, T: 2256, Avg. loss: 0.204474\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.49, NNZs: 25958, Bias: 0.071575, T: 4512, Avg. loss: 0.187313\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.86, NNZs: 25958, Bias: 0.086860, T: 6768, Avg. loss: 0.176139\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.15, NNZs: 25958, Bias: 0.100331, T: 9024, Avg. loss: 0.167637\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.38, NNZs: 25958, Bias: 0.112857, T: 11280, Avg. loss: 0.161313\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.56, NNZs: 25958, Bias: 0.124672, T: 13536, Avg. loss: 0.156304\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.01, NNZs: 25958, Bias: -0.076945, T: 2256, Avg. loss: 0.200238\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.48, NNZs: 25958, Bias: -0.110679, T: 4512, Avg. loss: 0.178992\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.84, NNZs: 25958, Bias: -0.136822, T: 6768, Avg. loss: 0.165078\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.15, NNZs: 25958, Bias: -0.159022, T: 9024, Avg. loss: 0.153724\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.43, NNZs: 25958, Bias: -0.178745, T: 11280, Avg. loss: 0.143883\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.67, NNZs: 25958, Bias: -0.196854, T: 13536, Avg. loss: 0.135230\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 3/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.2527955528897454, clf__eta0=0.4377192284389271, clf__fit_intercept=True, clf__l1_ratio=0.6515110441465675, clf__learning_rate=invscaling, clf__loss=huber, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.47239053945705856, clf__shuffle=False, clf__tol=0.9089234089706554, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.449 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 1.24, NNZs: 26761, Bias: -0.103442, T: 2256, Avg. loss: 0.187028\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.76, NNZs: 26761, Bias: -0.147046, T: 4512, Avg. loss: 0.155161\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.07, NNZs: 26761, Bias: -0.178449, T: 6768, Avg. loss: 0.138231\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.29, NNZs: 26761, Bias: -0.203505, T: 9024, Avg. loss: 0.127751\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.46, NNZs: 26761, Bias: -0.224873, T: 11280, Avg. loss: 0.119792\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.60, NNZs: 26761, Bias: -0.243790, T: 13536, Avg. loss: 0.113067\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.28, NNZs: 26761, Bias: -0.113961, T: 2256, Avg. loss: 0.181841\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.84, NNZs: 26761, Bias: -0.163724, T: 4512, Avg. loss: 0.144478\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.19, NNZs: 26761, Bias: -0.200015, T: 6768, Avg. loss: 0.123551\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.44, NNZs: 26761, Bias: -0.229202, T: 9024, Avg. loss: 0.109926\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.64, NNZs: 26761, Bias: -0.254149, T: 11280, Avg. loss: 0.099353\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.81, NNZs: 26761, Bias: -0.276120, T: 13536, Avg. loss: 0.090471\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.05, NNZs: 26761, Bias: 0.050615, T: 2256, Avg. loss: 0.203727\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.53, NNZs: 26761, Bias: 0.070520, T: 4512, Avg. loss: 0.186058\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.90, NNZs: 26761, Bias: 0.085899, T: 6768, Avg. loss: 0.174622\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.19, NNZs: 26761, Bias: 0.099513, T: 9024, Avg. loss: 0.166111\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.41, NNZs: 26761, Bias: 0.112193, T: 11280, Avg. loss: 0.159803\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.60, NNZs: 26761, Bias: 0.124165, T: 13536, Avg. loss: 0.154803\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.06, NNZs: 26761, Bias: -0.076804, T: 2256, Avg. loss: 0.198757\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.55, NNZs: 26761, Bias: -0.110541, T: 4512, Avg. loss: 0.176210\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.93, NNZs: 26761, Bias: -0.136670, T: 6768, Avg. loss: 0.161433\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.26, NNZs: 26761, Bias: -0.158873, T: 9024, Avg. loss: 0.149383\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.54, NNZs: 26761, Bias: -0.178728, T: 11280, Avg. loss: 0.139054\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.79, NNZs: 26761, Bias: -0.197025, T: 13536, Avg. loss: 0.130123\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 4/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.2527955528897454, clf__eta0=0.4377192284389271, clf__fit_intercept=True, clf__l1_ratio=0.6515110441465675, clf__learning_rate=invscaling, clf__loss=huber, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.47239053945705856, clf__shuffle=False, clf__tol=0.9089234089706554, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.445 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 1.23, NNZs: 26152, Bias: -0.103244, T: 2256, Avg. loss: 0.186868\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.75, NNZs: 26152, Bias: -0.146757, T: 4512, Avg. loss: 0.154932\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.06, NNZs: 26152, Bias: -0.177966, T: 6768, Avg. loss: 0.138341\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.26, NNZs: 26152, Bias: -0.202825, T: 9024, Avg. loss: 0.128168\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.42, NNZs: 26152, Bias: -0.224012, T: 11280, Avg. loss: 0.120457\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.56, NNZs: 26152, Bias: -0.242796, T: 13536, Avg. loss: 0.113931\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.28, NNZs: 26152, Bias: -0.115025, T: 2256, Avg. loss: 0.181887\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.83, NNZs: 26152, Bias: -0.164779, T: 4512, Avg. loss: 0.144989\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.17, NNZs: 26152, Bias: -0.201006, T: 6768, Avg. loss: 0.124569\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.41, NNZs: 26152, Bias: -0.230136, T: 9024, Avg. loss: 0.111243\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.60, NNZs: 26152, Bias: -0.255077, T: 11280, Avg. loss: 0.100862\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.77, NNZs: 26152, Bias: -0.277127, T: 13536, Avg. loss: 0.092056\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.07, NNZs: 26152, Bias: 0.051587, T: 2256, Avg. loss: 0.203057\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.56, NNZs: 26152, Bias: 0.071782, T: 4512, Avg. loss: 0.184615\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.93, NNZs: 26152, Bias: 0.087402, T: 6768, Avg. loss: 0.172700\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.22, NNZs: 26152, Bias: 0.101283, T: 9024, Avg. loss: 0.164062\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.44, NNZs: 26152, Bias: 0.114214, T: 11280, Avg. loss: 0.157723\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.62, NNZs: 26152, Bias: 0.126415, T: 13536, Avg. loss: 0.152687\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.06, NNZs: 26152, Bias: -0.076910, T: 2256, Avg. loss: 0.198805\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.55, NNZs: 26152, Bias: -0.110783, T: 4512, Avg. loss: 0.176327\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.93, NNZs: 26152, Bias: -0.136983, T: 6768, Avg. loss: 0.161627\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.25, NNZs: 26152, Bias: -0.159277, T: 9024, Avg. loss: 0.149667\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.53, NNZs: 26152, Bias: -0.179252, T: 11280, Avg. loss: 0.139519\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.77, NNZs: 26152, Bias: -0.197659, T: 13536, Avg. loss: 0.130783\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 5/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.2527955528897454, clf__eta0=0.4377192284389271, clf__fit_intercept=True, clf__l1_ratio=0.6515110441465675, clf__learning_rate=invscaling, clf__loss=huber, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.47239053945705856, clf__shuffle=False, clf__tol=0.9089234089706554, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.437 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 92.92, NNZs: 24461, Bias: -1.006831, T: 2256, Avg. loss: 0.772223\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 39.23, NNZs: 24856, Bias: -0.949733, T: 4512, Avg. loss: 0.921597\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 32.98, NNZs: 24942, Bias: -0.935631, T: 6768, Avg. loss: 0.268819\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 25.27, NNZs: 24941, Bias: -0.898523, T: 9024, Avg. loss: 0.151614\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 23.54, NNZs: 24943, Bias: -0.970492, T: 11280, Avg. loss: 0.064061\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 20.96, NNZs: 24946, Bias: -0.923751, T: 13536, Avg. loss: 0.026424\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 20.11, NNZs: 24950, Bias: -0.917894, T: 15792, Avg. loss: 0.009122\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 7 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 91.56, NNZs: 24304, Bias: -0.858721, T: 2256, Avg. loss: 0.732016\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 39.28, NNZs: 24780, Bias: -0.983961, T: 4512, Avg. loss: 0.929608\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 30.79, NNZs: 24893, Bias: -0.967062, T: 6768, Avg. loss: 0.257804\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 23.45, NNZs: 24896, Bias: -0.949082, T: 9024, Avg. loss: 0.150422\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 19.25, NNZs: 24880, Bias: -0.883442, T: 11280, Avg. loss: 0.060114\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 17.85, NNZs: 24896, Bias: -0.894072, T: 13536, Avg. loss: 0.023189\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 93.28, NNZs: 24375, Bias: 1.152890, T: 2256, Avg. loss: 0.785032\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 41.73, NNZs: 24857, Bias: 0.883940, T: 4512, Avg. loss: 0.927284\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 34.52, NNZs: 24946, Bias: 1.007078, T: 6768, Avg. loss: 0.271479\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 27.07, NNZs: 24958, Bias: 0.950769, T: 9024, Avg. loss: 0.157679\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 23.88, NNZs: 24963, Bias: 0.880531, T: 11280, Avg. loss: 0.068118\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 22.10, NNZs: 24964, Bias: 0.866465, T: 13536, Avg. loss: 0.024116\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 91.57, NNZs: 24415, Bias: -1.070782, T: 2256, Avg. loss: 0.751969\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 39.87, NNZs: 24768, Bias: -0.918994, T: 4512, Avg. loss: 0.926005\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 30.78, NNZs: 24884, Bias: -0.983130, T: 6768, Avg. loss: 0.259027\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 24.43, NNZs: 24882, Bias: -0.928914, T: 9024, Avg. loss: 0.149414\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 20.38, NNZs: 24879, Bias: -0.973909, T: 11280, Avg. loss: 0.061158\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 18.87, NNZs: 24884, Bias: -0.948322, T: 13536, Avg. loss: 0.022018\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 1/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.3241670976844645, clf__eta0=0.9631840511405841, clf__fit_intercept=True, clf__l1_ratio=0.5912641309775509, clf__learning_rate=optimal, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.6710686638981408, clf__shuffle=True, clf__tol=0.09654933943827881, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.741 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 91.64, NNZs: 24564, Bias: -1.030451, T: 2256, Avg. loss: 0.766052\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 40.14, NNZs: 24943, Bias: -0.862831, T: 4512, Avg. loss: 0.910453\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 33.01, NNZs: 25024, Bias: -0.970831, T: 6768, Avg. loss: 0.263107\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 25.37, NNZs: 25038, Bias: -0.920231, T: 9024, Avg. loss: 0.154270\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 22.20, NNZs: 25033, Bias: -0.921242, T: 11280, Avg. loss: 0.063649\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 20.63, NNZs: 25037, Bias: -0.929165, T: 13536, Avg. loss: 0.023451\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 91.10, NNZs: 24370, Bias: -0.933535, T: 2256, Avg. loss: 0.754662\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 39.96, NNZs: 24879, Bias: -1.042840, T: 4512, Avg. loss: 0.921676\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 30.73, NNZs: 24969, Bias: -0.943214, T: 6768, Avg. loss: 0.253997\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 23.80, NNZs: 25002, Bias: -0.986424, T: 9024, Avg. loss: 0.151995\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 19.94, NNZs: 24983, Bias: -0.928081, T: 11280, Avg. loss: 0.059451\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 18.27, NNZs: 24991, Bias: -0.920430, T: 13536, Avg. loss: 0.022301\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 92.12, NNZs: 24318, Bias: 0.972736, T: 2256, Avg. loss: 0.785692\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 42.55, NNZs: 24906, Bias: 0.889571, T: 4512, Avg. loss: 0.892756\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 35.18, NNZs: 25030, Bias: 0.952360, T: 6768, Avg. loss: 0.279869\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 27.71, NNZs: 25047, Bias: 0.898537, T: 9024, Avg. loss: 0.167861\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 24.72, NNZs: 25049, Bias: 0.868786, T: 11280, Avg. loss: 0.067207\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 22.91, NNZs: 25052, Bias: 0.898828, T: 13536, Avg. loss: 0.026001\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 22.24, NNZs: 25058, Bias: 0.865820, T: 15792, Avg. loss: 0.008576\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 7 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 91.28, NNZs: 24484, Bias: -1.068713, T: 2256, Avg. loss: 0.742495\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 38.81, NNZs: 24870, Bias: -0.929543, T: 4512, Avg. loss: 0.946986\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 31.50, NNZs: 24960, Bias: -0.911010, T: 6768, Avg. loss: 0.240695\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 23.94, NNZs: 24985, Bias: -0.932750, T: 9024, Avg. loss: 0.148876\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 20.35, NNZs: 24998, Bias: -0.899115, T: 11280, Avg. loss: 0.062769\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 18.38, NNZs: 24972, Bias: -0.903855, T: 13536, Avg. loss: 0.021867\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "[CV 2/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.3241670976844645, clf__eta0=0.9631840511405841, clf__fit_intercept=True, clf__l1_ratio=0.5912641309775509, clf__learning_rate=optimal, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.6710686638981408, clf__shuffle=True, clf__tol=0.09654933943827881, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.752 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 91.56, NNZs: 25137, Bias: -1.004189, T: 2256, Avg. loss: 0.771305\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 41.36, NNZs: 25519, Bias: -0.908694, T: 4512, Avg. loss: 0.887659\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 34.28, NNZs: 25629, Bias: -0.967364, T: 6768, Avg. loss: 0.270055\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 26.00, NNZs: 25633, Bias: -0.984115, T: 9024, Avg. loss: 0.167441\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 23.05, NNZs: 25636, Bias: -0.927189, T: 11280, Avg. loss: 0.069261\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 20.80, NNZs: 25637, Bias: -0.977550, T: 13536, Avg. loss: 0.021762\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 90.22, NNZs: 24831, Bias: -0.747353, T: 2256, Avg. loss: 0.724467\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 41.49, NNZs: 25462, Bias: -0.947722, T: 4512, Avg. loss: 0.886039\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 31.04, NNZs: 25603, Bias: -0.956209, T: 6768, Avg. loss: 0.267078\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 24.41, NNZs: 25591, Bias: -0.998741, T: 9024, Avg. loss: 0.149259\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 20.54, NNZs: 25602, Bias: -0.920351, T: 11280, Avg. loss: 0.060163\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 18.93, NNZs: 25611, Bias: -0.903472, T: 13536, Avg. loss: 0.025517\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 18.15, NNZs: 25612, Bias: -0.886596, T: 15792, Avg. loss: 0.007754\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 7 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 93.03, NNZs: 25202, Bias: 0.817174, T: 2256, Avg. loss: 0.796287\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 41.84, NNZs: 25532, Bias: 0.673096, T: 4512, Avg. loss: 0.899159\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 35.39, NNZs: 25644, Bias: 0.964052, T: 6768, Avg. loss: 0.278097\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 27.76, NNZs: 25651, Bias: 0.919046, T: 9024, Avg. loss: 0.163391\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 25.22, NNZs: 25670, Bias: 0.903377, T: 11280, Avg. loss: 0.065449\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 23.04, NNZs: 25664, Bias: 0.866592, T: 13536, Avg. loss: 0.026312\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 90.37, NNZs: 25077, Bias: -0.806037, T: 2256, Avg. loss: 0.755194\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 40.65, NNZs: 25513, Bias: -0.989367, T: 4512, Avg. loss: 0.908293\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 31.53, NNZs: 25604, Bias: -1.015144, T: 6768, Avg. loss: 0.260896\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 24.89, NNZs: 25621, Bias: -0.970759, T: 9024, Avg. loss: 0.155893\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 21.15, NNZs: 25618, Bias: -0.943895, T: 11280, Avg. loss: 0.062437\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 19.84, NNZs: 25622, Bias: -0.916192, T: 13536, Avg. loss: 0.023158\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 3/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.3241670976844645, clf__eta0=0.9631840511405841, clf__fit_intercept=True, clf__l1_ratio=0.5912641309775509, clf__learning_rate=optimal, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.6710686638981408, clf__shuffle=True, clf__tol=0.09654933943827881, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.820 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 93.39, NNZs: 26272, Bias: -0.889481, T: 2256, Avg. loss: 0.772876\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 40.90, NNZs: 26555, Bias: -0.929503, T: 4512, Avg. loss: 0.918530\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 33.46, NNZs: 26661, Bias: -0.988371, T: 6768, Avg. loss: 0.282765\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 26.23, NNZs: 26656, Bias: -0.888626, T: 9024, Avg. loss: 0.158598\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 23.03, NNZs: 26658, Bias: -0.955951, T: 11280, Avg. loss: 0.068545\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 21.14, NNZs: 26658, Bias: -0.890085, T: 13536, Avg. loss: 0.024357\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 20.14, NNZs: 26663, Bias: -0.911368, T: 15792, Avg. loss: 0.008626\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 7 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 92.85, NNZs: 26202, Bias: -0.999409, T: 2256, Avg. loss: 0.742895\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 40.50, NNZs: 26464, Bias: -0.923256, T: 4512, Avg. loss: 0.944429\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 30.87, NNZs: 26625, Bias: -0.954529, T: 6768, Avg. loss: 0.255478\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 24.10, NNZs: 26625, Bias: -0.959624, T: 9024, Avg. loss: 0.155686\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 19.66, NNZs: 26632, Bias: -0.903722, T: 11280, Avg. loss: 0.065920\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 18.38, NNZs: 26628, Bias: -0.948596, T: 13536, Avg. loss: 0.021718\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 93.65, NNZs: 26040, Bias: 0.793651, T: 2256, Avg. loss: 0.765671\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 40.66, NNZs: 26496, Bias: 0.849484, T: 4512, Avg. loss: 0.924493\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 35.12, NNZs: 26633, Bias: 0.884208, T: 6768, Avg. loss: 0.288039\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 28.21, NNZs: 26656, Bias: 0.821931, T: 9024, Avg. loss: 0.152025\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 24.88, NNZs: 26665, Bias: 0.864288, T: 11280, Avg. loss: 0.070755\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 23.00, NNZs: 26680, Bias: 0.863065, T: 13536, Avg. loss: 0.025726\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 22.32, NNZs: 26682, Bias: 0.862132, T: 15792, Avg. loss: 0.009070\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 7 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 91.72, NNZs: 25943, Bias: -0.819020, T: 2256, Avg. loss: 0.722456\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 41.80, NNZs: 26416, Bias: -0.987838, T: 4512, Avg. loss: 0.916260\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 31.64, NNZs: 26536, Bias: -0.956789, T: 6768, Avg. loss: 0.285077\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 24.89, NNZs: 26617, Bias: -0.888891, T: 9024, Avg. loss: 0.159290\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 21.92, NNZs: 26619, Bias: -0.890900, T: 11280, Avg. loss: 0.062418\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 19.99, NNZs: 26635, Bias: -0.877507, T: 13536, Avg. loss: 0.025226\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 4/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.3241670976844645, clf__eta0=0.9631840511405841, clf__fit_intercept=True, clf__l1_ratio=0.5912641309775509, clf__learning_rate=optimal, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.6710686638981408, clf__shuffle=True, clf__tol=0.09654933943827881, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.786 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 93.55, NNZs: 25655, Bias: -1.086203, T: 2256, Avg. loss: 0.792036\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 40.84, NNZs: 26010, Bias: -1.027748, T: 4512, Avg. loss: 0.910219\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 33.84, NNZs: 26083, Bias: -0.943704, T: 6768, Avg. loss: 0.283081\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 26.26, NNZs: 26091, Bias: -0.926347, T: 9024, Avg. loss: 0.157669\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 23.25, NNZs: 26084, Bias: -0.917593, T: 11280, Avg. loss: 0.068485\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 21.80, NNZs: 26093, Bias: -0.930091, T: 13536, Avg. loss: 0.023823\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 92.34, NNZs: 25676, Bias: -1.049253, T: 2256, Avg. loss: 0.759175\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 39.57, NNZs: 25947, Bias: -0.846777, T: 4512, Avg. loss: 0.927697\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 30.77, NNZs: 25969, Bias: -0.867079, T: 6768, Avg. loss: 0.248212\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 23.98, NNZs: 25975, Bias: -0.917540, T: 9024, Avg. loss: 0.146623\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 20.15, NNZs: 25962, Bias: -0.945786, T: 11280, Avg. loss: 0.063459\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 18.34, NNZs: 25969, Bias: -0.908146, T: 13536, Avg. loss: 0.019807\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 93.87, NNZs: 25601, Bias: 0.968568, T: 2256, Avg. loss: 0.786833\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 40.25, NNZs: 25977, Bias: 0.817188, T: 4512, Avg. loss: 0.912311\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 35.64, NNZs: 26063, Bias: 0.865935, T: 6768, Avg. loss: 0.280202\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 27.79, NNZs: 26093, Bias: 0.861139, T: 9024, Avg. loss: 0.160211\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 25.00, NNZs: 26109, Bias: 0.879905, T: 11280, Avg. loss: 0.071656\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 23.43, NNZs: 26107, Bias: 0.877490, T: 13536, Avg. loss: 0.024932\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 91.42, NNZs: 25585, Bias: -0.986662, T: 2256, Avg. loss: 0.745071\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 40.58, NNZs: 25883, Bias: -0.876644, T: 4512, Avg. loss: 0.926661\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 31.59, NNZs: 26034, Bias: -0.873698, T: 6768, Avg. loss: 0.254714\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 24.65, NNZs: 26075, Bias: -0.954862, T: 9024, Avg. loss: 0.151746\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 21.32, NNZs: 26073, Bias: -0.953194, T: 11280, Avg. loss: 0.065318\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 19.96, NNZs: 26074, Bias: -0.943043, T: 13536, Avg. loss: 0.022344\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 18.81, NNZs: 26078, Bias: -0.921976, T: 15792, Avg. loss: 0.008191\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 7 epochs took 0.02 seconds\n",
      "[CV 5/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.3241670976844645, clf__eta0=0.9631840511405841, clf__fit_intercept=True, clf__l1_ratio=0.5912641309775509, clf__learning_rate=optimal, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.6710686638981408, clf__shuffle=True, clf__tol=0.09654933943827881, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.759 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 42.53, NNZs: 5470, Bias: 0.000000, T: 2256, Avg. loss: 0.223242\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 53.29, NNZs: 3516, Bias: 0.000000, T: 4512, Avg. loss: 0.078345\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 61.06, NNZs: 2686, Bias: 0.000000, T: 6768, Avg. loss: 0.047133\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 68.04, NNZs: 2230, Bias: 0.000000, T: 9024, Avg. loss: 0.038485\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 73.59, NNZs: 1917, Bias: 0.000000, T: 11280, Avg. loss: 0.033966\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 78.72, NNZs: 1706, Bias: 0.000000, T: 13536, Avg. loss: 0.029806\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 62.07, NNZs: 7674, Bias: 0.000000, T: 2256, Avg. loss: 0.261355\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 71.16, NNZs: 4818, Bias: 0.000000, T: 4512, Avg. loss: 0.061944\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 79.06, NNZs: 3356, Bias: 0.000000, T: 6768, Avg. loss: 0.040238\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 85.64, NNZs: 2593, Bias: 0.000000, T: 9024, Avg. loss: 0.033084\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 90.64, NNZs: 2210, Bias: 0.000000, T: 11280, Avg. loss: 0.028632\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 95.42, NNZs: 1869, Bias: 0.000000, T: 13536, Avg. loss: 0.022392\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 26.79, NNZs: 3777, Bias: 0.000000, T: 2256, Avg. loss: 0.304654\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 35.03, NNZs: 2169, Bias: 0.000000, T: 4512, Avg. loss: 0.171186\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 41.59, NNZs: 1709, Bias: 0.000000, T: 6768, Avg. loss: 0.135322\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 46.64, NNZs: 1407, Bias: 0.000000, T: 9024, Avg. loss: 0.116725\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 51.43, NNZs: 1277, Bias: 0.000000, T: 11280, Avg. loss: 0.105494\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 55.44, NNZs: 1131, Bias: 0.000000, T: 13536, Avg. loss: 0.096468\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 33.01, NNZs: 4472, Bias: 0.000000, T: 2256, Avg. loss: 0.190037\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 42.56, NNZs: 2779, Bias: 0.000000, T: 4512, Avg. loss: 0.083242\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 49.71, NNZs: 2071, Bias: 0.000000, T: 6768, Avg. loss: 0.061501\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 55.97, NNZs: 1812, Bias: 0.000000, T: 9024, Avg. loss: 0.051505\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 61.38, NNZs: 1581, Bias: 0.000000, T: 11280, Avg. loss: 0.046056\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 66.02, NNZs: 1397, Bias: 0.000000, T: 13536, Avg. loss: 0.042919\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 1/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.3509613152086368, clf__eta0=0.9934401124631351, clf__fit_intercept=False, clf__l1_ratio=0.5204998682261415, clf__learning_rate=constant, clf__loss=hinge, clf__max_iter=40, clf__penalty=l1, clf__power_t=0.5098574122392232, clf__shuffle=False, clf__tol=0.5563103350645606, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.729 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 43.08, NNZs: 5554, Bias: 0.000000, T: 2256, Avg. loss: 0.239463\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 55.66, NNZs: 3755, Bias: 0.000000, T: 4512, Avg. loss: 0.084307\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 63.55, NNZs: 2929, Bias: 0.000000, T: 6768, Avg. loss: 0.050349\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 69.95, NNZs: 2382, Bias: 0.000000, T: 9024, Avg. loss: 0.040411\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 75.68, NNZs: 2055, Bias: 0.000000, T: 11280, Avg. loss: 0.038323\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 81.19, NNZs: 1787, Bias: 0.000000, T: 13536, Avg. loss: 0.034889\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 59.76, NNZs: 7694, Bias: 0.000000, T: 2256, Avg. loss: 0.261883\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 69.04, NNZs: 4599, Bias: 0.000000, T: 4512, Avg. loss: 0.061834\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 77.43, NNZs: 3409, Bias: 0.000000, T: 6768, Avg. loss: 0.046069\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 83.93, NNZs: 2651, Bias: 0.000000, T: 9024, Avg. loss: 0.033730\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 89.95, NNZs: 2295, Bias: 0.000000, T: 11280, Avg. loss: 0.030862\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 96.11, NNZs: 2091, Bias: 0.000000, T: 13536, Avg. loss: 0.035707\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 26.89, NNZs: 3812, Bias: 0.000000, T: 2256, Avg. loss: 0.342965\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 35.59, NNZs: 2333, Bias: 0.000000, T: 4512, Avg. loss: 0.188900\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 41.97, NNZs: 1746, Bias: 0.000000, T: 6768, Avg. loss: 0.154559\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 47.35, NNZs: 1498, Bias: 0.000000, T: 9024, Avg. loss: 0.137146\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 52.13, NNZs: 1335, Bias: 0.000000, T: 11280, Avg. loss: 0.122452\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 56.23, NNZs: 1231, Bias: 0.000000, T: 13536, Avg. loss: 0.114925\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 34.05, NNZs: 4461, Bias: 0.000000, T: 2256, Avg. loss: 0.203917\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 43.50, NNZs: 2801, Bias: 0.000000, T: 4512, Avg. loss: 0.089210\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 50.90, NNZs: 2145, Bias: 0.000000, T: 6768, Avg. loss: 0.066395\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 57.26, NNZs: 1827, Bias: 0.000000, T: 9024, Avg. loss: 0.056128\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 62.78, NNZs: 1621, Bias: 0.000000, T: 11280, Avg. loss: 0.050161\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 67.57, NNZs: 1501, Bias: 0.000000, T: 13536, Avg. loss: 0.045612\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 2/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.3509613152086368, clf__eta0=0.9934401124631351, clf__fit_intercept=False, clf__l1_ratio=0.5204998682261415, clf__learning_rate=constant, clf__loss=hinge, clf__max_iter=40, clf__penalty=l1, clf__power_t=0.5098574122392232, clf__shuffle=False, clf__tol=0.5563103350645606, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.844 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 43.94, NNZs: 5735, Bias: 0.000000, T: 2256, Avg. loss: 0.239314\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 55.07, NNZs: 3738, Bias: 0.000000, T: 4512, Avg. loss: 0.079916\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 63.29, NNZs: 2886, Bias: 0.000000, T: 6768, Avg. loss: 0.049740\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 69.68, NNZs: 2364, Bias: 0.000000, T: 9024, Avg. loss: 0.043032\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 75.51, NNZs: 2105, Bias: 0.000000, T: 11280, Avg. loss: 0.036849\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 81.05, NNZs: 1869, Bias: 0.000000, T: 13536, Avg. loss: 0.033508\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 62.80, NNZs: 8021, Bias: 0.000000, T: 2256, Avg. loss: 0.317025\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 73.31, NNZs: 5046, Bias: 0.000000, T: 4512, Avg. loss: 0.071602\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 80.77, NNZs: 3546, Bias: 0.000000, T: 6768, Avg. loss: 0.045734\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 87.16, NNZs: 2841, Bias: 0.000000, T: 9024, Avg. loss: 0.039953\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 93.23, NNZs: 2311, Bias: 0.000000, T: 11280, Avg. loss: 0.032760\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 99.10, NNZs: 2111, Bias: 0.000000, T: 13536, Avg. loss: 0.034425\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 27.57, NNZs: 4069, Bias: 0.000000, T: 2256, Avg. loss: 0.366849\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 35.96, NNZs: 2383, Bias: 0.000000, T: 4512, Avg. loss: 0.200323\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 42.54, NNZs: 1810, Bias: 0.000000, T: 6768, Avg. loss: 0.164337\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 48.25, NNZs: 1525, Bias: 0.000000, T: 9024, Avg. loss: 0.142182\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 53.12, NNZs: 1363, Bias: 0.000000, T: 11280, Avg. loss: 0.128789\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 57.57, NNZs: 1243, Bias: 0.000000, T: 13536, Avg. loss: 0.116472\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 33.91, NNZs: 4471, Bias: 0.000000, T: 2256, Avg. loss: 0.205382\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 43.13, NNZs: 2701, Bias: 0.000000, T: 4512, Avg. loss: 0.091930\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 50.38, NNZs: 2207, Bias: 0.000000, T: 6768, Avg. loss: 0.071621\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 56.93, NNZs: 1898, Bias: 0.000000, T: 9024, Avg. loss: 0.061210\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 62.59, NNZs: 1669, Bias: 0.000000, T: 11280, Avg. loss: 0.054626\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 67.58, NNZs: 1545, Bias: 0.000000, T: 13536, Avg. loss: 0.049886\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 3/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.3509613152086368, clf__eta0=0.9934401124631351, clf__fit_intercept=False, clf__l1_ratio=0.5204998682261415, clf__learning_rate=constant, clf__loss=hinge, clf__max_iter=40, clf__penalty=l1, clf__power_t=0.5098574122392232, clf__shuffle=False, clf__tol=0.5563103350645606, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.909 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 44.49, NNZs: 5827, Bias: 0.000000, T: 2256, Avg. loss: 0.234222\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 55.51, NNZs: 3720, Bias: 0.000000, T: 4512, Avg. loss: 0.079374\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 63.81, NNZs: 2859, Bias: 0.000000, T: 6768, Avg. loss: 0.052601\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 70.82, NNZs: 2352, Bias: 0.000000, T: 9024, Avg. loss: 0.042153\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 76.89, NNZs: 2066, Bias: 0.000000, T: 11280, Avg. loss: 0.033806\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 82.02, NNZs: 1791, Bias: 0.000000, T: 13536, Avg. loss: 0.030848\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 61.04, NNZs: 7857, Bias: 0.000000, T: 2256, Avg. loss: 0.268344\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 70.67, NNZs: 4850, Bias: 0.000000, T: 4512, Avg. loss: 0.055676\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 78.76, NNZs: 3466, Bias: 0.000000, T: 6768, Avg. loss: 0.035417\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 86.25, NNZs: 2921, Bias: 0.000000, T: 9024, Avg. loss: 0.034903\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 91.90, NNZs: 2423, Bias: 0.000000, T: 11280, Avg. loss: 0.026216\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 97.18, NNZs: 2094, Bias: 0.000000, T: 13536, Avg. loss: 0.027532\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 27.30, NNZs: 3813, Bias: 0.000000, T: 2256, Avg. loss: 0.356933\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 35.87, NNZs: 2273, Bias: 0.000000, T: 4512, Avg. loss: 0.182926\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 42.34, NNZs: 1711, Bias: 0.000000, T: 6768, Avg. loss: 0.147185\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 47.71, NNZs: 1476, Bias: 0.000000, T: 9024, Avg. loss: 0.126652\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 52.27, NNZs: 1272, Bias: 0.000000, T: 11280, Avg. loss: 0.114812\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 56.50, NNZs: 1166, Bias: 0.000000, T: 13536, Avg. loss: 0.107556\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 33.22, NNZs: 4409, Bias: 0.000000, T: 2256, Avg. loss: 0.193849\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 42.40, NNZs: 2741, Bias: 0.000000, T: 4512, Avg. loss: 0.090147\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 49.82, NNZs: 2140, Bias: 0.000000, T: 6768, Avg. loss: 0.069916\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 56.13, NNZs: 1805, Bias: 0.000000, T: 9024, Avg. loss: 0.057503\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 61.61, NNZs: 1599, Bias: 0.000000, T: 11280, Avg. loss: 0.052622\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 66.20, NNZs: 1452, Bias: 0.000000, T: 13536, Avg. loss: 0.047082\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 4/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.3509613152086368, clf__eta0=0.9934401124631351, clf__fit_intercept=False, clf__l1_ratio=0.5204998682261415, clf__learning_rate=constant, clf__loss=hinge, clf__max_iter=40, clf__penalty=l1, clf__power_t=0.5098574122392232, clf__shuffle=False, clf__tol=0.5563103350645606, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.836 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 43.97, NNZs: 5649, Bias: 0.000000, T: 2256, Avg. loss: 0.229951\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 55.59, NNZs: 3742, Bias: 0.000000, T: 4512, Avg. loss: 0.081774\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 63.98, NNZs: 2850, Bias: 0.000000, T: 6768, Avg. loss: 0.046697\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 70.85, NNZs: 2374, Bias: 0.000000, T: 9024, Avg. loss: 0.037758\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 76.60, NNZs: 2013, Bias: 0.000000, T: 11280, Avg. loss: 0.030655\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 81.82, NNZs: 1790, Bias: 0.000000, T: 13536, Avg. loss: 0.029086\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 59.27, NNZs: 7524, Bias: 0.000000, T: 2256, Avg. loss: 0.253702\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 71.65, NNZs: 4836, Bias: 0.000000, T: 4512, Avg. loss: 0.070592\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 79.06, NNZs: 3556, Bias: 0.000000, T: 6768, Avg. loss: 0.041894\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 86.23, NNZs: 2862, Bias: 0.000000, T: 9024, Avg. loss: 0.032138\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 92.07, NNZs: 2408, Bias: 0.000000, T: 11280, Avg. loss: 0.028658\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 97.79, NNZs: 2080, Bias: 0.000000, T: 13536, Avg. loss: 0.028993\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 26.76, NNZs: 3823, Bias: 0.000000, T: 2256, Avg. loss: 0.335123\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 35.42, NNZs: 2215, Bias: 0.000000, T: 4512, Avg. loss: 0.183258\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 41.91, NNZs: 1646, Bias: 0.000000, T: 6768, Avg. loss: 0.148443\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 47.26, NNZs: 1402, Bias: 0.000000, T: 9024, Avg. loss: 0.130129\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 51.89, NNZs: 1240, Bias: 0.000000, T: 11280, Avg. loss: 0.119303\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 56.21, NNZs: 1145, Bias: 0.000000, T: 13536, Avg. loss: 0.108721\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 33.44, NNZs: 4356, Bias: 0.000000, T: 2256, Avg. loss: 0.198174\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 43.09, NNZs: 2641, Bias: 0.000000, T: 4512, Avg. loss: 0.085741\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 50.40, NNZs: 2133, Bias: 0.000000, T: 6768, Avg. loss: 0.063275\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 56.71, NNZs: 1770, Bias: 0.000000, T: 9024, Avg. loss: 0.055376\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 62.12, NNZs: 1592, Bias: 0.000000, T: 11280, Avg. loss: 0.048070\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 67.12, NNZs: 1442, Bias: 0.000000, T: 13536, Avg. loss: 0.044409\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 5/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.3509613152086368, clf__eta0=0.9934401124631351, clf__fit_intercept=False, clf__l1_ratio=0.5204998682261415, clf__learning_rate=constant, clf__loss=hinge, clf__max_iter=40, clf__penalty=l1, clf__power_t=0.5098574122392232, clf__shuffle=False, clf__tol=0.5563103350645606, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.834 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.28, NNZs: 12897, Bias: 0.000000, T: 2256, Avg. loss: 0.693473\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.38, NNZs: 12897, Bias: 0.000000, T: 4512, Avg. loss: 0.677015\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.46, NNZs: 12897, Bias: 0.000000, T: 6768, Avg. loss: 0.666870\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.52, NNZs: 12897, Bias: 0.000000, T: 9024, Avg. loss: 0.659001\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.57, NNZs: 12897, Bias: 0.000000, T: 11280, Avg. loss: 0.652216\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.62, NNZs: 12897, Bias: 0.000000, T: 13536, Avg. loss: 0.646209\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.27, NNZs: 12897, Bias: 0.000000, T: 2256, Avg. loss: 0.692892\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.35, NNZs: 12897, Bias: 0.000000, T: 4512, Avg. loss: 0.678616\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.42, NNZs: 12897, Bias: 0.000000, T: 6768, Avg. loss: 0.669991\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.47, NNZs: 12897, Bias: 0.000000, T: 9024, Avg. loss: 0.663425\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.51, NNZs: 12897, Bias: 0.000000, T: 11280, Avg. loss: 0.657879\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.55, NNZs: 12897, Bias: 0.000000, T: 13536, Avg. loss: 0.652778\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.24, NNZs: 12897, Bias: 0.000000, T: 2256, Avg. loss: 0.698489\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.33, NNZs: 12897, Bias: 0.000000, T: 4512, Avg. loss: 0.687376\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.39, NNZs: 12897, Bias: 0.000000, T: 6768, Avg. loss: 0.680600\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.44, NNZs: 12897, Bias: 0.000000, T: 9024, Avg. loss: 0.675208\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.49, NNZs: 12897, Bias: 0.000000, T: 11280, Avg. loss: 0.670649\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.53, NNZs: 12897, Bias: 0.000000, T: 13536, Avg. loss: 0.666626\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.28, NNZs: 12897, Bias: 0.000000, T: 2256, Avg. loss: 0.695964\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.38, NNZs: 12897, Bias: 0.000000, T: 4512, Avg. loss: 0.680799\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.46, NNZs: 12897, Bias: 0.000000, T: 6768, Avg. loss: 0.671583\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.52, NNZs: 12897, Bias: 0.000000, T: 9024, Avg. loss: 0.664332\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.58, NNZs: 12897, Bias: 0.000000, T: 11280, Avg. loss: 0.658171\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.63, NNZs: 12897, Bias: 0.000000, T: 13536, Avg. loss: 0.652702\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "[CV 1/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.28658617296069355, clf__eta0=0.03398405924608927, clf__fit_intercept=False, clf__l1_ratio=0.08227014493927165, clf__learning_rate=invscaling, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.5467473202425025, clf__shuffle=True, clf__tol=0.9099604695658384, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.583 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.29, NNZs: 12717, Bias: 0.000000, T: 2256, Avg. loss: 0.692914\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.39, NNZs: 12717, Bias: 0.000000, T: 4512, Avg. loss: 0.676434\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.46, NNZs: 12717, Bias: 0.000000, T: 6768, Avg. loss: 0.666419\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.52, NNZs: 12717, Bias: 0.000000, T: 9024, Avg. loss: 0.658576\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.58, NNZs: 12717, Bias: 0.000000, T: 11280, Avg. loss: 0.651864\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.63, NNZs: 12717, Bias: 0.000000, T: 13536, Avg. loss: 0.645962\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.27, NNZs: 12717, Bias: 0.000000, T: 2256, Avg. loss: 0.709492\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.33, NNZs: 12717, Bias: 0.000000, T: 4512, Avg. loss: 0.695912\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.38, NNZs: 12717, Bias: 0.000000, T: 6768, Avg. loss: 0.687766\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.42, NNZs: 12717, Bias: 0.000000, T: 9024, Avg. loss: 0.681606\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.46, NNZs: 12717, Bias: 0.000000, T: 11280, Avg. loss: 0.676106\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.49, NNZs: 12717, Bias: 0.000000, T: 13536, Avg. loss: 0.671212\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.24, NNZs: 12717, Bias: 0.000000, T: 2256, Avg. loss: 0.698700\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.33, NNZs: 12717, Bias: 0.000000, T: 4512, Avg. loss: 0.687503\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.39, NNZs: 12717, Bias: 0.000000, T: 6768, Avg. loss: 0.680639\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.44, NNZs: 12717, Bias: 0.000000, T: 9024, Avg. loss: 0.675227\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.49, NNZs: 12717, Bias: 0.000000, T: 11280, Avg. loss: 0.670652\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.53, NNZs: 12717, Bias: 0.000000, T: 13536, Avg. loss: 0.666595\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.30, NNZs: 12717, Bias: 0.000000, T: 2256, Avg. loss: 0.694591\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.40, NNZs: 12717, Bias: 0.000000, T: 4512, Avg. loss: 0.679410\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.48, NNZs: 12717, Bias: 0.000000, T: 6768, Avg. loss: 0.670242\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.54, NNZs: 12717, Bias: 0.000000, T: 9024, Avg. loss: 0.662995\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.60, NNZs: 12717, Bias: 0.000000, T: 11280, Avg. loss: 0.656838\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.65, NNZs: 12717, Bias: 0.000000, T: 13536, Avg. loss: 0.651402\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "[CV 2/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.28658617296069355, clf__eta0=0.03398405924608927, clf__fit_intercept=False, clf__l1_ratio=0.08227014493927165, clf__learning_rate=invscaling, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.5467473202425025, clf__shuffle=True, clf__tol=0.9099604695658384, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.628 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.29, NNZs: 13141, Bias: 0.000000, T: 2256, Avg. loss: 0.693600\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.39, NNZs: 13141, Bias: 0.000000, T: 4512, Avg. loss: 0.677866\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.46, NNZs: 13141, Bias: 0.000000, T: 6768, Avg. loss: 0.668270\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.52, NNZs: 13141, Bias: 0.000000, T: 9024, Avg. loss: 0.660684\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.57, NNZs: 13141, Bias: 0.000000, T: 11280, Avg. loss: 0.654328\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.62, NNZs: 13141, Bias: 0.000000, T: 13536, Avg. loss: 0.648554\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.26, NNZs: 13141, Bias: 0.000000, T: 2256, Avg. loss: 0.694977\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.34, NNZs: 13141, Bias: 0.000000, T: 4512, Avg. loss: 0.680810\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.40, NNZs: 13141, Bias: 0.000000, T: 6768, Avg. loss: 0.672656\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.45, NNZs: 13141, Bias: 0.000000, T: 9024, Avg. loss: 0.665909\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.49, NNZs: 13141, Bias: 0.000000, T: 11280, Avg. loss: 0.660493\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.53, NNZs: 13141, Bias: 0.000000, T: 13536, Avg. loss: 0.655379\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.20, NNZs: 13141, Bias: 0.000000, T: 2256, Avg. loss: 0.701736\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.29, NNZs: 13141, Bias: 0.000000, T: 4512, Avg. loss: 0.691477\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.35, NNZs: 13141, Bias: 0.000000, T: 6768, Avg. loss: 0.685131\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.40, NNZs: 13141, Bias: 0.000000, T: 9024, Avg. loss: 0.680129\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.44, NNZs: 13141, Bias: 0.000000, T: 11280, Avg. loss: 0.675860\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.48, NNZs: 13141, Bias: 0.000000, T: 13536, Avg. loss: 0.672101\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.28, NNZs: 13141, Bias: 0.000000, T: 2256, Avg. loss: 0.695723\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.38, NNZs: 13141, Bias: 0.000000, T: 4512, Avg. loss: 0.681129\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.46, NNZs: 13141, Bias: 0.000000, T: 6768, Avg. loss: 0.672268\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.53, NNZs: 13141, Bias: 0.000000, T: 9024, Avg. loss: 0.665255\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.58, NNZs: 13141, Bias: 0.000000, T: 11280, Avg. loss: 0.659294\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.63, NNZs: 13141, Bias: 0.000000, T: 13536, Avg. loss: 0.654020\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "[CV 3/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.28658617296069355, clf__eta0=0.03398405924608927, clf__fit_intercept=False, clf__l1_ratio=0.08227014493927165, clf__learning_rate=invscaling, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.5467473202425025, clf__shuffle=True, clf__tol=0.9099604695658384, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.628 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.29, NNZs: 13618, Bias: 0.000000, T: 2256, Avg. loss: 0.692752\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.38, NNZs: 13618, Bias: 0.000000, T: 4512, Avg. loss: 0.676622\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.46, NNZs: 13618, Bias: 0.000000, T: 6768, Avg. loss: 0.666900\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.52, NNZs: 13618, Bias: 0.000000, T: 9024, Avg. loss: 0.659131\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.57, NNZs: 13618, Bias: 0.000000, T: 11280, Avg. loss: 0.652543\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.62, NNZs: 13618, Bias: 0.000000, T: 13536, Avg. loss: 0.646765\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.23, NNZs: 13618, Bias: 0.000000, T: 2256, Avg. loss: 0.699942\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.31, NNZs: 13618, Bias: 0.000000, T: 4512, Avg. loss: 0.685678\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.37, NNZs: 13618, Bias: 0.000000, T: 6768, Avg. loss: 0.677564\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.42, NNZs: 13618, Bias: 0.000000, T: 9024, Avg. loss: 0.670496\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.46, NNZs: 13618, Bias: 0.000000, T: 11280, Avg. loss: 0.665020\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.50, NNZs: 13618, Bias: 0.000000, T: 13536, Avg. loss: 0.660001\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.21, NNZs: 13618, Bias: 0.000000, T: 2256, Avg. loss: 0.701117\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.29, NNZs: 13618, Bias: 0.000000, T: 4512, Avg. loss: 0.690433\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.36, NNZs: 13618, Bias: 0.000000, T: 6768, Avg. loss: 0.683917\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.41, NNZs: 13618, Bias: 0.000000, T: 9024, Avg. loss: 0.678726\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.45, NNZs: 13618, Bias: 0.000000, T: 11280, Avg. loss: 0.674332\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.49, NNZs: 13618, Bias: 0.000000, T: 13536, Avg. loss: 0.670447\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.29, NNZs: 13618, Bias: 0.000000, T: 2256, Avg. loss: 0.695031\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.40, NNZs: 13618, Bias: 0.000000, T: 4512, Avg. loss: 0.679794\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.48, NNZs: 13618, Bias: 0.000000, T: 6768, Avg. loss: 0.670626\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.54, NNZs: 13618, Bias: 0.000000, T: 9024, Avg. loss: 0.663396\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.60, NNZs: 13618, Bias: 0.000000, T: 11280, Avg. loss: 0.657241\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.65, NNZs: 13618, Bias: 0.000000, T: 13536, Avg. loss: 0.651820\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "[CV 4/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.28658617296069355, clf__eta0=0.03398405924608927, clf__fit_intercept=False, clf__l1_ratio=0.08227014493927165, clf__learning_rate=invscaling, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.5467473202425025, clf__shuffle=True, clf__tol=0.9099604695658384, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.583 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.27, NNZs: 13464, Bias: 0.000000, T: 2256, Avg. loss: 0.694537\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.37, NNZs: 13464, Bias: 0.000000, T: 4512, Avg. loss: 0.678393\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.44, NNZs: 13464, Bias: 0.000000, T: 6768, Avg. loss: 0.668581\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.50, NNZs: 13464, Bias: 0.000000, T: 9024, Avg. loss: 0.660913\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.56, NNZs: 13464, Bias: 0.000000, T: 11280, Avg. loss: 0.654324\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.60, NNZs: 13464, Bias: 0.000000, T: 13536, Avg. loss: 0.648500\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.24, NNZs: 13464, Bias: 0.000000, T: 2256, Avg. loss: 0.695337\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.32, NNZs: 13464, Bias: 0.000000, T: 4512, Avg. loss: 0.681643\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.38, NNZs: 13464, Bias: 0.000000, T: 6768, Avg. loss: 0.673737\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.43, NNZs: 13464, Bias: 0.000000, T: 9024, Avg. loss: 0.667147\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.48, NNZs: 13464, Bias: 0.000000, T: 11280, Avg. loss: 0.661737\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.52, NNZs: 13464, Bias: 0.000000, T: 13536, Avg. loss: 0.656826\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.23, NNZs: 13464, Bias: 0.000000, T: 2256, Avg. loss: 0.699479\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.31, NNZs: 13464, Bias: 0.000000, T: 4512, Avg. loss: 0.688501\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.38, NNZs: 13464, Bias: 0.000000, T: 6768, Avg. loss: 0.681776\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.43, NNZs: 13464, Bias: 0.000000, T: 9024, Avg. loss: 0.676452\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.47, NNZs: 13464, Bias: 0.000000, T: 11280, Avg. loss: 0.671891\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.51, NNZs: 13464, Bias: 0.000000, T: 13536, Avg. loss: 0.667876\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.29, NNZs: 13464, Bias: 0.000000, T: 2256, Avg. loss: 0.694749\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.40, NNZs: 13464, Bias: 0.000000, T: 4512, Avg. loss: 0.679545\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.48, NNZs: 13464, Bias: 0.000000, T: 6768, Avg. loss: 0.670377\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.54, NNZs: 13464, Bias: 0.000000, T: 9024, Avg. loss: 0.663154\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.60, NNZs: 13464, Bias: 0.000000, T: 11280, Avg. loss: 0.656987\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.65, NNZs: 13464, Bias: 0.000000, T: 13536, Avg. loss: 0.651560\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 5/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.28658617296069355, clf__eta0=0.03398405924608927, clf__fit_intercept=False, clf__l1_ratio=0.08227014493927165, clf__learning_rate=invscaling, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.5467473202425025, clf__shuffle=True, clf__tol=0.9099604695658384, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.617 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 24.26, NNZs: 12896, Bias: 0.000000, T: 2256, Avg. loss: 0.332510\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 32.29, NNZs: 12896, Bias: 0.000000, T: 4512, Avg. loss: 0.192766\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 36.80, NNZs: 12896, Bias: 0.000000, T: 6768, Avg. loss: 0.149037\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 39.57, NNZs: 12896, Bias: 0.000000, T: 9024, Avg. loss: 0.128521\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 41.34, NNZs: 12896, Bias: 0.000000, T: 11280, Avg. loss: 0.117127\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 42.51, NNZs: 12896, Bias: 0.000000, T: 13536, Avg. loss: 0.110268\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 42.62, NNZs: 12896, Bias: 0.000000, T: 15792, Avg. loss: 0.106443\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 42.71, NNZs: 12896, Bias: 0.000000, T: 18048, Avg. loss: 0.103103\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 42.80, NNZs: 12896, Bias: 0.000000, T: 20304, Avg. loss: 0.101320\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 42.87, NNZs: 12896, Bias: 0.000000, T: 22560, Avg. loss: 0.100247\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 42.94, NNZs: 12896, Bias: 0.000000, T: 24816, Avg. loss: 0.099528\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 42.96, NNZs: 12896, Bias: 0.000000, T: 27072, Avg. loss: 0.098856\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 42.97, NNZs: 12896, Bias: 0.000000, T: 29328, Avg. loss: 0.098658\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 42.98, NNZs: 12896, Bias: 0.000000, T: 31584, Avg. loss: 0.098479\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 42.99, NNZs: 12896, Bias: 0.000000, T: 33840, Avg. loss: 0.098316\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 43.00, NNZs: 12896, Bias: 0.000000, T: 36096, Avg. loss: 0.098168\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 43.00, NNZs: 12896, Bias: 0.000000, T: 38352, Avg. loss: 0.098009\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 43.00, NNZs: 12896, Bias: 0.000000, T: 40608, Avg. loss: 0.097979\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 43.00, NNZs: 12896, Bias: 0.000000, T: 42864, Avg. loss: 0.097949\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 43.00, NNZs: 12896, Bias: 0.000000, T: 45120, Avg. loss: 0.097919\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 29.25, NNZs: 12896, Bias: 0.000000, T: 2256, Avg. loss: 0.364236\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 38.31, NNZs: 12896, Bias: 0.000000, T: 4512, Avg. loss: 0.180456\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 42.74, NNZs: 12896, Bias: 0.000000, T: 6768, Avg. loss: 0.131605\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 45.17, NNZs: 12896, Bias: 0.000000, T: 9024, Avg. loss: 0.111855\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 46.57, NNZs: 12896, Bias: 0.000000, T: 11280, Avg. loss: 0.102122\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 47.42, NNZs: 12896, Bias: 0.000000, T: 13536, Avg. loss: 0.096775\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 47.39, NNZs: 12896, Bias: 0.000000, T: 15792, Avg. loss: 0.092472\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 47.36, NNZs: 12896, Bias: 0.000000, T: 18048, Avg. loss: 0.089690\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 47.33, NNZs: 12896, Bias: 0.000000, T: 20304, Avg. loss: 0.088237\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 47.30, NNZs: 12896, Bias: 0.000000, T: 22560, Avg. loss: 0.087401\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 47.28, NNZs: 12896, Bias: 0.000000, T: 24816, Avg. loss: 0.086891\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 47.27, NNZs: 12896, Bias: 0.000000, T: 27072, Avg. loss: 0.087184\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 47.26, NNZs: 12896, Bias: 0.000000, T: 29328, Avg. loss: 0.086812\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 47.25, NNZs: 12896, Bias: 0.000000, T: 31584, Avg. loss: 0.086511\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 47.24, NNZs: 12896, Bias: 0.000000, T: 33840, Avg. loss: 0.086263\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 47.23, NNZs: 12896, Bias: 0.000000, T: 36096, Avg. loss: 0.086058\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 47.22, NNZs: 12896, Bias: 0.000000, T: 38352, Avg. loss: 0.086088\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 47.22, NNZs: 12896, Bias: 0.000000, T: 40608, Avg. loss: 0.086040\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 47.22, NNZs: 12896, Bias: 0.000000, T: 42864, Avg. loss: 0.085994\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 47.22, NNZs: 12896, Bias: 0.000000, T: 45120, Avg. loss: 0.085950\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 15.84, NNZs: 12896, Bias: 0.000000, T: 2256, Avg. loss: 0.425191\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 21.04, NNZs: 12896, Bias: 0.000000, T: 4512, Avg. loss: 0.301468\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 24.13, NNZs: 12896, Bias: 0.000000, T: 6768, Avg. loss: 0.247068\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 26.14, NNZs: 12896, Bias: 0.000000, T: 9024, Avg. loss: 0.219832\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 27.51, NNZs: 12896, Bias: 0.000000, T: 11280, Avg. loss: 0.203793\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 28.48, NNZs: 12896, Bias: 0.000000, T: 13536, Avg. loss: 0.193503\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 28.59, NNZs: 12896, Bias: 0.000000, T: 15792, Avg. loss: 0.193138\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 28.70, NNZs: 12896, Bias: 0.000000, T: 18048, Avg. loss: 0.189263\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 28.81, NNZs: 12896, Bias: 0.000000, T: 20304, Avg. loss: 0.186323\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 28.92, NNZs: 12896, Bias: 0.000000, T: 22560, Avg. loss: 0.184027\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 29.02, NNZs: 12896, Bias: 0.000000, T: 24816, Avg. loss: 0.182188\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 29.04, NNZs: 12896, Bias: 0.000000, T: 27072, Avg. loss: 0.181860\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 29.06, NNZs: 12896, Bias: 0.000000, T: 29328, Avg. loss: 0.181469\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 29.08, NNZs: 12896, Bias: 0.000000, T: 31584, Avg. loss: 0.181096\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 29.09, NNZs: 12896, Bias: 0.000000, T: 33840, Avg. loss: 0.180739\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 29.11, NNZs: 12896, Bias: 0.000000, T: 36096, Avg. loss: 0.180397\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 29.12, NNZs: 12896, Bias: 0.000000, T: 38352, Avg. loss: 0.180312\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 29.12, NNZs: 12896, Bias: 0.000000, T: 40608, Avg. loss: 0.180244\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 29.12, NNZs: 12896, Bias: 0.000000, T: 42864, Avg. loss: 0.180175\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 29.13, NNZs: 12896, Bias: 0.000000, T: 45120, Avg. loss: 0.180108\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 22.06, NNZs: 12896, Bias: 0.000000, T: 2256, Avg. loss: 0.327394\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 28.12, NNZs: 12896, Bias: 0.000000, T: 4512, Avg. loss: 0.186230\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 31.72, NNZs: 12896, Bias: 0.000000, T: 6768, Avg. loss: 0.153163\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 34.14, NNZs: 12896, Bias: 0.000000, T: 9024, Avg. loss: 0.135771\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 35.83, NNZs: 12896, Bias: 0.000000, T: 11280, Avg. loss: 0.125185\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 37.03, NNZs: 12896, Bias: 0.000000, T: 13536, Avg. loss: 0.118318\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 37.23, NNZs: 12896, Bias: 0.000000, T: 15792, Avg. loss: 0.109806\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 37.39, NNZs: 12896, Bias: 0.000000, T: 18048, Avg. loss: 0.108916\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 37.54, NNZs: 12896, Bias: 0.000000, T: 20304, Avg. loss: 0.108181\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 37.68, NNZs: 12896, Bias: 0.000000, T: 22560, Avg. loss: 0.107537\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 37.80, NNZs: 12896, Bias: 0.000000, T: 24816, Avg. loss: 0.106963\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 37.82, NNZs: 12896, Bias: 0.000000, T: 27072, Avg. loss: 0.105570\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 37.84, NNZs: 12896, Bias: 0.000000, T: 29328, Avg. loss: 0.105472\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 37.87, NNZs: 12896, Bias: 0.000000, T: 31584, Avg. loss: 0.105376\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 37.89, NNZs: 12896, Bias: 0.000000, T: 33840, Avg. loss: 0.105281\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 37.91, NNZs: 12896, Bias: 0.000000, T: 36096, Avg. loss: 0.105189\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 37.92, NNZs: 12896, Bias: 0.000000, T: 38352, Avg. loss: 0.104919\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 37.92, NNZs: 12896, Bias: 0.000000, T: 40608, Avg. loss: 0.104901\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 37.92, NNZs: 12896, Bias: 0.000000, T: 42864, Avg. loss: 0.104883\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 37.93, NNZs: 12896, Bias: 0.000000, T: 45120, Avg. loss: 0.104865\n",
      "Total training time: 0.05 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s finished\n",
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.42493015701647596, clf__eta0=0.6773009699604285, clf__fit_intercept=False, clf__l1_ratio=0.7301998277223162, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.017782879504616322, clf__shuffle=False, clf__tol=0.19519881462597577, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.662 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s finished\n",
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 24.32, NNZs: 12715, Bias: 0.000000, T: 2256, Avg. loss: 0.347518\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 32.35, NNZs: 12715, Bias: 0.000000, T: 4512, Avg. loss: 0.206632\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 36.92, NNZs: 12715, Bias: 0.000000, T: 6768, Avg. loss: 0.161887\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 39.76, NNZs: 12715, Bias: 0.000000, T: 9024, Avg. loss: 0.140229\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 41.58, NNZs: 12715, Bias: 0.000000, T: 11280, Avg. loss: 0.128070\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 42.79, NNZs: 12715, Bias: 0.000000, T: 13536, Avg. loss: 0.120702\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 42.89, NNZs: 12715, Bias: 0.000000, T: 15792, Avg. loss: 0.115235\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 42.98, NNZs: 12715, Bias: 0.000000, T: 18048, Avg. loss: 0.112652\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 43.07, NNZs: 12715, Bias: 0.000000, T: 20304, Avg. loss: 0.111178\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 43.15, NNZs: 12715, Bias: 0.000000, T: 22560, Avg. loss: 0.110232\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 43.23, NNZs: 12715, Bias: 0.000000, T: 24816, Avg. loss: 0.109557\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 43.24, NNZs: 12715, Bias: 0.000000, T: 27072, Avg. loss: 0.108522\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 43.25, NNZs: 12715, Bias: 0.000000, T: 29328, Avg. loss: 0.108365\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 43.26, NNZs: 12715, Bias: 0.000000, T: 31584, Avg. loss: 0.108221\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 43.27, NNZs: 12715, Bias: 0.000000, T: 33840, Avg. loss: 0.108088\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 43.28, NNZs: 12715, Bias: 0.000000, T: 36096, Avg. loss: 0.107964\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 43.28, NNZs: 12715, Bias: 0.000000, T: 38352, Avg. loss: 0.107742\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 43.29, NNZs: 12715, Bias: 0.000000, T: 40608, Avg. loss: 0.107718\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 43.29, NNZs: 12715, Bias: 0.000000, T: 42864, Avg. loss: 0.107693\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 43.29, NNZs: 12715, Bias: 0.000000, T: 45120, Avg. loss: 0.107669\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 29.55, NNZs: 12715, Bias: 0.000000, T: 2256, Avg. loss: 0.385619\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 38.57, NNZs: 12715, Bias: 0.000000, T: 4512, Avg. loss: 0.198889\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 43.07, NNZs: 12715, Bias: 0.000000, T: 6768, Avg. loss: 0.147850\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 45.57, NNZs: 12715, Bias: 0.000000, T: 9024, Avg. loss: 0.126154\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 47.04, NNZs: 12715, Bias: 0.000000, T: 11280, Avg. loss: 0.115380\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 47.93, NNZs: 12715, Bias: 0.000000, T: 13536, Avg. loss: 0.109430\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 47.90, NNZs: 12715, Bias: 0.000000, T: 15792, Avg. loss: 0.103615\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 47.88, NNZs: 12715, Bias: 0.000000, T: 18048, Avg. loss: 0.101407\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 47.85, NNZs: 12715, Bias: 0.000000, T: 20304, Avg. loss: 0.099934\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 47.83, NNZs: 12715, Bias: 0.000000, T: 22560, Avg. loss: 0.099030\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 47.81, NNZs: 12715, Bias: 0.000000, T: 24816, Avg. loss: 0.098474\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 47.80, NNZs: 12715, Bias: 0.000000, T: 27072, Avg. loss: 0.098081\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 47.79, NNZs: 12715, Bias: 0.000000, T: 29328, Avg. loss: 0.097797\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 47.79, NNZs: 12715, Bias: 0.000000, T: 31584, Avg. loss: 0.097568\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 47.78, NNZs: 12715, Bias: 0.000000, T: 33840, Avg. loss: 0.097381\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 47.77, NNZs: 12715, Bias: 0.000000, T: 36096, Avg. loss: 0.097226\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 47.77, NNZs: 12715, Bias: 0.000000, T: 38352, Avg. loss: 0.097137\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 47.77, NNZs: 12715, Bias: 0.000000, T: 40608, Avg. loss: 0.097100\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 47.76, NNZs: 12715, Bias: 0.000000, T: 42864, Avg. loss: 0.097065\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 47.76, NNZs: 12715, Bias: 0.000000, T: 45120, Avg. loss: 0.097031\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 15.62, NNZs: 12715, Bias: 0.000000, T: 2256, Avg. loss: 0.449117\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 20.84, NNZs: 12715, Bias: 0.000000, T: 4512, Avg. loss: 0.320643\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 24.00, NNZs: 12715, Bias: 0.000000, T: 6768, Avg. loss: 0.267337\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 26.08, NNZs: 12715, Bias: 0.000000, T: 9024, Avg. loss: 0.239600\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 27.52, NNZs: 12715, Bias: 0.000000, T: 11280, Avg. loss: 0.222860\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 28.54, NNZs: 12715, Bias: 0.000000, T: 13536, Avg. loss: 0.211943\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 28.65, NNZs: 12715, Bias: 0.000000, T: 15792, Avg. loss: 0.208113\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 28.76, NNZs: 12715, Bias: 0.000000, T: 18048, Avg. loss: 0.204951\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 28.87, NNZs: 12715, Bias: 0.000000, T: 20304, Avg. loss: 0.202507\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 28.98, NNZs: 12715, Bias: 0.000000, T: 22560, Avg. loss: 0.200557\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 29.09, NNZs: 12715, Bias: 0.000000, T: 24816, Avg. loss: 0.198958\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 29.11, NNZs: 12715, Bias: 0.000000, T: 27072, Avg. loss: 0.197927\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 29.12, NNZs: 12715, Bias: 0.000000, T: 29328, Avg. loss: 0.197611\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 29.14, NNZs: 12715, Bias: 0.000000, T: 31584, Avg. loss: 0.197307\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 29.16, NNZs: 12715, Bias: 0.000000, T: 33840, Avg. loss: 0.197015\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 29.18, NNZs: 12715, Bias: 0.000000, T: 36096, Avg. loss: 0.196734\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 29.18, NNZs: 12715, Bias: 0.000000, T: 38352, Avg. loss: 0.196515\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 29.19, NNZs: 12715, Bias: 0.000000, T: 40608, Avg. loss: 0.196459\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 29.19, NNZs: 12715, Bias: 0.000000, T: 42864, Avg. loss: 0.196403\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 29.19, NNZs: 12715, Bias: 0.000000, T: 45120, Avg. loss: 0.196348\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 22.11, NNZs: 12715, Bias: 0.000000, T: 2256, Avg. loss: 0.340192\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 28.43, NNZs: 12715, Bias: 0.000000, T: 4512, Avg. loss: 0.197901\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 32.16, NNZs: 12715, Bias: 0.000000, T: 6768, Avg. loss: 0.162600\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 34.64, NNZs: 12715, Bias: 0.000000, T: 9024, Avg. loss: 0.144186\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 36.35, NNZs: 12715, Bias: 0.000000, T: 11280, Avg. loss: 0.133086\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 37.55, NNZs: 12715, Bias: 0.000000, T: 13536, Avg. loss: 0.125944\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 37.72, NNZs: 12715, Bias: 0.000000, T: 15792, Avg. loss: 0.117260\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 37.88, NNZs: 12715, Bias: 0.000000, T: 18048, Avg. loss: 0.116489\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 38.02, NNZs: 12715, Bias: 0.000000, T: 20304, Avg. loss: 0.115793\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 38.15, NNZs: 12715, Bias: 0.000000, T: 22560, Avg. loss: 0.115164\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 38.27, NNZs: 12715, Bias: 0.000000, T: 24816, Avg. loss: 0.114594\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 38.29, NNZs: 12715, Bias: 0.000000, T: 27072, Avg. loss: 0.113173\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 38.31, NNZs: 12715, Bias: 0.000000, T: 29328, Avg. loss: 0.113079\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 38.33, NNZs: 12715, Bias: 0.000000, T: 31584, Avg. loss: 0.112986\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 38.35, NNZs: 12715, Bias: 0.000000, T: 33840, Avg. loss: 0.112894\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 38.38, NNZs: 12715, Bias: 0.000000, T: 36096, Avg. loss: 0.112804\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 38.38, NNZs: 12715, Bias: 0.000000, T: 38352, Avg. loss: 0.112529\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 38.38, NNZs: 12715, Bias: 0.000000, T: 40608, Avg. loss: 0.112512\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 38.39, NNZs: 12715, Bias: 0.000000, T: 42864, Avg. loss: 0.112494\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 38.39, NNZs: 12715, Bias: 0.000000, T: 45120, Avg. loss: 0.112477\n",
      "Total training time: 0.04 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.42493015701647596, clf__eta0=0.6773009699604285, clf__fit_intercept=False, clf__l1_ratio=0.7301998277223162, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.017782879504616322, clf__shuffle=False, clf__tol=0.19519881462597577, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.726 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s finished\n",
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 24.90, NNZs: 13144, Bias: 0.000000, T: 2256, Avg. loss: 0.345107\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 32.58, NNZs: 13144, Bias: 0.000000, T: 4512, Avg. loss: 0.196413\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 36.90, NNZs: 13144, Bias: 0.000000, T: 6768, Avg. loss: 0.154403\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 39.56, NNZs: 13144, Bias: 0.000000, T: 9024, Avg. loss: 0.134403\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 41.28, NNZs: 13144, Bias: 0.000000, T: 11280, Avg. loss: 0.123218\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 42.41, NNZs: 13144, Bias: 0.000000, T: 13536, Avg. loss: 0.116438\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 42.49, NNZs: 13144, Bias: 0.000000, T: 15792, Avg. loss: 0.109397\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 42.57, NNZs: 13144, Bias: 0.000000, T: 18048, Avg. loss: 0.108028\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 42.65, NNZs: 13144, Bias: 0.000000, T: 20304, Avg. loss: 0.107151\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 42.72, NNZs: 13144, Bias: 0.000000, T: 22560, Avg. loss: 0.106520\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 42.79, NNZs: 13144, Bias: 0.000000, T: 24816, Avg. loss: 0.106023\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 42.80, NNZs: 13144, Bias: 0.000000, T: 27072, Avg. loss: 0.104637\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 42.81, NNZs: 13144, Bias: 0.000000, T: 29328, Avg. loss: 0.104559\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 42.82, NNZs: 13144, Bias: 0.000000, T: 31584, Avg. loss: 0.104484\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 42.83, NNZs: 13144, Bias: 0.000000, T: 33840, Avg. loss: 0.104411\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 42.84, NNZs: 13144, Bias: 0.000000, T: 36096, Avg. loss: 0.104342\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 42.84, NNZs: 13144, Bias: 0.000000, T: 38352, Avg. loss: 0.104068\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 42.84, NNZs: 13144, Bias: 0.000000, T: 40608, Avg. loss: 0.104055\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 42.84, NNZs: 13144, Bias: 0.000000, T: 42864, Avg. loss: 0.104042\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 42.85, NNZs: 13144, Bias: 0.000000, T: 45120, Avg. loss: 0.104029\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 29.43, NNZs: 13144, Bias: 0.000000, T: 2256, Avg. loss: 0.393964\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 38.69, NNZs: 13144, Bias: 0.000000, T: 4512, Avg. loss: 0.198835\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 43.30, NNZs: 13144, Bias: 0.000000, T: 6768, Avg. loss: 0.146408\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 45.84, NNZs: 13144, Bias: 0.000000, T: 9024, Avg. loss: 0.124777\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 47.32, NNZs: 13144, Bias: 0.000000, T: 11280, Avg. loss: 0.114097\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 48.22, NNZs: 13144, Bias: 0.000000, T: 13536, Avg. loss: 0.108225\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 48.20, NNZs: 13144, Bias: 0.000000, T: 15792, Avg. loss: 0.101762\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 48.17, NNZs: 13144, Bias: 0.000000, T: 18048, Avg. loss: 0.099396\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 48.15, NNZs: 13144, Bias: 0.000000, T: 20304, Avg. loss: 0.098151\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 48.13, NNZs: 13144, Bias: 0.000000, T: 22560, Avg. loss: 0.097437\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 48.11, NNZs: 13144, Bias: 0.000000, T: 24816, Avg. loss: 0.097006\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 48.11, NNZs: 13144, Bias: 0.000000, T: 27072, Avg. loss: 0.096576\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 48.10, NNZs: 13144, Bias: 0.000000, T: 29328, Avg. loss: 0.096299\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 48.09, NNZs: 13144, Bias: 0.000000, T: 31584, Avg. loss: 0.096082\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 48.08, NNZs: 13144, Bias: 0.000000, T: 33840, Avg. loss: 0.095908\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 48.07, NNZs: 13144, Bias: 0.000000, T: 36096, Avg. loss: 0.095768\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 48.07, NNZs: 13144, Bias: 0.000000, T: 38352, Avg. loss: 0.095658\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 48.07, NNZs: 13144, Bias: 0.000000, T: 40608, Avg. loss: 0.095626\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 48.07, NNZs: 13144, Bias: 0.000000, T: 42864, Avg. loss: 0.095594\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 48.06, NNZs: 13144, Bias: 0.000000, T: 45120, Avg. loss: 0.095565\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 15.64, NNZs: 13144, Bias: 0.000000, T: 2256, Avg. loss: 0.455473\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 20.88, NNZs: 13144, Bias: 0.000000, T: 4512, Avg. loss: 0.315398\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 24.01, NNZs: 13144, Bias: 0.000000, T: 6768, Avg. loss: 0.262392\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 26.07, NNZs: 13144, Bias: 0.000000, T: 9024, Avg. loss: 0.235042\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 27.49, NNZs: 13144, Bias: 0.000000, T: 11280, Avg. loss: 0.218565\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 28.50, NNZs: 13144, Bias: 0.000000, T: 13536, Avg. loss: 0.207823\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 28.63, NNZs: 13144, Bias: 0.000000, T: 15792, Avg. loss: 0.200979\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 28.75, NNZs: 13144, Bias: 0.000000, T: 18048, Avg. loss: 0.198722\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 28.87, NNZs: 13144, Bias: 0.000000, T: 20304, Avg. loss: 0.196885\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 28.98, NNZs: 13144, Bias: 0.000000, T: 22560, Avg. loss: 0.195351\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 29.09, NNZs: 13144, Bias: 0.000000, T: 24816, Avg. loss: 0.194041\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 29.11, NNZs: 13144, Bias: 0.000000, T: 27072, Avg. loss: 0.192780\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 29.13, NNZs: 13144, Bias: 0.000000, T: 29328, Avg. loss: 0.192529\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 29.15, NNZs: 13144, Bias: 0.000000, T: 31584, Avg. loss: 0.192286\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 29.17, NNZs: 13144, Bias: 0.000000, T: 33840, Avg. loss: 0.192050\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 29.19, NNZs: 13144, Bias: 0.000000, T: 36096, Avg. loss: 0.191821\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 29.19, NNZs: 13144, Bias: 0.000000, T: 38352, Avg. loss: 0.191571\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 29.20, NNZs: 13144, Bias: 0.000000, T: 40608, Avg. loss: 0.191526\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 29.20, NNZs: 13144, Bias: 0.000000, T: 42864, Avg. loss: 0.191481\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 29.20, NNZs: 13144, Bias: 0.000000, T: 45120, Avg. loss: 0.191436\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 22.30, NNZs: 13144, Bias: 0.000000, T: 2256, Avg. loss: 0.336266\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 28.43, NNZs: 13144, Bias: 0.000000, T: 4512, Avg. loss: 0.194517\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 32.05, NNZs: 13144, Bias: 0.000000, T: 6768, Avg. loss: 0.160291\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 34.46, NNZs: 13144, Bias: 0.000000, T: 9024, Avg. loss: 0.142306\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 36.14, NNZs: 13144, Bias: 0.000000, T: 11280, Avg. loss: 0.131370\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 37.33, NNZs: 13144, Bias: 0.000000, T: 13536, Avg. loss: 0.124276\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 37.51, NNZs: 13144, Bias: 0.000000, T: 15792, Avg. loss: 0.115528\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 37.66, NNZs: 13144, Bias: 0.000000, T: 18048, Avg. loss: 0.114818\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 37.80, NNZs: 13144, Bias: 0.000000, T: 20304, Avg. loss: 0.114167\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 37.93, NNZs: 13144, Bias: 0.000000, T: 22560, Avg. loss: 0.113564\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 38.05, NNZs: 13144, Bias: 0.000000, T: 24816, Avg. loss: 0.113009\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 38.07, NNZs: 13144, Bias: 0.000000, T: 27072, Avg. loss: 0.111559\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 38.09, NNZs: 13144, Bias: 0.000000, T: 29328, Avg. loss: 0.111472\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 38.12, NNZs: 13144, Bias: 0.000000, T: 31584, Avg. loss: 0.111386\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 38.14, NNZs: 13144, Bias: 0.000000, T: 33840, Avg. loss: 0.111300\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 38.16, NNZs: 13144, Bias: 0.000000, T: 36096, Avg. loss: 0.111215\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 38.16, NNZs: 13144, Bias: 0.000000, T: 38352, Avg. loss: 0.110934\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 38.17, NNZs: 13144, Bias: 0.000000, T: 40608, Avg. loss: 0.110918\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 38.17, NNZs: 13144, Bias: 0.000000, T: 42864, Avg. loss: 0.110901\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 38.17, NNZs: 13144, Bias: 0.000000, T: 45120, Avg. loss: 0.110885\n",
      "Total training time: 0.05 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.42493015701647596, clf__eta0=0.6773009699604285, clf__fit_intercept=False, clf__l1_ratio=0.7301998277223162, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.017782879504616322, clf__shuffle=False, clf__tol=0.19519881462597577, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.761 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s finished\n",
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 25.07, NNZs: 13616, Bias: 0.000000, T: 2256, Avg. loss: 0.345668\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 32.80, NNZs: 13616, Bias: 0.000000, T: 4512, Avg. loss: 0.192366\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 37.19, NNZs: 13616, Bias: 0.000000, T: 6768, Avg. loss: 0.149395\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 39.89, NNZs: 13616, Bias: 0.000000, T: 9024, Avg. loss: 0.129017\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 41.62, NNZs: 13616, Bias: 0.000000, T: 11280, Avg. loss: 0.117742\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 42.75, NNZs: 13616, Bias: 0.000000, T: 13536, Avg. loss: 0.110995\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 42.83, NNZs: 13616, Bias: 0.000000, T: 15792, Avg. loss: 0.102863\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 42.91, NNZs: 13616, Bias: 0.000000, T: 18048, Avg. loss: 0.102053\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 42.99, NNZs: 13616, Bias: 0.000000, T: 20304, Avg. loss: 0.101434\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 43.06, NNZs: 13616, Bias: 0.000000, T: 22560, Avg. loss: 0.100932\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 43.13, NNZs: 13616, Bias: 0.000000, T: 24816, Avg. loss: 0.100507\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 43.14, NNZs: 13616, Bias: 0.000000, T: 27072, Avg. loss: 0.099265\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 43.15, NNZs: 13616, Bias: 0.000000, T: 29328, Avg. loss: 0.099192\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 43.16, NNZs: 13616, Bias: 0.000000, T: 31584, Avg. loss: 0.099121\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 43.17, NNZs: 13616, Bias: 0.000000, T: 33840, Avg. loss: 0.099053\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 43.18, NNZs: 13616, Bias: 0.000000, T: 36096, Avg. loss: 0.098988\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 43.19, NNZs: 13616, Bias: 0.000000, T: 38352, Avg. loss: 0.098750\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 43.19, NNZs: 13616, Bias: 0.000000, T: 40608, Avg. loss: 0.098738\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 43.19, NNZs: 13616, Bias: 0.000000, T: 42864, Avg. loss: 0.098725\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 43.19, NNZs: 13616, Bias: 0.000000, T: 45120, Avg. loss: 0.098713\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 29.56, NNZs: 13616, Bias: 0.000000, T: 2256, Avg. loss: 0.372481\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 38.44, NNZs: 13616, Bias: 0.000000, T: 4512, Avg. loss: 0.184784\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 42.79, NNZs: 13616, Bias: 0.000000, T: 6768, Avg. loss: 0.134811\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 45.18, NNZs: 13616, Bias: 0.000000, T: 9024, Avg. loss: 0.114669\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 46.56, NNZs: 13616, Bias: 0.000000, T: 11280, Avg. loss: 0.104831\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 47.39, NNZs: 13616, Bias: 0.000000, T: 13536, Avg. loss: 0.099446\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 47.37, NNZs: 13616, Bias: 0.000000, T: 15792, Avg. loss: 0.094747\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 47.35, NNZs: 13616, Bias: 0.000000, T: 18048, Avg. loss: 0.092356\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 47.33, NNZs: 13616, Bias: 0.000000, T: 20304, Avg. loss: 0.091075\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 47.31, NNZs: 13616, Bias: 0.000000, T: 22560, Avg. loss: 0.090317\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 47.29, NNZs: 13616, Bias: 0.000000, T: 24816, Avg. loss: 0.089841\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 47.28, NNZs: 13616, Bias: 0.000000, T: 27072, Avg. loss: 0.089490\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 47.27, NNZs: 13616, Bias: 0.000000, T: 29328, Avg. loss: 0.089251\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 47.26, NNZs: 13616, Bias: 0.000000, T: 31584, Avg. loss: 0.089053\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 47.26, NNZs: 13616, Bias: 0.000000, T: 33840, Avg. loss: 0.088888\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 47.25, NNZs: 13616, Bias: 0.000000, T: 36096, Avg. loss: 0.088749\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 47.25, NNZs: 13616, Bias: 0.000000, T: 38352, Avg. loss: 0.088642\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 47.24, NNZs: 13616, Bias: 0.000000, T: 40608, Avg. loss: 0.088612\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 47.24, NNZs: 13616, Bias: 0.000000, T: 42864, Avg. loss: 0.088583\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 47.24, NNZs: 13616, Bias: 0.000000, T: 45120, Avg. loss: 0.088554\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 15.49, NNZs: 13616, Bias: 0.000000, T: 2256, Avg. loss: 0.455275\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 20.82, NNZs: 13616, Bias: 0.000000, T: 4512, Avg. loss: 0.316172\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 24.03, NNZs: 13616, Bias: 0.000000, T: 6768, Avg. loss: 0.262608\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 26.14, NNZs: 13616, Bias: 0.000000, T: 9024, Avg. loss: 0.234782\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 27.59, NNZs: 13616, Bias: 0.000000, T: 11280, Avg. loss: 0.217986\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 28.63, NNZs: 13616, Bias: 0.000000, T: 13536, Avg. loss: 0.207040\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 28.76, NNZs: 13616, Bias: 0.000000, T: 15792, Avg. loss: 0.200548\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 28.89, NNZs: 13616, Bias: 0.000000, T: 18048, Avg. loss: 0.198043\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 29.01, NNZs: 13616, Bias: 0.000000, T: 20304, Avg. loss: 0.196030\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 29.13, NNZs: 13616, Bias: 0.000000, T: 22560, Avg. loss: 0.194369\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 29.24, NNZs: 13616, Bias: 0.000000, T: 24816, Avg. loss: 0.192965\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 29.26, NNZs: 13616, Bias: 0.000000, T: 27072, Avg. loss: 0.191810\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 29.28, NNZs: 13616, Bias: 0.000000, T: 29328, Avg. loss: 0.191532\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 29.30, NNZs: 13616, Bias: 0.000000, T: 31584, Avg. loss: 0.191263\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 29.32, NNZs: 13616, Bias: 0.000000, T: 33840, Avg. loss: 0.191004\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 29.34, NNZs: 13616, Bias: 0.000000, T: 36096, Avg. loss: 0.190753\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 29.34, NNZs: 13616, Bias: 0.000000, T: 38352, Avg. loss: 0.190522\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 29.35, NNZs: 13616, Bias: 0.000000, T: 40608, Avg. loss: 0.190472\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 29.35, NNZs: 13616, Bias: 0.000000, T: 42864, Avg. loss: 0.190422\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 29.36, NNZs: 13616, Bias: 0.000000, T: 45120, Avg. loss: 0.190373\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 22.44, NNZs: 13616, Bias: 0.000000, T: 2256, Avg. loss: 0.325139\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 28.45, NNZs: 13616, Bias: 0.000000, T: 4512, Avg. loss: 0.183435\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 31.98, NNZs: 13616, Bias: 0.000000, T: 6768, Avg. loss: 0.149944\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 34.32, NNZs: 13616, Bias: 0.000000, T: 9024, Avg. loss: 0.132643\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 35.92, NNZs: 13616, Bias: 0.000000, T: 11280, Avg. loss: 0.122303\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 37.04, NNZs: 13616, Bias: 0.000000, T: 13536, Avg. loss: 0.115695\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 37.21, NNZs: 13616, Bias: 0.000000, T: 15792, Avg. loss: 0.107768\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 37.35, NNZs: 13616, Bias: 0.000000, T: 18048, Avg. loss: 0.107043\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 37.49, NNZs: 13616, Bias: 0.000000, T: 20304, Avg. loss: 0.106396\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 37.61, NNZs: 13616, Bias: 0.000000, T: 22560, Avg. loss: 0.105816\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 37.72, NNZs: 13616, Bias: 0.000000, T: 24816, Avg. loss: 0.105290\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 37.74, NNZs: 13616, Bias: 0.000000, T: 27072, Avg. loss: 0.104017\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 37.76, NNZs: 13616, Bias: 0.000000, T: 29328, Avg. loss: 0.103925\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 37.78, NNZs: 13616, Bias: 0.000000, T: 31584, Avg. loss: 0.103835\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 37.80, NNZs: 13616, Bias: 0.000000, T: 33840, Avg. loss: 0.103747\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 37.82, NNZs: 13616, Bias: 0.000000, T: 36096, Avg. loss: 0.103660\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 37.83, NNZs: 13616, Bias: 0.000000, T: 38352, Avg. loss: 0.103415\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 37.83, NNZs: 13616, Bias: 0.000000, T: 40608, Avg. loss: 0.103398\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 37.84, NNZs: 13616, Bias: 0.000000, T: 42864, Avg. loss: 0.103381\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 37.84, NNZs: 13616, Bias: 0.000000, T: 45120, Avg. loss: 0.103364\n",
      "Total training time: 0.05 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.42493015701647596, clf__eta0=0.6773009699604285, clf__fit_intercept=False, clf__l1_ratio=0.7301998277223162, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.017782879504616322, clf__shuffle=False, clf__tol=0.19519881462597577, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.677 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s finished\n",
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 24.08, NNZs: 13463, Bias: 0.000000, T: 2256, Avg. loss: 0.353334\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 32.56, NNZs: 13463, Bias: 0.000000, T: 4512, Avg. loss: 0.209990\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 37.40, NNZs: 13463, Bias: 0.000000, T: 6768, Avg. loss: 0.162674\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 40.38, NNZs: 13463, Bias: 0.000000, T: 9024, Avg. loss: 0.140016\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 42.29, NNZs: 13463, Bias: 0.000000, T: 11280, Avg. loss: 0.127428\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 43.54, NNZs: 13463, Bias: 0.000000, T: 13536, Avg. loss: 0.119872\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 43.66, NNZs: 13463, Bias: 0.000000, T: 15792, Avg. loss: 0.116424\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 43.77, NNZs: 13463, Bias: 0.000000, T: 18048, Avg. loss: 0.112242\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 43.86, NNZs: 13463, Bias: 0.000000, T: 20304, Avg. loss: 0.110220\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 43.94, NNZs: 13463, Bias: 0.000000, T: 22560, Avg. loss: 0.109069\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 44.02, NNZs: 13463, Bias: 0.000000, T: 24816, Avg. loss: 0.108317\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 44.03, NNZs: 13463, Bias: 0.000000, T: 27072, Avg. loss: 0.107562\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 44.04, NNZs: 13463, Bias: 0.000000, T: 29328, Avg. loss: 0.107347\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 44.06, NNZs: 13463, Bias: 0.000000, T: 31584, Avg. loss: 0.107155\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 44.07, NNZs: 13463, Bias: 0.000000, T: 33840, Avg. loss: 0.106982\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 44.08, NNZs: 13463, Bias: 0.000000, T: 36096, Avg. loss: 0.106826\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 44.08, NNZs: 13463, Bias: 0.000000, T: 38352, Avg. loss: 0.106645\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 44.08, NNZs: 13463, Bias: 0.000000, T: 40608, Avg. loss: 0.106612\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 44.08, NNZs: 13463, Bias: 0.000000, T: 42864, Avg. loss: 0.106581\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 44.09, NNZs: 13463, Bias: 0.000000, T: 45120, Avg. loss: 0.106550\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 29.37, NNZs: 13463, Bias: 0.000000, T: 2256, Avg. loss: 0.364643\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 38.52, NNZs: 13463, Bias: 0.000000, T: 4512, Avg. loss: 0.193362\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 43.05, NNZs: 13463, Bias: 0.000000, T: 6768, Avg. loss: 0.140654\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 45.52, NNZs: 13463, Bias: 0.000000, T: 9024, Avg. loss: 0.118486\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 46.95, NNZs: 13463, Bias: 0.000000, T: 11280, Avg. loss: 0.107709\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 47.80, NNZs: 13463, Bias: 0.000000, T: 13536, Avg. loss: 0.101899\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 47.79, NNZs: 13463, Bias: 0.000000, T: 15792, Avg. loss: 0.102260\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 47.76, NNZs: 13463, Bias: 0.000000, T: 18048, Avg. loss: 0.096073\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 47.73, NNZs: 13463, Bias: 0.000000, T: 20304, Avg. loss: 0.093550\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 47.70, NNZs: 13463, Bias: 0.000000, T: 22560, Avg. loss: 0.092302\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 47.68, NNZs: 13463, Bias: 0.000000, T: 24816, Avg. loss: 0.091615\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 47.67, NNZs: 13463, Bias: 0.000000, T: 27072, Avg. loss: 0.092016\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 47.66, NNZs: 13463, Bias: 0.000000, T: 29328, Avg. loss: 0.091605\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 47.65, NNZs: 13463, Bias: 0.000000, T: 31584, Avg. loss: 0.091270\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 47.64, NNZs: 13463, Bias: 0.000000, T: 33840, Avg. loss: 0.090994\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 47.63, NNZs: 13463, Bias: 0.000000, T: 36096, Avg. loss: 0.090765\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 47.63, NNZs: 13463, Bias: 0.000000, T: 38352, Avg. loss: 0.090777\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 47.62, NNZs: 13463, Bias: 0.000000, T: 40608, Avg. loss: 0.090726\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 47.62, NNZs: 13463, Bias: 0.000000, T: 42864, Avg. loss: 0.090676\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 47.62, NNZs: 13463, Bias: 0.000000, T: 45120, Avg. loss: 0.090628\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 15.55, NNZs: 13463, Bias: 0.000000, T: 2256, Avg. loss: 0.444988\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 20.68, NNZs: 13463, Bias: 0.000000, T: 4512, Avg. loss: 0.319104\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 23.81, NNZs: 13463, Bias: 0.000000, T: 6768, Avg. loss: 0.265642\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 25.90, NNZs: 13463, Bias: 0.000000, T: 9024, Avg. loss: 0.237769\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 27.35, NNZs: 13463, Bias: 0.000000, T: 11280, Avg. loss: 0.220954\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 28.39, NNZs: 13463, Bias: 0.000000, T: 13536, Avg. loss: 0.209989\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 28.51, NNZs: 13463, Bias: 0.000000, T: 15792, Avg. loss: 0.209321\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 28.63, NNZs: 13463, Bias: 0.000000, T: 18048, Avg. loss: 0.204959\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 28.75, NNZs: 13463, Bias: 0.000000, T: 20304, Avg. loss: 0.201730\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 28.87, NNZs: 13463, Bias: 0.000000, T: 22560, Avg. loss: 0.199253\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 28.99, NNZs: 13463, Bias: 0.000000, T: 24816, Avg. loss: 0.197292\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 29.01, NNZs: 13463, Bias: 0.000000, T: 27072, Avg. loss: 0.196671\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 29.03, NNZs: 13463, Bias: 0.000000, T: 29328, Avg. loss: 0.196264\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 29.05, NNZs: 13463, Bias: 0.000000, T: 31584, Avg. loss: 0.195876\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 29.07, NNZs: 13463, Bias: 0.000000, T: 33840, Avg. loss: 0.195506\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 29.09, NNZs: 13463, Bias: 0.000000, T: 36096, Avg. loss: 0.195152\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 29.09, NNZs: 13463, Bias: 0.000000, T: 38352, Avg. loss: 0.195005\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 29.09, NNZs: 13463, Bias: 0.000000, T: 40608, Avg. loss: 0.194934\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 29.10, NNZs: 13463, Bias: 0.000000, T: 42864, Avg. loss: 0.194863\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 29.10, NNZs: 13463, Bias: 0.000000, T: 45120, Avg. loss: 0.194793\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 22.00, NNZs: 13463, Bias: 0.000000, T: 2256, Avg. loss: 0.329931\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 28.22, NNZs: 13463, Bias: 0.000000, T: 4512, Avg. loss: 0.187426\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 31.90, NNZs: 13463, Bias: 0.000000, T: 6768, Avg. loss: 0.153117\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 34.34, NNZs: 13463, Bias: 0.000000, T: 9024, Avg. loss: 0.135380\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 36.02, NNZs: 13463, Bias: 0.000000, T: 11280, Avg. loss: 0.124748\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 37.19, NNZs: 13463, Bias: 0.000000, T: 13536, Avg. loss: 0.117934\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 37.41, NNZs: 13463, Bias: 0.000000, T: 15792, Avg. loss: 0.109903\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 37.58, NNZs: 13463, Bias: 0.000000, T: 18048, Avg. loss: 0.108915\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 37.73, NNZs: 13463, Bias: 0.000000, T: 20304, Avg. loss: 0.108217\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 37.86, NNZs: 13463, Bias: 0.000000, T: 22560, Avg. loss: 0.107602\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 37.98, NNZs: 13463, Bias: 0.000000, T: 24816, Avg. loss: 0.107047\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 38.00, NNZs: 13463, Bias: 0.000000, T: 27072, Avg. loss: 0.105671\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 38.03, NNZs: 13463, Bias: 0.000000, T: 29328, Avg. loss: 0.105582\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 38.05, NNZs: 13463, Bias: 0.000000, T: 31584, Avg. loss: 0.105495\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 38.07, NNZs: 13463, Bias: 0.000000, T: 33840, Avg. loss: 0.105408\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 38.09, NNZs: 13463, Bias: 0.000000, T: 36096, Avg. loss: 0.105323\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 38.10, NNZs: 13463, Bias: 0.000000, T: 38352, Avg. loss: 0.105056\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 38.10, NNZs: 13463, Bias: 0.000000, T: 40608, Avg. loss: 0.105040\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 38.11, NNZs: 13463, Bias: 0.000000, T: 42864, Avg. loss: 0.105023\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 38.11, NNZs: 13463, Bias: 0.000000, T: 45120, Avg. loss: 0.105007\n",
      "Total training time: 0.05 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.42493015701647596, clf__eta0=0.6773009699604285, clf__fit_intercept=False, clf__l1_ratio=0.7301998277223162, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.017782879504616322, clf__shuffle=False, clf__tol=0.19519881462597577, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.691 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 59.78, NNZs: 7518, Bias: -0.970396, T: 2256, Avg. loss: 0.072785\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 40.12, NNZs: 8256, Bias: -1.199085, T: 4512, Avg. loss: 0.012688\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 30.14, NNZs: 8393, Bias: -1.084277, T: 6768, Avg. loss: 0.001184\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 23.73, NNZs: 8428, Bias: -1.083578, T: 9024, Avg. loss: 0.000428\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 20.33, NNZs: 8465, Bias: -1.002498, T: 11280, Avg. loss: 0.000337\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 17.64, NNZs: 8569, Bias: -0.976342, T: 13536, Avg. loss: 0.000219\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 111.00, NNZs: 8613, Bias: -1.915065, T: 2256, Avg. loss: 0.252349\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 73.54, NNZs: 9129, Bias: -1.916150, T: 4512, Avg. loss: 0.023838\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 55.81, NNZs: 9378, Bias: -1.807450, T: 6768, Avg. loss: 0.006993\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 46.09, NNZs: 9529, Bias: -1.675096, T: 9024, Avg. loss: 0.005318\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 39.95, NNZs: 9702, Bias: -1.568136, T: 11280, Avg. loss: 0.003310\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 34.85, NNZs: 9813, Bias: -1.530888, T: 13536, Avg. loss: 0.001239\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 23.73, NNZs: 6631, Bias: 0.395107, T: 2256, Avg. loss: 0.028223\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 15.76, NNZs: 7074, Bias: 0.396002, T: 4512, Avg. loss: 0.004863\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 11.88, NNZs: 7307, Bias: 0.379089, T: 6768, Avg. loss: 0.001221\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 9.58, NNZs: 7415, Bias: 0.352865, T: 9024, Avg. loss: 0.000449\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 8.01, NNZs: 7574, Bias: 0.341029, T: 11280, Avg. loss: 0.000088\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 7.02, NNZs: 7626, Bias: 0.315326, T: 13536, Avg. loss: 0.000027\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 34.67, NNZs: 6790, Bias: -0.882576, T: 2256, Avg. loss: 0.040640\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 23.61, NNZs: 7581, Bias: -0.816586, T: 4512, Avg. loss: 0.006024\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 17.79, NNZs: 7804, Bias: -0.794920, T: 6768, Avg. loss: 0.001616\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 14.04, NNZs: 7853, Bias: -0.785123, T: 9024, Avg. loss: 0.000466\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 11.71, NNZs: 7871, Bias: -0.767186, T: 11280, Avg. loss: 0.000210\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 10.21, NNZs: 7912, Bias: -0.742654, T: 13536, Avg. loss: 0.000194\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "[CV 1/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.21123614325601048, clf__eta0=0.32979731781585486, clf__fit_intercept=True, clf__l1_ratio=0.4775095579144826, clf__learning_rate=optimal, clf__loss=perceptron, clf__max_iter=30, clf__penalty=l2, clf__power_t=0.6427671735097384, clf__shuffle=False, clf__tol=0.2651165400908262, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.771 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 61.36, NNZs: 7053, Bias: -0.902672, T: 2256, Avg. loss: 0.070457\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 40.03, NNZs: 7692, Bias: -1.182363, T: 4512, Avg. loss: 0.016009\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 30.79, NNZs: 8094, Bias: -1.097083, T: 6768, Avg. loss: 0.003453\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 24.49, NNZs: 8173, Bias: -1.059787, T: 9024, Avg. loss: 0.000537\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 20.62, NNZs: 8220, Bias: -1.002497, T: 11280, Avg. loss: 0.000059\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 17.78, NNZs: 8247, Bias: -0.973396, T: 13536, Avg. loss: 0.000087\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 110.25, NNZs: 8579, Bias: -2.334063, T: 2256, Avg. loss: 0.253886\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 76.95, NNZs: 9212, Bias: -2.160961, T: 4512, Avg. loss: 0.046143\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 58.97, NNZs: 9506, Bias: -2.046372, T: 6768, Avg. loss: 0.015909\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 48.59, NNZs: 9570, Bias: -1.904336, T: 9024, Avg. loss: 0.004079\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 40.99, NNZs: 9648, Bias: -1.854682, T: 11280, Avg. loss: 0.001861\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 34.81, NNZs: 9660, Bias: -1.887409, T: 13536, Avg. loss: 0.000974\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 22.29, NNZs: 5796, Bias: 0.342961, T: 2256, Avg. loss: 0.027807\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 15.36, NNZs: 6547, Bias: 0.372367, T: 4512, Avg. loss: 0.004975\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 11.56, NNZs: 6867, Bias: 0.378015, T: 6768, Avg. loss: 0.002039\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 9.36, NNZs: 6954, Bias: 0.351006, T: 9024, Avg. loss: 0.000276\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 7.90, NNZs: 7230, Bias: 0.334123, T: 11280, Avg. loss: 0.000170\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 6.85, NNZs: 7352, Bias: 0.321038, T: 13536, Avg. loss: 0.000090\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 35.53, NNZs: 6829, Bias: -0.930059, T: 2256, Avg. loss: 0.050509\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 23.01, NNZs: 7315, Bias: -1.001857, T: 4512, Avg. loss: 0.007150\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 17.39, NNZs: 7430, Bias: -0.969469, T: 6768, Avg. loss: 0.001853\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 14.08, NNZs: 7509, Bias: -0.928848, T: 9024, Avg. loss: 0.000830\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 11.93, NNZs: 7577, Bias: -0.908821, T: 11280, Avg. loss: 0.000423\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 10.36, NNZs: 7616, Bias: -0.887421, T: 13536, Avg. loss: 0.000126\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "[CV 2/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.21123614325601048, clf__eta0=0.32979731781585486, clf__fit_intercept=True, clf__l1_ratio=0.4775095579144826, clf__learning_rate=optimal, clf__loss=perceptron, clf__max_iter=30, clf__penalty=l2, clf__power_t=0.6427671735097384, clf__shuffle=False, clf__tol=0.2651165400908262, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.817 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 60.52, NNZs: 7320, Bias: -1.197868, T: 2256, Avg. loss: 0.078650\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 40.83, NNZs: 8161, Bias: -1.242139, T: 4512, Avg. loss: 0.009248\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 30.43, NNZs: 8413, Bias: -1.237149, T: 6768, Avg. loss: 0.002114\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 24.63, NNZs: 8512, Bias: -1.184765, T: 9024, Avg. loss: 0.000707\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 20.63, NNZs: 8589, Bias: -1.148446, T: 11280, Avg. loss: 0.000354\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 18.15, NNZs: 8612, Bias: -1.085944, T: 13536, Avg. loss: 0.000168\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 110.38, NNZs: 8782, Bias: -2.005462, T: 2256, Avg. loss: 0.258745\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 78.05, NNZs: 9566, Bias: -1.929468, T: 4512, Avg. loss: 0.049143\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 59.24, NNZs: 9770, Bias: -1.840296, T: 6768, Avg. loss: 0.010628\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 47.56, NNZs: 9885, Bias: -1.804776, T: 9024, Avg. loss: 0.001638\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 40.54, NNZs: 9980, Bias: -1.740263, T: 11280, Avg. loss: 0.003138\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 35.64, NNZs: 10022, Bias: -1.678485, T: 13536, Avg. loss: 0.003022\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 24.54, NNZs: 6410, Bias: 0.279856, T: 2256, Avg. loss: 0.033761\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 16.32, NNZs: 7400, Bias: 0.436838, T: 4512, Avg. loss: 0.006543\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 12.28, NNZs: 7693, Bias: 0.394741, T: 6768, Avg. loss: 0.001375\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 9.97, NNZs: 7903, Bias: 0.378093, T: 9024, Avg. loss: 0.000896\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 8.32, NNZs: 7953, Bias: 0.365630, T: 11280, Avg. loss: 0.000208\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 7.14, NNZs: 8001, Bias: 0.353705, T: 13536, Avg. loss: 0.000035\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 34.74, NNZs: 7139, Bias: -0.949327, T: 2256, Avg. loss: 0.047014\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 22.81, NNZs: 7570, Bias: -0.840769, T: 4512, Avg. loss: 0.006516\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 16.88, NNZs: 7687, Bias: -0.806211, T: 6768, Avg. loss: 0.002242\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 13.79, NNZs: 7723, Bias: -0.737747, T: 9024, Avg. loss: 0.000880\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 11.60, NNZs: 7742, Bias: -0.712275, T: 11280, Avg. loss: 0.000537\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 9.97, NNZs: 7863, Bias: -0.701310, T: 13536, Avg. loss: 0.000056\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "[CV 3/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.21123614325601048, clf__eta0=0.32979731781585486, clf__fit_intercept=True, clf__l1_ratio=0.4775095579144826, clf__learning_rate=optimal, clf__loss=perceptron, clf__max_iter=30, clf__penalty=l2, clf__power_t=0.6427671735097384, clf__shuffle=False, clf__tol=0.2651165400908262, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.866 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 57.46, NNZs: 7924, Bias: -1.380330, T: 2256, Avg. loss: 0.083557\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 39.81, NNZs: 8805, Bias: -1.313307, T: 4512, Avg. loss: 0.013437\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 30.09, NNZs: 9030, Bias: -1.213949, T: 6768, Avg. loss: 0.001925\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 23.95, NNZs: 9131, Bias: -1.194390, T: 9024, Avg. loss: 0.000279\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 20.28, NNZs: 9181, Bias: -1.145394, T: 11280, Avg. loss: 0.000471\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 17.68, NNZs: 9203, Bias: -1.092962, T: 13536, Avg. loss: 0.000266\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 114.38, NNZs: 9102, Bias: -2.051692, T: 2256, Avg. loss: 0.270559\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 81.60, NNZs: 10386, Bias: -1.993197, T: 4512, Avg. loss: 0.068160\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 63.20, NNZs: 10572, Bias: -1.777206, T: 6768, Avg. loss: 0.011492\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 50.42, NNZs: 10667, Bias: -1.726572, T: 9024, Avg. loss: 0.003837\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 40.96, NNZs: 10684, Bias: -1.791715, T: 11280, Avg. loss: 0.001149\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 35.54, NNZs: 10711, Bias: -1.718151, T: 13536, Avg. loss: 0.000370\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 25.45, NNZs: 7538, Bias: 0.308432, T: 2256, Avg. loss: 0.034460\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 16.99, NNZs: 8312, Bias: 0.385574, T: 4512, Avg. loss: 0.004074\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 12.59, NNZs: 8372, Bias: 0.342182, T: 6768, Avg. loss: 0.000712\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 9.97, NNZs: 8477, Bias: 0.332309, T: 9024, Avg. loss: 0.000127\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 8.34, NNZs: 8538, Bias: 0.311075, T: 11280, Avg. loss: 0.000033\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 7.26, NNZs: 8575, Bias: 0.296889, T: 13536, Avg. loss: 0.000104\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 35.61, NNZs: 7070, Bias: -0.913265, T: 2256, Avg. loss: 0.053584\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 23.86, NNZs: 7606, Bias: -0.891470, T: 4512, Avg. loss: 0.005340\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 17.92, NNZs: 7784, Bias: -0.836287, T: 6768, Avg. loss: 0.000830\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 14.32, NNZs: 7905, Bias: -0.801186, T: 9024, Avg. loss: 0.000243\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 12.14, NNZs: 7982, Bias: -0.771072, T: 11280, Avg. loss: 0.000247\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 10.60, NNZs: 8038, Bias: -0.740060, T: 13536, Avg. loss: 0.000090\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "[CV 4/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.21123614325601048, clf__eta0=0.32979731781585486, clf__fit_intercept=True, clf__l1_ratio=0.4775095579144826, clf__learning_rate=optimal, clf__loss=perceptron, clf__max_iter=30, clf__penalty=l2, clf__power_t=0.6427671735097384, clf__shuffle=False, clf__tol=0.2651165400908262, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.848 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 59.93, NNZs: 7928, Bias: -0.950723, T: 2256, Avg. loss: 0.078273\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 42.34, NNZs: 8853, Bias: -1.098890, T: 4512, Avg. loss: 0.011597\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 31.13, NNZs: 9107, Bias: -1.201554, T: 6768, Avg. loss: 0.002774\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 25.50, NNZs: 9204, Bias: -1.089007, T: 9024, Avg. loss: 0.000463\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 21.49, NNZs: 9303, Bias: -1.053914, T: 11280, Avg. loss: 0.000643\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 18.65, NNZs: 9315, Bias: -1.010491, T: 13536, Avg. loss: 0.000204\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 112.18, NNZs: 9241, Bias: -1.921299, T: 2256, Avg. loss: 0.298304\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 76.20, NNZs: 9784, Bias: -1.938421, T: 4512, Avg. loss: 0.030904\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 56.91, NNZs: 10021, Bias: -1.911608, T: 6768, Avg. loss: 0.006676\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 46.15, NNZs: 10148, Bias: -1.889477, T: 9024, Avg. loss: 0.006727\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 38.60, NNZs: 10223, Bias: -1.870937, T: 11280, Avg. loss: 0.001096\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 34.57, NNZs: 10300, Bias: -1.725270, T: 13536, Avg. loss: 0.000691\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 23.16, NNZs: 6820, Bias: 0.342533, T: 2256, Avg. loss: 0.034291\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 16.43, NNZs: 7717, Bias: 0.318658, T: 4512, Avg. loss: 0.009311\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 12.41, NNZs: 8052, Bias: 0.353171, T: 6768, Avg. loss: 0.002570\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 10.11, NNZs: 8248, Bias: 0.331749, T: 9024, Avg. loss: 0.000437\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 8.46, NNZs: 8341, Bias: 0.333583, T: 11280, Avg. loss: 0.000943\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 7.31, NNZs: 8532, Bias: 0.323634, T: 13536, Avg. loss: 0.000498\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 33.95, NNZs: 6848, Bias: -0.927225, T: 2256, Avg. loss: 0.048885\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 23.04, NNZs: 7557, Bias: -0.895452, T: 4512, Avg. loss: 0.009036\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 17.28, NNZs: 7772, Bias: -0.867820, T: 6768, Avg. loss: 0.002423\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 14.16, NNZs: 7893, Bias: -0.813023, T: 9024, Avg. loss: 0.001687\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 11.94, NNZs: 7938, Bias: -0.791596, T: 11280, Avg. loss: 0.000579\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 10.33, NNZs: 7938, Bias: -0.770760, T: 13536, Avg. loss: 0.000327\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "[CV 5/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.21123614325601048, clf__eta0=0.32979731781585486, clf__fit_intercept=True, clf__l1_ratio=0.4775095579144826, clf__learning_rate=optimal, clf__loss=perceptron, clf__max_iter=30, clf__penalty=l2, clf__power_t=0.6427671735097384, clf__shuffle=False, clf__tol=0.2651165400908262, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.817 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 48.40, NNZs: 5786, Bias: 0.000000, T: 2820, Avg. loss: 0.214285\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 61.76, NNZs: 3456, Bias: 0.000000, T: 5640, Avg. loss: 0.077588\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 71.54, NNZs: 2670, Bias: 0.000000, T: 8460, Avg. loss: 0.051090\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 79.67, NNZs: 2214, Bias: 0.000000, T: 11280, Avg. loss: 0.041188\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 86.04, NNZs: 1843, Bias: 0.000000, T: 14100, Avg. loss: 0.035691\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 92.33, NNZs: 1672, Bias: 0.000000, T: 16920, Avg. loss: 0.035864\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 68.72, NNZs: 8465, Bias: 0.000000, T: 2820, Avg. loss: 0.262156\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 80.98, NNZs: 4799, Bias: 0.000000, T: 5640, Avg. loss: 0.060028\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 90.42, NNZs: 3333, Bias: 0.000000, T: 8460, Avg. loss: 0.041903\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 98.75, NNZs: 2623, Bias: 0.000000, T: 11280, Avg. loss: 0.039427\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 106.00, NNZs: 2302, Bias: 0.000000, T: 14100, Avg. loss: 0.033958\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 113.07, NNZs: 2038, Bias: 0.000000, T: 16920, Avg. loss: 0.030824\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 30.02, NNZs: 3438, Bias: 0.000000, T: 2820, Avg. loss: 0.336985\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 39.92, NNZs: 1893, Bias: 0.000000, T: 5640, Avg. loss: 0.192187\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 47.25, NNZs: 1433, Bias: 0.000000, T: 8460, Avg. loss: 0.159934\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 53.35, NNZs: 1230, Bias: 0.000000, T: 11280, Avg. loss: 0.141479\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 58.55, NNZs: 1075, Bias: 0.000000, T: 14100, Avg. loss: 0.129911\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 63.23, NNZs: 991, Bias: 0.000000, T: 16920, Avg. loss: 0.121849\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 37.21, NNZs: 4274, Bias: 0.000000, T: 2820, Avg. loss: 0.192118\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 48.64, NNZs: 2526, Bias: 0.000000, T: 5640, Avg. loss: 0.093071\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 57.15, NNZs: 1940, Bias: 0.000000, T: 8460, Avg. loss: 0.072307\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 64.38, NNZs: 1698, Bias: 0.000000, T: 11280, Avg. loss: 0.062664\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 70.88, NNZs: 1509, Bias: 0.000000, T: 14100, Avg. loss: 0.055915\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 76.08, NNZs: 1394, Bias: 0.000000, T: 16920, Avg. loss: 0.052404\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "0.9329787234042554\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      precision    recall  f1-score   support\n",
      "\n",
      "      Geen gebruiker       0.69      0.98      0.81        83\n",
      "   Huidige gebruiker       0.67      0.68      0.68        38\n",
      "      Niets gevonden       0.98      0.94      0.96       611\n",
      "Voormalige gebruiker       0.99      0.93      0.96       208\n",
      "\n",
      "            accuracy                           0.93       940\n",
      "           macro avg       0.83      0.88      0.85       940\n",
      "        weighted avg       0.94      0.93      0.94       940\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ngram 2 Stopwords kept\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(2,2), lowercase=True, token_pattern=r\"(?u)\\b\\w\\w+\\b|\\+|\\-\")),\n",
    "    ('clf', SGDClassifier(early_stopping=True, n_iter_no_change=5, validation_fraction = 0.25, verbose=3)),\n",
    "])\n",
    "random_search = RandomizedSearchCV(estimator=pipeline, param_distributions=parameter_grid, random_state=500, verbose=3, scoring='f1_macro')\n",
    "random_search.fit(train_set['text'], train_set['label'])  \n",
    "predicted_nb = random_search.predict(test_set['text'])\n",
    "print(np.mean(predicted_nb == test_set['label']))\n",
    "cm = confusion_matrix(test_set['label'], predicted_nb)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=random_search.classes_)\n",
    "disp.plot()\n",
    "\n",
    "plt.show()\n",
    "print(metrics.classification_report(test_set['label'], predicted_nb,\n",
    "    target_names=random_search.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "253be629",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump\n",
    "\n",
    "dump(random_search, open('smoking_ml_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "28c7442f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set['predicted'] = predicted_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0e1bfd33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>conclusie:  normale nacontrole. kijkt goed ter...</td>\n",
       "      <td>Niets gevonden</td>\n",
       "      <td>Niets gevonden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>conclusie:  samenvatting abcde: icc bij trauma...</td>\n",
       "      <td>Niets gevonden</td>\n",
       "      <td>Niets gevonden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>beloop:  staat gepland voor tc, echter nummer ...</td>\n",
       "      <td>Niets gevonden</td>\n",
       "      <td>Niets gevonden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>beloop:  lab belt: materiaal van 24-uurs urine...</td>\n",
       "      <td>Niets gevonden</td>\n",
       "      <td>Niets gevonden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>beloop:  beloop: reguliere controle na acdf c4...</td>\n",
       "      <td>Huidige gebruiker</td>\n",
       "      <td>Huidige gebruiker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4678</th>\n",
       "      <td>samenvatting:  voorgeschiedenis: in verleden p...</td>\n",
       "      <td>Geen gebruiker</td>\n",
       "      <td>Geen gebruiker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4682</th>\n",
       "      <td>anamnese:  nog steeds hielspoor links, heeft a...</td>\n",
       "      <td>Geen gebruiker</td>\n",
       "      <td>Geen gebruiker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4688</th>\n",
       "      <td>reden van komst / verwijzing:  reden verwijzin...</td>\n",
       "      <td>Geen gebruiker</td>\n",
       "      <td>Geen gebruiker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4691</th>\n",
       "      <td>anamnese:   verkort consult: aandachtspunten u...</td>\n",
       "      <td>Huidige gebruiker</td>\n",
       "      <td>Huidige gebruiker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4699</th>\n",
       "      <td>reden van komst / verwijzing:  reden van komst...</td>\n",
       "      <td>Geen gebruiker</td>\n",
       "      <td>Geen gebruiker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>940 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text              label  \\\n",
       "2     conclusie:  normale nacontrole. kijkt goed ter...     Niets gevonden   \n",
       "17    conclusie:  samenvatting abcde: icc bij trauma...     Niets gevonden   \n",
       "37    beloop:  staat gepland voor tc, echter nummer ...     Niets gevonden   \n",
       "40    beloop:  lab belt: materiaal van 24-uurs urine...     Niets gevonden   \n",
       "48    beloop:  beloop: reguliere controle na acdf c4...  Huidige gebruiker   \n",
       "...                                                 ...                ...   \n",
       "4678  samenvatting:  voorgeschiedenis: in verleden p...     Geen gebruiker   \n",
       "4682  anamnese:  nog steeds hielspoor links, heeft a...     Geen gebruiker   \n",
       "4688  reden van komst / verwijzing:  reden verwijzin...     Geen gebruiker   \n",
       "4691  anamnese:   verkort consult: aandachtspunten u...  Huidige gebruiker   \n",
       "4699  reden van komst / verwijzing:  reden van komst...     Geen gebruiker   \n",
       "\n",
       "              predicted  \n",
       "2        Niets gevonden  \n",
       "17       Niets gevonden  \n",
       "37       Niets gevonden  \n",
       "40       Niets gevonden  \n",
       "48    Huidige gebruiker  \n",
       "...                 ...  \n",
       "4678     Geen gebruiker  \n",
       "4682     Geen gebruiker  \n",
       "4688     Geen gebruiker  \n",
       "4691  Huidige gebruiker  \n",
       "4699     Geen gebruiker  \n",
       "\n",
       "[940 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eef0d5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.to_csv('sgd_smoking_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf614eb",
   "metadata": {},
   "source": [
    "## Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bdff84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rook_corpus = rook_corpus_backup.copy()\n",
    "stemmer = SnowballStemmer(\"dutch\")\n",
    "rook_corpus['text'] = rook_corpus['text'].str.lower()\n",
    "rook_corpus['text'] = [stemmer.stem(text) for text in rook_corpus['text']]\n",
    "rook_corpus['label'] = rook_corpus['label'].str.replace('Niets gevonden','Geen gebruiker')\n",
    "rook_corpus['label'] = rook_corpus['label'].str.replace('Voormalige gebruiker','Geen gebruiker')\n",
    "rook_corpus = rook_corpus.drop(rook_corpus[rook_corpus.label == '--'].index)\n",
    "rook_corpus = rook_corpus.drop(rook_corpus[rook_corpus.label == 'Onbekend'].index)\n",
    "rook_corpus_backup = rook_corpus.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fda6a117",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = rook_corpus.loc[indices['index']]\n",
    "train_set = rook_corpus.loc[~rook_corpus.index.isin(test_set.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "736ec2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = {'clf__loss':              ['hinge', 'log_loss', 'log', 'modified_huber', 'squared_hinge', 'perceptron', 'squared_error', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "                  'clf__penalty':           ['l2', 'l1'],\n",
    "                  'clf__l1_ratio':          sp_randFloat(),\n",
    "                  'clf__fit_intercept':     [True, False],\n",
    "                  'clf__max_iter':          [int(x) for x in np.linspace(start = 10, stop = 100, num = 10)],\n",
    "                  'clf__tol':               sp_randFloat(),\n",
    "                  'clf__shuffle':           [True, False],\n",
    "                  'clf__epsilon':           sp_randFloat(),\n",
    "                  'clf__learning_rate':     ['constant', 'optimal', 'invscaling', 'adaptive'],\n",
    "                  'clf__eta0':              sp_randFloat(),\n",
    "                  'clf__power_t':           sp_randFloat(),\n",
    "                  'clf__class_weight':      ['balanced', None],\n",
    "                  'clf__warm_start':        [True, False],\n",
    "                  'clf__average':           [True, False],\n",
    "                  'tfidf__max_df':          [0.90, 0.95],\n",
    "                  'tfidf__min_df':          [3, 5]\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ce4af30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "-- Epoch 1\n",
      "Norm: 18.40, NNZs: 2218, Bias: 0.000000, T: 2256, Avg. loss: 0.263580\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 24.71, NNZs: 1179, Bias: 0.000000, T: 4512, Avg. loss: 0.199774\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 29.70, NNZs: 988, Bias: 0.000000, T: 6768, Avg. loss: 0.181247\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 33.58, NNZs: 856, Bias: 0.000000, T: 9024, Avg. loss: 0.170372\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 37.20, NNZs: 771, Bias: 0.000000, T: 11280, Avg. loss: 0.161485\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 40.87, NNZs: 704, Bias: 0.000000, T: 13536, Avg. loss: 0.154326\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 41.44, NNZs: 681, Bias: 0.000000, T: 15792, Avg. loss: 0.148946\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 42.01, NNZs: 676, Bias: 0.000000, T: 18048, Avg. loss: 0.147956\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 42.61, NNZs: 663, Bias: 0.000000, T: 20304, Avg. loss: 0.146848\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 43.20, NNZs: 655, Bias: 0.000000, T: 22560, Avg. loss: 0.145798\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 43.76, NNZs: 645, Bias: 0.000000, T: 24816, Avg. loss: 0.144814\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 43.87, NNZs: 641, Bias: 0.000000, T: 27072, Avg. loss: 0.143855\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 43.98, NNZs: 640, Bias: 0.000000, T: 29328, Avg. loss: 0.143696\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 44.10, NNZs: 637, Bias: 0.000000, T: 31584, Avg. loss: 0.143493\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 44.21, NNZs: 637, Bias: 0.000000, T: 33840, Avg. loss: 0.143300\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 44.32, NNZs: 635, Bias: 0.000000, T: 36096, Avg. loss: 0.143103\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 44.34, NNZs: 635, Bias: 0.000000, T: 38352, Avg. loss: 0.142925\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 44.36, NNZs: 634, Bias: 0.000000, T: 40608, Avg. loss: 0.142891\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 44.38, NNZs: 634, Bias: 0.000000, T: 42864, Avg. loss: 0.142854\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 44.41, NNZs: 634, Bias: 0.000000, T: 45120, Avg. loss: 0.142816\n",
      "Total training time: 0.13 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.06171699256249541, clf__eta0=0.6666115972798587, clf__fit_intercept=False, clf__l1_ratio=0.9792901432894962, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.15075392531110676, clf__shuffle=True, clf__tol=0.365636830734297, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.490 total time=   1.5s\n",
      "-- Epoch 1\n",
      "Norm: 18.96, NNZs: 2282, Bias: 0.000000, T: 2256, Avg. loss: 0.259260\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 24.85, NNZs: 1138, Bias: 0.000000, T: 4512, Avg. loss: 0.196494\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 29.14, NNZs: 907, Bias: 0.000000, T: 6768, Avg. loss: 0.180886\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 33.31, NNZs: 791, Bias: 0.000000, T: 9024, Avg. loss: 0.168861\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 36.91, NNZs: 723, Bias: 0.000000, T: 11280, Avg. loss: 0.160621\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 40.35, NNZs: 679, Bias: 0.000000, T: 13536, Avg. loss: 0.153225\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 40.86, NNZs: 653, Bias: 0.000000, T: 15792, Avg. loss: 0.148165\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 41.40, NNZs: 643, Bias: 0.000000, T: 18048, Avg. loss: 0.147252\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 41.97, NNZs: 635, Bias: 0.000000, T: 20304, Avg. loss: 0.146260\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 42.54, NNZs: 630, Bias: 0.000000, T: 22560, Avg. loss: 0.145260\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 43.09, NNZs: 623, Bias: 0.000000, T: 24816, Avg. loss: 0.144303\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 43.20, NNZs: 620, Bias: 0.000000, T: 27072, Avg. loss: 0.143383\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 43.31, NNZs: 620, Bias: 0.000000, T: 29328, Avg. loss: 0.143211\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 43.42, NNZs: 618, Bias: 0.000000, T: 31584, Avg. loss: 0.143036\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 43.53, NNZs: 615, Bias: 0.000000, T: 33840, Avg. loss: 0.142842\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 43.63, NNZs: 613, Bias: 0.000000, T: 36096, Avg. loss: 0.142663\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 43.66, NNZs: 613, Bias: 0.000000, T: 38352, Avg. loss: 0.142485\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 43.68, NNZs: 613, Bias: 0.000000, T: 40608, Avg. loss: 0.142451\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 43.70, NNZs: 613, Bias: 0.000000, T: 42864, Avg. loss: 0.142418\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 43.72, NNZs: 613, Bias: 0.000000, T: 45120, Avg. loss: 0.142382\n",
      "Total training time: 0.15 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.06171699256249541, clf__eta0=0.6666115972798587, clf__fit_intercept=False, clf__l1_ratio=0.9792901432894962, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.15075392531110676, clf__shuffle=True, clf__tol=0.365636830734297, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.488 total time=   1.6s\n",
      "-- Epoch 1\n",
      "Norm: 18.73, NNZs: 2321, Bias: 0.000000, T: 2256, Avg. loss: 0.265481\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 24.58, NNZs: 1179, Bias: 0.000000, T: 4512, Avg. loss: 0.203432\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 29.37, NNZs: 975, Bias: 0.000000, T: 6768, Avg. loss: 0.186790\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 33.34, NNZs: 855, Bias: 0.000000, T: 9024, Avg. loss: 0.175916\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 37.21, NNZs: 780, Bias: 0.000000, T: 11280, Avg. loss: 0.167147\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 40.69, NNZs: 719, Bias: 0.000000, T: 13536, Avg. loss: 0.159649\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 41.17, NNZs: 697, Bias: 0.000000, T: 15792, Avg. loss: 0.154976\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 41.69, NNZs: 696, Bias: 0.000000, T: 18048, Avg. loss: 0.153743\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 42.26, NNZs: 685, Bias: 0.000000, T: 20304, Avg. loss: 0.152743\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 42.83, NNZs: 674, Bias: 0.000000, T: 22560, Avg. loss: 0.151785\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 43.37, NNZs: 663, Bias: 0.000000, T: 24816, Avg. loss: 0.150764\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 43.48, NNZs: 663, Bias: 0.000000, T: 27072, Avg. loss: 0.149828\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 43.59, NNZs: 659, Bias: 0.000000, T: 29328, Avg. loss: 0.149648\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 43.70, NNZs: 659, Bias: 0.000000, T: 31584, Avg. loss: 0.149473\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 43.81, NNZs: 657, Bias: 0.000000, T: 33840, Avg. loss: 0.149284\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 43.92, NNZs: 655, Bias: 0.000000, T: 36096, Avg. loss: 0.149088\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 43.94, NNZs: 654, Bias: 0.000000, T: 38352, Avg. loss: 0.148907\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 43.96, NNZs: 654, Bias: 0.000000, T: 40608, Avg. loss: 0.148872\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 43.98, NNZs: 654, Bias: 0.000000, T: 42864, Avg. loss: 0.148833\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 44.00, NNZs: 654, Bias: 0.000000, T: 45120, Avg. loss: 0.148798\n",
      "Total training time: 0.14 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.06171699256249541, clf__eta0=0.6666115972798587, clf__fit_intercept=False, clf__l1_ratio=0.9792901432894962, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.15075392531110676, clf__shuffle=True, clf__tol=0.365636830734297, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.490 total time=   1.6s\n",
      "-- Epoch 1\n",
      "Norm: 18.78, NNZs: 2262, Bias: 0.000000, T: 2256, Avg. loss: 0.257708\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 24.65, NNZs: 1140, Bias: 0.000000, T: 4512, Avg. loss: 0.197373\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 29.02, NNZs: 924, Bias: 0.000000, T: 6768, Avg. loss: 0.181098\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 33.01, NNZs: 813, Bias: 0.000000, T: 9024, Avg. loss: 0.170843\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 36.47, NNZs: 740, Bias: 0.000000, T: 11280, Avg. loss: 0.162691\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 39.89, NNZs: 684, Bias: 0.000000, T: 13536, Avg. loss: 0.156094\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 40.47, NNZs: 654, Bias: 0.000000, T: 15792, Avg. loss: 0.150616\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 41.06, NNZs: 649, Bias: 0.000000, T: 18048, Avg. loss: 0.149667\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 41.64, NNZs: 635, Bias: 0.000000, T: 20304, Avg. loss: 0.148631\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 42.19, NNZs: 629, Bias: 0.000000, T: 22560, Avg. loss: 0.147626\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 42.76, NNZs: 624, Bias: 0.000000, T: 24816, Avg. loss: 0.146682\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 42.87, NNZs: 621, Bias: 0.000000, T: 27072, Avg. loss: 0.145728\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 42.98, NNZs: 621, Bias: 0.000000, T: 29328, Avg. loss: 0.145565\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 43.08, NNZs: 619, Bias: 0.000000, T: 31584, Avg. loss: 0.145398\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 43.19, NNZs: 617, Bias: 0.000000, T: 33840, Avg. loss: 0.145215\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 43.30, NNZs: 613, Bias: 0.000000, T: 36096, Avg. loss: 0.145034\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 43.32, NNZs: 613, Bias: 0.000000, T: 38352, Avg. loss: 0.144859\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 43.34, NNZs: 612, Bias: 0.000000, T: 40608, Avg. loss: 0.144824\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 43.36, NNZs: 611, Bias: 0.000000, T: 42864, Avg. loss: 0.144791\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 43.38, NNZs: 611, Bias: 0.000000, T: 45120, Avg. loss: 0.144757\n",
      "Total training time: 0.14 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.06171699256249541, clf__eta0=0.6666115972798587, clf__fit_intercept=False, clf__l1_ratio=0.9792901432894962, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.15075392531110676, clf__shuffle=True, clf__tol=0.365636830734297, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.490 total time=   1.5s\n",
      "-- Epoch 1\n",
      "Norm: 19.11, NNZs: 2288, Bias: 0.000000, T: 2256, Avg. loss: 0.257593\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 24.68, NNZs: 1137, Bias: 0.000000, T: 4512, Avg. loss: 0.198000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 29.08, NNZs: 928, Bias: 0.000000, T: 6768, Avg. loss: 0.182259\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 33.26, NNZs: 814, Bias: 0.000000, T: 9024, Avg. loss: 0.170592\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 36.53, NNZs: 746, Bias: 0.000000, T: 11280, Avg. loss: 0.161729\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 39.94, NNZs: 675, Bias: 0.000000, T: 13536, Avg. loss: 0.155614\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 40.61, NNZs: 652, Bias: 0.000000, T: 15792, Avg. loss: 0.150711\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 41.21, NNZs: 648, Bias: 0.000000, T: 18048, Avg. loss: 0.149500\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 41.80, NNZs: 643, Bias: 0.000000, T: 20304, Avg. loss: 0.148422\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 42.40, NNZs: 638, Bias: 0.000000, T: 22560, Avg. loss: 0.147349\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 42.94, NNZs: 629, Bias: 0.000000, T: 24816, Avg. loss: 0.146295\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 43.05, NNZs: 625, Bias: 0.000000, T: 27072, Avg. loss: 0.145411\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 43.16, NNZs: 623, Bias: 0.000000, T: 29328, Avg. loss: 0.145249\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 43.27, NNZs: 620, Bias: 0.000000, T: 31584, Avg. loss: 0.145056\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 43.38, NNZs: 619, Bias: 0.000000, T: 33840, Avg. loss: 0.144862\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 43.48, NNZs: 619, Bias: 0.000000, T: 36096, Avg. loss: 0.144679\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 43.51, NNZs: 619, Bias: 0.000000, T: 38352, Avg. loss: 0.144493\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 43.53, NNZs: 619, Bias: 0.000000, T: 40608, Avg. loss: 0.144460\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 43.55, NNZs: 618, Bias: 0.000000, T: 42864, Avg. loss: 0.144420\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 43.57, NNZs: 618, Bias: 0.000000, T: 45120, Avg. loss: 0.144387\n",
      "Total training time: 0.14 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.06171699256249541, clf__eta0=0.6666115972798587, clf__fit_intercept=False, clf__l1_ratio=0.9792901432894962, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.15075392531110676, clf__shuffle=True, clf__tol=0.365636830734297, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.489 total time=   1.5s\n",
      "-- Epoch 1\n",
      "Norm: 139778991018856.41, NNZs: 21253, Bias: 0.000000, T: 2256, Avg. loss: 3123021134527619200450560.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 93523897927562.53, NNZs: 21253, Bias: 0.000000, T: 4512, Avg. loss: 6593259318316962154545152.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 66889118193606.20, NNZs: 21253, Bias: 0.000000, T: 6768, Avg. loss: 2607106467527789658505216.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 49176006815333.08, NNZs: 21253, Bias: 0.000000, T: 9024, Avg. loss: 1198502412978658926919680.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 36619135848949.55, NNZs: 21253, Bias: 0.000000, T: 11280, Avg. loss: 600795006462529269399552.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27898438578685.74, NNZs: 21253, Bias: 0.000000, T: 13536, Avg. loss: 301386884259158689841152.000000\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "[CV 1/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.7915127974877743, clf__eta0=0.05539740212799926, clf__fit_intercept=False, clf__l1_ratio=0.9152680641407671, clf__learning_rate=optimal, clf__loss=squared_epsilon_insensitive, clf__max_iter=80, clf__penalty=l1, clf__power_t=0.6359093112142983, clf__shuffle=True, clf__tol=0.9361199211609239, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.380 total time=   1.4s\n",
      "-- Epoch 1\n",
      "Norm: 137748568001276.72, NNZs: 20874, Bias: 0.000000, T: 2256, Avg. loss: 2988870729977571959635968.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 92901923978548.91, NNZs: 20874, Bias: 0.000000, T: 4512, Avg. loss: 6427162427971791661039616.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 66758349540640.32, NNZs: 20874, Bias: 0.000000, T: 6768, Avg. loss: 2554531253304831732875264.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 49682430314129.54, NNZs: 20874, Bias: 0.000000, T: 9024, Avg. loss: 1176306675231930449920000.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 37500750678509.98, NNZs: 20874, Bias: 0.000000, T: 11280, Avg. loss: 603892546253282833596416.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 28779063950528.12, NNZs: 20874, Bias: 0.000000, T: 13536, Avg. loss: 312055332278202833829888.000000\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "[CV 2/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.7915127974877743, clf__eta0=0.05539740212799926, clf__fit_intercept=False, clf__l1_ratio=0.9152680641407671, clf__learning_rate=optimal, clf__loss=squared_epsilon_insensitive, clf__max_iter=80, clf__penalty=l1, clf__power_t=0.6359093112142983, clf__shuffle=True, clf__tol=0.9361199211609239, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.308 total time=   1.4s\n",
      "-- Epoch 1\n",
      "Norm: 132836383097713.08, NNZs: 21291, Bias: 0.000000, T: 2256, Avg. loss: 2821425288711224078368768.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 88244716959602.08, NNZs: 21293, Bias: 0.000000, T: 4512, Avg. loss: 6053721520431334959349760.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 63028221549283.02, NNZs: 21293, Bias: 0.000000, T: 6768, Avg. loss: 2311894745985505290092544.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 46177694907468.67, NNZs: 21293, Bias: 0.000000, T: 9024, Avg. loss: 1074138893350155940003840.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 34513494960236.41, NNZs: 21293, Bias: 0.000000, T: 11280, Avg. loss: 521889814835336090484736.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 26127378237905.60, NNZs: 21293, Bias: 0.000000, T: 13536, Avg. loss: 267393658826799062188032.000000\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "[CV 3/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.7915127974877743, clf__eta0=0.05539740212799926, clf__fit_intercept=False, clf__l1_ratio=0.9152680641407671, clf__learning_rate=optimal, clf__loss=squared_epsilon_insensitive, clf__max_iter=80, clf__penalty=l1, clf__power_t=0.6359093112142983, clf__shuffle=True, clf__tol=0.9361199211609239, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.366 total time=   1.4s\n",
      "-- Epoch 1\n",
      "Norm: 135972532902923.33, NNZs: 21030, Bias: 0.000000, T: 2256, Avg. loss: 3064807818116123676639232.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 92186070030869.14, NNZs: 21031, Bias: 0.000000, T: 4512, Avg. loss: 6107363610287110801588224.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 65780660908240.06, NNZs: 21031, Bias: 0.000000, T: 6768, Avg. loss: 2534138615889975868129280.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 48669529779435.98, NNZs: 21031, Bias: 0.000000, T: 9024, Avg. loss: 1148064611906906163773440.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 36457485509904.92, NNZs: 21031, Bias: 0.000000, T: 11280, Avg. loss: 578201387580730332151808.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27435597018575.07, NNZs: 21031, Bias: 0.000000, T: 13536, Avg. loss: 304655140572802953773056.000000\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "[CV 4/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.7915127974877743, clf__eta0=0.05539740212799926, clf__fit_intercept=False, clf__l1_ratio=0.9152680641407671, clf__learning_rate=optimal, clf__loss=squared_epsilon_insensitive, clf__max_iter=80, clf__penalty=l1, clf__power_t=0.6359093112142983, clf__shuffle=True, clf__tol=0.9361199211609239, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.277 total time=   1.4s\n",
      "-- Epoch 1\n",
      "Norm: 132460275154256.70, NNZs: 21208, Bias: 0.000000, T: 2256, Avg. loss: 2948752744283190260137984.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 88241982116882.67, NNZs: 21208, Bias: 0.000000, T: 4512, Avg. loss: 6043280602458709032960000.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 63427412199201.90, NNZs: 21208, Bias: 0.000000, T: 6768, Avg. loss: 2310545379610726540247040.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 47049536633161.67, NNZs: 21208, Bias: 0.000000, T: 9024, Avg. loss: 1052665812994669699661824.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 35393279651223.43, NNZs: 21208, Bias: 0.000000, T: 11280, Avg. loss: 536457304656794850689024.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27178795779623.91, NNZs: 21208, Bias: 0.000000, T: 13536, Avg. loss: 273202281651125071380480.000000\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "[CV 5/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.7915127974877743, clf__eta0=0.05539740212799926, clf__fit_intercept=False, clf__l1_ratio=0.9152680641407671, clf__learning_rate=optimal, clf__loss=squared_epsilon_insensitive, clf__max_iter=80, clf__penalty=l1, clf__power_t=0.6359093112142983, clf__shuffle=True, clf__tol=0.9361199211609239, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.375 total time=   1.4s\n",
      "-- Epoch 1\n",
      "Norm: 31.34, NNZs: 8234, Bias: 0.000000, T: 2256, Avg. loss: 0.190844\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 38.35, NNZs: 4008, Bias: 0.000000, T: 4512, Avg. loss: 0.050509\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 43.92, NNZs: 2763, Bias: 0.000000, T: 6768, Avg. loss: 0.043179\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 48.43, NNZs: 2151, Bias: 0.000000, T: 9024, Avg. loss: 0.034503\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 52.41, NNZs: 1813, Bias: 0.000000, T: 11280, Avg. loss: 0.031119\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 55.89, NNZs: 1575, Bias: 0.000000, T: 13536, Avg. loss: 0.028210\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.03646223783802971, clf__eta0=0.7491267567674796, clf__fit_intercept=False, clf__l1_ratio=0.775818217437024, clf__learning_rate=constant, clf__loss=squared_hinge, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.4028006727705291, clf__shuffle=True, clf__tol=0.1730703028465106, clf__warm_start=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.795 total time=   1.4s\n",
      "-- Epoch 1\n",
      "Norm: 31.24, NNZs: 7907, Bias: 0.000000, T: 2256, Avg. loss: 0.189210\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 38.37, NNZs: 3970, Bias: 0.000000, T: 4512, Avg. loss: 0.053886\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 44.01, NNZs: 2779, Bias: 0.000000, T: 6768, Avg. loss: 0.042775\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 48.60, NNZs: 2180, Bias: 0.000000, T: 9024, Avg. loss: 0.034906\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 52.40, NNZs: 1771, Bias: 0.000000, T: 11280, Avg. loss: 0.031203\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 55.89, NNZs: 1561, Bias: 0.000000, T: 13536, Avg. loss: 0.027130\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "[CV 2/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.03646223783802971, clf__eta0=0.7491267567674796, clf__fit_intercept=False, clf__l1_ratio=0.775818217437024, clf__learning_rate=constant, clf__loss=squared_hinge, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.4028006727705291, clf__shuffle=True, clf__tol=0.1730703028465106, clf__warm_start=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.588 total time=   1.4s\n",
      "-- Epoch 1\n",
      "Norm: 31.36, NNZs: 8049, Bias: 0.000000, T: 2256, Avg. loss: 0.184860\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 38.09, NNZs: 3855, Bias: 0.000000, T: 4512, Avg. loss: 0.049877\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 43.23, NNZs: 2589, Bias: 0.000000, T: 6768, Avg. loss: 0.035942\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 47.79, NNZs: 2050, Bias: 0.000000, T: 9024, Avg. loss: 0.034114\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 51.63, NNZs: 1684, Bias: 0.000000, T: 11280, Avg. loss: 0.029805\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 55.09, NNZs: 1506, Bias: 0.000000, T: 13536, Avg. loss: 0.026978\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "[CV 3/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.03646223783802971, clf__eta0=0.7491267567674796, clf__fit_intercept=False, clf__l1_ratio=0.775818217437024, clf__learning_rate=constant, clf__loss=squared_hinge, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.4028006727705291, clf__shuffle=True, clf__tol=0.1730703028465106, clf__warm_start=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.717 total time=   1.4s\n",
      "-- Epoch 1\n",
      "Norm: 30.96, NNZs: 7746, Bias: 0.000000, T: 2256, Avg. loss: 0.182765\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 37.83, NNZs: 3706, Bias: 0.000000, T: 4512, Avg. loss: 0.051495\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 42.97, NNZs: 2575, Bias: 0.000000, T: 6768, Avg. loss: 0.038010\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 47.37, NNZs: 2016, Bias: 0.000000, T: 9024, Avg. loss: 0.031896\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 51.24, NNZs: 1679, Bias: 0.000000, T: 11280, Avg. loss: 0.029830\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 54.57, NNZs: 1455, Bias: 0.000000, T: 13536, Avg. loss: 0.026040\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "[CV 4/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.03646223783802971, clf__eta0=0.7491267567674796, clf__fit_intercept=False, clf__l1_ratio=0.775818217437024, clf__learning_rate=constant, clf__loss=squared_hinge, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.4028006727705291, clf__shuffle=True, clf__tol=0.1730703028465106, clf__warm_start=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.701 total time=   1.4s\n",
      "-- Epoch 1\n",
      "Norm: 31.45, NNZs: 8218, Bias: 0.000000, T: 2256, Avg. loss: 0.195592\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 38.42, NNZs: 3880, Bias: 0.000000, T: 4512, Avg. loss: 0.051915\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 43.78, NNZs: 2671, Bias: 0.000000, T: 6768, Avg. loss: 0.041601\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 48.26, NNZs: 2085, Bias: 0.000000, T: 9024, Avg. loss: 0.034772\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 52.24, NNZs: 1701, Bias: 0.000000, T: 11280, Avg. loss: 0.030652\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 55.56, NNZs: 1488, Bias: 0.000000, T: 13536, Avg. loss: 0.026509\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "[CV 5/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.03646223783802971, clf__eta0=0.7491267567674796, clf__fit_intercept=False, clf__l1_ratio=0.775818217437024, clf__learning_rate=constant, clf__loss=squared_hinge, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.4028006727705291, clf__shuffle=True, clf__tol=0.1730703028465106, clf__warm_start=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.658 total time=   1.4s\n",
      "-- Epoch 1\n",
      "Norm: 33.54, NNZs: 12306, Bias: 0.000000, T: 2256, Avg. loss: 0.494848\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 60.64, NNZs: 8199, Bias: 0.000000, T: 4512, Avg. loss: 0.568518\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 142.68, NNZs: 8711, Bias: 0.000000, T: 6768, Avg. loss: 3.266053\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 389.35, NNZs: 10814, Bias: 0.000000, T: 9024, Avg. loss: 22.935584\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1226.79, NNZs: 15550, Bias: 0.000000, T: 11280, Avg. loss: 224.090043\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 4084.02, NNZs: 19029, Bias: 0.000000, T: 13536, Avg. loss: 2512.783984\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.05 seconds\n",
      "[CV 1/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.24457156361183285, clf__eta0=0.332929742792607, clf__fit_intercept=False, clf__l1_ratio=0.920539731041378, clf__learning_rate=constant, clf__loss=squared_error, clf__max_iter=100, clf__penalty=l1, clf__power_t=0.5734177157821045, clf__shuffle=True, clf__tol=0.6492274795888617, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.390 total time=   1.4s\n",
      "-- Epoch 1\n",
      "Norm: 33.92, NNZs: 12188, Bias: 0.000000, T: 2256, Avg. loss: 0.459128\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 65.75, NNZs: 7725, Bias: 0.000000, T: 4512, Avg. loss: 0.795127\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 156.75, NNZs: 8282, Bias: 0.000000, T: 6768, Avg. loss: 3.301925\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 450.76, NNZs: 10823, Bias: 0.000000, T: 9024, Avg. loss: 33.204349\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1547.47, NNZs: 15529, Bias: 0.000000, T: 11280, Avg. loss: 400.622061\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 5546.14, NNZs: 18979, Bias: 0.000000, T: 13536, Avg. loss: 4323.530248\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "[CV 2/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.24457156361183285, clf__eta0=0.332929742792607, clf__fit_intercept=False, clf__l1_ratio=0.920539731041378, clf__learning_rate=constant, clf__loss=squared_error, clf__max_iter=100, clf__penalty=l1, clf__power_t=0.5734177157821045, clf__shuffle=True, clf__tol=0.6492274795888617, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.462 total time=   1.4s\n",
      "-- Epoch 1\n",
      "Norm: 34.84, NNZs: 11939, Bias: 0.000000, T: 2256, Avg. loss: 0.465846\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 73.18, NNZs: 8769, Bias: 0.000000, T: 4512, Avg. loss: 1.071774\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 176.76, NNZs: 10217, Bias: 0.000000, T: 6768, Avg. loss: 5.095426\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 487.73, NNZs: 12886, Bias: 0.000000, T: 9024, Avg. loss: 44.452292\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1511.47, NNZs: 16666, Bias: 0.000000, T: 11280, Avg. loss: 383.197673\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 5244.16, NNZs: 19567, Bias: 0.000000, T: 13536, Avg. loss: 4034.631241\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.24457156361183285, clf__eta0=0.332929742792607, clf__fit_intercept=False, clf__l1_ratio=0.920539731041378, clf__learning_rate=constant, clf__loss=squared_error, clf__max_iter=100, clf__penalty=l1, clf__power_t=0.5734177157821045, clf__shuffle=True, clf__tol=0.6492274795888617, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.369 total time=   1.4s\n",
      "-- Epoch 1\n",
      "Norm: 31.97, NNZs: 11871, Bias: 0.000000, T: 2256, Avg. loss: 0.449988\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 51.80, NNZs: 7263, Bias: 0.000000, T: 4512, Avg. loss: 0.469258\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 106.59, NNZs: 7406, Bias: 0.000000, T: 6768, Avg. loss: 1.517385\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 284.04, NNZs: 9387, Bias: 0.000000, T: 9024, Avg. loss: 10.718991\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 931.01, NNZs: 13578, Bias: 0.000000, T: 11280, Avg. loss: 116.074286\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3051.04, NNZs: 17932, Bias: 0.000000, T: 13536, Avg. loss: 1504.139334\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "[CV 4/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.24457156361183285, clf__eta0=0.332929742792607, clf__fit_intercept=False, clf__l1_ratio=0.920539731041378, clf__learning_rate=constant, clf__loss=squared_error, clf__max_iter=100, clf__penalty=l1, clf__power_t=0.5734177157821045, clf__shuffle=True, clf__tol=0.6492274795888617, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.435 total time=   1.4s\n",
      "-- Epoch 1\n",
      "Norm: 30.06, NNZs: 12005, Bias: 0.000000, T: 2256, Avg. loss: 0.462931\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 46.19, NNZs: 6968, Bias: 0.000000, T: 4512, Avg. loss: 0.261959\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 99.98, NNZs: 7323, Bias: 0.000000, T: 6768, Avg. loss: 1.098526\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 293.18, NNZs: 8876, Bias: 0.000000, T: 9024, Avg. loss: 10.453290\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1033.24, NNZs: 13583, Bias: 0.000000, T: 11280, Avg. loss: 124.144934\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3883.19, NNZs: 18565, Bias: 0.000000, T: 13536, Avg. loss: 2186.293912\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.05 seconds\n",
      "[CV 5/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.24457156361183285, clf__eta0=0.332929742792607, clf__fit_intercept=False, clf__l1_ratio=0.920539731041378, clf__learning_rate=constant, clf__loss=squared_error, clf__max_iter=100, clf__penalty=l1, clf__power_t=0.5734177157821045, clf__shuffle=True, clf__tol=0.6492274795888617, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.403 total time=   1.4s\n",
      "-- Epoch 1\n",
      "Norm: 2.14, NNZs: 37188, Bias: -0.107177, T: 2256, Avg. loss: 0.133587\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2.59, NNZs: 37188, Bias: -0.142763, T: 4512, Avg. loss: 0.087237\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.84, NNZs: 37188, Bias: -0.166167, T: 6768, Avg. loss: 0.072297\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3.01, NNZs: 37188, Bias: -0.183845, T: 9024, Avg. loss: 0.063548\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3.14, NNZs: 37188, Bias: -0.198139, T: 11280, Avg. loss: 0.057640\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.24, NNZs: 37188, Bias: -0.210155, T: 13536, Avg. loss: 0.053329\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 1/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.2527955528897454, clf__eta0=0.4377192284389271, clf__fit_intercept=True, clf__l1_ratio=0.6515110441465675, clf__learning_rate=invscaling, clf__loss=huber, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.47239053945705856, clf__shuffle=False, clf__tol=0.9089234089706554, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.491 total time=   1.4s\n",
      "-- Epoch 1\n",
      "Norm: 2.12, NNZs: 37108, Bias: -0.107528, T: 2256, Avg. loss: 0.136140\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2.60, NNZs: 37108, Bias: -0.143739, T: 4512, Avg. loss: 0.086547\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.85, NNZs: 37108, Bias: -0.167085, T: 6768, Avg. loss: 0.071734\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3.02, NNZs: 37108, Bias: -0.184647, T: 9024, Avg. loss: 0.063265\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3.14, NNZs: 37108, Bias: -0.198837, T: 11280, Avg. loss: 0.057489\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.24, NNZs: 37108, Bias: -0.210771, T: 13536, Avg. loss: 0.053229\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 2/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.2527955528897454, clf__eta0=0.4377192284389271, clf__fit_intercept=True, clf__l1_ratio=0.6515110441465675, clf__learning_rate=invscaling, clf__loss=huber, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.47239053945705856, clf__shuffle=False, clf__tol=0.9089234089706554, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.491 total time=   1.4s\n",
      "-- Epoch 1\n",
      "Norm: 2.16, NNZs: 37483, Bias: -0.106976, T: 2256, Avg. loss: 0.133728\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2.62, NNZs: 37483, Bias: -0.142421, T: 4512, Avg. loss: 0.085985\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.85, NNZs: 37483, Bias: -0.165368, T: 6768, Avg. loss: 0.071752\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3.01, NNZs: 37483, Bias: -0.182683, T: 9024, Avg. loss: 0.063528\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3.13, NNZs: 37483, Bias: -0.196739, T: 11280, Avg. loss: 0.057902\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.23, NNZs: 37483, Bias: -0.208594, T: 13536, Avg. loss: 0.053740\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 3/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.2527955528897454, clf__eta0=0.4377192284389271, clf__fit_intercept=True, clf__l1_ratio=0.6515110441465675, clf__learning_rate=invscaling, clf__loss=huber, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.47239053945705856, clf__shuffle=False, clf__tol=0.9089234089706554, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.490 total time=   1.4s\n",
      "-- Epoch 1\n",
      "Norm: 2.15, NNZs: 36944, Bias: -0.106485, T: 2256, Avg. loss: 0.132990\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2.61, NNZs: 36944, Bias: -0.141458, T: 4512, Avg. loss: 0.084855\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.84, NNZs: 36944, Bias: -0.164004, T: 6768, Avg. loss: 0.070776\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3.00, NNZs: 36944, Bias: -0.180988, T: 9024, Avg. loss: 0.062716\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3.12, NNZs: 36944, Bias: -0.194783, T: 11280, Avg. loss: 0.057215\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.21, NNZs: 36944, Bias: -0.206443, T: 13536, Avg. loss: 0.053132\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 4/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.2527955528897454, clf__eta0=0.4377192284389271, clf__fit_intercept=True, clf__l1_ratio=0.6515110441465675, clf__learning_rate=invscaling, clf__loss=huber, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.47239053945705856, clf__shuffle=False, clf__tol=0.9089234089706554, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.490 total time=   1.4s\n",
      "-- Epoch 1\n",
      "Norm: 2.13, NNZs: 37282, Bias: -0.107745, T: 2256, Avg. loss: 0.135490\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2.61, NNZs: 37282, Bias: -0.143991, T: 4512, Avg. loss: 0.086641\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.86, NNZs: 37282, Bias: -0.167415, T: 6768, Avg. loss: 0.071829\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3.02, NNZs: 37282, Bias: -0.185021, T: 9024, Avg. loss: 0.063347\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3.14, NNZs: 37282, Bias: -0.199255, T: 11280, Avg. loss: 0.057574\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.24, NNZs: 37282, Bias: -0.211233, T: 13536, Avg. loss: 0.053314\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.2527955528897454, clf__eta0=0.4377192284389271, clf__fit_intercept=True, clf__l1_ratio=0.6515110441465675, clf__learning_rate=invscaling, clf__loss=huber, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.47239053945705856, clf__shuffle=False, clf__tol=0.9089234089706554, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.490 total time=   1.4s\n",
      "-- Epoch 1\n",
      "Norm: 91.34, NNZs: 36682, Bias: -1.001852, T: 2256, Avg. loss: 0.863232\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 39.41, NNZs: 36996, Bias: -0.974046, T: 4512, Avg. loss: 0.946902\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 30.73, NNZs: 37107, Bias: -0.927107, T: 6768, Avg. loss: 0.249424\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 24.55, NNZs: 37062, Bias: -0.940026, T: 9024, Avg. loss: 0.165667\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 21.32, NNZs: 37136, Bias: -0.945662, T: 11280, Avg. loss: 0.066727\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 19.84, NNZs: 37146, Bias: -0.943317, T: 13536, Avg. loss: 0.026698\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 19.16, NNZs: 37144, Bias: -0.974545, T: 15792, Avg. loss: 0.009582\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 7 epochs took 0.03 seconds\n",
      "[CV 1/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.3241670976844645, clf__eta0=0.9631840511405841, clf__fit_intercept=True, clf__l1_ratio=0.5912641309775509, clf__learning_rate=optimal, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.6710686638981408, clf__shuffle=True, clf__tol=0.09654933943827881, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.634 total time=   1.4s\n",
      "-- Epoch 1\n",
      "Norm: 91.89, NNZs: 36305, Bias: -0.843596, T: 2256, Avg. loss: 0.848649\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 41.90, NNZs: 36856, Bias: -0.814563, T: 4512, Avg. loss: 0.912868\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 32.02, NNZs: 37004, Bias: -0.973988, T: 6768, Avg. loss: 0.278021\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 25.04, NNZs: 37026, Bias: -0.888947, T: 9024, Avg. loss: 0.169793\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 21.58, NNZs: 37041, Bias: -0.956385, T: 11280, Avg. loss: 0.070880\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 19.51, NNZs: 37059, Bias: -0.919708, T: 13536, Avg. loss: 0.031662\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 18.87, NNZs: 37061, Bias: -0.952294, T: 15792, Avg. loss: 0.009640\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 17.93, NNZs: 37063, Bias: -0.923349, T: 18048, Avg. loss: 0.003705\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 17.59, NNZs: 37064, Bias: -0.933872, T: 20304, Avg. loss: 0.003262\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 9 epochs took 0.04 seconds\n",
      "[CV 2/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.3241670976844645, clf__eta0=0.9631840511405841, clf__fit_intercept=True, clf__l1_ratio=0.5912641309775509, clf__learning_rate=optimal, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.6710686638981408, clf__shuffle=True, clf__tol=0.09654933943827881, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.525 total time=   1.4s\n",
      "-- Epoch 1\n",
      "Norm: 91.48, NNZs: 36716, Bias: -1.159417, T: 2256, Avg. loss: 0.833578\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 42.01, NNZs: 37266, Bias: -0.958062, T: 4512, Avg. loss: 0.924503\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 31.66, NNZs: 37324, Bias: -1.053288, T: 6768, Avg. loss: 0.280468\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 24.27, NNZs: 37365, Bias: -0.951084, T: 9024, Avg. loss: 0.165383\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 21.16, NNZs: 37354, Bias: -1.006258, T: 11280, Avg. loss: 0.063773\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 19.33, NNZs: 37352, Bias: -0.998025, T: 13536, Avg. loss: 0.026854\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 3/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.3241670976844645, clf__eta0=0.9631840511405841, clf__fit_intercept=True, clf__l1_ratio=0.5912641309775509, clf__learning_rate=optimal, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.6710686638981408, clf__shuffle=True, clf__tol=0.09654933943827881, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.553 total time=   1.5s\n",
      "-- Epoch 1\n",
      "Norm: 91.45, NNZs: 36354, Bias: -0.956696, T: 2256, Avg. loss: 0.852477\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 41.19, NNZs: 36747, Bias: -0.899611, T: 4512, Avg. loss: 0.918017\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 32.00, NNZs: 36830, Bias: -0.921014, T: 6768, Avg. loss: 0.269220\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 25.00, NNZs: 36853, Bias: -0.906825, T: 9024, Avg. loss: 0.170324\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 21.28, NNZs: 36852, Bias: -0.953710, T: 11280, Avg. loss: 0.076509\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 19.51, NNZs: 36848, Bias: -0.930607, T: 13536, Avg. loss: 0.025968\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 4/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.3241670976844645, clf__eta0=0.9631840511405841, clf__fit_intercept=True, clf__l1_ratio=0.5912641309775509, clf__learning_rate=optimal, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.6710686638981408, clf__shuffle=True, clf__tol=0.09654933943827881, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.553 total time=   1.4s\n",
      "-- Epoch 1\n",
      "Norm: 91.36, NNZs: 36795, Bias: -0.876769, T: 2256, Avg. loss: 0.870465\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 41.28, NNZs: 37125, Bias: -0.966667, T: 4512, Avg. loss: 0.915312\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 31.30, NNZs: 37202, Bias: -0.894675, T: 6768, Avg. loss: 0.269555\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 24.50, NNZs: 37240, Bias: -0.958654, T: 9024, Avg. loss: 0.168944\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 21.17, NNZs: 37257, Bias: -0.902081, T: 11280, Avg. loss: 0.073153\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 19.51, NNZs: 37268, Bias: -0.960425, T: 13536, Avg. loss: 0.026600\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 18.93, NNZs: 37275, Bias: -0.914094, T: 15792, Avg. loss: 0.010901\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 17.88, NNZs: 37274, Bias: -0.921031, T: 18048, Avg. loss: 0.003690\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 17.40, NNZs: 37277, Bias: -0.931187, T: 20304, Avg. loss: 0.002802\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 16.93, NNZs: 37276, Bias: -0.918446, T: 22560, Avg. loss: 0.002303\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 16.64, NNZs: 37278, Bias: -0.926692, T: 24816, Avg. loss: 0.002063\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 11 epochs took 0.04 seconds\n",
      "[CV 5/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.3241670976844645, clf__eta0=0.9631840511405841, clf__fit_intercept=True, clf__l1_ratio=0.5912641309775509, clf__learning_rate=optimal, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.6710686638981408, clf__shuffle=True, clf__tol=0.09654933943827881, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.490 total time=   1.4s\n",
      "-- Epoch 1\n",
      "Norm: 77.72, NNZs: 9678, Bias: 0.000000, T: 2256, Avg. loss: 0.809659\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 92.12, NNZs: 6069, Bias: 0.000000, T: 4512, Avg. loss: 0.265914\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 104.77, NNZs: 4415, Bias: 0.000000, T: 6768, Avg. loss: 0.167925\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 112.28, NNZs: 3212, Bias: 0.000000, T: 9024, Avg. loss: 0.114899\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 117.87, NNZs: 2631, Bias: 0.000000, T: 11280, Avg. loss: 0.068496\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 123.90, NNZs: 2138, Bias: 0.000000, T: 13536, Avg. loss: 0.078943\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.3509613152086368, clf__eta0=0.9934401124631351, clf__fit_intercept=False, clf__l1_ratio=0.5204998682261415, clf__learning_rate=constant, clf__loss=hinge, clf__max_iter=40, clf__penalty=l1, clf__power_t=0.5098574122392232, clf__shuffle=False, clf__tol=0.5563103350645606, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.696 total time=   1.4s\n",
      "-- Epoch 1\n",
      "Norm: 78.37, NNZs: 9722, Bias: 0.000000, T: 2256, Avg. loss: 0.938999\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 92.83, NNZs: 5946, Bias: 0.000000, T: 4512, Avg. loss: 0.283003\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 102.35, NNZs: 4084, Bias: 0.000000, T: 6768, Avg. loss: 0.155910\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 109.75, NNZs: 3038, Bias: 0.000000, T: 9024, Avg. loss: 0.122895\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 116.77, NNZs: 2509, Bias: 0.000000, T: 11280, Avg. loss: 0.079992\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 121.10, NNZs: 2091, Bias: 0.000000, T: 13536, Avg. loss: 0.047422\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 2/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.3509613152086368, clf__eta0=0.9934401124631351, clf__fit_intercept=False, clf__l1_ratio=0.5204998682261415, clf__learning_rate=constant, clf__loss=hinge, clf__max_iter=40, clf__penalty=l1, clf__power_t=0.5098574122392232, clf__shuffle=False, clf__tol=0.5563103350645606, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.702 total time=   1.4s\n",
      "-- Epoch 1\n",
      "Norm: 80.41, NNZs: 9808, Bias: 0.000000, T: 2256, Avg. loss: 0.831613\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 97.06, NNZs: 6323, Bias: 0.000000, T: 4512, Avg. loss: 0.320993\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 105.62, NNZs: 4323, Bias: 0.000000, T: 6768, Avg. loss: 0.169048\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 114.83, NNZs: 3530, Bias: 0.000000, T: 9024, Avg. loss: 0.134714\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 120.22, NNZs: 2771, Bias: 0.000000, T: 11280, Avg. loss: 0.079930\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 124.81, NNZs: 2306, Bias: 0.000000, T: 13536, Avg. loss: 0.048154\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "[CV 3/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.3509613152086368, clf__eta0=0.9934401124631351, clf__fit_intercept=False, clf__l1_ratio=0.5204998682261415, clf__learning_rate=constant, clf__loss=hinge, clf__max_iter=40, clf__penalty=l1, clf__power_t=0.5098574122392232, clf__shuffle=False, clf__tol=0.5563103350645606, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.744 total time=   1.4s\n",
      "-- Epoch 1\n",
      "Norm: 78.52, NNZs: 9499, Bias: 0.000000, T: 2256, Avg. loss: 0.840645\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 93.94, NNZs: 5999, Bias: 0.000000, T: 4512, Avg. loss: 0.319771\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 101.73, NNZs: 3982, Bias: 0.000000, T: 6768, Avg. loss: 0.130276\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 109.33, NNZs: 2992, Bias: 0.000000, T: 9024, Avg. loss: 0.113150\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 114.94, NNZs: 2407, Bias: 0.000000, T: 11280, Avg. loss: 0.067421\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 120.48, NNZs: 2037, Bias: 0.000000, T: 13536, Avg. loss: 0.048856\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 4/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.3509613152086368, clf__eta0=0.9934401124631351, clf__fit_intercept=False, clf__l1_ratio=0.5204998682261415, clf__learning_rate=constant, clf__loss=hinge, clf__max_iter=40, clf__penalty=l1, clf__power_t=0.5098574122392232, clf__shuffle=False, clf__tol=0.5563103350645606, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.757 total time=   1.4s\n",
      "-- Epoch 1\n",
      "Norm: 81.82, NNZs: 9762, Bias: 0.000000, T: 2256, Avg. loss: 0.892016\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 96.06, NNZs: 6213, Bias: 0.000000, T: 4512, Avg. loss: 0.317018\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 105.30, NNZs: 4326, Bias: 0.000000, T: 6768, Avg. loss: 0.188837\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 113.83, NNZs: 3309, Bias: 0.000000, T: 9024, Avg. loss: 0.112884\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 119.95, NNZs: 2758, Bias: 0.000000, T: 11280, Avg. loss: 0.077530\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 126.19, NNZs: 2360, Bias: 0.000000, T: 13536, Avg. loss: 0.079358\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "[CV 5/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.3509613152086368, clf__eta0=0.9934401124631351, clf__fit_intercept=False, clf__l1_ratio=0.5204998682261415, clf__learning_rate=constant, clf__loss=hinge, clf__max_iter=40, clf__penalty=l1, clf__power_t=0.5098574122392232, clf__shuffle=False, clf__tol=0.5563103350645606, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.743 total time=   1.4s\n",
      "-- Epoch 1\n",
      "Norm: 0.17, NNZs: 21252, Bias: 0.000000, T: 2256, Avg. loss: 0.711648\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.23, NNZs: 21252, Bias: 0.000000, T: 4512, Avg. loss: 0.721756\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.29, NNZs: 21252, Bias: 0.000000, T: 6768, Avg. loss: 0.724473\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.33, NNZs: 21252, Bias: 0.000000, T: 9024, Avg. loss: 0.731451\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.37, NNZs: 21252, Bias: 0.000000, T: 11280, Avg. loss: 0.737854\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.41, NNZs: 21252, Bias: 0.000000, T: 13536, Avg. loss: 0.739770\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 1/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.28658617296069355, clf__eta0=0.03398405924608927, clf__fit_intercept=False, clf__l1_ratio=0.08227014493927165, clf__learning_rate=invscaling, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.5467473202425025, clf__shuffle=True, clf__tol=0.9099604695658384, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.164 total time=   1.4s\n",
      "-- Epoch 1\n",
      "Norm: 0.18, NNZs: 20870, Bias: 0.000000, T: 2256, Avg. loss: 0.714848\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.24, NNZs: 20870, Bias: 0.000000, T: 4512, Avg. loss: 0.720893\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.30, NNZs: 20870, Bias: 0.000000, T: 6768, Avg. loss: 0.728619\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.34, NNZs: 20870, Bias: 0.000000, T: 9024, Avg. loss: 0.733516\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.38, NNZs: 20870, Bias: 0.000000, T: 11280, Avg. loss: 0.736107\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.42, NNZs: 20870, Bias: 0.000000, T: 13536, Avg. loss: 0.738907\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 2/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.28658617296069355, clf__eta0=0.03398405924608927, clf__fit_intercept=False, clf__l1_ratio=0.08227014493927165, clf__learning_rate=invscaling, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.5467473202425025, clf__shuffle=True, clf__tol=0.9099604695658384, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.148 total time=   1.4s\n",
      "-- Epoch 1\n",
      "Norm: 0.30, NNZs: 21292, Bias: 0.000000, T: 2256, Avg. loss: 0.723371\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.36, NNZs: 21292, Bias: 0.000000, T: 4512, Avg. loss: 0.731889\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.40, NNZs: 21292, Bias: 0.000000, T: 6768, Avg. loss: 0.738707\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.44, NNZs: 21292, Bias: 0.000000, T: 9024, Avg. loss: 0.743757\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.48, NNZs: 21292, Bias: 0.000000, T: 11280, Avg. loss: 0.747066\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.51, NNZs: 21292, Bias: 0.000000, T: 13536, Avg. loss: 0.750232\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.28658617296069355, clf__eta0=0.03398405924608927, clf__fit_intercept=False, clf__l1_ratio=0.08227014493927165, clf__learning_rate=invscaling, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.5467473202425025, clf__shuffle=True, clf__tol=0.9099604695658384, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.145 total time=   1.4s\n",
      "-- Epoch 1\n",
      "Norm: 0.19, NNZs: 21030, Bias: 0.000000, T: 2256, Avg. loss: 0.716713\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.26, NNZs: 21030, Bias: 0.000000, T: 4512, Avg. loss: 0.725040\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.32, NNZs: 21030, Bias: 0.000000, T: 6768, Avg. loss: 0.730881\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.36, NNZs: 21030, Bias: 0.000000, T: 9024, Avg. loss: 0.734505\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.40, NNZs: 21030, Bias: 0.000000, T: 11280, Avg. loss: 0.738712\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.44, NNZs: 21030, Bias: 0.000000, T: 13536, Avg. loss: 0.741609\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 4/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.28658617296069355, clf__eta0=0.03398405924608927, clf__fit_intercept=False, clf__l1_ratio=0.08227014493927165, clf__learning_rate=invscaling, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.5467473202425025, clf__shuffle=True, clf__tol=0.9099604695658384, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.170 total time=   1.3s\n",
      "-- Epoch 1\n",
      "Norm: 0.19, NNZs: 21210, Bias: 0.000000, T: 2256, Avg. loss: 0.714111\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.25, NNZs: 21210, Bias: 0.000000, T: 4512, Avg. loss: 0.724477\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.31, NNZs: 21210, Bias: 0.000000, T: 6768, Avg. loss: 0.729041\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.35, NNZs: 21210, Bias: 0.000000, T: 9024, Avg. loss: 0.735036\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.39, NNZs: 21210, Bias: 0.000000, T: 11280, Avg. loss: 0.738847\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.43, NNZs: 21210, Bias: 0.000000, T: 13536, Avg. loss: 0.743052\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 5/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.28658617296069355, clf__eta0=0.03398405924608927, clf__fit_intercept=False, clf__l1_ratio=0.08227014493927165, clf__learning_rate=invscaling, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.5467473202425025, clf__shuffle=True, clf__tol=0.9099604695658384, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.136 total time=   1.3s\n",
      "-- Epoch 1\n",
      "Norm: 31.05, NNZs: 21251, Bias: 0.000000, T: 2256, Avg. loss: 0.670165\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 37.57, NNZs: 21251, Bias: 0.000000, T: 4512, Avg. loss: 0.272281\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 40.89, NNZs: 21251, Bias: 0.000000, T: 6768, Avg. loss: 0.191632\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 42.77, NNZs: 21251, Bias: 0.000000, T: 9024, Avg. loss: 0.164201\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 43.89, NNZs: 21251, Bias: 0.000000, T: 11280, Avg. loss: 0.150706\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 44.57, NNZs: 21251, Bias: 0.000000, T: 13536, Avg. loss: 0.143181\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 44.52, NNZs: 21251, Bias: 0.000000, T: 15792, Avg. loss: 0.129846\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 44.48, NNZs: 21251, Bias: 0.000000, T: 18048, Avg. loss: 0.127740\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 44.44, NNZs: 21251, Bias: 0.000000, T: 20304, Avg. loss: 0.126890\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 44.41, NNZs: 21251, Bias: 0.000000, T: 22560, Avg. loss: 0.126423\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 44.38, NNZs: 21251, Bias: 0.000000, T: 24816, Avg. loss: 0.126134\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 44.37, NNZs: 21251, Bias: 0.000000, T: 27072, Avg. loss: 0.122328\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 44.36, NNZs: 21251, Bias: 0.000000, T: 29328, Avg. loss: 0.122862\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 44.35, NNZs: 21251, Bias: 0.000000, T: 31584, Avg. loss: 0.123157\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 44.34, NNZs: 21251, Bias: 0.000000, T: 33840, Avg. loss: 0.123312\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 44.33, NNZs: 21251, Bias: 0.000000, T: 36096, Avg. loss: 0.123387\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 44.32, NNZs: 21251, Bias: 0.000000, T: 38352, Avg. loss: 0.122382\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 44.32, NNZs: 21251, Bias: 0.000000, T: 40608, Avg. loss: 0.122441\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 44.32, NNZs: 21251, Bias: 0.000000, T: 42864, Avg. loss: 0.122494\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 44.32, NNZs: 21251, Bias: 0.000000, T: 45120, Avg. loss: 0.122540\n",
      "Total training time: 0.07 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.42493015701647596, clf__eta0=0.6773009699604285, clf__fit_intercept=False, clf__l1_ratio=0.7301998277223162, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.017782879504616322, clf__shuffle=False, clf__tol=0.19519881462597577, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.723 total time=   1.4s\n",
      "-- Epoch 1\n",
      "Norm: 31.08, NNZs: 20868, Bias: 0.000000, T: 2256, Avg. loss: 0.647681\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 37.34, NNZs: 20868, Bias: 0.000000, T: 4512, Avg. loss: 0.265903\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 40.55, NNZs: 20868, Bias: 0.000000, T: 6768, Avg. loss: 0.190185\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 42.39, NNZs: 20868, Bias: 0.000000, T: 9024, Avg. loss: 0.161191\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 43.48, NNZs: 20868, Bias: 0.000000, T: 11280, Avg. loss: 0.147584\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 44.16, NNZs: 20868, Bias: 0.000000, T: 13536, Avg. loss: 0.140063\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 44.08, NNZs: 20868, Bias: 0.000000, T: 15792, Avg. loss: 0.136316\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 44.04, NNZs: 20868, Bias: 0.000000, T: 18048, Avg. loss: 0.125106\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 44.01, NNZs: 20868, Bias: 0.000000, T: 20304, Avg. loss: 0.123748\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 43.98, NNZs: 20868, Bias: 0.000000, T: 22560, Avg. loss: 0.123276\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 43.96, NNZs: 20868, Bias: 0.000000, T: 24816, Avg. loss: 0.123021\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 43.95, NNZs: 20868, Bias: 0.000000, T: 27072, Avg. loss: 0.124357\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 43.94, NNZs: 20868, Bias: 0.000000, T: 29328, Avg. loss: 0.122769\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 43.92, NNZs: 20868, Bias: 0.000000, T: 31584, Avg. loss: 0.121830\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 43.91, NNZs: 20868, Bias: 0.000000, T: 33840, Avg. loss: 0.121268\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 43.91, NNZs: 20868, Bias: 0.000000, T: 36096, Avg. loss: 0.120926\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 43.90, NNZs: 20868, Bias: 0.000000, T: 38352, Avg. loss: 0.120845\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 43.90, NNZs: 20868, Bias: 0.000000, T: 40608, Avg. loss: 0.120755\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 43.90, NNZs: 20868, Bias: 0.000000, T: 42864, Avg. loss: 0.120673\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 43.90, NNZs: 20868, Bias: 0.000000, T: 45120, Avg. loss: 0.120599\n",
      "Total training time: 0.07 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.42493015701647596, clf__eta0=0.6773009699604285, clf__fit_intercept=False, clf__l1_ratio=0.7301998277223162, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.017782879504616322, clf__shuffle=False, clf__tol=0.19519881462597577, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.731 total time=   1.4s\n",
      "-- Epoch 1\n",
      "Norm: 30.90, NNZs: 21291, Bias: 0.000000, T: 2256, Avg. loss: 0.663057\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 37.36, NNZs: 21291, Bias: 0.000000, T: 4512, Avg. loss: 0.262786\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 40.68, NNZs: 21291, Bias: 0.000000, T: 6768, Avg. loss: 0.187059\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 42.55, NNZs: 21291, Bias: 0.000000, T: 9024, Avg. loss: 0.159667\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 43.66, NNZs: 21291, Bias: 0.000000, T: 11280, Avg. loss: 0.146234\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 44.35, NNZs: 21291, Bias: 0.000000, T: 13536, Avg. loss: 0.138791\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 44.27, NNZs: 21291, Bias: 0.000000, T: 15792, Avg. loss: 0.128913\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 44.22, NNZs: 21291, Bias: 0.000000, T: 18048, Avg. loss: 0.121885\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 44.17, NNZs: 21291, Bias: 0.000000, T: 20304, Avg. loss: 0.121187\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 44.13, NNZs: 21291, Bias: 0.000000, T: 22560, Avg. loss: 0.121053\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 44.10, NNZs: 21291, Bias: 0.000000, T: 24816, Avg. loss: 0.121024\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 44.09, NNZs: 21291, Bias: 0.000000, T: 27072, Avg. loss: 0.121874\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 44.07, NNZs: 21291, Bias: 0.000000, T: 29328, Avg. loss: 0.120519\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 44.06, NNZs: 21291, Bias: 0.000000, T: 31584, Avg. loss: 0.119718\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 44.05, NNZs: 21291, Bias: 0.000000, T: 33840, Avg. loss: 0.119247\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 44.04, NNZs: 21291, Bias: 0.000000, T: 36096, Avg. loss: 0.118972\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 44.04, NNZs: 21291, Bias: 0.000000, T: 38352, Avg. loss: 0.119024\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 44.03, NNZs: 21291, Bias: 0.000000, T: 40608, Avg. loss: 0.118935\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 44.03, NNZs: 21291, Bias: 0.000000, T: 42864, Avg. loss: 0.118854\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 44.03, NNZs: 21291, Bias: 0.000000, T: 45120, Avg. loss: 0.118781\n",
      "Total training time: 0.07 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.42493015701647596, clf__eta0=0.6773009699604285, clf__fit_intercept=False, clf__l1_ratio=0.7301998277223162, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.017782879504616322, clf__shuffle=False, clf__tol=0.19519881462597577, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.727 total time=   1.4s\n",
      "-- Epoch 1\n",
      "Norm: 31.30, NNZs: 21035, Bias: 0.000000, T: 2256, Avg. loss: 0.638531\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 37.46, NNZs: 21035, Bias: 0.000000, T: 4512, Avg. loss: 0.260577\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 40.53, NNZs: 21035, Bias: 0.000000, T: 6768, Avg. loss: 0.183081\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 42.25, NNZs: 21035, Bias: 0.000000, T: 9024, Avg. loss: 0.156474\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 43.28, NNZs: 21035, Bias: 0.000000, T: 11280, Avg. loss: 0.143662\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 43.91, NNZs: 21035, Bias: 0.000000, T: 13536, Avg. loss: 0.136563\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 43.85, NNZs: 21035, Bias: 0.000000, T: 15792, Avg. loss: 0.126960\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 43.81, NNZs: 21035, Bias: 0.000000, T: 18048, Avg. loss: 0.122241\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 43.77, NNZs: 21035, Bias: 0.000000, T: 20304, Avg. loss: 0.121341\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 43.74, NNZs: 21035, Bias: 0.000000, T: 22560, Avg. loss: 0.120909\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 43.71, NNZs: 21035, Bias: 0.000000, T: 24816, Avg. loss: 0.120631\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 43.71, NNZs: 21035, Bias: 0.000000, T: 27072, Avg. loss: 0.117114\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 43.70, NNZs: 21035, Bias: 0.000000, T: 29328, Avg. loss: 0.117590\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 43.69, NNZs: 21035, Bias: 0.000000, T: 31584, Avg. loss: 0.117861\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 43.68, NNZs: 21035, Bias: 0.000000, T: 33840, Avg. loss: 0.118009\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 43.67, NNZs: 21035, Bias: 0.000000, T: 36096, Avg. loss: 0.118086\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 43.66, NNZs: 21035, Bias: 0.000000, T: 38352, Avg. loss: 0.117397\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 43.66, NNZs: 21035, Bias: 0.000000, T: 40608, Avg. loss: 0.117428\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 43.66, NNZs: 21035, Bias: 0.000000, T: 42864, Avg. loss: 0.117456\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 43.66, NNZs: 21035, Bias: 0.000000, T: 45120, Avg. loss: 0.117481\n",
      "Total training time: 0.07 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.42493015701647596, clf__eta0=0.6773009699604285, clf__fit_intercept=False, clf__l1_ratio=0.7301998277223162, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.017782879504616322, clf__shuffle=False, clf__tol=0.19519881462597577, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.616 total time=   1.4s\n",
      "-- Epoch 1\n",
      "Norm: 31.79, NNZs: 21208, Bias: 0.000000, T: 2256, Avg. loss: 0.613458\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 37.58, NNZs: 21208, Bias: 0.000000, T: 4512, Avg. loss: 0.261065\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 40.45, NNZs: 21208, Bias: 0.000000, T: 6768, Avg. loss: 0.183954\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 42.09, NNZs: 21208, Bias: 0.000000, T: 9024, Avg. loss: 0.157067\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 43.08, NNZs: 21208, Bias: 0.000000, T: 11280, Avg. loss: 0.143955\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 43.69, NNZs: 21208, Bias: 0.000000, T: 13536, Avg. loss: 0.136747\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 44.08, NNZs: 21208, Bias: 0.000000, T: 15792, Avg. loss: 0.132466\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 43.96, NNZs: 21208, Bias: 0.000000, T: 18048, Avg. loss: 0.131354\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 43.89, NNZs: 21208, Bias: 0.000000, T: 20304, Avg. loss: 0.121836\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 43.83, NNZs: 21208, Bias: 0.000000, T: 22560, Avg. loss: 0.119984\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 43.77, NNZs: 21208, Bias: 0.000000, T: 24816, Avg. loss: 0.119379\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 43.73, NNZs: 21208, Bias: 0.000000, T: 27072, Avg. loss: 0.119135\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 43.71, NNZs: 21208, Bias: 0.000000, T: 29328, Avg. loss: 0.117643\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 43.70, NNZs: 21208, Bias: 0.000000, T: 31584, Avg. loss: 0.117537\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 43.68, NNZs: 21208, Bias: 0.000000, T: 33840, Avg. loss: 0.117447\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 43.67, NNZs: 21208, Bias: 0.000000, T: 36096, Avg. loss: 0.117370\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 43.65, NNZs: 21208, Bias: 0.000000, T: 38352, Avg. loss: 0.117307\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 43.65, NNZs: 21208, Bias: 0.000000, T: 40608, Avg. loss: 0.117007\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 43.65, NNZs: 21208, Bias: 0.000000, T: 42864, Avg. loss: 0.116990\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 43.64, NNZs: 21208, Bias: 0.000000, T: 45120, Avg. loss: 0.116974\n",
      "Total training time: 0.08 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.42493015701647596, clf__eta0=0.6773009699604285, clf__fit_intercept=False, clf__l1_ratio=0.7301998277223162, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.017782879504616322, clf__shuffle=False, clf__tol=0.19519881462597577, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.714 total time=   1.4s\n",
      "-- Epoch 1\n",
      "Norm: 172.14, NNZs: 19661, Bias: -2.448452, T: 2256, Avg. loss: 1.823954\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 125.43, NNZs: 20193, Bias: -2.834126, T: 4512, Avg. loss: 0.428886\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 98.99, NNZs: 20349, Bias: -3.042356, T: 6768, Avg. loss: 0.201566\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 82.03, NNZs: 20420, Bias: -2.929916, T: 9024, Avg. loss: 0.072477\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 69.46, NNZs: 20442, Bias: -2.928040, T: 11280, Avg. loss: 0.049496\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 60.75, NNZs: 20449, Bias: -2.866583, T: 13536, Avg. loss: 0.018707\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "[CV 1/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.21123614325601048, clf__eta0=0.32979731781585486, clf__fit_intercept=True, clf__l1_ratio=0.4775095579144826, clf__learning_rate=optimal, clf__loss=perceptron, clf__max_iter=30, clf__penalty=l2, clf__power_t=0.6427671735097384, clf__shuffle=False, clf__tol=0.2651165400908262, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.612 total time=   1.3s\n",
      "-- Epoch 1\n",
      "Norm: 165.96, NNZs: 19139, Bias: -2.660038, T: 2256, Avg. loss: 1.446059\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 126.98, NNZs: 19895, Bias: -2.565088, T: 4512, Avg. loss: 0.471696\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 100.87, NNZs: 20028, Bias: -2.550199, T: 6768, Avg. loss: 0.168429\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 82.11, NNZs: 20083, Bias: -2.500373, T: 9024, Avg. loss: 0.043354\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 69.18, NNZs: 20098, Bias: -2.467114, T: 11280, Avg. loss: 0.024126\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 59.72, NNZs: 20106, Bias: -2.461741, T: 13536, Avg. loss: 0.011013\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "[CV 2/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.21123614325601048, clf__eta0=0.32979731781585486, clf__fit_intercept=True, clf__l1_ratio=0.4775095579144826, clf__learning_rate=optimal, clf__loss=perceptron, clf__max_iter=30, clf__penalty=l2, clf__power_t=0.6427671735097384, clf__shuffle=False, clf__tol=0.2651165400908262, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.686 total time=   1.3s\n",
      "-- Epoch 1\n",
      "Norm: 164.43, NNZs: 19125, Bias: -2.450694, T: 2256, Avg. loss: 1.495303\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 124.63, NNZs: 19900, Bias: -2.006664, T: 4512, Avg. loss: 0.455158\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 99.13, NNZs: 20187, Bias: -2.140738, T: 6768, Avg. loss: 0.169605\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 82.23, NNZs: 20277, Bias: -2.137526, T: 9024, Avg. loss: 0.089342\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 69.12, NNZs: 20301, Bias: -2.195860, T: 11280, Avg. loss: 0.035201\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 59.70, NNZs: 20307, Bias: -2.164863, T: 13536, Avg. loss: 0.013176\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "[CV 3/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.21123614325601048, clf__eta0=0.32979731781585486, clf__fit_intercept=True, clf__l1_ratio=0.4775095579144826, clf__learning_rate=optimal, clf__loss=perceptron, clf__max_iter=30, clf__penalty=l2, clf__power_t=0.6427671735097384, clf__shuffle=False, clf__tol=0.2651165400908262, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.755 total time=   1.4s\n",
      "-- Epoch 1\n",
      "Norm: 179.75, NNZs: 19277, Bias: -1.745318, T: 2256, Avg. loss: 1.684284\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 130.58, NNZs: 19803, Bias: -2.200176, T: 4512, Avg. loss: 0.488474\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 101.06, NNZs: 19901, Bias: -1.981032, T: 6768, Avg. loss: 0.122816\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 81.45, NNZs: 19934, Bias: -2.121569, T: 9024, Avg. loss: 0.061026\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 68.02, NNZs: 19941, Bias: -2.092936, T: 11280, Avg. loss: 0.012288\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 58.84, NNZs: 19954, Bias: -2.047623, T: 13536, Avg. loss: 0.016376\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "[CV 4/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.21123614325601048, clf__eta0=0.32979731781585486, clf__fit_intercept=True, clf__l1_ratio=0.4775095579144826, clf__learning_rate=optimal, clf__loss=perceptron, clf__max_iter=30, clf__penalty=l2, clf__power_t=0.6427671735097384, clf__shuffle=False, clf__tol=0.2651165400908262, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.659 total time=   1.3s\n",
      "-- Epoch 1\n",
      "Norm: 176.76, NNZs: 19370, Bias: -2.020744, T: 2256, Avg. loss: 1.578407\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 131.05, NNZs: 20082, Bias: -1.908380, T: 4512, Avg. loss: 0.404763\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 100.39, NNZs: 20184, Bias: -2.304431, T: 6768, Avg. loss: 0.169471\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 82.29, NNZs: 20214, Bias: -2.251670, T: 9024, Avg. loss: 0.062855\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 70.08, NNZs: 20235, Bias: -2.222458, T: 11280, Avg. loss: 0.048468\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 60.18, NNZs: 20251, Bias: -2.301795, T: 13536, Avg. loss: 0.019699\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 5/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.21123614325601048, clf__eta0=0.32979731781585486, clf__fit_intercept=True, clf__l1_ratio=0.4775095579144826, clf__learning_rate=optimal, clf__loss=perceptron, clf__max_iter=30, clf__penalty=l2, clf__power_t=0.6427671735097384, clf__shuffle=False, clf__tol=0.2651165400908262, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.657 total time=   1.4s\n",
      "-- Epoch 1\n",
      "Norm: 85.97, NNZs: 9671, Bias: 0.000000, T: 2820, Avg. loss: 0.797971\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 104.40, NNZs: 5774, Bias: 0.000000, T: 5640, Avg. loss: 0.291206\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 115.87, NNZs: 3751, Bias: 0.000000, T: 8460, Avg. loss: 0.144529\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 124.26, NNZs: 2860, Bias: 0.000000, T: 11280, Avg. loss: 0.104176\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 131.55, NNZs: 2230, Bias: 0.000000, T: 14100, Avg. loss: 0.074821\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 138.06, NNZs: 1863, Bias: 0.000000, T: 16920, Avg. loss: 0.066301\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "0.9574468085106383\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "   Geen gebruiker       0.98      0.97      0.98       904\n",
      "Huidige gebruiker       0.45      0.53      0.49        36\n",
      "\n",
      "         accuracy                           0.96       940\n",
      "        macro avg       0.72      0.75      0.73       940\n",
      "     weighted avg       0.96      0.96      0.96       940\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ngram 2 Stopwords kept\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1,2), lowercase=True, token_pattern=r\"(?u)\\b\\w\\w+\\b|\\+|\\-\")),\n",
    "    ('clf', SGDClassifier(early_stopping=True, n_iter_no_change=5, validation_fraction = 0.25, verbose=3)),\n",
    "])\n",
    "random_search = RandomizedSearchCV(estimator=pipeline, param_distributions=parameter_grid, random_state=500, verbose=3, scoring='f1_macro')\n",
    "random_search.fit(X_train, y_train)  \n",
    "predicted_nb = random_search.predict(X_test)\n",
    "print(np.mean(predicted_nb == y_test))\n",
    "cm = confusion_matrix(y_test, predicted_nb)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=random_search.classes_)\n",
    "disp.plot()\n",
    "\n",
    "plt.show()\n",
    "print(metrics.classification_report(y_test, predicted_nb,\n",
    "    target_names=random_search.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8f8905",
   "metadata": {},
   "source": [
    "# Alcohol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ed66e8",
   "metadata": {},
   "source": [
    "## Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36bf3f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "alcohol_corpus = Corpus[[\"text\", \"Alcohol\"]].rename(columns={\"Alcohol\":\"label\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f22715b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beloop: \\tPatiÃ«nte heeft 10 minuten van te vo...</td>\n",
       "      <td>Niets gevonden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beloop: \\tG5P4 36 wkGrav 1e lijnALL geen Hb Pa...</td>\n",
       "      <td>Niets gevonden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Conclusie: \\tNormale nacontrole. Kijkt goed te...</td>\n",
       "      <td>Niets gevonden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beleid: \\tAlgemeen: Dagopname voor 3x PC  a 2....</td>\n",
       "      <td>Niets gevonden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anamnese: \\t34W4D</td>\n",
       "      <td>Niets gevonden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4695</th>\n",
       "      <td>Beloop: \\tCONSULTENKAMERGezien door co-ass Y. ...</td>\n",
       "      <td>Geen gebruiker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4696</th>\n",
       "      <td>Reden van komst / Verwijzing: \\tReden verwijzi...</td>\n",
       "      <td>Geen gebruiker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4697</th>\n",
       "      <td>Beloop: \\tMR CPG7P4M4 //  MI: 4x sectio ia, 1x...</td>\n",
       "      <td>Geen gebruiker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4698</th>\n",
       "      <td>Reden van komst / Verwijzing: \\tReden van koms...</td>\n",
       "      <td>Geen gebruiker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4699</th>\n",
       "      <td>Reden van komst / Verwijzing: \\tReden van koms...</td>\n",
       "      <td>Geen gebruiker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4700 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text           label\n",
       "0     Beloop: \\tPatiÃ«nte heeft 10 minuten van te vo...  Niets gevonden\n",
       "1     Beloop: \\tG5P4 36 wkGrav 1e lijnALL geen Hb Pa...  Niets gevonden\n",
       "2     Conclusie: \\tNormale nacontrole. Kijkt goed te...  Niets gevonden\n",
       "3     Beleid: \\tAlgemeen: Dagopname voor 3x PC  a 2....  Niets gevonden\n",
       "4                                     Anamnese: \\t34W4D  Niets gevonden\n",
       "...                                                 ...             ...\n",
       "4695  Beloop: \\tCONSULTENKAMERGezien door co-ass Y. ...  Geen gebruiker\n",
       "4696  Reden van komst / Verwijzing: \\tReden verwijzi...  Geen gebruiker\n",
       "4697  Beloop: \\tMR CPG7P4M4 //  MI: 4x sectio ia, 1x...  Geen gebruiker\n",
       "4698  Reden van komst / Verwijzing: \\tReden van koms...  Geen gebruiker\n",
       "4699  Reden van komst / Verwijzing: \\tReden van koms...  Geen gebruiker\n",
       "\n",
       "[4700 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alcohol_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e53aa371",
   "metadata": {},
   "outputs": [],
   "source": [
    "alcohol_corpus['text'] = alcohol_corpus['text'].str.replace('\\t',' ')\n",
    "alcohol_corpus.drop_duplicates(inplace=True)\n",
    "alcohol_corpus['text'] = alcohol_corpus['text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "43b154cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"dutch\")\n",
    "alcohol_corpus['text'] = alcohol_corpus['text'].str.lower()\n",
    "alcohol_corpus['text'] = [stemmer.stem(text) for text in alcohol_corpus['text']]\n",
    "alcohol_corpus = alcohol_corpus.drop(alcohol_corpus[alcohol_corpus.label == '--'].index)\n",
    "alcohol_corpus_backup = alcohol_corpus.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "04b9939d",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_stopwords = lambda x: ' '.join([item for item in x.split() if item not in full_stopwords])\n",
    "less_stopwords = lambda x: ' '.join([item for item in x.split() if item not in filtered_stopwords])\n",
    "\n",
    "alcohol_corpus[\"text\"] = alcohol_corpus[\"text\"].apply(less_stopwords)\n",
    "X_train, X_test, y_train, y_test = train_test_split(alcohol_corpus['text'], alcohol_corpus['label'], test_size=0.2, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1671f29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = alcohol_corpus.loc[indices['index']]\n",
    "train_set = alcohol_corpus.loc[~alcohol_corpus.index.isin(test_set.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14266c97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 22.28, NNZs: 4032, Bias: 0.000000, T: 2256, Avg. loss: 0.426019\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 32.24, NNZs: 2175, Bias: 0.000000, T: 4512, Avg. loss: 0.303465\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 39.70, NNZs: 1695, Bias: 0.000000, T: 6768, Avg. loss: 0.259607\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 45.81, NNZs: 1423, Bias: 0.000000, T: 9024, Avg. loss: 0.233179\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 51.19, NNZs: 1228, Bias: 0.000000, T: 11280, Avg. loss: 0.214469\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 55.93, NNZs: 1077, Bias: 0.000000, T: 13536, Avg. loss: 0.201947\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 56.78, NNZs: 1036, Bias: 0.000000, T: 15792, Avg. loss: 0.192500\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 57.61, NNZs: 1026, Bias: 0.000000, T: 18048, Avg. loss: 0.190619\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 58.42, NNZs: 1005, Bias: 0.000000, T: 20304, Avg. loss: 0.188804\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 59.21, NNZs: 990, Bias: 0.000000, T: 22560, Avg. loss: 0.186848\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 60.01, NNZs: 977, Bias: 0.000000, T: 24816, Avg. loss: 0.185323\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 60.16, NNZs: 971, Bias: 0.000000, T: 27072, Avg. loss: 0.183784\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 60.31, NNZs: 967, Bias: 0.000000, T: 29328, Avg. loss: 0.183469\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 60.47, NNZs: 960, Bias: 0.000000, T: 31584, Avg. loss: 0.183158\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 60.62, NNZs: 957, Bias: 0.000000, T: 33840, Avg. loss: 0.182833\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 60.77, NNZs: 956, Bias: 0.000000, T: 36096, Avg. loss: 0.182524\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 60.80, NNZs: 955, Bias: 0.000000, T: 38352, Avg. loss: 0.182222\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 60.83, NNZs: 955, Bias: 0.000000, T: 40608, Avg. loss: 0.182162\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 60.86, NNZs: 953, Bias: 0.000000, T: 42864, Avg. loss: 0.182098\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 60.90, NNZs: 952, Bias: 0.000000, T: 45120, Avg. loss: 0.182037\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 23.12, NNZs: 3625, Bias: 0.000000, T: 2256, Avg. loss: 0.342649\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 31.69, NNZs: 1997, Bias: 0.000000, T: 4512, Avg. loss: 0.226211\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 38.09, NNZs: 1510, Bias: 0.000000, T: 6768, Avg. loss: 0.195189\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 43.34, NNZs: 1249, Bias: 0.000000, T: 9024, Avg. loss: 0.175659\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 47.98, NNZs: 1065, Bias: 0.000000, T: 11280, Avg. loss: 0.163960\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 51.95, NNZs: 940, Bias: 0.000000, T: 13536, Avg. loss: 0.155238\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 52.68, NNZs: 904, Bias: 0.000000, T: 15792, Avg. loss: 0.149503\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 53.40, NNZs: 894, Bias: 0.000000, T: 18048, Avg. loss: 0.148069\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 54.10, NNZs: 883, Bias: 0.000000, T: 20304, Avg. loss: 0.146900\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 54.79, NNZs: 862, Bias: 0.000000, T: 22560, Avg. loss: 0.145652\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 55.47, NNZs: 848, Bias: 0.000000, T: 24816, Avg. loss: 0.144488\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 55.61, NNZs: 843, Bias: 0.000000, T: 27072, Avg. loss: 0.143518\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 55.74, NNZs: 842, Bias: 0.000000, T: 29328, Avg. loss: 0.143296\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 55.87, NNZs: 840, Bias: 0.000000, T: 31584, Avg. loss: 0.143047\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 56.00, NNZs: 839, Bias: 0.000000, T: 33840, Avg. loss: 0.142854\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 56.13, NNZs: 839, Bias: 0.000000, T: 36096, Avg. loss: 0.142639\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 56.16, NNZs: 837, Bias: 0.000000, T: 38352, Avg. loss: 0.142436\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 56.19, NNZs: 837, Bias: 0.000000, T: 40608, Avg. loss: 0.142394\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 56.21, NNZs: 837, Bias: 0.000000, T: 42864, Avg. loss: 0.142355\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 56.24, NNZs: 836, Bias: 0.000000, T: 45120, Avg. loss: 0.142308\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 24.81, NNZs: 4488, Bias: 0.000000, T: 2256, Avg. loss: 0.346348\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 34.38, NNZs: 2337, Bias: 0.000000, T: 4512, Avg. loss: 0.209234\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 41.22, NNZs: 1761, Bias: 0.000000, T: 6768, Avg. loss: 0.174511\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 46.77, NNZs: 1504, Bias: 0.000000, T: 9024, Avg. loss: 0.156233\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 51.54, NNZs: 1334, Bias: 0.000000, T: 11280, Avg. loss: 0.144162\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 55.72, NNZs: 1220, Bias: 0.000000, T: 13536, Avg. loss: 0.135877\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 56.47, NNZs: 1178, Bias: 0.000000, T: 15792, Avg. loss: 0.130456\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 57.20, NNZs: 1143, Bias: 0.000000, T: 18048, Avg. loss: 0.129397\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 57.93, NNZs: 1093, Bias: 0.000000, T: 20304, Avg. loss: 0.128369\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 58.64, NNZs: 1067, Bias: 0.000000, T: 22560, Avg. loss: 0.127282\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 59.34, NNZs: 1049, Bias: 0.000000, T: 24816, Avg. loss: 0.126254\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 59.47, NNZs: 1042, Bias: 0.000000, T: 27072, Avg. loss: 0.125373\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 59.61, NNZs: 1042, Bias: 0.000000, T: 29328, Avg. loss: 0.125193\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 59.75, NNZs: 1037, Bias: 0.000000, T: 31584, Avg. loss: 0.125010\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 59.88, NNZs: 1033, Bias: 0.000000, T: 33840, Avg. loss: 0.124825\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 60.02, NNZs: 1031, Bias: 0.000000, T: 36096, Avg. loss: 0.124629\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 60.05, NNZs: 1031, Bias: 0.000000, T: 38352, Avg. loss: 0.124462\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 60.07, NNZs: 1031, Bias: 0.000000, T: 40608, Avg. loss: 0.124425\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 60.10, NNZs: 1029, Bias: 0.000000, T: 42864, Avg. loss: 0.124391\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 60.13, NNZs: 1029, Bias: 0.000000, T: 45120, Avg. loss: 0.124354\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 22.48, NNZs: 2410, Bias: 0.000000, T: 2256, Avg. loss: 0.160254\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 28.50, NNZs: 1088, Bias: 0.000000, T: 4512, Avg. loss: 0.078655\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 32.51, NNZs: 787, Bias: 0.000000, T: 6768, Avg. loss: 0.067111\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 35.55, NNZs: 614, Bias: 0.000000, T: 9024, Avg. loss: 0.062049\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 38.18, NNZs: 513, Bias: 0.000000, T: 11280, Avg. loss: 0.059232\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 40.44, NNZs: 453, Bias: 0.000000, T: 13536, Avg. loss: 0.057253\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 40.86, NNZs: 437, Bias: 0.000000, T: 15792, Avg. loss: 0.056144\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 41.28, NNZs: 433, Bias: 0.000000, T: 18048, Avg. loss: 0.055897\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 41.69, NNZs: 419, Bias: 0.000000, T: 20304, Avg. loss: 0.055621\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 42.09, NNZs: 407, Bias: 0.000000, T: 22560, Avg. loss: 0.055365\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 42.48, NNZs: 401, Bias: 0.000000, T: 24816, Avg. loss: 0.055120\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 42.55, NNZs: 400, Bias: 0.000000, T: 27072, Avg. loss: 0.054895\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 42.63, NNZs: 400, Bias: 0.000000, T: 29328, Avg. loss: 0.054852\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 42.71, NNZs: 400, Bias: 0.000000, T: 31584, Avg. loss: 0.054809\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 42.78, NNZs: 399, Bias: 0.000000, T: 33840, Avg. loss: 0.054767\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 42.86, NNZs: 396, Bias: 0.000000, T: 36096, Avg. loss: 0.054722\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 42.87, NNZs: 396, Bias: 0.000000, T: 38352, Avg. loss: 0.054682\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 42.89, NNZs: 396, Bias: 0.000000, T: 40608, Avg. loss: 0.054674\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 42.90, NNZs: 396, Bias: 0.000000, T: 42864, Avg. loss: 0.054666\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 42.92, NNZs: 396, Bias: 0.000000, T: 45120, Avg. loss: 0.054657\n",
      "Total training time: 0.11 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.5s finished\n",
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.06171699256249541, clf__eta0=0.6666115972798587, clf__fit_intercept=False, clf__l1_ratio=0.9792901432894962, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.15075392531110676, clf__shuffle=True, clf__tol=0.365636830734297, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.630 total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 22.41, NNZs: 4093, Bias: 0.000000, T: 2256, Avg. loss: 0.427913\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 32.55, NNZs: 2196, Bias: 0.000000, T: 4512, Avg. loss: 0.300284\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 39.97, NNZs: 1701, Bias: 0.000000, T: 6768, Avg. loss: 0.257400\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 46.00, NNZs: 1401, Bias: 0.000000, T: 9024, Avg. loss: 0.231677\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 51.36, NNZs: 1216, Bias: 0.000000, T: 11280, Avg. loss: 0.214081\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 56.03, NNZs: 1074, Bias: 0.000000, T: 13536, Avg. loss: 0.201656\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 56.86, NNZs: 1035, Bias: 0.000000, T: 15792, Avg. loss: 0.192747\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 57.67, NNZs: 1023, Bias: 0.000000, T: 18048, Avg. loss: 0.191076\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 58.47, NNZs: 1008, Bias: 0.000000, T: 20304, Avg. loss: 0.189251\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 59.25, NNZs: 987, Bias: 0.000000, T: 22560, Avg. loss: 0.187643\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 60.02, NNZs: 973, Bias: 0.000000, T: 24816, Avg. loss: 0.186014\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 60.17, NNZs: 966, Bias: 0.000000, T: 27072, Avg. loss: 0.184619\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 60.32, NNZs: 965, Bias: 0.000000, T: 29328, Avg. loss: 0.184319\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 60.47, NNZs: 961, Bias: 0.000000, T: 31584, Avg. loss: 0.184030\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 60.62, NNZs: 959, Bias: 0.000000, T: 33840, Avg. loss: 0.183726\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 60.77, NNZs: 956, Bias: 0.000000, T: 36096, Avg. loss: 0.183415\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 60.80, NNZs: 956, Bias: 0.000000, T: 38352, Avg. loss: 0.183158\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 60.83, NNZs: 956, Bias: 0.000000, T: 40608, Avg. loss: 0.183101\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 60.86, NNZs: 955, Bias: 0.000000, T: 42864, Avg. loss: 0.183044\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 60.89, NNZs: 955, Bias: 0.000000, T: 45120, Avg. loss: 0.182983\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 23.17, NNZs: 3774, Bias: 0.000000, T: 2256, Avg. loss: 0.341771\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 31.67, NNZs: 1998, Bias: 0.000000, T: 4512, Avg. loss: 0.227248\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 38.05, NNZs: 1507, Bias: 0.000000, T: 6768, Avg. loss: 0.194562\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 43.31, NNZs: 1265, Bias: 0.000000, T: 9024, Avg. loss: 0.177116\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 47.92, NNZs: 1076, Bias: 0.000000, T: 11280, Avg. loss: 0.164928\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 51.94, NNZs: 997, Bias: 0.000000, T: 13536, Avg. loss: 0.155569\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 52.67, NNZs: 944, Bias: 0.000000, T: 15792, Avg. loss: 0.149758\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 53.38, NNZs: 913, Bias: 0.000000, T: 18048, Avg. loss: 0.148319\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 54.08, NNZs: 904, Bias: 0.000000, T: 20304, Avg. loss: 0.147246\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 54.76, NNZs: 890, Bias: 0.000000, T: 22560, Avg. loss: 0.145943\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 55.43, NNZs: 881, Bias: 0.000000, T: 24816, Avg. loss: 0.144946\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 55.56, NNZs: 875, Bias: 0.000000, T: 27072, Avg. loss: 0.143899\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 55.70, NNZs: 874, Bias: 0.000000, T: 29328, Avg. loss: 0.143703\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 55.83, NNZs: 872, Bias: 0.000000, T: 31584, Avg. loss: 0.143502\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 55.96, NNZs: 870, Bias: 0.000000, T: 33840, Avg. loss: 0.143285\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 56.09, NNZs: 867, Bias: 0.000000, T: 36096, Avg. loss: 0.143087\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 56.11, NNZs: 866, Bias: 0.000000, T: 38352, Avg. loss: 0.142877\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 56.14, NNZs: 866, Bias: 0.000000, T: 40608, Avg. loss: 0.142837\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 56.17, NNZs: 865, Bias: 0.000000, T: 42864, Avg. loss: 0.142796\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 56.19, NNZs: 863, Bias: 0.000000, T: 45120, Avg. loss: 0.142756\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 24.88, NNZs: 4462, Bias: 0.000000, T: 2256, Avg. loss: 0.346543\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 34.49, NNZs: 2347, Bias: 0.000000, T: 4512, Avg. loss: 0.207260\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 41.37, NNZs: 1773, Bias: 0.000000, T: 6768, Avg. loss: 0.172555\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 46.90, NNZs: 1513, Bias: 0.000000, T: 9024, Avg. loss: 0.154390\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 51.64, NNZs: 1342, Bias: 0.000000, T: 11280, Avg. loss: 0.142290\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 55.83, NNZs: 1222, Bias: 0.000000, T: 13536, Avg. loss: 0.134624\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 56.57, NNZs: 1168, Bias: 0.000000, T: 15792, Avg. loss: 0.128965\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 57.31, NNZs: 1143, Bias: 0.000000, T: 18048, Avg. loss: 0.127904\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 58.04, NNZs: 1124, Bias: 0.000000, T: 20304, Avg. loss: 0.126779\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 58.75, NNZs: 1109, Bias: 0.000000, T: 22560, Avg. loss: 0.125716\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 59.45, NNZs: 1098, Bias: 0.000000, T: 24816, Avg. loss: 0.124793\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 59.58, NNZs: 1091, Bias: 0.000000, T: 27072, Avg. loss: 0.123891\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 59.72, NNZs: 1085, Bias: 0.000000, T: 29328, Avg. loss: 0.123721\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 59.86, NNZs: 1082, Bias: 0.000000, T: 31584, Avg. loss: 0.123539\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 59.99, NNZs: 1079, Bias: 0.000000, T: 33840, Avg. loss: 0.123356\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 60.13, NNZs: 1073, Bias: 0.000000, T: 36096, Avg. loss: 0.123170\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 60.16, NNZs: 1072, Bias: 0.000000, T: 38352, Avg. loss: 0.123007\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 60.18, NNZs: 1067, Bias: 0.000000, T: 40608, Avg. loss: 0.122974\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 60.21, NNZs: 1067, Bias: 0.000000, T: 42864, Avg. loss: 0.122935\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 60.24, NNZs: 1067, Bias: 0.000000, T: 45120, Avg. loss: 0.122900\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 22.54, NNZs: 2569, Bias: 0.000000, T: 2256, Avg. loss: 0.160365\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 28.53, NNZs: 1089, Bias: 0.000000, T: 4512, Avg. loss: 0.079413\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 32.53, NNZs: 790, Bias: 0.000000, T: 6768, Avg. loss: 0.068239\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 35.51, NNZs: 632, Bias: 0.000000, T: 9024, Avg. loss: 0.062994\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 38.14, NNZs: 520, Bias: 0.000000, T: 11280, Avg. loss: 0.060839\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 40.41, NNZs: 463, Bias: 0.000000, T: 13536, Avg. loss: 0.058872\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 40.83, NNZs: 443, Bias: 0.000000, T: 15792, Avg. loss: 0.057808\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 41.24, NNZs: 436, Bias: 0.000000, T: 18048, Avg. loss: 0.057594\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 41.64, NNZs: 431, Bias: 0.000000, T: 20304, Avg. loss: 0.057371\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 42.04, NNZs: 417, Bias: 0.000000, T: 22560, Avg. loss: 0.057139\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 42.43, NNZs: 407, Bias: 0.000000, T: 24816, Avg. loss: 0.056914\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 42.50, NNZs: 406, Bias: 0.000000, T: 27072, Avg. loss: 0.056724\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 42.58, NNZs: 403, Bias: 0.000000, T: 29328, Avg. loss: 0.056691\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 42.65, NNZs: 400, Bias: 0.000000, T: 31584, Avg. loss: 0.056649\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 42.73, NNZs: 399, Bias: 0.000000, T: 33840, Avg. loss: 0.056610\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 42.81, NNZs: 399, Bias: 0.000000, T: 36096, Avg. loss: 0.056565\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 42.82, NNZs: 398, Bias: 0.000000, T: 38352, Avg. loss: 0.056532\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 42.84, NNZs: 398, Bias: 0.000000, T: 40608, Avg. loss: 0.056524\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 42.85, NNZs: 398, Bias: 0.000000, T: 42864, Avg. loss: 0.056516\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 42.87, NNZs: 398, Bias: 0.000000, T: 45120, Avg. loss: 0.056508\n",
      "Total training time: 0.11 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.5s finished\n",
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.06171699256249541, clf__eta0=0.6666115972798587, clf__fit_intercept=False, clf__l1_ratio=0.9792901432894962, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.15075392531110676, clf__shuffle=True, clf__tol=0.365636830734297, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.662 total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 22.73, NNZs: 4178, Bias: 0.000000, T: 2256, Avg. loss: 0.421863\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 32.70, NNZs: 2185, Bias: 0.000000, T: 4512, Avg. loss: 0.293588\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 40.07, NNZs: 1672, Bias: 0.000000, T: 6768, Avg. loss: 0.250344\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 46.24, NNZs: 1384, Bias: 0.000000, T: 9024, Avg. loss: 0.224188\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 51.56, NNZs: 1205, Bias: 0.000000, T: 11280, Avg. loss: 0.206572\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 56.32, NNZs: 1091, Bias: 0.000000, T: 13536, Avg. loss: 0.193438\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 57.17, NNZs: 1064, Bias: 0.000000, T: 15792, Avg. loss: 0.184352\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 57.99, NNZs: 1052, Bias: 0.000000, T: 18048, Avg. loss: 0.182393\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 58.81, NNZs: 1033, Bias: 0.000000, T: 20304, Avg. loss: 0.180655\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 59.62, NNZs: 1014, Bias: 0.000000, T: 22560, Avg. loss: 0.178814\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 60.41, NNZs: 994, Bias: 0.000000, T: 24816, Avg. loss: 0.177112\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 60.56, NNZs: 990, Bias: 0.000000, T: 27072, Avg. loss: 0.175692\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 60.72, NNZs: 989, Bias: 0.000000, T: 29328, Avg. loss: 0.175384\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 60.87, NNZs: 986, Bias: 0.000000, T: 31584, Avg. loss: 0.175051\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 61.03, NNZs: 980, Bias: 0.000000, T: 33840, Avg. loss: 0.174746\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 61.18, NNZs: 980, Bias: 0.000000, T: 36096, Avg. loss: 0.174421\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 61.21, NNZs: 980, Bias: 0.000000, T: 38352, Avg. loss: 0.174140\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 61.24, NNZs: 979, Bias: 0.000000, T: 40608, Avg. loss: 0.174082\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 61.27, NNZs: 979, Bias: 0.000000, T: 42864, Avg. loss: 0.174018\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 61.30, NNZs: 979, Bias: 0.000000, T: 45120, Avg. loss: 0.173957\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 23.26, NNZs: 3885, Bias: 0.000000, T: 2256, Avg. loss: 0.343396\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 32.01, NNZs: 2038, Bias: 0.000000, T: 4512, Avg. loss: 0.224215\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 38.47, NNZs: 1559, Bias: 0.000000, T: 6768, Avg. loss: 0.192894\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 43.72, NNZs: 1243, Bias: 0.000000, T: 9024, Avg. loss: 0.174741\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 48.26, NNZs: 1071, Bias: 0.000000, T: 11280, Avg. loss: 0.161879\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 52.30, NNZs: 974, Bias: 0.000000, T: 13536, Avg. loss: 0.151580\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 53.05, NNZs: 939, Bias: 0.000000, T: 15792, Avg. loss: 0.146775\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 53.77, NNZs: 925, Bias: 0.000000, T: 18048, Avg. loss: 0.145448\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 54.48, NNZs: 900, Bias: 0.000000, T: 20304, Avg. loss: 0.144139\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 55.18, NNZs: 888, Bias: 0.000000, T: 22560, Avg. loss: 0.142891\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 55.87, NNZs: 872, Bias: 0.000000, T: 24816, Avg. loss: 0.141623\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 56.00, NNZs: 865, Bias: 0.000000, T: 27072, Avg. loss: 0.140719\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 56.14, NNZs: 863, Bias: 0.000000, T: 29328, Avg. loss: 0.140492\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 56.27, NNZs: 859, Bias: 0.000000, T: 31584, Avg. loss: 0.140249\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 56.40, NNZs: 855, Bias: 0.000000, T: 33840, Avg. loss: 0.140014\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 56.54, NNZs: 854, Bias: 0.000000, T: 36096, Avg. loss: 0.139799\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 56.56, NNZs: 853, Bias: 0.000000, T: 38352, Avg. loss: 0.139600\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 56.59, NNZs: 853, Bias: 0.000000, T: 40608, Avg. loss: 0.139562\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 56.61, NNZs: 853, Bias: 0.000000, T: 42864, Avg. loss: 0.139515\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 56.64, NNZs: 853, Bias: 0.000000, T: 45120, Avg. loss: 0.139472\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 24.94, NNZs: 4567, Bias: 0.000000, T: 2256, Avg. loss: 0.350364\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 34.67, NNZs: 2383, Bias: 0.000000, T: 4512, Avg. loss: 0.209026\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 41.61, NNZs: 1824, Bias: 0.000000, T: 6768, Avg. loss: 0.173034\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 47.18, NNZs: 1512, Bias: 0.000000, T: 9024, Avg. loss: 0.154699\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 51.93, NNZs: 1336, Bias: 0.000000, T: 11280, Avg. loss: 0.142773\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 56.17, NNZs: 1226, Bias: 0.000000, T: 13536, Avg. loss: 0.133707\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 56.93, NNZs: 1158, Bias: 0.000000, T: 15792, Avg. loss: 0.128269\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 57.68, NNZs: 1130, Bias: 0.000000, T: 18048, Avg. loss: 0.127195\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 58.41, NNZs: 1111, Bias: 0.000000, T: 20304, Avg. loss: 0.126003\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 59.13, NNZs: 1089, Bias: 0.000000, T: 22560, Avg. loss: 0.124902\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 59.84, NNZs: 1046, Bias: 0.000000, T: 24816, Avg. loss: 0.123844\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 59.98, NNZs: 1038, Bias: 0.000000, T: 27072, Avg. loss: 0.122962\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 60.12, NNZs: 1035, Bias: 0.000000, T: 29328, Avg. loss: 0.122779\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 60.25, NNZs: 1033, Bias: 0.000000, T: 31584, Avg. loss: 0.122577\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 60.39, NNZs: 1027, Bias: 0.000000, T: 33840, Avg. loss: 0.122364\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 60.53, NNZs: 1027, Bias: 0.000000, T: 36096, Avg. loss: 0.122173\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 60.56, NNZs: 1023, Bias: 0.000000, T: 38352, Avg. loss: 0.122000\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 60.58, NNZs: 1023, Bias: 0.000000, T: 40608, Avg. loss: 0.121963\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 60.61, NNZs: 1021, Bias: 0.000000, T: 42864, Avg. loss: 0.121926\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 60.64, NNZs: 1021, Bias: 0.000000, T: 45120, Avg. loss: 0.121886\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 22.60, NNZs: 2457, Bias: 0.000000, T: 2256, Avg. loss: 0.157738\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 28.38, NNZs: 1106, Bias: 0.000000, T: 4512, Avg. loss: 0.080547\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 32.39, NNZs: 763, Bias: 0.000000, T: 6768, Avg. loss: 0.070139\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 35.50, NNZs: 599, Bias: 0.000000, T: 9024, Avg. loss: 0.064944\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 38.14, NNZs: 501, Bias: 0.000000, T: 11280, Avg. loss: 0.062215\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 40.37, NNZs: 440, Bias: 0.000000, T: 13536, Avg. loss: 0.060007\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 40.78, NNZs: 427, Bias: 0.000000, T: 15792, Avg. loss: 0.058863\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 41.18, NNZs: 417, Bias: 0.000000, T: 18048, Avg. loss: 0.058642\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 41.57, NNZs: 402, Bias: 0.000000, T: 20304, Avg. loss: 0.058421\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 41.95, NNZs: 397, Bias: 0.000000, T: 22560, Avg. loss: 0.058211\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 42.33, NNZs: 391, Bias: 0.000000, T: 24816, Avg. loss: 0.057975\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 42.40, NNZs: 390, Bias: 0.000000, T: 27072, Avg. loss: 0.057836\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 42.48, NNZs: 388, Bias: 0.000000, T: 29328, Avg. loss: 0.057799\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 42.55, NNZs: 387, Bias: 0.000000, T: 31584, Avg. loss: 0.057764\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 42.63, NNZs: 386, Bias: 0.000000, T: 33840, Avg. loss: 0.057722\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 42.70, NNZs: 384, Bias: 0.000000, T: 36096, Avg. loss: 0.057702\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 42.71, NNZs: 384, Bias: 0.000000, T: 38352, Avg. loss: 0.057660\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 42.73, NNZs: 383, Bias: 0.000000, T: 40608, Avg. loss: 0.057653\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 42.74, NNZs: 383, Bias: 0.000000, T: 42864, Avg. loss: 0.057647\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 42.76, NNZs: 383, Bias: 0.000000, T: 45120, Avg. loss: 0.057640\n",
      "Total training time: 0.11 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.5s finished\n",
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.06171699256249541, clf__eta0=0.6666115972798587, clf__fit_intercept=False, clf__l1_ratio=0.9792901432894962, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.15075392531110676, clf__shuffle=True, clf__tol=0.365636830734297, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.668 total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 22.58, NNZs: 4203, Bias: 0.000000, T: 2256, Avg. loss: 0.424875\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 32.45, NNZs: 2233, Bias: 0.000000, T: 4512, Avg. loss: 0.295643\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 40.02, NNZs: 1751, Bias: 0.000000, T: 6768, Avg. loss: 0.252773\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 46.27, NNZs: 1415, Bias: 0.000000, T: 9024, Avg. loss: 0.226342\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 51.59, NNZs: 1266, Bias: 0.000000, T: 11280, Avg. loss: 0.208733\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 56.32, NNZs: 1148, Bias: 0.000000, T: 13536, Avg. loss: 0.195060\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 57.18, NNZs: 1105, Bias: 0.000000, T: 15792, Avg. loss: 0.187155\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 58.00, NNZs: 1087, Bias: 0.000000, T: 18048, Avg. loss: 0.185096\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 58.82, NNZs: 1070, Bias: 0.000000, T: 20304, Avg. loss: 0.183380\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 59.62, NNZs: 1058, Bias: 0.000000, T: 22560, Avg. loss: 0.181589\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 60.41, NNZs: 1041, Bias: 0.000000, T: 24816, Avg. loss: 0.179907\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 60.56, NNZs: 1030, Bias: 0.000000, T: 27072, Avg. loss: 0.178460\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 60.72, NNZs: 1022, Bias: 0.000000, T: 29328, Avg. loss: 0.178149\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 60.87, NNZs: 1016, Bias: 0.000000, T: 31584, Avg. loss: 0.177825\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 61.02, NNZs: 1017, Bias: 0.000000, T: 33840, Avg. loss: 0.177517\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 61.18, NNZs: 1012, Bias: 0.000000, T: 36096, Avg. loss: 0.177218\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 61.21, NNZs: 1012, Bias: 0.000000, T: 38352, Avg. loss: 0.176911\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 61.24, NNZs: 1012, Bias: 0.000000, T: 40608, Avg. loss: 0.176851\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 61.27, NNZs: 1012, Bias: 0.000000, T: 42864, Avg. loss: 0.176793\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 61.30, NNZs: 1010, Bias: 0.000000, T: 45120, Avg. loss: 0.176731\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 23.27, NNZs: 3896, Bias: 0.000000, T: 2256, Avg. loss: 0.343326\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 32.11, NNZs: 2068, Bias: 0.000000, T: 4512, Avg. loss: 0.224416\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 38.47, NNZs: 1606, Bias: 0.000000, T: 6768, Avg. loss: 0.192296\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 43.82, NNZs: 1310, Bias: 0.000000, T: 9024, Avg. loss: 0.174599\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 48.37, NNZs: 1128, Bias: 0.000000, T: 11280, Avg. loss: 0.162085\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 52.45, NNZs: 997, Bias: 0.000000, T: 13536, Avg. loss: 0.153448\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 53.17, NNZs: 958, Bias: 0.000000, T: 15792, Avg. loss: 0.147532\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 53.88, NNZs: 930, Bias: 0.000000, T: 18048, Avg. loss: 0.146083\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 54.57, NNZs: 913, Bias: 0.000000, T: 20304, Avg. loss: 0.144769\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 55.26, NNZs: 898, Bias: 0.000000, T: 22560, Avg. loss: 0.143681\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 55.93, NNZs: 877, Bias: 0.000000, T: 24816, Avg. loss: 0.142610\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 56.06, NNZs: 871, Bias: 0.000000, T: 27072, Avg. loss: 0.141614\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 56.19, NNZs: 867, Bias: 0.000000, T: 29328, Avg. loss: 0.141389\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 56.32, NNZs: 862, Bias: 0.000000, T: 31584, Avg. loss: 0.141181\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 56.46, NNZs: 860, Bias: 0.000000, T: 33840, Avg. loss: 0.140969\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 56.59, NNZs: 859, Bias: 0.000000, T: 36096, Avg. loss: 0.140750\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 56.61, NNZs: 859, Bias: 0.000000, T: 38352, Avg. loss: 0.140564\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 56.64, NNZs: 858, Bias: 0.000000, T: 40608, Avg. loss: 0.140525\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 56.66, NNZs: 858, Bias: 0.000000, T: 42864, Avg. loss: 0.140486\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 56.69, NNZs: 858, Bias: 0.000000, T: 45120, Avg. loss: 0.140444\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 24.83, NNZs: 4399, Bias: 0.000000, T: 2256, Avg. loss: 0.350028\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 34.59, NNZs: 2312, Bias: 0.000000, T: 4512, Avg. loss: 0.210785\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 41.55, NNZs: 1835, Bias: 0.000000, T: 6768, Avg. loss: 0.175300\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 47.13, NNZs: 1533, Bias: 0.000000, T: 9024, Avg. loss: 0.156585\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 51.87, NNZs: 1370, Bias: 0.000000, T: 11280, Avg. loss: 0.144487\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 56.10, NNZs: 1207, Bias: 0.000000, T: 13536, Avg. loss: 0.136491\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 56.86, NNZs: 1173, Bias: 0.000000, T: 15792, Avg. loss: 0.130718\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 57.60, NNZs: 1155, Bias: 0.000000, T: 18048, Avg. loss: 0.129569\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 58.33, NNZs: 1130, Bias: 0.000000, T: 20304, Avg. loss: 0.128426\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 59.05, NNZs: 1109, Bias: 0.000000, T: 22560, Avg. loss: 0.127471\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 59.75, NNZs: 1080, Bias: 0.000000, T: 24816, Avg. loss: 0.126415\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 59.89, NNZs: 1072, Bias: 0.000000, T: 27072, Avg. loss: 0.125536\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 60.03, NNZs: 1061, Bias: 0.000000, T: 29328, Avg. loss: 0.125353\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 60.17, NNZs: 1045, Bias: 0.000000, T: 31584, Avg. loss: 0.125163\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 60.30, NNZs: 1044, Bias: 0.000000, T: 33840, Avg. loss: 0.124981\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 60.44, NNZs: 1041, Bias: 0.000000, T: 36096, Avg. loss: 0.124791\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 60.47, NNZs: 1041, Bias: 0.000000, T: 38352, Avg. loss: 0.124615\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 60.49, NNZs: 1040, Bias: 0.000000, T: 40608, Avg. loss: 0.124581\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 60.52, NNZs: 1040, Bias: 0.000000, T: 42864, Avg. loss: 0.124543\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 60.55, NNZs: 1040, Bias: 0.000000, T: 45120, Avg. loss: 0.124507\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 22.50, NNZs: 2439, Bias: 0.000000, T: 2256, Avg. loss: 0.161107\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 28.51, NNZs: 1098, Bias: 0.000000, T: 4512, Avg. loss: 0.078627\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 32.56, NNZs: 782, Bias: 0.000000, T: 6768, Avg. loss: 0.067156\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 35.69, NNZs: 610, Bias: 0.000000, T: 9024, Avg. loss: 0.062183\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 38.25, NNZs: 512, Bias: 0.000000, T: 11280, Avg. loss: 0.059259\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 40.51, NNZs: 446, Bias: 0.000000, T: 13536, Avg. loss: 0.057516\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 40.92, NNZs: 436, Bias: 0.000000, T: 15792, Avg. loss: 0.056500\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 41.33, NNZs: 426, Bias: 0.000000, T: 18048, Avg. loss: 0.056226\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 41.73, NNZs: 417, Bias: 0.000000, T: 20304, Avg. loss: 0.056009\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 42.13, NNZs: 400, Bias: 0.000000, T: 22560, Avg. loss: 0.055776\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 42.51, NNZs: 394, Bias: 0.000000, T: 24816, Avg. loss: 0.055563\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 42.59, NNZs: 393, Bias: 0.000000, T: 27072, Avg. loss: 0.055347\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 42.66, NNZs: 392, Bias: 0.000000, T: 29328, Avg. loss: 0.055309\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 42.74, NNZs: 390, Bias: 0.000000, T: 31584, Avg. loss: 0.055262\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 42.81, NNZs: 388, Bias: 0.000000, T: 33840, Avg. loss: 0.055228\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 42.89, NNZs: 387, Bias: 0.000000, T: 36096, Avg. loss: 0.055180\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 42.90, NNZs: 387, Bias: 0.000000, T: 38352, Avg. loss: 0.055145\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 42.92, NNZs: 386, Bias: 0.000000, T: 40608, Avg. loss: 0.055139\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 42.93, NNZs: 386, Bias: 0.000000, T: 42864, Avg. loss: 0.055130\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 42.95, NNZs: 386, Bias: 0.000000, T: 45120, Avg. loss: 0.055122\n",
      "Total training time: 0.11 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.5s finished\n",
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.06171699256249541, clf__eta0=0.6666115972798587, clf__fit_intercept=False, clf__l1_ratio=0.9792901432894962, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.15075392531110676, clf__shuffle=True, clf__tol=0.365636830734297, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.677 total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 22.82, NNZs: 4113, Bias: 0.000000, T: 2256, Avg. loss: 0.422830\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 32.75, NNZs: 2193, Bias: 0.000000, T: 4512, Avg. loss: 0.292320\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 40.30, NNZs: 1701, Bias: 0.000000, T: 6768, Avg. loss: 0.248594\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 46.45, NNZs: 1431, Bias: 0.000000, T: 9024, Avg. loss: 0.220788\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 51.86, NNZs: 1208, Bias: 0.000000, T: 11280, Avg. loss: 0.203497\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 56.62, NNZs: 1067, Bias: 0.000000, T: 13536, Avg. loss: 0.190278\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 57.47, NNZs: 1019, Bias: 0.000000, T: 15792, Avg. loss: 0.181312\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 58.29, NNZs: 1000, Bias: 0.000000, T: 18048, Avg. loss: 0.179614\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 59.10, NNZs: 979, Bias: 0.000000, T: 20304, Avg. loss: 0.177766\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 59.90, NNZs: 967, Bias: 0.000000, T: 22560, Avg. loss: 0.176034\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 60.69, NNZs: 949, Bias: 0.000000, T: 24816, Avg. loss: 0.174425\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 60.84, NNZs: 942, Bias: 0.000000, T: 27072, Avg. loss: 0.172986\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 61.00, NNZs: 938, Bias: 0.000000, T: 29328, Avg. loss: 0.172687\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 61.15, NNZs: 933, Bias: 0.000000, T: 31584, Avg. loss: 0.172377\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 61.30, NNZs: 931, Bias: 0.000000, T: 33840, Avg. loss: 0.172074\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 61.45, NNZs: 928, Bias: 0.000000, T: 36096, Avg. loss: 0.171768\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 61.48, NNZs: 928, Bias: 0.000000, T: 38352, Avg. loss: 0.171502\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 61.51, NNZs: 927, Bias: 0.000000, T: 40608, Avg. loss: 0.171445\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 61.54, NNZs: 927, Bias: 0.000000, T: 42864, Avg. loss: 0.171386\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 61.57, NNZs: 925, Bias: 0.000000, T: 45120, Avg. loss: 0.171326\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 23.13, NNZs: 3894, Bias: 0.000000, T: 2256, Avg. loss: 0.344277\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 31.88, NNZs: 2023, Bias: 0.000000, T: 4512, Avg. loss: 0.228896\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 38.22, NNZs: 1570, Bias: 0.000000, T: 6768, Avg. loss: 0.197388\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 43.60, NNZs: 1190, Bias: 0.000000, T: 9024, Avg. loss: 0.179132\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 48.11, NNZs: 1049, Bias: 0.000000, T: 11280, Avg. loss: 0.166453\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 52.19, NNZs: 927, Bias: 0.000000, T: 13536, Avg. loss: 0.157080\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 52.92, NNZs: 907, Bias: 0.000000, T: 15792, Avg. loss: 0.150992\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 53.63, NNZs: 895, Bias: 0.000000, T: 18048, Avg. loss: 0.149779\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 54.32, NNZs: 880, Bias: 0.000000, T: 20304, Avg. loss: 0.148452\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 55.01, NNZs: 863, Bias: 0.000000, T: 22560, Avg. loss: 0.147240\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 55.69, NNZs: 852, Bias: 0.000000, T: 24816, Avg. loss: 0.146135\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 55.82, NNZs: 844, Bias: 0.000000, T: 27072, Avg. loss: 0.145037\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 55.95, NNZs: 842, Bias: 0.000000, T: 29328, Avg. loss: 0.144814\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 56.08, NNZs: 840, Bias: 0.000000, T: 31584, Avg. loss: 0.144600\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 56.22, NNZs: 840, Bias: 0.000000, T: 33840, Avg. loss: 0.144400\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 56.35, NNZs: 837, Bias: 0.000000, T: 36096, Avg. loss: 0.144183\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 56.37, NNZs: 837, Bias: 0.000000, T: 38352, Avg. loss: 0.143971\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 56.40, NNZs: 837, Bias: 0.000000, T: 40608, Avg. loss: 0.143930\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 56.42, NNZs: 836, Bias: 0.000000, T: 42864, Avg. loss: 0.143889\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 56.45, NNZs: 835, Bias: 0.000000, T: 45120, Avg. loss: 0.143844\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 24.97, NNZs: 4578, Bias: 0.000000, T: 2256, Avg. loss: 0.350239\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 34.62, NNZs: 2307, Bias: 0.000000, T: 4512, Avg. loss: 0.209875\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 41.54, NNZs: 1812, Bias: 0.000000, T: 6768, Avg. loss: 0.174536\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 47.10, NNZs: 1546, Bias: 0.000000, T: 9024, Avg. loss: 0.155665\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 51.87, NNZs: 1365, Bias: 0.000000, T: 11280, Avg. loss: 0.143477\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 56.08, NNZs: 1215, Bias: 0.000000, T: 13536, Avg. loss: 0.135448\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 56.84, NNZs: 1167, Bias: 0.000000, T: 15792, Avg. loss: 0.129772\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 57.58, NNZs: 1151, Bias: 0.000000, T: 18048, Avg. loss: 0.128645\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 58.30, NNZs: 1128, Bias: 0.000000, T: 20304, Avg. loss: 0.127565\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 59.02, NNZs: 1095, Bias: 0.000000, T: 22560, Avg. loss: 0.126463\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 59.72, NNZs: 1083, Bias: 0.000000, T: 24816, Avg. loss: 0.125383\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 59.86, NNZs: 1078, Bias: 0.000000, T: 27072, Avg. loss: 0.124596\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 60.00, NNZs: 1074, Bias: 0.000000, T: 29328, Avg. loss: 0.124408\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 60.13, NNZs: 1064, Bias: 0.000000, T: 31584, Avg. loss: 0.124202\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 60.27, NNZs: 1058, Bias: 0.000000, T: 33840, Avg. loss: 0.124017\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 60.41, NNZs: 1043, Bias: 0.000000, T: 36096, Avg. loss: 0.123823\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 60.43, NNZs: 1043, Bias: 0.000000, T: 38352, Avg. loss: 0.123658\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 60.46, NNZs: 1042, Bias: 0.000000, T: 40608, Avg. loss: 0.123619\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 60.49, NNZs: 1042, Bias: 0.000000, T: 42864, Avg. loss: 0.123583\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 60.51, NNZs: 1040, Bias: 0.000000, T: 45120, Avg. loss: 0.123544\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 22.49, NNZs: 2460, Bias: 0.000000, T: 2256, Avg. loss: 0.159652\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 28.52, NNZs: 1095, Bias: 0.000000, T: 4512, Avg. loss: 0.077363\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 32.45, NNZs: 763, Bias: 0.000000, T: 6768, Avg. loss: 0.066239\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 35.57, NNZs: 631, Bias: 0.000000, T: 9024, Avg. loss: 0.061734\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 38.19, NNZs: 530, Bias: 0.000000, T: 11280, Avg. loss: 0.058913\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 40.46, NNZs: 464, Bias: 0.000000, T: 13536, Avg. loss: 0.056976\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 40.88, NNZs: 442, Bias: 0.000000, T: 15792, Avg. loss: 0.055948\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 41.28, NNZs: 428, Bias: 0.000000, T: 18048, Avg. loss: 0.055683\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 41.68, NNZs: 415, Bias: 0.000000, T: 20304, Avg. loss: 0.055483\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 42.07, NNZs: 403, Bias: 0.000000, T: 22560, Avg. loss: 0.055234\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 42.46, NNZs: 398, Bias: 0.000000, T: 24816, Avg. loss: 0.055012\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 42.53, NNZs: 397, Bias: 0.000000, T: 27072, Avg. loss: 0.054838\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 42.61, NNZs: 396, Bias: 0.000000, T: 29328, Avg. loss: 0.054788\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 42.68, NNZs: 395, Bias: 0.000000, T: 31584, Avg. loss: 0.054763\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 42.76, NNZs: 393, Bias: 0.000000, T: 33840, Avg. loss: 0.054723\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 42.83, NNZs: 393, Bias: 0.000000, T: 36096, Avg. loss: 0.054688\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 42.85, NNZs: 393, Bias: 0.000000, T: 38352, Avg. loss: 0.054649\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 42.86, NNZs: 393, Bias: 0.000000, T: 40608, Avg. loss: 0.054642\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 42.88, NNZs: 390, Bias: 0.000000, T: 42864, Avg. loss: 0.054635\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 42.89, NNZs: 390, Bias: 0.000000, T: 45120, Avg. loss: 0.054628\n",
      "Total training time: 0.10 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.5s finished\n",
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.06171699256249541, clf__eta0=0.6666115972798587, clf__fit_intercept=False, clf__l1_ratio=0.9792901432894962, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.15075392531110676, clf__shuffle=True, clf__tol=0.365636830734297, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.664 total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 135208437855017.58, NNZs: 17369, Bias: 0.000000, T: 2256, Avg. loss: 3159735526189288598274048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 90458317988936.83, NNZs: 17370, Bias: 0.000000, T: 4512, Avg. loss: 6227555488884622903738368.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 65669914223434.09, NNZs: 17370, Bias: 0.000000, T: 6768, Avg. loss: 2344905630950912570687488.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 48677859029785.43, NNZs: 17370, Bias: 0.000000, T: 9024, Avg. loss: 1140102015532013807730688.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 36719067757188.27, NNZs: 17370, Bias: 0.000000, T: 11280, Avg. loss: 565561984923455612518400.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 28096541423354.12, NNZs: 17370, Bias: 0.000000, T: 13536, Avg. loss: 296707762406625407664128.000000\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 132540923139497.66, NNZs: 17370, Bias: 0.000000, T: 2256, Avg. loss: 3186092712451300881596416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 88923815181229.88, NNZs: 17370, Bias: 0.000000, T: 4512, Avg. loss: 5983745419470980471848960.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 64512060800246.22, NNZs: 17370, Bias: 0.000000, T: 6768, Avg. loss: 2289406057919418055262208.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 47504408533679.62, NNZs: 17370, Bias: 0.000000, T: 9024, Avg. loss: 1112983458795719009239040.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 35955660922970.02, NNZs: 17370, Bias: 0.000000, T: 11280, Avg. loss: 532364542177927292256256.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27555945067566.08, NNZs: 17370, Bias: 0.000000, T: 13536, Avg. loss: 277875888740275119456256.000000\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 134748604789517.70, NNZs: 17370, Bias: 0.000000, T: 2256, Avg. loss: 3293264001573420210847744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 91512451329120.19, NNZs: 17370, Bias: 0.000000, T: 4512, Avg. loss: 6120788744918435778002944.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 66332877414015.50, NNZs: 17370, Bias: 0.000000, T: 6768, Avg. loss: 2439421979154896637657088.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 49628571054691.34, NNZs: 17370, Bias: 0.000000, T: 9024, Avg. loss: 1136025610713493124677632.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 38137049905331.14, NNZs: 17370, Bias: 0.000000, T: 11280, Avg. loss: 566593596863980612091904.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 29881284537990.17, NNZs: 17370, Bias: 0.000000, T: 13536, Avg. loss: 307050929455536717955072.000000\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 135280604351824.75, NNZs: 17370, Bias: 0.000000, T: 2256, Avg. loss: 3326864124793982076059648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 91814866710074.39, NNZs: 17370, Bias: 0.000000, T: 4512, Avg. loss: 6169104004790143768592384.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 65988777540859.00, NNZs: 17370, Bias: 0.000000, T: 6768, Avg. loss: 2487054008809082824163328.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 49386803176614.34, NNZs: 17370, Bias: 0.000000, T: 9024, Avg. loss: 1123310151919583568592896.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 37474850620977.40, NNZs: 17370, Bias: 0.000000, T: 11280, Avg. loss: 575313272865044639514624.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 28925440502276.96, NNZs: 17370, Bias: 0.000000, T: 13536, Avg. loss: 302485504530111774326784.000000\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "[CV 1/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.7915127974877743, clf__eta0=0.05539740212799926, clf__fit_intercept=False, clf__l1_ratio=0.9152680641407671, clf__learning_rate=optimal, clf__loss=squared_epsilon_insensitive, clf__max_iter=80, clf__penalty=l1, clf__power_t=0.6359093112142983, clf__shuffle=True, clf__tol=0.9361199211609239, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.212 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 135224464018049.58, NNZs: 17633, Bias: 0.000000, T: 2256, Avg. loss: 3358140037039954702893056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 90884836972817.39, NNZs: 17633, Bias: 0.000000, T: 4512, Avg. loss: 6254454509666459155693568.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 65399421708126.90, NNZs: 17633, Bias: 0.000000, T: 6768, Avg. loss: 2468285062418262153756672.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 48497788897576.82, NNZs: 17633, Bias: 0.000000, T: 9024, Avg. loss: 1112418192006189632454656.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 36486643158442.62, NNZs: 17633, Bias: 0.000000, T: 11280, Avg. loss: 573890221563757388103680.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27969368946553.19, NNZs: 17633, Bias: 0.000000, T: 13536, Avg. loss: 297281588399863630921728.000000\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 139827638243515.81, NNZs: 17633, Bias: 0.000000, T: 2256, Avg. loss: 3440543008507379631259648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 94633679826499.20, NNZs: 17633, Bias: 0.000000, T: 4512, Avg. loss: 6605209853028347452325888.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 68358055194983.54, NNZs: 17633, Bias: 0.000000, T: 6768, Avg. loss: 2663327293202957701480448.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 50809295356366.48, NNZs: 17633, Bias: 0.000000, T: 9024, Avg. loss: 1227738222957390702051328.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 38314247843057.51, NNZs: 17633, Bias: 0.000000, T: 11280, Avg. loss: 622066735479610970996736.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 29500296733564.50, NNZs: 17633, Bias: 0.000000, T: 13536, Avg. loss: 320184279980769334525952.000000\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 128071489726764.31, NNZs: 17632, Bias: 0.000000, T: 2256, Avg. loss: 2791634513171351448059904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 86574614848354.41, NNZs: 17633, Bias: 0.000000, T: 4512, Avg. loss: 5571146093451464295841792.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 61408453472616.16, NNZs: 17633, Bias: 0.000000, T: 6768, Avg. loss: 2220329526684658809438208.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 45461022580906.91, NNZs: 17633, Bias: 0.000000, T: 9024, Avg. loss: 977321486012238008418304.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 34541612019990.36, NNZs: 17633, Bias: 0.000000, T: 11280, Avg. loss: 480140270817400726749184.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 26530827184256.62, NNZs: 17633, Bias: 0.000000, T: 13536, Avg. loss: 257899837751579081965568.000000\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 130507611791011.06, NNZs: 17632, Bias: 0.000000, T: 2256, Avg. loss: 3031386455270409094823936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 85624078683247.66, NNZs: 17633, Bias: 0.000000, T: 4512, Avg. loss: 5916124002026489890471936.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 60670453748884.27, NNZs: 17633, Bias: 0.000000, T: 6768, Avg. loss: 2217175239266946540109824.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 44688986617376.86, NNZs: 17633, Bias: 0.000000, T: 9024, Avg. loss: 984131222571881282404352.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 33257200862684.31, NNZs: 17633, Bias: 0.000000, T: 11280, Avg. loss: 493070630305284531159040.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 25120503236115.51, NNZs: 17633, Bias: 0.000000, T: 13536, Avg. loss: 244546798870839607427072.000000\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 2/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.7915127974877743, clf__eta0=0.05539740212799926, clf__fit_intercept=False, clf__l1_ratio=0.9152680641407671, clf__learning_rate=optimal, clf__loss=squared_epsilon_insensitive, clf__max_iter=80, clf__penalty=l1, clf__power_t=0.6359093112142983, clf__shuffle=True, clf__tol=0.9361199211609239, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.180 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 132600406456444.33, NNZs: 17254, Bias: 0.000000, T: 2256, Avg. loss: 3153097852969110479044608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 89914171063809.58, NNZs: 17256, Bias: 0.000000, T: 4512, Avg. loss: 6019705774292475622457344.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 65815008484605.12, NNZs: 17256, Bias: 0.000000, T: 6768, Avg. loss: 2316008527318844694331392.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 49253607226464.09, NNZs: 17256, Bias: 0.000000, T: 9024, Avg. loss: 1115182379927677941317632.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 37125830875619.73, NNZs: 17256, Bias: 0.000000, T: 11280, Avg. loss: 578789537846683599110144.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 28805674104363.43, NNZs: 17256, Bias: 0.000000, T: 13536, Avg. loss: 290909219466619153022976.000000\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 132924550316705.83, NNZs: 17256, Bias: 0.000000, T: 2256, Avg. loss: 3075959798851717545590784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 87530251379511.22, NNZs: 17256, Bias: 0.000000, T: 4512, Avg. loss: 6115387231411541565767680.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 63107109941630.12, NNZs: 17256, Bias: 0.000000, T: 6768, Avg. loss: 2246355818188217518129152.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 46315863834504.25, NNZs: 17256, Bias: 0.000000, T: 9024, Avg. loss: 1057938057980349383704576.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 34711502844163.00, NNZs: 17256, Bias: 0.000000, T: 11280, Avg. loss: 514126440284480419659776.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 26467522462282.80, NNZs: 17256, Bias: 0.000000, T: 13536, Avg. loss: 262546906913221522751488.000000\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 140260642926696.62, NNZs: 17256, Bias: 0.000000, T: 2256, Avg. loss: 3667967928916256510443520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 96556607334137.75, NNZs: 17256, Bias: 0.000000, T: 4512, Avg. loss: 6424240611325932409454592.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 70713198491141.30, NNZs: 17256, Bias: 0.000000, T: 6768, Avg. loss: 2629409558327932689055744.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 53107214603330.60, NNZs: 17256, Bias: 0.000000, T: 9024, Avg. loss: 1275935908210675575422976.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 40542823982237.52, NNZs: 17256, Bias: 0.000000, T: 11280, Avg. loss: 661161940527262233264128.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 31397162045499.74, NNZs: 17256, Bias: 0.000000, T: 13536, Avg. loss: 352413492993413959647232.000000\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 114265385679052.36, NNZs: 17241, Bias: 0.000000, T: 2256, Avg. loss: 2205842042527083225153536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 77670124420669.36, NNZs: 17256, Bias: 0.000000, T: 4512, Avg. loss: 4545632755698381363347456.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 54837008819660.30, NNZs: 17256, Bias: 0.000000, T: 6768, Avg. loss: 1847511778243350024421376.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 39963030493331.54, NNZs: 17256, Bias: 0.000000, T: 9024, Avg. loss: 829907581496356050567168.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 29728368633001.57, NNZs: 17256, Bias: 0.000000, T: 11280, Avg. loss: 393276189052606470946816.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 22604312793984.29, NNZs: 17256, Bias: 0.000000, T: 13536, Avg. loss: 197404115380340156006400.000000\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "[CV 3/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.7915127974877743, clf__eta0=0.05539740212799926, clf__fit_intercept=False, clf__l1_ratio=0.9152680641407671, clf__learning_rate=optimal, clf__loss=squared_epsilon_insensitive, clf__max_iter=80, clf__penalty=l1, clf__power_t=0.6359093112142983, clf__shuffle=True, clf__tol=0.9361199211609239, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.172 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 132426276466853.84, NNZs: 17607, Bias: 0.000000, T: 2256, Avg. loss: 3086186809553323275845632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 90320308802609.75, NNZs: 17607, Bias: 0.000000, T: 4512, Avg. loss: 5861835691964838027722752.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 64485358068475.57, NNZs: 17607, Bias: 0.000000, T: 6768, Avg. loss: 2431121970453107645087744.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 48195368874102.28, NNZs: 17607, Bias: 0.000000, T: 9024, Avg. loss: 1068291228811501137559552.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 36237222269138.60, NNZs: 17607, Bias: 0.000000, T: 11280, Avg. loss: 552531841634973308157952.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27895996971696.45, NNZs: 17607, Bias: 0.000000, T: 13536, Avg. loss: 281992393845365832417280.000000\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 131406098330521.83, NNZs: 17603, Bias: 0.000000, T: 2256, Avg. loss: 3102136335897203037962240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 88044354141184.69, NNZs: 17607, Bias: 0.000000, T: 4512, Avg. loss: 5835203886070217142435840.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 62994544263383.66, NNZs: 17607, Bias: 0.000000, T: 6768, Avg. loss: 2315086388937373503193088.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 47548070744663.11, NNZs: 17607, Bias: 0.000000, T: 9024, Avg. loss: 1012573822370835517669376.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 36034003092845.50, NNZs: 17607, Bias: 0.000000, T: 11280, Avg. loss: 542829362714909415047168.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27787744313143.22, NNZs: 17607, Bias: 0.000000, T: 13536, Avg. loss: 282407593834986201939968.000000\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 137618352958243.50, NNZs: 17607, Bias: 0.000000, T: 2256, Avg. loss: 3500565288156616477114368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 94398240592105.62, NNZs: 17607, Bias: 0.000000, T: 4512, Avg. loss: 6336975117713790067539968.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 68612797686094.49, NNZs: 17607, Bias: 0.000000, T: 6768, Avg. loss: 2595562976247835749515264.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 50699720711860.62, NNZs: 17607, Bias: 0.000000, T: 9024, Avg. loss: 1228248268878284570230784.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 38339470037529.45, NNZs: 17607, Bias: 0.000000, T: 11280, Avg. loss: 612211613532417882587136.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 29242474451514.67, NNZs: 17607, Bias: 0.000000, T: 13536, Avg. loss: 324725710516518752616448.000000\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 132327958333537.05, NNZs: 17607, Bias: 0.000000, T: 2256, Avg. loss: 3385379892847479619584000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 90861785683281.02, NNZs: 17607, Bias: 0.000000, T: 4512, Avg. loss: 5752434350755686981304320.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 66220627553889.48, NNZs: 17607, Bias: 0.000000, T: 6768, Avg. loss: 2351928000439963936096256.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 49313488157766.05, NNZs: 17607, Bias: 0.000000, T: 9024, Avg. loss: 1143116544353474810216448.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 37518508011178.35, NNZs: 17607, Bias: 0.000000, T: 11280, Avg. loss: 576133302430473010544640.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 29034516130837.34, NNZs: 17607, Bias: 0.000000, T: 13536, Avg. loss: 304696766956574649352192.000000\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 4/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.7915127974877743, clf__eta0=0.05539740212799926, clf__fit_intercept=False, clf__l1_ratio=0.9152680641407671, clf__learning_rate=optimal, clf__loss=squared_epsilon_insensitive, clf__max_iter=80, clf__penalty=l1, clf__power_t=0.6359093112142983, clf__shuffle=True, clf__tol=0.9361199211609239, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.166 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 129453272720612.69, NNZs: 17617, Bias: 0.000000, T: 2256, Avg. loss: 2864039084354335080972288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 86742969871799.61, NNZs: 17618, Bias: 0.000000, T: 4512, Avg. loss: 5783945251447821087801344.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 61900326516487.14, NNZs: 17618, Bias: 0.000000, T: 6768, Avg. loss: 2236228692129595351105536.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 45450563965346.59, NNZs: 17618, Bias: 0.000000, T: 9024, Avg. loss: 1025347515109142794600448.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 33894128226023.77, NNZs: 17618, Bias: 0.000000, T: 11280, Avg. loss: 503254461711605229944832.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 25585147141871.43, NNZs: 17618, Bias: 0.000000, T: 13536, Avg. loss: 258627399187101885923328.000000\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 134510997865930.30, NNZs: 17618, Bias: 0.000000, T: 2256, Avg. loss: 3310085385093688344969216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 92238284419098.16, NNZs: 17618, Bias: 0.000000, T: 4512, Avg. loss: 5987800397079773242720256.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 66672353648528.11, NNZs: 17618, Bias: 0.000000, T: 6768, Avg. loss: 2466881874596931766845440.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 49745115061059.37, NNZs: 17618, Bias: 0.000000, T: 9024, Avg. loss: 1160252304336493253492736.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 37819592558210.63, NNZs: 17618, Bias: 0.000000, T: 11280, Avg. loss: 594131801606442662756352.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 29362854723553.40, NNZs: 17618, Bias: 0.000000, T: 13536, Avg. loss: 309389424291267722870784.000000\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 127682998590979.27, NNZs: 17618, Bias: 0.000000, T: 2256, Avg. loss: 2817549751987617086308352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 85052323981183.86, NNZs: 17618, Bias: 0.000000, T: 4512, Avg. loss: 5589705294297559335960576.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 60518270710066.27, NNZs: 17618, Bias: 0.000000, T: 6768, Avg. loss: 2139545273576155527512064.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 44314475739981.05, NNZs: 17618, Bias: 0.000000, T: 9024, Avg. loss: 973776285975152087269376.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 33355720447181.84, NNZs: 17618, Bias: 0.000000, T: 11280, Avg. loss: 464148539779331315990528.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 25357216879514.40, NNZs: 17618, Bias: 0.000000, T: 13536, Avg. loss: 242689713845965477117952.000000\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 123966019800743.69, NNZs: 17615, Bias: 0.000000, T: 2256, Avg. loss: 2541124060540257811038208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 81749821074164.78, NNZs: 17618, Bias: 0.000000, T: 4512, Avg. loss: 5379146493394921082322944.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 57274243981673.23, NNZs: 17618, Bias: 0.000000, T: 6768, Avg. loss: 2045829435998456143413248.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 42139296150028.44, NNZs: 17618, Bias: 0.000000, T: 9024, Avg. loss: 873571333199075192340480.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 31287924194974.32, NNZs: 17618, Bias: 0.000000, T: 11280, Avg. loss: 442421526424703150850048.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 23860469271977.39, NNZs: 17618, Bias: 0.000000, T: 13536, Avg. loss: 215079478524432101670912.000000\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "[CV 5/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.7915127974877743, clf__eta0=0.05539740212799926, clf__fit_intercept=False, clf__l1_ratio=0.9152680641407671, clf__learning_rate=optimal, clf__loss=squared_epsilon_insensitive, clf__max_iter=80, clf__penalty=l1, clf__power_t=0.6359093112142983, clf__shuffle=True, clf__tol=0.9361199211609239, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.158 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 41.12, NNZs: 11529, Bias: 0.000000, T: 2256, Avg. loss: 0.312161\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 48.15, NNZs: 5087, Bias: 0.000000, T: 4512, Avg. loss: 0.058083\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 53.81, NNZs: 3371, Bias: 0.000000, T: 6768, Avg. loss: 0.046959\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 58.72, NNZs: 2575, Bias: 0.000000, T: 9024, Avg. loss: 0.040460\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 62.92, NNZs: 2112, Bias: 0.000000, T: 11280, Avg. loss: 0.034645\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 66.71, NNZs: 1843, Bias: 0.000000, T: 13536, Avg. loss: 0.033299\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 34.55, NNZs: 8802, Bias: 0.000000, T: 2256, Avg. loss: 0.211172\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 40.93, NNZs: 3964, Bias: 0.000000, T: 4512, Avg. loss: 0.047314\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 46.16, NNZs: 2639, Bias: 0.000000, T: 6768, Avg. loss: 0.035405\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 50.51, NNZs: 2104, Bias: 0.000000, T: 9024, Avg. loss: 0.030097\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 54.23, NNZs: 1753, Bias: 0.000000, T: 11280, Avg. loss: 0.027151\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 57.56, NNZs: 1563, Bias: 0.000000, T: 13536, Avg. loss: 0.025195\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 34.21, NNZs: 8501, Bias: 0.000000, T: 2256, Avg. loss: 0.179320\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 40.02, NNZs: 3929, Bias: 0.000000, T: 4512, Avg. loss: 0.036947\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 44.93, NNZs: 2682, Bias: 0.000000, T: 6768, Avg. loss: 0.029277\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 49.16, NNZs: 2061, Bias: 0.000000, T: 9024, Avg. loss: 0.026869\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 52.76, NNZs: 1730, Bias: 0.000000, T: 11280, Avg. loss: 0.023296\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 56.01, NNZs: 1500, Bias: 0.000000, T: 13536, Avg. loss: 0.022670\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 20.33, NNZs: 3152, Bias: 0.000000, T: 2256, Avg. loss: 0.061510\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 24.54, NNZs: 1651, Bias: 0.000000, T: 4512, Avg. loss: 0.018095\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 27.99, NNZs: 1189, Bias: 0.000000, T: 6768, Avg. loss: 0.012650\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 30.62, NNZs: 975, Bias: 0.000000, T: 9024, Avg. loss: 0.012848\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 33.13, NNZs: 863, Bias: 0.000000, T: 11280, Avg. loss: 0.011639\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 35.34, NNZs: 771, Bias: 0.000000, T: 13536, Avg. loss: 0.010073\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 1/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.03646223783802971, clf__eta0=0.7491267567674796, clf__fit_intercept=False, clf__l1_ratio=0.775818217437024, clf__learning_rate=constant, clf__loss=squared_hinge, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.4028006727705291, clf__shuffle=True, clf__tol=0.1730703028465106, clf__warm_start=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.709 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 40.99, NNZs: 11303, Bias: 0.000000, T: 2256, Avg. loss: 0.312184\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 47.77, NNZs: 5074, Bias: 0.000000, T: 4512, Avg. loss: 0.060744\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 53.91, NNZs: 3335, Bias: 0.000000, T: 6768, Avg. loss: 0.049440\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 58.82, NNZs: 2582, Bias: 0.000000, T: 9024, Avg. loss: 0.041597\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 63.07, NNZs: 2130, Bias: 0.000000, T: 11280, Avg. loss: 0.037103\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 66.87, NNZs: 1837, Bias: 0.000000, T: 13536, Avg. loss: 0.033559\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 34.90, NNZs: 8713, Bias: 0.000000, T: 2256, Avg. loss: 0.223613\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 41.24, NNZs: 3990, Bias: 0.000000, T: 4512, Avg. loss: 0.046562\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 46.61, NNZs: 2772, Bias: 0.000000, T: 6768, Avg. loss: 0.040298\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 51.00, NNZs: 2169, Bias: 0.000000, T: 9024, Avg. loss: 0.032725\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 54.64, NNZs: 1784, Bias: 0.000000, T: 11280, Avg. loss: 0.027657\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 58.09, NNZs: 1580, Bias: 0.000000, T: 13536, Avg. loss: 0.027316\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 33.93, NNZs: 8478, Bias: 0.000000, T: 2256, Avg. loss: 0.181618\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 39.72, NNZs: 3857, Bias: 0.000000, T: 4512, Avg. loss: 0.036283\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 44.80, NNZs: 2572, Bias: 0.000000, T: 6768, Avg. loss: 0.031144\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 48.86, NNZs: 2005, Bias: 0.000000, T: 9024, Avg. loss: 0.024530\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 52.45, NNZs: 1688, Bias: 0.000000, T: 11280, Avg. loss: 0.024325\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 55.76, NNZs: 1468, Bias: 0.000000, T: 13536, Avg. loss: 0.022113\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 20.39, NNZs: 3261, Bias: 0.000000, T: 2256, Avg. loss: 0.058888\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 24.26, NNZs: 1716, Bias: 0.000000, T: 4512, Avg. loss: 0.014457\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 27.58, NNZs: 1301, Bias: 0.000000, T: 6768, Avg. loss: 0.013672\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 30.30, NNZs: 1036, Bias: 0.000000, T: 9024, Avg. loss: 0.011939\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 32.66, NNZs: 858, Bias: 0.000000, T: 11280, Avg. loss: 0.009642\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 34.92, NNZs: 767, Bias: 0.000000, T: 13536, Avg. loss: 0.010411\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 2/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.03646223783802971, clf__eta0=0.7491267567674796, clf__fit_intercept=False, clf__l1_ratio=0.775818217437024, clf__learning_rate=constant, clf__loss=squared_hinge, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.4028006727705291, clf__shuffle=True, clf__tol=0.1730703028465106, clf__warm_start=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.714 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 41.10, NNZs: 11421, Bias: 0.000000, T: 2256, Avg. loss: 0.310849\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 48.32, NNZs: 5277, Bias: 0.000000, T: 4512, Avg. loss: 0.059463\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 54.16, NNZs: 3498, Bias: 0.000000, T: 6768, Avg. loss: 0.047399\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 58.99, NNZs: 2665, Bias: 0.000000, T: 9024, Avg. loss: 0.038210\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 63.27, NNZs: 2210, Bias: 0.000000, T: 11280, Avg. loss: 0.033708\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 67.00, NNZs: 1909, Bias: 0.000000, T: 13536, Avg. loss: 0.030544\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 35.36, NNZs: 8869, Bias: 0.000000, T: 2256, Avg. loss: 0.224687\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 41.96, NNZs: 4033, Bias: 0.000000, T: 4512, Avg. loss: 0.047916\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 47.16, NNZs: 2709, Bias: 0.000000, T: 6768, Avg. loss: 0.038139\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 51.41, NNZs: 2172, Bias: 0.000000, T: 9024, Avg. loss: 0.030208\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 55.22, NNZs: 1789, Bias: 0.000000, T: 11280, Avg. loss: 0.029890\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 58.62, NNZs: 1562, Bias: 0.000000, T: 13536, Avg. loss: 0.027234\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 34.88, NNZs: 8902, Bias: 0.000000, T: 2256, Avg. loss: 0.178918\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 40.42, NNZs: 3993, Bias: 0.000000, T: 4512, Avg. loss: 0.032539\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 45.38, NNZs: 2740, Bias: 0.000000, T: 6768, Avg. loss: 0.026437\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 49.49, NNZs: 2110, Bias: 0.000000, T: 9024, Avg. loss: 0.022877\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 53.13, NNZs: 1770, Bias: 0.000000, T: 11280, Avg. loss: 0.020093\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 56.30, NNZs: 1496, Bias: 0.000000, T: 13536, Avg. loss: 0.018102\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 20.50, NNZs: 3394, Bias: 0.000000, T: 2256, Avg. loss: 0.059804\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 24.84, NNZs: 1888, Bias: 0.000000, T: 4512, Avg. loss: 0.017803\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 28.14, NNZs: 1331, Bias: 0.000000, T: 6768, Avg. loss: 0.014648\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 30.87, NNZs: 1022, Bias: 0.000000, T: 9024, Avg. loss: 0.010987\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 33.34, NNZs: 844, Bias: 0.000000, T: 11280, Avg. loss: 0.010112\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 35.55, NNZs: 725, Bias: 0.000000, T: 13536, Avg. loss: 0.010311\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 3/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.03646223783802971, clf__eta0=0.7491267567674796, clf__fit_intercept=False, clf__l1_ratio=0.775818217437024, clf__learning_rate=constant, clf__loss=squared_hinge, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.4028006727705291, clf__shuffle=True, clf__tol=0.1730703028465106, clf__warm_start=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.699 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 40.37, NNZs: 11104, Bias: 0.000000, T: 2256, Avg. loss: 0.289133\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 47.36, NNZs: 5057, Bias: 0.000000, T: 4512, Avg. loss: 0.060136\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 53.11, NNZs: 3322, Bias: 0.000000, T: 6768, Avg. loss: 0.046959\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 58.04, NNZs: 2535, Bias: 0.000000, T: 9024, Avg. loss: 0.040807\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 62.26, NNZs: 2080, Bias: 0.000000, T: 11280, Avg. loss: 0.033751\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 65.90, NNZs: 1799, Bias: 0.000000, T: 13536, Avg. loss: 0.032161\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 34.70, NNZs: 8531, Bias: 0.000000, T: 2256, Avg. loss: 0.208637\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 41.00, NNZs: 3779, Bias: 0.000000, T: 4512, Avg. loss: 0.044182\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 46.17, NNZs: 2597, Bias: 0.000000, T: 6768, Avg. loss: 0.036099\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 50.39, NNZs: 2046, Bias: 0.000000, T: 9024, Avg. loss: 0.028296\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 54.07, NNZs: 1711, Bias: 0.000000, T: 11280, Avg. loss: 0.026658\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 57.27, NNZs: 1498, Bias: 0.000000, T: 13536, Avg. loss: 0.023054\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 34.36, NNZs: 8736, Bias: 0.000000, T: 2256, Avg. loss: 0.182450\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 39.95, NNZs: 3913, Bias: 0.000000, T: 4512, Avg. loss: 0.042583\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 45.03, NNZs: 2670, Bias: 0.000000, T: 6768, Avg. loss: 0.033919\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 49.23, NNZs: 2093, Bias: 0.000000, T: 9024, Avg. loss: 0.027010\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 52.97, NNZs: 1765, Bias: 0.000000, T: 11280, Avg. loss: 0.026786\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 56.24, NNZs: 1545, Bias: 0.000000, T: 13536, Avg. loss: 0.023199\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 20.20, NNZs: 3399, Bias: 0.000000, T: 2256, Avg. loss: 0.059037\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 24.12, NNZs: 1726, Bias: 0.000000, T: 4512, Avg. loss: 0.014434\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 27.45, NNZs: 1281, Bias: 0.000000, T: 6768, Avg. loss: 0.014743\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 30.28, NNZs: 1002, Bias: 0.000000, T: 9024, Avg. loss: 0.010928\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 32.71, NNZs: 851, Bias: 0.000000, T: 11280, Avg. loss: 0.010411\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 34.85, NNZs: 736, Bias: 0.000000, T: 13536, Avg. loss: 0.009060\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 4/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.03646223783802971, clf__eta0=0.7491267567674796, clf__fit_intercept=False, clf__l1_ratio=0.775818217437024, clf__learning_rate=constant, clf__loss=squared_hinge, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.4028006727705291, clf__shuffle=True, clf__tol=0.1730703028465106, clf__warm_start=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.695 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 40.98, NNZs: 11430, Bias: 0.000000, T: 2256, Avg. loss: 0.305926\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 48.13, NNZs: 5247, Bias: 0.000000, T: 4512, Avg. loss: 0.065230\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 53.89, NNZs: 3321, Bias: 0.000000, T: 6768, Avg. loss: 0.048375\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 58.89, NNZs: 2567, Bias: 0.000000, T: 9024, Avg. loss: 0.042671\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 63.13, NNZs: 2099, Bias: 0.000000, T: 11280, Avg. loss: 0.037198\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 66.90, NNZs: 1798, Bias: 0.000000, T: 13536, Avg. loss: 0.035643\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 35.30, NNZs: 8834, Bias: 0.000000, T: 2256, Avg. loss: 0.224276\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 41.59, NNZs: 4045, Bias: 0.000000, T: 4512, Avg. loss: 0.045715\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 46.93, NNZs: 2662, Bias: 0.000000, T: 6768, Avg. loss: 0.037057\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 51.20, NNZs: 2093, Bias: 0.000000, T: 9024, Avg. loss: 0.030962\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 54.98, NNZs: 1752, Bias: 0.000000, T: 11280, Avg. loss: 0.027075\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 58.36, NNZs: 1514, Bias: 0.000000, T: 13536, Avg. loss: 0.025083\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 35.22, NNZs: 8907, Bias: 0.000000, T: 2256, Avg. loss: 0.195196\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 40.94, NNZs: 4054, Bias: 0.000000, T: 4512, Avg. loss: 0.039446\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 46.14, NNZs: 2746, Bias: 0.000000, T: 6768, Avg. loss: 0.035891\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 50.48, NNZs: 2113, Bias: 0.000000, T: 9024, Avg. loss: 0.032069\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 54.31, NNZs: 1790, Bias: 0.000000, T: 11280, Avg. loss: 0.027328\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 57.67, NNZs: 1567, Bias: 0.000000, T: 13536, Avg. loss: 0.025157\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 20.59, NNZs: 3254, Bias: 0.000000, T: 2256, Avg. loss: 0.057492\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 24.27, NNZs: 1656, Bias: 0.000000, T: 4512, Avg. loss: 0.014134\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 27.37, NNZs: 1216, Bias: 0.000000, T: 6768, Avg. loss: 0.014146\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 30.27, NNZs: 996, Bias: 0.000000, T: 9024, Avg. loss: 0.010240\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 32.59, NNZs: 815, Bias: 0.000000, T: 11280, Avg. loss: 0.009494\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 34.81, NNZs: 747, Bias: 0.000000, T: 13536, Avg. loss: 0.010671\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 5/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.03646223783802971, clf__eta0=0.7491267567674796, clf__fit_intercept=False, clf__l1_ratio=0.775818217437024, clf__learning_rate=constant, clf__loss=squared_hinge, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.4028006727705291, clf__shuffle=True, clf__tol=0.1730703028465106, clf__warm_start=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.716 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 16.05, NNZs: 6636, Bias: 0.000000, T: 2256, Avg. loss: 0.202025\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 21.76, NNZs: 4384, Bias: 0.000000, T: 4512, Avg. loss: 0.097866\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 25.67, NNZs: 3457, Bias: 0.000000, T: 6768, Avg. loss: 0.075779\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 28.74, NNZs: 2926, Bias: 0.000000, T: 9024, Avg. loss: 0.065821\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 31.40, NNZs: 2603, Bias: 0.000000, T: 11280, Avg. loss: 0.059507\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 33.68, NNZs: 2362, Bias: 0.000000, T: 13536, Avg. loss: 0.055758\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 15.12, NNZs: 6078, Bias: 0.000000, T: 2256, Avg. loss: 0.152134\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 19.99, NNZs: 3993, Bias: 0.000000, T: 4512, Avg. loss: 0.070494\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 23.52, NNZs: 3123, Bias: 0.000000, T: 6768, Avg. loss: 0.054227\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 26.37, NNZs: 2664, Bias: 0.000000, T: 9024, Avg. loss: 0.047483\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 28.82, NNZs: 2389, Bias: 0.000000, T: 11280, Avg. loss: 0.042963\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 30.93, NNZs: 2146, Bias: 0.000000, T: 13536, Avg. loss: 0.039658\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 10.38, NNZs: 3396, Bias: 0.000000, T: 2256, Avg. loss: 0.216761\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 13.43, NNZs: 2006, Bias: 0.000000, T: 4512, Avg. loss: 0.124532\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 15.74, NNZs: 1611, Bias: 0.000000, T: 6768, Avg. loss: 0.109625\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 17.64, NNZs: 1391, Bias: 0.000000, T: 9024, Avg. loss: 0.100992\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 19.33, NNZs: 1236, Bias: 0.000000, T: 11280, Avg. loss: 0.096238\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 20.87, NNZs: 1140, Bias: 0.000000, T: 13536, Avg. loss: 0.091198\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 113.09, NNZs: 11232, Bias: 0.000000, T: 2256, Avg. loss: 1.584944\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1980.63, NNZs: 15347, Bias: 0.000000, T: 4512, Avg. loss: 161.829825\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 129574.79, NNZs: 17335, Bias: 0.000000, T: 6768, Avg. loss: 2743968.128796\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 9375041.34, NNZs: 17366, Bias: 0.000000, T: 9024, Avg. loss: 4535301597.549938\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 259073948.65, NNZs: 17370, Bias: 0.000000, T: 11280, Avg. loss: 13211175882191.542969\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 11175760308.73, NNZs: 17370, Bias: 0.000000, T: 13536, Avg. loss: 26265007015919044.000000\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 1/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.24457156361183285, clf__eta0=0.332929742792607, clf__fit_intercept=False, clf__l1_ratio=0.920539731041378, clf__learning_rate=constant, clf__loss=squared_error, clf__max_iter=100, clf__penalty=l1, clf__power_t=0.5734177157821045, clf__shuffle=True, clf__tol=0.6492274795888617, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.222 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 16.30, NNZs: 6428, Bias: 0.000000, T: 2256, Avg. loss: 0.200076\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 21.55, NNZs: 4251, Bias: 0.000000, T: 4512, Avg. loss: 0.097160\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 25.51, NNZs: 3475, Bias: 0.000000, T: 6768, Avg. loss: 0.075251\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 28.51, NNZs: 2897, Bias: 0.000000, T: 9024, Avg. loss: 0.066479\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 31.18, NNZs: 2549, Bias: 0.000000, T: 11280, Avg. loss: 0.060360\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 33.52, NNZs: 2335, Bias: 0.000000, T: 13536, Avg. loss: 0.056328\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 6 epochs took 0.05 seconds\n",
      "-- Epoch 1\n",
      "Norm: 14.99, NNZs: 6117, Bias: 0.000000, T: 2256, Avg. loss: 0.149471\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 19.88, NNZs: 3936, Bias: 0.000000, T: 4512, Avg. loss: 0.069160\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 23.44, NNZs: 3077, Bias: 0.000000, T: 6768, Avg. loss: 0.052961\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 26.22, NNZs: 2582, Bias: 0.000000, T: 9024, Avg. loss: 0.045396\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 28.71, NNZs: 2335, Bias: 0.000000, T: 11280, Avg. loss: 0.041302\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 30.77, NNZs: 2077, Bias: 0.000000, T: 13536, Avg. loss: 0.038044\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 6 epochs took 0.05 seconds\n",
      "-- Epoch 1\n",
      "Norm: 10.33, NNZs: 3403, Bias: 0.000000, T: 2256, Avg. loss: 0.214240\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 13.47, NNZs: 2029, Bias: 0.000000, T: 4512, Avg. loss: 0.118148\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 15.68, NNZs: 1618, Bias: 0.000000, T: 6768, Avg. loss: 0.103089\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 17.59, NNZs: 1356, Bias: 0.000000, T: 9024, Avg. loss: 0.094744\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 19.31, NNZs: 1207, Bias: 0.000000, T: 11280, Avg. loss: 0.091618\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 20.84, NNZs: 1098, Bias: 0.000000, T: 13536, Avg. loss: 0.086725\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 6 epochs took 0.05 seconds\n",
      "-- Epoch 1\n",
      "Norm: 118.75, NNZs: 12120, Bias: 0.000000, T: 2256, Avg. loss: 2.282674\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2002.80, NNZs: 16723, Bias: 0.000000, T: 4512, Avg. loss: 822.606868\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 129040.39, NNZs: 17558, Bias: 0.000000, T: 6768, Avg. loss: 2284370.787622\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2353807.15, NNZs: 17629, Bias: 0.000000, T: 9024, Avg. loss: 1018719698.555871\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 63850663.66, NNZs: 17629, Bias: 0.000000, T: 11280, Avg. loss: 963741719127.247437\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2408275687.47, NNZs: 17629, Bias: 0.000000, T: 13536, Avg. loss: 835737197698069.750000\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "[CV 2/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.24457156361183285, clf__eta0=0.332929742792607, clf__fit_intercept=False, clf__l1_ratio=0.920539731041378, clf__learning_rate=constant, clf__loss=squared_error, clf__max_iter=100, clf__penalty=l1, clf__power_t=0.5734177157821045, clf__shuffle=True, clf__tol=0.6492274795888617, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.241 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 16.31, NNZs: 6620, Bias: 0.000000, T: 2256, Avg. loss: 0.202330\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 21.84, NNZs: 4482, Bias: 0.000000, T: 4512, Avg. loss: 0.098753\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 25.73, NNZs: 3482, Bias: 0.000000, T: 6768, Avg. loss: 0.076977\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 28.75, NNZs: 2967, Bias: 0.000000, T: 9024, Avg. loss: 0.065783\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 31.44, NNZs: 2583, Bias: 0.000000, T: 11280, Avg. loss: 0.060374\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 33.77, NNZs: 2301, Bias: 0.000000, T: 13536, Avg. loss: 0.055712\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 15.10, NNZs: 6091, Bias: 0.000000, T: 2256, Avg. loss: 0.151315\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 20.06, NNZs: 3992, Bias: 0.000000, T: 4512, Avg. loss: 0.069852\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 23.58, NNZs: 3130, Bias: 0.000000, T: 6768, Avg. loss: 0.054270\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 26.41, NNZs: 2688, Bias: 0.000000, T: 9024, Avg. loss: 0.046518\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 28.85, NNZs: 2388, Bias: 0.000000, T: 11280, Avg. loss: 0.041776\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 30.96, NNZs: 2144, Bias: 0.000000, T: 13536, Avg. loss: 0.039224\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 10.31, NNZs: 3407, Bias: 0.000000, T: 2256, Avg. loss: 0.220925\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 13.56, NNZs: 2051, Bias: 0.000000, T: 4512, Avg. loss: 0.124388\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 15.83, NNZs: 1625, Bias: 0.000000, T: 6768, Avg. loss: 0.107324\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 17.80, NNZs: 1377, Bias: 0.000000, T: 9024, Avg. loss: 0.100483\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 19.48, NNZs: 1194, Bias: 0.000000, T: 11280, Avg. loss: 0.094015\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 21.03, NNZs: 1080, Bias: 0.000000, T: 13536, Avg. loss: 0.090388\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 95.90, NNZs: 11428, Bias: 0.000000, T: 2256, Avg. loss: 1.452638\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2028.22, NNZs: 16483, Bias: 0.000000, T: 4512, Avg. loss: 744.580867\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 29269.00, NNZs: 17170, Bias: 0.000000, T: 6768, Avg. loss: 143280.895828\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2291699.37, NNZs: 17254, Bias: 0.000000, T: 9024, Avg. loss: 783372274.313394\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 47152792.59, NNZs: 17258, Bias: 0.000000, T: 11280, Avg. loss: 480678888861.831665\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 928493743.80, NNZs: 17258, Bias: 0.000000, T: 13536, Avg. loss: 196962037667381.906250\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "[CV 3/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.24457156361183285, clf__eta0=0.332929742792607, clf__fit_intercept=False, clf__l1_ratio=0.920539731041378, clf__learning_rate=constant, clf__loss=squared_error, clf__max_iter=100, clf__penalty=l1, clf__power_t=0.5734177157821045, clf__shuffle=True, clf__tol=0.6492274795888617, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.267 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 16.33, NNZs: 6667, Bias: 0.000000, T: 2256, Avg. loss: 0.197369\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 21.68, NNZs: 4373, Bias: 0.000000, T: 4512, Avg. loss: 0.094338\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 25.49, NNZs: 3394, Bias: 0.000000, T: 6768, Avg. loss: 0.073184\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 28.55, NNZs: 2852, Bias: 0.000000, T: 9024, Avg. loss: 0.063143\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 31.21, NNZs: 2507, Bias: 0.000000, T: 11280, Avg. loss: 0.056609\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 33.46, NNZs: 2252, Bias: 0.000000, T: 13536, Avg. loss: 0.053355\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 15.25, NNZs: 6254, Bias: 0.000000, T: 2256, Avg. loss: 0.150549\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 20.31, NNZs: 4046, Bias: 0.000000, T: 4512, Avg. loss: 0.069587\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 23.76, NNZs: 3222, Bias: 0.000000, T: 6768, Avg. loss: 0.051467\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 26.64, NNZs: 2746, Bias: 0.000000, T: 9024, Avg. loss: 0.045850\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 29.11, NNZs: 2447, Bias: 0.000000, T: 11280, Avg. loss: 0.040916\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 31.24, NNZs: 2194, Bias: 0.000000, T: 13536, Avg. loss: 0.037847\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 10.38, NNZs: 3353, Bias: 0.000000, T: 2256, Avg. loss: 0.217659\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 13.63, NNZs: 2049, Bias: 0.000000, T: 4512, Avg. loss: 0.119458\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 15.86, NNZs: 1614, Bias: 0.000000, T: 6768, Avg. loss: 0.103514\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 17.85, NNZs: 1363, Bias: 0.000000, T: 9024, Avg. loss: 0.096576\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 19.54, NNZs: 1225, Bias: 0.000000, T: 11280, Avg. loss: 0.089768\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 21.10, NNZs: 1134, Bias: 0.000000, T: 13536, Avg. loss: 0.086798\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 478.87, NNZs: 15855, Bias: 0.000000, T: 2256, Avg. loss: 45.209466\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 133826.00, NNZs: 17539, Bias: 0.000000, T: 4512, Avg. loss: 1016972.212484\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 20735451.11, NNZs: 17607, Bias: 0.000000, T: 6768, Avg. loss: 32816236058.445770\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 532479517.04, NNZs: 17607, Bias: 0.000000, T: 9024, Avg. loss: 39263277491628.804688\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 240970470744.41, NNZs: 17607, Bias: 0.000000, T: 11280, Avg. loss: 8338927543592356864.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 20601467971651.54, NNZs: 17607, Bias: 0.000000, T: 13536, Avg. loss: 151872498442815672418304.000000\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "[CV 4/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.24457156361183285, clf__eta0=0.332929742792607, clf__fit_intercept=False, clf__l1_ratio=0.920539731041378, clf__learning_rate=constant, clf__loss=squared_error, clf__max_iter=100, clf__penalty=l1, clf__power_t=0.5734177157821045, clf__shuffle=True, clf__tol=0.6492274795888617, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.205 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 16.34, NNZs: 6756, Bias: 0.000000, T: 2256, Avg. loss: 0.199667\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 21.75, NNZs: 4456, Bias: 0.000000, T: 4512, Avg. loss: 0.096698\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 25.64, NNZs: 3466, Bias: 0.000000, T: 6768, Avg. loss: 0.074361\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 28.68, NNZs: 2874, Bias: 0.000000, T: 9024, Avg. loss: 0.063844\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 31.22, NNZs: 2516, Bias: 0.000000, T: 11280, Avg. loss: 0.058510\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 33.48, NNZs: 2259, Bias: 0.000000, T: 13536, Avg. loss: 0.053367\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 15.06, NNZs: 6336, Bias: 0.000000, T: 2256, Avg. loss: 0.150947\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 19.91, NNZs: 4039, Bias: 0.000000, T: 4512, Avg. loss: 0.072088\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 23.56, NNZs: 3254, Bias: 0.000000, T: 6768, Avg. loss: 0.056746\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 26.43, NNZs: 2770, Bias: 0.000000, T: 9024, Avg. loss: 0.048553\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 28.83, NNZs: 2433, Bias: 0.000000, T: 11280, Avg. loss: 0.044210\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 31.03, NNZs: 2200, Bias: 0.000000, T: 13536, Avg. loss: 0.040456\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 10.34, NNZs: 3370, Bias: 0.000000, T: 2256, Avg. loss: 0.225240\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 13.76, NNZs: 2036, Bias: 0.000000, T: 4512, Avg. loss: 0.126893\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 15.99, NNZs: 1611, Bias: 0.000000, T: 6768, Avg. loss: 0.110011\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 17.90, NNZs: 1390, Bias: 0.000000, T: 9024, Avg. loss: 0.099833\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 19.62, NNZs: 1241, Bias: 0.000000, T: 11280, Avg. loss: 0.094678\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 21.12, NNZs: 1118, Bias: 0.000000, T: 13536, Avg. loss: 0.090482\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 114.05, NNZs: 12884, Bias: 0.000000, T: 2256, Avg. loss: 2.527538\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 3035.12, NNZs: 16147, Bias: 0.000000, T: 4512, Avg. loss: 307.927921\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 75664.61, NNZs: 17560, Bias: 0.000000, T: 6768, Avg. loss: 991839.768803\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1007818.52, NNZs: 17606, Bias: 0.000000, T: 9024, Avg. loss: 78262043.490907\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 26583663.69, NNZs: 17615, Bias: 0.000000, T: 11280, Avg. loss: 46835812417.721359\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2617926778.71, NNZs: 17615, Bias: 0.000000, T: 13536, Avg. loss: 606237024343244.875000\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 5/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.24457156361183285, clf__eta0=0.332929742792607, clf__fit_intercept=False, clf__l1_ratio=0.920539731041378, clf__learning_rate=constant, clf__loss=squared_error, clf__max_iter=100, clf__penalty=l1, clf__power_t=0.5734177157821045, clf__shuffle=True, clf__tol=0.6492274795888617, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.211 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 1.36, NNZs: 30800, Bias: -0.085960, T: 2256, Avg. loss: 0.188491\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.93, NNZs: 30800, Bias: -0.122620, T: 4512, Avg. loss: 0.159215\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.33, NNZs: 30800, Bias: -0.149788, T: 6768, Avg. loss: 0.141347\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.61, NNZs: 30800, Bias: -0.171032, T: 9024, Avg. loss: 0.129673\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.82, NNZs: 30800, Bias: -0.188376, T: 11280, Avg. loss: 0.121527\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.99, NNZs: 30800, Bias: -0.202956, T: 13536, Avg. loss: 0.115431\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.48, NNZs: 30800, Bias: -0.093452, T: 2256, Avg. loss: 0.181492\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2.11, NNZs: 30800, Bias: -0.133989, T: 4512, Avg. loss: 0.145892\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.56, NNZs: 30800, Bias: -0.164296, T: 6768, Avg. loss: 0.123624\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.88, NNZs: 30800, Bias: -0.187672, T: 9024, Avg. loss: 0.109037\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3.11, NNZs: 30800, Bias: -0.206083, T: 11280, Avg. loss: 0.099687\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.28, NNZs: 30800, Bias: -0.220958, T: 13536, Avg. loss: 0.093415\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.22, NNZs: 30800, Bias: 0.056632, T: 2256, Avg. loss: 0.198168\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.77, NNZs: 30800, Bias: 0.079037, T: 4512, Avg. loss: 0.175769\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.19, NNZs: 30800, Bias: 0.096562, T: 6768, Avg. loss: 0.161207\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.52, NNZs: 30800, Bias: 0.112031, T: 9024, Avg. loss: 0.149991\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.80, NNZs: 30800, Bias: 0.126383, T: 11280, Avg. loss: 0.141274\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.03, NNZs: 30800, Bias: 0.139854, T: 13536, Avg. loss: 0.134029\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2.16, NNZs: 30800, Bias: -0.117108, T: 2256, Avg. loss: 0.132075\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2.68, NNZs: 30800, Bias: -0.157167, T: 4512, Avg. loss: 0.077775\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.95, NNZs: 30800, Bias: -0.183269, T: 6768, Avg. loss: 0.060630\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3.13, NNZs: 30800, Bias: -0.202897, T: 9024, Avg. loss: 0.050711\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3.27, NNZs: 30800, Bias: -0.218676, T: 11280, Avg. loss: 0.043958\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.37, NNZs: 30800, Bias: -0.231844, T: 13536, Avg. loss: 0.039025\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 1/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.2527955528897454, clf__eta0=0.4377192284389271, clf__fit_intercept=True, clf__l1_ratio=0.6515110441465675, clf__learning_rate=invscaling, clf__loss=huber, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.47239053945705856, clf__shuffle=False, clf__tol=0.9089234089706554, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.336 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 1.35, NNZs: 31087, Bias: -0.083363, T: 2256, Avg. loss: 0.189241\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.91, NNZs: 31087, Bias: -0.119885, T: 4512, Avg. loss: 0.160416\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.30, NNZs: 31087, Bias: -0.146848, T: 6768, Avg. loss: 0.143008\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.57, NNZs: 31087, Bias: -0.168027, T: 9024, Avg. loss: 0.131623\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.78, NNZs: 31087, Bias: -0.185440, T: 11280, Avg. loss: 0.123558\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.95, NNZs: 31087, Bias: -0.200153, T: 13536, Avg. loss: 0.117435\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.45, NNZs: 31087, Bias: -0.090365, T: 2256, Avg. loss: 0.182745\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2.09, NNZs: 31087, Bias: -0.130888, T: 4512, Avg. loss: 0.146737\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.55, NNZs: 31087, Bias: -0.161301, T: 6768, Avg. loss: 0.124014\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.88, NNZs: 31087, Bias: -0.184756, T: 9024, Avg. loss: 0.109081\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3.11, NNZs: 31087, Bias: -0.203210, T: 11280, Avg. loss: 0.099538\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.28, NNZs: 31087, Bias: -0.218140, T: 13536, Avg. loss: 0.093144\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.21, NNZs: 31087, Bias: 0.050824, T: 2256, Avg. loss: 0.198695\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.75, NNZs: 31087, Bias: 0.073095, T: 4512, Avg. loss: 0.176977\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.17, NNZs: 31087, Bias: 0.090562, T: 6768, Avg. loss: 0.162772\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.50, NNZs: 31087, Bias: 0.105946, T: 9024, Avg. loss: 0.151765\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.77, NNZs: 31087, Bias: 0.120173, T: 11280, Avg. loss: 0.143078\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.01, NNZs: 31087, Bias: 0.133515, T: 13536, Avg. loss: 0.135805\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2.18, NNZs: 31087, Bias: -0.116685, T: 2256, Avg. loss: 0.131081\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2.69, NNZs: 31087, Bias: -0.156660, T: 4512, Avg. loss: 0.077832\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.96, NNZs: 31087, Bias: -0.182665, T: 6768, Avg. loss: 0.060967\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3.13, NNZs: 31087, Bias: -0.202166, T: 9024, Avg. loss: 0.051242\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3.26, NNZs: 31087, Bias: -0.217896, T: 11280, Avg. loss: 0.044555\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.37, NNZs: 31087, Bias: -0.231102, T: 13536, Avg. loss: 0.039573\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 2/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.2527955528897454, clf__eta0=0.4377192284389271, clf__fit_intercept=True, clf__l1_ratio=0.6515110441465675, clf__learning_rate=invscaling, clf__loss=huber, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.47239053945705856, clf__shuffle=False, clf__tol=0.9089234089706554, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.334 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 1.35, NNZs: 30611, Bias: -0.084910, T: 2256, Avg. loss: 0.188952\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.91, NNZs: 30611, Bias: -0.121533, T: 4512, Avg. loss: 0.160444\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.31, NNZs: 30611, Bias: -0.148994, T: 6768, Avg. loss: 0.142668\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.60, NNZs: 30611, Bias: -0.170504, T: 9024, Avg. loss: 0.130829\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.81, NNZs: 30611, Bias: -0.188064, T: 11280, Avg. loss: 0.122622\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.98, NNZs: 30611, Bias: -0.202825, T: 13536, Avg. loss: 0.116516\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.48, NNZs: 30611, Bias: -0.092581, T: 2256, Avg. loss: 0.181681\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2.11, NNZs: 30611, Bias: -0.133166, T: 4512, Avg. loss: 0.145951\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.57, NNZs: 30611, Bias: -0.163435, T: 6768, Avg. loss: 0.123695\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.88, NNZs: 30611, Bias: -0.186630, T: 9024, Avg. loss: 0.109323\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3.10, NNZs: 30611, Bias: -0.204839, T: 11280, Avg. loss: 0.100213\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.27, NNZs: 30611, Bias: -0.219586, T: 13536, Avg. loss: 0.094086\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.20, NNZs: 30611, Bias: 0.054573, T: 2256, Avg. loss: 0.198692\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.74, NNZs: 30611, Bias: 0.076952, T: 4512, Avg. loss: 0.176731\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.16, NNZs: 30611, Bias: 0.094455, T: 6768, Avg. loss: 0.162372\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.50, NNZs: 30611, Bias: 0.109855, T: 9024, Avg. loss: 0.151229\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.77, NNZs: 30611, Bias: 0.124104, T: 11280, Avg. loss: 0.142505\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.01, NNZs: 30611, Bias: 0.137485, T: 13536, Avg. loss: 0.135255\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2.18, NNZs: 30611, Bias: -0.116969, T: 2256, Avg. loss: 0.131242\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2.70, NNZs: 30611, Bias: -0.156983, T: 4512, Avg. loss: 0.077489\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.96, NNZs: 30611, Bias: -0.182926, T: 6768, Avg. loss: 0.060739\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3.14, NNZs: 30611, Bias: -0.202378, T: 9024, Avg. loss: 0.051137\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3.27, NNZs: 30611, Bias: -0.218054, T: 11280, Avg. loss: 0.044579\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.37, NNZs: 30611, Bias: -0.231222, T: 13536, Avg. loss: 0.039704\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 3/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.2527955528897454, clf__eta0=0.4377192284389271, clf__fit_intercept=True, clf__l1_ratio=0.6515110441465675, clf__learning_rate=invscaling, clf__loss=huber, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.47239053945705856, clf__shuffle=False, clf__tol=0.9089234089706554, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.316 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 1.31, NNZs: 30973, Bias: -0.083153, T: 2256, Avg. loss: 0.190043\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.88, NNZs: 30973, Bias: -0.119770, T: 4512, Avg. loss: 0.161195\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.28, NNZs: 30973, Bias: -0.147073, T: 6768, Avg. loss: 0.143317\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.56, NNZs: 30973, Bias: -0.168480, T: 9024, Avg. loss: 0.131508\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.78, NNZs: 30973, Bias: -0.185993, T: 11280, Avg. loss: 0.123290\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.95, NNZs: 30973, Bias: -0.200747, T: 13536, Avg. loss: 0.117142\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.44, NNZs: 30973, Bias: -0.092131, T: 2256, Avg. loss: 0.182755\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2.07, NNZs: 30973, Bias: -0.132738, T: 4512, Avg. loss: 0.147297\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.53, NNZs: 30973, Bias: -0.163145, T: 6768, Avg. loss: 0.124985\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.85, NNZs: 30973, Bias: -0.186577, T: 9024, Avg. loss: 0.110367\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3.07, NNZs: 30973, Bias: -0.205052, T: 11280, Avg. loss: 0.101034\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.24, NNZs: 30973, Bias: -0.220024, T: 13536, Avg. loss: 0.094747\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.18, NNZs: 30973, Bias: 0.052554, T: 2256, Avg. loss: 0.199378\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.72, NNZs: 30973, Bias: 0.074985, T: 4512, Avg. loss: 0.177777\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.13, NNZs: 30973, Bias: 0.092512, T: 6768, Avg. loss: 0.163644\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.46, NNZs: 30973, Bias: 0.107972, T: 9024, Avg. loss: 0.152700\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.73, NNZs: 30973, Bias: 0.122284, T: 11280, Avg. loss: 0.144145\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.97, NNZs: 30973, Bias: 0.135702, T: 13536, Avg. loss: 0.137012\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2.17, NNZs: 30973, Bias: -0.116848, T: 2256, Avg. loss: 0.131137\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2.67, NNZs: 30973, Bias: -0.156580, T: 4512, Avg. loss: 0.077752\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.93, NNZs: 30973, Bias: -0.182482, T: 6768, Avg. loss: 0.061075\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3.11, NNZs: 30973, Bias: -0.202020, T: 9024, Avg. loss: 0.051384\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3.24, NNZs: 30973, Bias: -0.217805, T: 11280, Avg. loss: 0.044692\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.35, NNZs: 30973, Bias: -0.231052, T: 13536, Avg. loss: 0.039718\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 4/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.2527955528897454, clf__eta0=0.4377192284389271, clf__fit_intercept=True, clf__l1_ratio=0.6515110441465675, clf__learning_rate=invscaling, clf__loss=huber, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.47239053945705856, clf__shuffle=False, clf__tol=0.9089234089706554, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.328 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 1.29, NNZs: 31025, Bias: -0.082268, T: 2256, Avg. loss: 0.190959\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.84, NNZs: 31025, Bias: -0.118837, T: 4512, Avg. loss: 0.163003\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.25, NNZs: 31025, Bias: -0.146468, T: 6768, Avg. loss: 0.145285\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.54, NNZs: 31025, Bias: -0.168281, T: 9024, Avg. loss: 0.133210\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.76, NNZs: 31025, Bias: -0.186161, T: 11280, Avg. loss: 0.124804\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.93, NNZs: 31025, Bias: -0.201230, T: 13536, Avg. loss: 0.118542\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.48, NNZs: 31025, Bias: -0.092746, T: 2256, Avg. loss: 0.181869\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2.11, NNZs: 31025, Bias: -0.133363, T: 4512, Avg. loss: 0.146287\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.55, NNZs: 31025, Bias: -0.163555, T: 6768, Avg. loss: 0.124353\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.87, NNZs: 31025, Bias: -0.186728, T: 9024, Avg. loss: 0.110242\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3.09, NNZs: 31025, Bias: -0.205007, T: 11280, Avg. loss: 0.101244\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.25, NNZs: 31025, Bias: -0.219885, T: 13536, Avg. loss: 0.095123\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.19, NNZs: 31025, Bias: 0.052226, T: 2256, Avg. loss: 0.199405\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.72, NNZs: 31025, Bias: 0.074658, T: 4512, Avg. loss: 0.178085\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.13, NNZs: 31025, Bias: 0.092172, T: 6768, Avg. loss: 0.164135\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.46, NNZs: 31025, Bias: 0.107513, T: 9024, Avg. loss: 0.153246\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.74, NNZs: 31025, Bias: 0.121680, T: 11280, Avg. loss: 0.144653\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.97, NNZs: 31025, Bias: 0.134975, T: 13536, Avg. loss: 0.137507\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2.16, NNZs: 31025, Bias: -0.117095, T: 2256, Avg. loss: 0.132202\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2.68, NNZs: 31025, Bias: -0.157464, T: 4512, Avg. loss: 0.078671\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.94, NNZs: 31025, Bias: -0.183732, T: 6768, Avg. loss: 0.061746\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3.12, NNZs: 31025, Bias: -0.203488, T: 9024, Avg. loss: 0.052047\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3.25, NNZs: 31025, Bias: -0.219437, T: 11280, Avg. loss: 0.045392\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.36, NNZs: 31025, Bias: -0.232841, T: 13536, Avg. loss: 0.040444\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 5/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.2527955528897454, clf__eta0=0.4377192284389271, clf__fit_intercept=True, clf__l1_ratio=0.6515110441465675, clf__learning_rate=invscaling, clf__loss=huber, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.47239053945705856, clf__shuffle=False, clf__tol=0.9089234089706554, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.329 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 91.11, NNZs: 30366, Bias: -0.940927, T: 2256, Avg. loss: 0.932137\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 44.13, NNZs: 30644, Bias: -1.002930, T: 4512, Avg. loss: 0.884721\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 35.93, NNZs: 30695, Bias: -1.005794, T: 6768, Avg. loss: 0.306489\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 30.27, NNZs: 30720, Bias: -0.976119, T: 9024, Avg. loss: 0.171558\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 27.59, NNZs: 30727, Bias: -0.962940, T: 11280, Avg. loss: 0.073078\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 26.22, NNZs: 30732, Bias: -1.007554, T: 13536, Avg. loss: 0.031189\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 25.17, NNZs: 30714, Bias: -1.031453, T: 15792, Avg. loss: 0.015143\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 7 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 87.80, NNZs: 30195, Bias: -1.025485, T: 2256, Avg. loss: 0.895799\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 42.10, NNZs: 30521, Bias: -0.995114, T: 4512, Avg. loss: 0.894620\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 33.39, NNZs: 30676, Bias: -0.872656, T: 6768, Avg. loss: 0.273514\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 27.58, NNZs: 30684, Bias: -0.898029, T: 9024, Avg. loss: 0.173922\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 24.13, NNZs: 30688, Bias: -0.975085, T: 11280, Avg. loss: 0.071075\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 22.45, NNZs: 30684, Bias: -0.937541, T: 13536, Avg. loss: 0.029850\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 21.40, NNZs: 30686, Bias: -0.962835, T: 15792, Avg. loss: 0.012707\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 20.96, NNZs: 30690, Bias: -0.956728, T: 18048, Avg. loss: 0.005374\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 8 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 90.38, NNZs: 30358, Bias: 0.906470, T: 2256, Avg. loss: 0.933795\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 42.76, NNZs: 30616, Bias: 0.797843, T: 4512, Avg. loss: 0.867646\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 33.76, NNZs: 30687, Bias: 1.041799, T: 6768, Avg. loss: 0.301892\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 26.84, NNZs: 30686, Bias: 1.024504, T: 9024, Avg. loss: 0.172807\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 23.62, NNZs: 30711, Bias: 1.047289, T: 11280, Avg. loss: 0.067894\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 21.36, NNZs: 30709, Bias: 1.022319, T: 13536, Avg. loss: 0.027142\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 87.92, NNZs: 30169, Bias: -1.154751, T: 2256, Avg. loss: 0.860802\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 39.28, NNZs: 30484, Bias: -0.904798, T: 4512, Avg. loss: 0.894142\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 27.84, NNZs: 30648, Bias: -0.975650, T: 6768, Avg. loss: 0.259077\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 18.87, NNZs: 30660, Bias: -0.963648, T: 9024, Avg. loss: 0.151665\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 13.13, NNZs: 30621, Bias: -0.906864, T: 11280, Avg. loss: 0.059295\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 10.14, NNZs: 30626, Bias: -0.925199, T: 13536, Avg. loss: 0.019641\n",
      "Total training time: 0.07 seconds.\n",
      "Convergence after 6 epochs took 0.07 seconds\n",
      "[CV 1/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.3241670976844645, clf__eta0=0.9631840511405841, clf__fit_intercept=True, clf__l1_ratio=0.5912641309775509, clf__learning_rate=optimal, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.6710686638981408, clf__shuffle=True, clf__tol=0.09654933943827881, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.692 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 91.60, NNZs: 30636, Bias: -0.894366, T: 2256, Avg. loss: 0.912972\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 43.59, NNZs: 30889, Bias: -0.860367, T: 4512, Avg. loss: 0.899958\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 36.36, NNZs: 30978, Bias: -1.038384, T: 6768, Avg. loss: 0.296444\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 30.10, NNZs: 30975, Bias: -1.049291, T: 9024, Avg. loss: 0.168854\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 28.02, NNZs: 30996, Bias: -1.091688, T: 11280, Avg. loss: 0.082097\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 26.71, NNZs: 31000, Bias: -1.038010, T: 13536, Avg. loss: 0.030782\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 89.22, NNZs: 30557, Bias: -0.860715, T: 2256, Avg. loss: 0.913532\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 42.01, NNZs: 30883, Bias: -0.865980, T: 4512, Avg. loss: 0.892369\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 34.59, NNZs: 30960, Bias: -0.975931, T: 6768, Avg. loss: 0.287068\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 27.04, NNZs: 30966, Bias: -0.980345, T: 9024, Avg. loss: 0.175821\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 24.23, NNZs: 30971, Bias: -0.946238, T: 11280, Avg. loss: 0.078784\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 22.73, NNZs: 30958, Bias: -0.929664, T: 13536, Avg. loss: 0.031637\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 90.81, NNZs: 30618, Bias: 0.915191, T: 2256, Avg. loss: 0.905020\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 40.35, NNZs: 30836, Bias: 0.762088, T: 4512, Avg. loss: 0.912267\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 33.41, NNZs: 30939, Bias: 1.092700, T: 6768, Avg. loss: 0.281317\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 26.41, NNZs: 30971, Bias: 1.020601, T: 9024, Avg. loss: 0.153981\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 23.14, NNZs: 30977, Bias: 1.031418, T: 11280, Avg. loss: 0.071820\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 20.93, NNZs: 30974, Bias: 1.062007, T: 13536, Avg. loss: 0.024362\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 87.80, NNZs: 30377, Bias: -0.753371, T: 2256, Avg. loss: 0.844105\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 39.17, NNZs: 30820, Bias: -0.780291, T: 4512, Avg. loss: 0.902602\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 28.19, NNZs: 30935, Bias: -0.783345, T: 6768, Avg. loss: 0.258615\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 19.12, NNZs: 30920, Bias: -0.900572, T: 9024, Avg. loss: 0.155853\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 13.68, NNZs: 30903, Bias: -0.917963, T: 11280, Avg. loss: 0.062890\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 10.24, NNZs: 30892, Bias: -0.895420, T: 13536, Avg. loss: 0.020810\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 9.01, NNZs: 30894, Bias: -0.883493, T: 15792, Avg. loss: 0.005031\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 8.25, NNZs: 30889, Bias: -0.906379, T: 18048, Avg. loss: 0.001425\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 7.64, NNZs: 30886, Bias: -0.906676, T: 20304, Avg. loss: 0.000321\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 9 epochs took 0.03 seconds\n",
      "[CV 2/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.3241670976844645, clf__eta0=0.9631840511405841, clf__fit_intercept=True, clf__l1_ratio=0.5912641309775509, clf__learning_rate=optimal, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.6710686638981408, clf__shuffle=True, clf__tol=0.09654933943827881, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.710 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 91.29, NNZs: 30165, Bias: -1.120401, T: 2256, Avg. loss: 0.951574\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 43.11, NNZs: 30415, Bias: -0.892877, T: 4512, Avg. loss: 0.901777\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 36.74, NNZs: 30497, Bias: -1.118388, T: 6768, Avg. loss: 0.297544\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 30.22, NNZs: 30493, Bias: -1.001591, T: 9024, Avg. loss: 0.180701\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 27.15, NNZs: 30527, Bias: -1.006957, T: 11280, Avg. loss: 0.072032\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 26.29, NNZs: 30537, Bias: -1.009005, T: 13536, Avg. loss: 0.035001\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 90.28, NNZs: 29903, Bias: -0.980833, T: 2256, Avg. loss: 0.884564\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 43.29, NNZs: 30329, Bias: -0.712661, T: 4512, Avg. loss: 0.896308\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 33.61, NNZs: 30391, Bias: -0.969955, T: 6768, Avg. loss: 0.272372\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 26.96, NNZs: 30390, Bias: -0.906278, T: 9024, Avg. loss: 0.167300\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 24.07, NNZs: 30365, Bias: -0.942845, T: 11280, Avg. loss: 0.069111\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 21.95, NNZs: 30363, Bias: -0.922319, T: 13536, Avg. loss: 0.030290\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 91.72, NNZs: 30111, Bias: 0.928355, T: 2256, Avg. loss: 0.873070\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 42.27, NNZs: 30388, Bias: 0.994214, T: 4512, Avg. loss: 0.908339\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 34.27, NNZs: 30489, Bias: 0.984277, T: 6768, Avg. loss: 0.294736\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 25.78, NNZs: 30508, Bias: 1.095128, T: 9024, Avg. loss: 0.169909\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 23.56, NNZs: 30529, Bias: 1.067314, T: 11280, Avg. loss: 0.068761\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 20.69, NNZs: 30538, Bias: 1.058556, T: 13536, Avg. loss: 0.026363\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 88.47, NNZs: 30072, Bias: -0.906946, T: 2256, Avg. loss: 0.845276\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 39.74, NNZs: 30410, Bias: -0.870549, T: 4512, Avg. loss: 0.910615\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 28.65, NNZs: 30472, Bias: -1.007004, T: 6768, Avg. loss: 0.256524\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 19.22, NNZs: 30478, Bias: -0.936068, T: 9024, Avg. loss: 0.162183\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 13.63, NNZs: 30446, Bias: -0.923039, T: 11280, Avg. loss: 0.062520\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 10.35, NNZs: 30427, Bias: -0.895738, T: 13536, Avg. loss: 0.022206\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 8.59, NNZs: 30419, Bias: -0.885915, T: 15792, Avg. loss: 0.006272\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 8.38, NNZs: 30416, Bias: -0.891951, T: 18048, Avg. loss: 0.001517\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 8 epochs took 0.03 seconds\n",
      "[CV 3/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.3241670976844645, clf__eta0=0.9631840511405841, clf__fit_intercept=True, clf__l1_ratio=0.5912641309775509, clf__learning_rate=optimal, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.6710686638981408, clf__shuffle=True, clf__tol=0.09654933943827881, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.677 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 90.51, NNZs: 30491, Bias: -0.944512, T: 2256, Avg. loss: 0.944466\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 43.94, NNZs: 30812, Bias: -1.157587, T: 4512, Avg. loss: 0.889852\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 36.77, NNZs: 30884, Bias: -1.044101, T: 6768, Avg. loss: 0.312900\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 30.95, NNZs: 30906, Bias: -0.957597, T: 9024, Avg. loss: 0.171194\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 27.89, NNZs: 30922, Bias: -1.067305, T: 11280, Avg. loss: 0.077673\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 26.35, NNZs: 30938, Bias: -1.056838, T: 13536, Avg. loss: 0.033980\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 25.39, NNZs: 30943, Bias: -1.061295, T: 15792, Avg. loss: 0.015140\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 7 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 89.75, NNZs: 30443, Bias: -1.017459, T: 2256, Avg. loss: 0.921418\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 42.66, NNZs: 30794, Bias: -0.856308, T: 4512, Avg. loss: 0.897436\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 33.52, NNZs: 30873, Bias: -0.946529, T: 6768, Avg. loss: 0.273066\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 27.46, NNZs: 30872, Bias: -0.990265, T: 9024, Avg. loss: 0.164658\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 23.99, NNZs: 30880, Bias: -0.950510, T: 11280, Avg. loss: 0.072300\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 22.40, NNZs: 30892, Bias: -0.929822, T: 13536, Avg. loss: 0.028202\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 90.13, NNZs: 30593, Bias: 1.022368, T: 2256, Avg. loss: 0.895276\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 41.95, NNZs: 30832, Bias: 1.027770, T: 4512, Avg. loss: 0.894827\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 34.16, NNZs: 30920, Bias: 1.065538, T: 6768, Avg. loss: 0.297875\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 26.57, NNZs: 30919, Bias: 0.982621, T: 9024, Avg. loss: 0.171749\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 23.71, NNZs: 30914, Bias: 1.018080, T: 11280, Avg. loss: 0.068646\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 21.34, NNZs: 30910, Bias: 1.031322, T: 13536, Avg. loss: 0.024319\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 88.36, NNZs: 30515, Bias: -0.880480, T: 2256, Avg. loss: 0.887267\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 39.47, NNZs: 30786, Bias: -0.731811, T: 4512, Avg. loss: 0.907907\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 28.10, NNZs: 30880, Bias: -0.928392, T: 6768, Avg. loss: 0.263896\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 18.81, NNZs: 30853, Bias: -0.909060, T: 9024, Avg. loss: 0.162389\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 13.27, NNZs: 30836, Bias: -0.910554, T: 11280, Avg. loss: 0.060640\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 9.93, NNZs: 30834, Bias: -0.895888, T: 13536, Avg. loss: 0.022834\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 4/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.3241670976844645, clf__eta0=0.9631840511405841, clf__fit_intercept=True, clf__l1_ratio=0.5912641309775509, clf__learning_rate=optimal, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.6710686638981408, clf__shuffle=True, clf__tol=0.09654933943827881, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.678 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 91.28, NNZs: 30678, Bias: -1.047255, T: 2256, Avg. loss: 0.931704\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 43.77, NNZs: 30913, Bias: -0.809277, T: 4512, Avg. loss: 0.888960\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 37.76, NNZs: 31016, Bias: -0.985466, T: 6768, Avg. loss: 0.320720\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 30.38, NNZs: 31029, Bias: -0.974305, T: 9024, Avg. loss: 0.177107\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 28.22, NNZs: 31029, Bias: -1.034819, T: 11280, Avg. loss: 0.081269\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 26.34, NNZs: 31026, Bias: -1.016184, T: 13536, Avg. loss: 0.032635\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 90.32, NNZs: 30663, Bias: -0.785589, T: 2256, Avg. loss: 0.940080\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 42.42, NNZs: 30902, Bias: -0.664392, T: 4512, Avg. loss: 0.909449\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 34.61, NNZs: 30990, Bias: -0.890390, T: 6768, Avg. loss: 0.277311\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 27.48, NNZs: 30980, Bias: -0.913145, T: 9024, Avg. loss: 0.172471\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 24.52, NNZs: 30974, Bias: -0.885307, T: 11280, Avg. loss: 0.067305\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 22.83, NNZs: 30969, Bias: -0.893340, T: 13536, Avg. loss: 0.032560\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 90.79, NNZs: 30646, Bias: 0.823164, T: 2256, Avg. loss: 0.898047\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 43.26, NNZs: 30939, Bias: 1.004436, T: 4512, Avg. loss: 0.903253\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 34.28, NNZs: 31011, Bias: 0.976008, T: 6768, Avg. loss: 0.306999\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 26.84, NNZs: 31021, Bias: 0.972417, T: 9024, Avg. loss: 0.169552\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 23.75, NNZs: 31028, Bias: 1.022009, T: 11280, Avg. loss: 0.071643\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 21.90, NNZs: 31030, Bias: 1.027048, T: 13536, Avg. loss: 0.026818\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 88.33, NNZs: 30589, Bias: -0.853824, T: 2256, Avg. loss: 0.868367\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 38.42, NNZs: 30935, Bias: -0.949327, T: 4512, Avg. loss: 0.917271\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 28.28, NNZs: 30991, Bias: -1.022808, T: 6768, Avg. loss: 0.247491\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 18.65, NNZs: 30996, Bias: -0.908712, T: 9024, Avg. loss: 0.155379\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 13.12, NNZs: 30956, Bias: -0.903037, T: 11280, Avg. loss: 0.062148\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 10.27, NNZs: 30947, Bias: -0.936154, T: 13536, Avg. loss: 0.021187\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 5/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.3241670976844645, clf__eta0=0.9631840511405841, clf__fit_intercept=True, clf__l1_ratio=0.5912641309775509, clf__learning_rate=optimal, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.6710686638981408, clf__shuffle=True, clf__tol=0.09654933943827881, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.693 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 42.59, NNZs: 5853, Bias: 0.000000, T: 2256, Avg. loss: 0.283312\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 54.12, NNZs: 3439, Bias: 0.000000, T: 4512, Avg. loss: 0.103273\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 62.52, NNZs: 2533, Bias: 0.000000, T: 6768, Avg. loss: 0.070923\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 69.27, NNZs: 1997, Bias: 0.000000, T: 9024, Avg. loss: 0.055759\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 75.14, NNZs: 1756, Bias: 0.000000, T: 11280, Avg. loss: 0.049447\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 80.39, NNZs: 1563, Bias: 0.000000, T: 13536, Avg. loss: 0.043985\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 37.68, NNZs: 5020, Bias: 0.000000, T: 2256, Avg. loss: 0.211942\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 49.10, NNZs: 3034, Bias: 0.000000, T: 4512, Avg. loss: 0.071293\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 57.24, NNZs: 2235, Bias: 0.000000, T: 6768, Avg. loss: 0.046250\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 63.72, NNZs: 1870, Bias: 0.000000, T: 9024, Avg. loss: 0.037680\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 69.23, NNZs: 1620, Bias: 0.000000, T: 11280, Avg. loss: 0.031119\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 74.46, NNZs: 1487, Bias: 0.000000, T: 13536, Avg. loss: 0.027950\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 26.26, NNZs: 3057, Bias: 0.000000, T: 2256, Avg. loss: 0.280556\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 33.99, NNZs: 1670, Bias: 0.000000, T: 4512, Avg. loss: 0.117348\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 39.41, NNZs: 1241, Bias: 0.000000, T: 6768, Avg. loss: 0.095542\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 43.89, NNZs: 1039, Bias: 0.000000, T: 9024, Avg. loss: 0.082980\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 47.85, NNZs: 909, Bias: 0.000000, T: 11280, Avg. loss: 0.076725\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 51.28, NNZs: 757, Bias: 0.000000, T: 13536, Avg. loss: 0.071010\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 140.28, NNZs: 10095, Bias: 0.000000, T: 2256, Avg. loss: 1.152290\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 156.25, NNZs: 6217, Bias: 0.000000, T: 4512, Avg. loss: 0.213414\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 155.76, NNZs: 4402, Bias: 0.000000, T: 6768, Avg. loss: 0.081598\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 155.73, NNZs: 3366, Bias: 0.000000, T: 9024, Avg. loss: 0.019490\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 166.07, NNZs: 2648, Bias: 0.000000, T: 11280, Avg. loss: 0.023409\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 165.28, NNZs: 2157, Bias: 0.000000, T: 13536, Avg. loss: 0.087328\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 1/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.3509613152086368, clf__eta0=0.9934401124631351, clf__fit_intercept=False, clf__l1_ratio=0.5204998682261415, clf__learning_rate=constant, clf__loss=hinge, clf__max_iter=40, clf__penalty=l1, clf__power_t=0.5098574122392232, clf__shuffle=False, clf__tol=0.5563103350645606, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.696 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 42.69, NNZs: 5818, Bias: 0.000000, T: 2256, Avg. loss: 0.278638\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 53.05, NNZs: 3247, Bias: 0.000000, T: 4512, Avg. loss: 0.096658\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 61.84, NNZs: 2412, Bias: 0.000000, T: 6768, Avg. loss: 0.068479\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 68.62, NNZs: 1984, Bias: 0.000000, T: 9024, Avg. loss: 0.054123\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 74.30, NNZs: 1681, Bias: 0.000000, T: 11280, Avg. loss: 0.047395\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 79.50, NNZs: 1483, Bias: 0.000000, T: 13536, Avg. loss: 0.041004\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 36.02, NNZs: 4780, Bias: 0.000000, T: 2256, Avg. loss: 0.203562\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 48.63, NNZs: 2962, Bias: 0.000000, T: 4512, Avg. loss: 0.070376\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 56.27, NNZs: 2203, Bias: 0.000000, T: 6768, Avg. loss: 0.046709\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 62.52, NNZs: 1824, Bias: 0.000000, T: 9024, Avg. loss: 0.038858\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 68.15, NNZs: 1590, Bias: 0.000000, T: 11280, Avg. loss: 0.032094\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 73.41, NNZs: 1418, Bias: 0.000000, T: 13536, Avg. loss: 0.029721\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 26.24, NNZs: 2837, Bias: 0.000000, T: 2256, Avg. loss: 0.282491\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 33.69, NNZs: 1539, Bias: 0.000000, T: 4512, Avg. loss: 0.111680\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 39.05, NNZs: 1146, Bias: 0.000000, T: 6768, Avg. loss: 0.089029\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 43.62, NNZs: 942, Bias: 0.000000, T: 9024, Avg. loss: 0.077248\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 47.46, NNZs: 826, Bias: 0.000000, T: 11280, Avg. loss: 0.070026\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 50.94, NNZs: 740, Bias: 0.000000, T: 13536, Avg. loss: 0.064404\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 149.47, NNZs: 9497, Bias: 0.000000, T: 2256, Avg. loss: 1.039755\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 165.83, NNZs: 6191, Bias: 0.000000, T: 4512, Avg. loss: 0.331073\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 165.14, NNZs: 4482, Bias: 0.000000, T: 6768, Avg. loss: 0.116002\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 164.97, NNZs: 3358, Bias: 0.000000, T: 9024, Avg. loss: 0.029335\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 164.95, NNZs: 2671, Bias: 0.000000, T: 11280, Avg. loss: 0.015147\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 165.01, NNZs: 2191, Bias: 0.000000, T: 13536, Avg. loss: 0.007933\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 2/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.3509613152086368, clf__eta0=0.9934401124631351, clf__fit_intercept=False, clf__l1_ratio=0.5204998682261415, clf__learning_rate=constant, clf__loss=hinge, clf__max_iter=40, clf__penalty=l1, clf__power_t=0.5098574122392232, clf__shuffle=False, clf__tol=0.5563103350645606, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.797 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 42.17, NNZs: 5975, Bias: 0.000000, T: 2256, Avg. loss: 0.281499\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 53.73, NNZs: 3543, Bias: 0.000000, T: 4512, Avg. loss: 0.100899\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 62.05, NNZs: 2607, Bias: 0.000000, T: 6768, Avg. loss: 0.068201\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 69.12, NNZs: 2105, Bias: 0.000000, T: 9024, Avg. loss: 0.055929\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 75.17, NNZs: 1797, Bias: 0.000000, T: 11280, Avg. loss: 0.045875\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 80.08, NNZs: 1573, Bias: 0.000000, T: 13536, Avg. loss: 0.040676\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 37.02, NNZs: 4933, Bias: 0.000000, T: 2256, Avg. loss: 0.207818\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 48.85, NNZs: 3055, Bias: 0.000000, T: 4512, Avg. loss: 0.075243\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 56.87, NNZs: 2373, Bias: 0.000000, T: 6768, Avg. loss: 0.047027\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 63.48, NNZs: 1897, Bias: 0.000000, T: 9024, Avg. loss: 0.036748\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 68.52, NNZs: 1622, Bias: 0.000000, T: 11280, Avg. loss: 0.032267\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 73.63, NNZs: 1457, Bias: 0.000000, T: 13536, Avg. loss: 0.029002\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 26.33, NNZs: 3018, Bias: 0.000000, T: 2256, Avg. loss: 0.293819\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 33.70, NNZs: 1678, Bias: 0.000000, T: 4512, Avg. loss: 0.118920\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 39.13, NNZs: 1246, Bias: 0.000000, T: 6768, Avg. loss: 0.094685\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 43.82, NNZs: 1002, Bias: 0.000000, T: 9024, Avg. loss: 0.083200\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 47.78, NNZs: 857, Bias: 0.000000, T: 11280, Avg. loss: 0.074227\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 51.36, NNZs: 779, Bias: 0.000000, T: 13536, Avg. loss: 0.069393\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 139.19, NNZs: 9527, Bias: 0.000000, T: 2256, Avg. loss: 0.948991\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 149.69, NNZs: 5356, Bias: 0.000000, T: 4512, Avg. loss: 0.071175\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 158.32, NNZs: 3899, Bias: 0.000000, T: 6768, Avg. loss: 0.126439\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 157.14, NNZs: 3154, Bias: 0.000000, T: 9024, Avg. loss: 0.155937\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 156.47, NNZs: 2424, Bias: 0.000000, T: 11280, Avg. loss: 0.063939\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 156.21, NNZs: 1970, Bias: 0.000000, T: 13536, Avg. loss: 0.033510\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 3/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.3509613152086368, clf__eta0=0.9934401124631351, clf__fit_intercept=False, clf__l1_ratio=0.5204998682261415, clf__learning_rate=constant, clf__loss=hinge, clf__max_iter=40, clf__penalty=l1, clf__power_t=0.5098574122392232, clf__shuffle=False, clf__tol=0.5563103350645606, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.703 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 42.17, NNZs: 5785, Bias: 0.000000, T: 2256, Avg. loss: 0.278455\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 53.80, NNZs: 3373, Bias: 0.000000, T: 4512, Avg. loss: 0.095209\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 62.36, NNZs: 2603, Bias: 0.000000, T: 6768, Avg. loss: 0.067467\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 68.67, NNZs: 2034, Bias: 0.000000, T: 9024, Avg. loss: 0.051397\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 74.98, NNZs: 1738, Bias: 0.000000, T: 11280, Avg. loss: 0.043874\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 80.20, NNZs: 1535, Bias: 0.000000, T: 13536, Avg. loss: 0.038222\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 37.19, NNZs: 4861, Bias: 0.000000, T: 2256, Avg. loss: 0.210892\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 48.72, NNZs: 3054, Bias: 0.000000, T: 4512, Avg. loss: 0.069859\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 56.88, NNZs: 2358, Bias: 0.000000, T: 6768, Avg. loss: 0.043986\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 63.70, NNZs: 1909, Bias: 0.000000, T: 9024, Avg. loss: 0.034580\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 69.05, NNZs: 1650, Bias: 0.000000, T: 11280, Avg. loss: 0.027948\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 74.07, NNZs: 1495, Bias: 0.000000, T: 13536, Avg. loss: 0.025021\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 26.11, NNZs: 3022, Bias: 0.000000, T: 2256, Avg. loss: 0.288489\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 33.62, NNZs: 1665, Bias: 0.000000, T: 4512, Avg. loss: 0.117535\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 39.00, NNZs: 1241, Bias: 0.000000, T: 6768, Avg. loss: 0.095394\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 43.49, NNZs: 1039, Bias: 0.000000, T: 9024, Avg. loss: 0.083869\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 47.43, NNZs: 894, Bias: 0.000000, T: 11280, Avg. loss: 0.076292\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 50.94, NNZs: 810, Bias: 0.000000, T: 13536, Avg. loss: 0.072010\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 130.62, NNZs: 8646, Bias: 0.000000, T: 2256, Avg. loss: 0.744852\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 147.94, NNZs: 5753, Bias: 0.000000, T: 4512, Avg. loss: 0.255438\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 147.03, NNZs: 4229, Bias: 0.000000, T: 6768, Avg. loss: 0.128196\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 146.87, NNZs: 3181, Bias: 0.000000, T: 9024, Avg. loss: 0.029921\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 157.91, NNZs: 2527, Bias: 0.000000, T: 11280, Avg. loss: 0.020461\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 157.12, NNZs: 2078, Bias: 0.000000, T: 13536, Avg. loss: 0.084197\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 4/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.3509613152086368, clf__eta0=0.9934401124631351, clf__fit_intercept=False, clf__l1_ratio=0.5204998682261415, clf__learning_rate=constant, clf__loss=hinge, clf__max_iter=40, clf__penalty=l1, clf__power_t=0.5098574122392232, clf__shuffle=False, clf__tol=0.5563103350645606, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.687 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 42.77, NNZs: 6020, Bias: 0.000000, T: 2256, Avg. loss: 0.276443\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 54.22, NNZs: 3551, Bias: 0.000000, T: 4512, Avg. loss: 0.095243\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 62.42, NNZs: 2480, Bias: 0.000000, T: 6768, Avg. loss: 0.067396\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 69.23, NNZs: 1996, Bias: 0.000000, T: 9024, Avg. loss: 0.054657\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 75.43, NNZs: 1735, Bias: 0.000000, T: 11280, Avg. loss: 0.046105\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 80.27, NNZs: 1511, Bias: 0.000000, T: 13536, Avg. loss: 0.040724\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 37.92, NNZs: 5249, Bias: 0.000000, T: 2256, Avg. loss: 0.212574\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 50.13, NNZs: 3176, Bias: 0.000000, T: 4512, Avg. loss: 0.075067\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 58.20, NNZs: 2348, Bias: 0.000000, T: 6768, Avg. loss: 0.046746\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 64.31, NNZs: 1927, Bias: 0.000000, T: 9024, Avg. loss: 0.035206\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 69.79, NNZs: 1658, Bias: 0.000000, T: 11280, Avg. loss: 0.030145\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 75.16, NNZs: 1490, Bias: 0.000000, T: 13536, Avg. loss: 0.027244\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 26.30, NNZs: 3043, Bias: 0.000000, T: 2256, Avg. loss: 0.299018\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 33.77, NNZs: 1634, Bias: 0.000000, T: 4512, Avg. loss: 0.119602\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 39.37, NNZs: 1220, Bias: 0.000000, T: 6768, Avg. loss: 0.094028\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 43.90, NNZs: 1012, Bias: 0.000000, T: 9024, Avg. loss: 0.082167\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 47.95, NNZs: 862, Bias: 0.000000, T: 11280, Avg. loss: 0.074196\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 51.54, NNZs: 787, Bias: 0.000000, T: 13536, Avg. loss: 0.067386\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 141.06, NNZs: 8412, Bias: 0.000000, T: 2256, Avg. loss: 0.778854\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 151.81, NNZs: 5412, Bias: 0.000000, T: 4512, Avg. loss: 0.255004\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 160.24, NNZs: 4235, Bias: 0.000000, T: 6768, Avg. loss: 0.227961\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 160.29, NNZs: 3183, Bias: 0.000000, T: 9024, Avg. loss: 0.021856\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 160.39, NNZs: 2574, Bias: 0.000000, T: 11280, Avg. loss: 0.006632\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 160.54, NNZs: 2119, Bias: 0.000000, T: 13536, Avg. loss: 0.002017\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 5/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.3509613152086368, clf__eta0=0.9934401124631351, clf__fit_intercept=False, clf__l1_ratio=0.5204998682261415, clf__learning_rate=constant, clf__loss=hinge, clf__max_iter=40, clf__penalty=l1, clf__power_t=0.5098574122392232, clf__shuffle=False, clf__tol=0.5563103350645606, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.715 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.24, NNZs: 17368, Bias: 0.000000, T: 2256, Avg. loss: 0.696902\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.33, NNZs: 17368, Bias: 0.000000, T: 4512, Avg. loss: 0.682943\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.39, NNZs: 17368, Bias: 0.000000, T: 6768, Avg. loss: 0.674402\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.45, NNZs: 17368, Bias: 0.000000, T: 9024, Avg. loss: 0.667842\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.50, NNZs: 17368, Bias: 0.000000, T: 11280, Avg. loss: 0.662130\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.54, NNZs: 17368, Bias: 0.000000, T: 13536, Avg. loss: 0.657111\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.29, NNZs: 17368, Bias: 0.000000, T: 2256, Avg. loss: 0.693953\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.39, NNZs: 17368, Bias: 0.000000, T: 4512, Avg. loss: 0.676737\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.47, NNZs: 17368, Bias: 0.000000, T: 6768, Avg. loss: 0.666061\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.54, NNZs: 17368, Bias: 0.000000, T: 9024, Avg. loss: 0.657486\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.60, NNZs: 17368, Bias: 0.000000, T: 11280, Avg. loss: 0.650474\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.65, NNZs: 17368, Bias: 0.000000, T: 13536, Avg. loss: 0.644037\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.26, NNZs: 17368, Bias: 0.000000, T: 2256, Avg. loss: 0.699227\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.35, NNZs: 17368, Bias: 0.000000, T: 4512, Avg. loss: 0.687664\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.43, NNZs: 17368, Bias: 0.000000, T: 6768, Avg. loss: 0.680652\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.48, NNZs: 17368, Bias: 0.000000, T: 9024, Avg. loss: 0.675171\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.54, NNZs: 17368, Bias: 0.000000, T: 11280, Avg. loss: 0.670485\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.58, NNZs: 17368, Bias: 0.000000, T: 13536, Avg. loss: 0.666338\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.43, NNZs: 17368, Bias: 0.000000, T: 2256, Avg. loss: 0.696766\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.55, NNZs: 17368, Bias: 0.000000, T: 4512, Avg. loss: 0.656850\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.65, NNZs: 17368, Bias: 0.000000, T: 6768, Avg. loss: 0.632064\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.74, NNZs: 17368, Bias: 0.000000, T: 9024, Avg. loss: 0.613318\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.82, NNZs: 17368, Bias: 0.000000, T: 11280, Avg. loss: 0.597598\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.89, NNZs: 17368, Bias: 0.000000, T: 13536, Avg. loss: 0.585566\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 1/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.28658617296069355, clf__eta0=0.03398405924608927, clf__fit_intercept=False, clf__l1_ratio=0.08227014493927165, clf__learning_rate=invscaling, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.5467473202425025, clf__shuffle=True, clf__tol=0.9099604695658384, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.512 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.23, NNZs: 17634, Bias: 0.000000, T: 2256, Avg. loss: 0.698535\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.32, NNZs: 17634, Bias: 0.000000, T: 4512, Avg. loss: 0.684374\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.38, NNZs: 17634, Bias: 0.000000, T: 6768, Avg. loss: 0.675883\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.44, NNZs: 17634, Bias: 0.000000, T: 9024, Avg. loss: 0.669136\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.49, NNZs: 17634, Bias: 0.000000, T: 11280, Avg. loss: 0.663430\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.53, NNZs: 17634, Bias: 0.000000, T: 13536, Avg. loss: 0.658392\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.30, NNZs: 17634, Bias: 0.000000, T: 2256, Avg. loss: 0.692791\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.41, NNZs: 17634, Bias: 0.000000, T: 4512, Avg. loss: 0.674524\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.49, NNZs: 17634, Bias: 0.000000, T: 6768, Avg. loss: 0.663246\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.56, NNZs: 17634, Bias: 0.000000, T: 9024, Avg. loss: 0.654821\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.62, NNZs: 17634, Bias: 0.000000, T: 11280, Avg. loss: 0.647241\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.67, NNZs: 17634, Bias: 0.000000, T: 13536, Avg. loss: 0.640727\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.22, NNZs: 17634, Bias: 0.000000, T: 2256, Avg. loss: 0.701947\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.31, NNZs: 17634, Bias: 0.000000, T: 4512, Avg. loss: 0.691765\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.38, NNZs: 17634, Bias: 0.000000, T: 6768, Avg. loss: 0.685456\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.44, NNZs: 17634, Bias: 0.000000, T: 9024, Avg. loss: 0.680564\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.49, NNZs: 17634, Bias: 0.000000, T: 11280, Avg. loss: 0.676476\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.53, NNZs: 17634, Bias: 0.000000, T: 13536, Avg. loss: 0.672679\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.40, NNZs: 17634, Bias: 0.000000, T: 2256, Avg. loss: 0.662996\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.54, NNZs: 17634, Bias: 0.000000, T: 4512, Avg. loss: 0.629444\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.65, NNZs: 17634, Bias: 0.000000, T: 6768, Avg. loss: 0.604497\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.73, NNZs: 17634, Bias: 0.000000, T: 9024, Avg. loss: 0.589181\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.81, NNZs: 17634, Bias: 0.000000, T: 11280, Avg. loss: 0.574643\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.88, NNZs: 17634, Bias: 0.000000, T: 13536, Avg. loss: 0.562203\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 2/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.28658617296069355, clf__eta0=0.03398405924608927, clf__fit_intercept=False, clf__l1_ratio=0.08227014493927165, clf__learning_rate=invscaling, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.5467473202425025, clf__shuffle=True, clf__tol=0.9099604695658384, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.545 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.24, NNZs: 17258, Bias: 0.000000, T: 2256, Avg. loss: 0.696150\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.33, NNZs: 17258, Bias: 0.000000, T: 4512, Avg. loss: 0.682409\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.39, NNZs: 17258, Bias: 0.000000, T: 6768, Avg. loss: 0.674168\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.45, NNZs: 17258, Bias: 0.000000, T: 9024, Avg. loss: 0.667697\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.49, NNZs: 17258, Bias: 0.000000, T: 11280, Avg. loss: 0.662217\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.54, NNZs: 17258, Bias: 0.000000, T: 13536, Avg. loss: 0.657263\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.29, NNZs: 17258, Bias: 0.000000, T: 2256, Avg. loss: 0.691479\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.40, NNZs: 17258, Bias: 0.000000, T: 4512, Avg. loss: 0.673038\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.48, NNZs: 17258, Bias: 0.000000, T: 6768, Avg. loss: 0.661983\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.55, NNZs: 17258, Bias: 0.000000, T: 9024, Avg. loss: 0.653681\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.60, NNZs: 17258, Bias: 0.000000, T: 11280, Avg. loss: 0.646484\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.66, NNZs: 17258, Bias: 0.000000, T: 13536, Avg. loss: 0.640088\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.27, NNZs: 17258, Bias: 0.000000, T: 2256, Avg. loss: 0.699836\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.36, NNZs: 17258, Bias: 0.000000, T: 4512, Avg. loss: 0.689014\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.43, NNZs: 17258, Bias: 0.000000, T: 6768, Avg. loss: 0.682456\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.49, NNZs: 17258, Bias: 0.000000, T: 9024, Avg. loss: 0.677410\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.54, NNZs: 17258, Bias: 0.000000, T: 11280, Avg. loss: 0.673192\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.59, NNZs: 17258, Bias: 0.000000, T: 13536, Avg. loss: 0.669272\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.39, NNZs: 17258, Bias: 0.000000, T: 2256, Avg. loss: 0.657534\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.52, NNZs: 17258, Bias: 0.000000, T: 4512, Avg. loss: 0.626969\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.62, NNZs: 17258, Bias: 0.000000, T: 6768, Avg. loss: 0.606141\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.71, NNZs: 17258, Bias: 0.000000, T: 9024, Avg. loss: 0.590215\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.78, NNZs: 17258, Bias: 0.000000, T: 11280, Avg. loss: 0.574014\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.84, NNZs: 17258, Bias: 0.000000, T: 13536, Avg. loss: 0.564469\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 3/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.28658617296069355, clf__eta0=0.03398405924608927, clf__fit_intercept=False, clf__l1_ratio=0.08227014493927165, clf__learning_rate=invscaling, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.5467473202425025, clf__shuffle=True, clf__tol=0.9099604695658384, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.507 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.25, NNZs: 17609, Bias: 0.000000, T: 2256, Avg. loss: 0.694856\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.34, NNZs: 17609, Bias: 0.000000, T: 4512, Avg. loss: 0.680283\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.41, NNZs: 17609, Bias: 0.000000, T: 6768, Avg. loss: 0.671518\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.46, NNZs: 17609, Bias: 0.000000, T: 9024, Avg. loss: 0.664700\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.51, NNZs: 17609, Bias: 0.000000, T: 11280, Avg. loss: 0.658885\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.55, NNZs: 17609, Bias: 0.000000, T: 13536, Avg. loss: 0.653785\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.29, NNZs: 17609, Bias: 0.000000, T: 2256, Avg. loss: 0.692717\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.39, NNZs: 17609, Bias: 0.000000, T: 4512, Avg. loss: 0.675424\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.47, NNZs: 17609, Bias: 0.000000, T: 6768, Avg. loss: 0.665034\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.54, NNZs: 17609, Bias: 0.000000, T: 9024, Avg. loss: 0.656858\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.60, NNZs: 17609, Bias: 0.000000, T: 11280, Avg. loss: 0.649835\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.65, NNZs: 17609, Bias: 0.000000, T: 13536, Avg. loss: 0.643642\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.23, NNZs: 17609, Bias: 0.000000, T: 2256, Avg. loss: 0.700601\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.33, NNZs: 17609, Bias: 0.000000, T: 4512, Avg. loss: 0.690673\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.40, NNZs: 17609, Bias: 0.000000, T: 6768, Avg. loss: 0.684256\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.45, NNZs: 17609, Bias: 0.000000, T: 9024, Avg. loss: 0.679308\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.50, NNZs: 17609, Bias: 0.000000, T: 11280, Avg. loss: 0.675137\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.55, NNZs: 17609, Bias: 0.000000, T: 13536, Avg. loss: 0.671374\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.43, NNZs: 17609, Bias: 0.000000, T: 2256, Avg. loss: 0.700293\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.54, NNZs: 17609, Bias: 0.000000, T: 4512, Avg. loss: 0.659657\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.64, NNZs: 17609, Bias: 0.000000, T: 6768, Avg. loss: 0.639563\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.72, NNZs: 17609, Bias: 0.000000, T: 9024, Avg. loss: 0.622740\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.80, NNZs: 17609, Bias: 0.000000, T: 11280, Avg. loss: 0.605128\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.87, NNZs: 17609, Bias: 0.000000, T: 13536, Avg. loss: 0.593247\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 4/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.28658617296069355, clf__eta0=0.03398405924608927, clf__fit_intercept=False, clf__l1_ratio=0.08227014493927165, clf__learning_rate=invscaling, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.5467473202425025, clf__shuffle=True, clf__tol=0.9099604695658384, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.493 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.25, NNZs: 17613, Bias: 0.000000, T: 2256, Avg. loss: 0.694904\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.34, NNZs: 17613, Bias: 0.000000, T: 4512, Avg. loss: 0.680907\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.41, NNZs: 17613, Bias: 0.000000, T: 6768, Avg. loss: 0.672291\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.46, NNZs: 17613, Bias: 0.000000, T: 9024, Avg. loss: 0.665430\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.51, NNZs: 17613, Bias: 0.000000, T: 11280, Avg. loss: 0.659767\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.55, NNZs: 17613, Bias: 0.000000, T: 13536, Avg. loss: 0.654730\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.29, NNZs: 17613, Bias: 0.000000, T: 2256, Avg. loss: 0.690088\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.40, NNZs: 17613, Bias: 0.000000, T: 4512, Avg. loss: 0.672588\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.48, NNZs: 17613, Bias: 0.000000, T: 6768, Avg. loss: 0.661790\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.54, NNZs: 17613, Bias: 0.000000, T: 9024, Avg. loss: 0.653442\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.60, NNZs: 17613, Bias: 0.000000, T: 11280, Avg. loss: 0.646112\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.65, NNZs: 17613, Bias: 0.000000, T: 13536, Avg. loss: 0.639784\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.25, NNZs: 17613, Bias: 0.000000, T: 2256, Avg. loss: 0.700335\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.35, NNZs: 17613, Bias: 0.000000, T: 4512, Avg. loss: 0.690375\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.41, NNZs: 17613, Bias: 0.000000, T: 6768, Avg. loss: 0.683964\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.47, NNZs: 17613, Bias: 0.000000, T: 9024, Avg. loss: 0.679144\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.52, NNZs: 17613, Bias: 0.000000, T: 11280, Avg. loss: 0.674961\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.57, NNZs: 17613, Bias: 0.000000, T: 13536, Avg. loss: 0.671321\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.43, NNZs: 17613, Bias: 0.000000, T: 2256, Avg. loss: 0.650222\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.57, NNZs: 17613, Bias: 0.000000, T: 4512, Avg. loss: 0.616384\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.67, NNZs: 17613, Bias: 0.000000, T: 6768, Avg. loss: 0.593311\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.76, NNZs: 17613, Bias: 0.000000, T: 9024, Avg. loss: 0.574557\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.84, NNZs: 17613, Bias: 0.000000, T: 11280, Avg. loss: 0.561788\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.91, NNZs: 17613, Bias: 0.000000, T: 13536, Avg. loss: 0.546028\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 5/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.28658617296069355, clf__eta0=0.03398405924608927, clf__fit_intercept=False, clf__l1_ratio=0.08227014493927165, clf__learning_rate=invscaling, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.5467473202425025, clf__shuffle=True, clf__tol=0.9099604695658384, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.570 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 22.93, NNZs: 17371, Bias: 0.000000, T: 2256, Avg. loss: 0.389702\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 30.86, NNZs: 17371, Bias: 0.000000, T: 4512, Avg. loss: 0.231918\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 35.48, NNZs: 17371, Bias: 0.000000, T: 6768, Avg. loss: 0.186136\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 38.45, NNZs: 17371, Bias: 0.000000, T: 9024, Avg. loss: 0.162964\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 40.43, NNZs: 17371, Bias: 0.000000, T: 11280, Avg. loss: 0.149426\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 41.80, NNZs: 17371, Bias: 0.000000, T: 13536, Avg. loss: 0.140905\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 41.97, NNZs: 17371, Bias: 0.000000, T: 15792, Avg. loss: 0.129861\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 42.13, NNZs: 17371, Bias: 0.000000, T: 18048, Avg. loss: 0.129135\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 42.27, NNZs: 17371, Bias: 0.000000, T: 20304, Avg. loss: 0.128341\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 42.41, NNZs: 17371, Bias: 0.000000, T: 22560, Avg. loss: 0.127663\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 42.54, NNZs: 17371, Bias: 0.000000, T: 24816, Avg. loss: 0.127056\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 42.56, NNZs: 17371, Bias: 0.000000, T: 27072, Avg. loss: 0.125266\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 42.58, NNZs: 17371, Bias: 0.000000, T: 29328, Avg. loss: 0.125231\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 42.60, NNZs: 17371, Bias: 0.000000, T: 31584, Avg. loss: 0.125156\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 42.63, NNZs: 17371, Bias: 0.000000, T: 33840, Avg. loss: 0.125063\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 42.65, NNZs: 17371, Bias: 0.000000, T: 36096, Avg. loss: 0.124964\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 42.65, NNZs: 17371, Bias: 0.000000, T: 38352, Avg. loss: 0.124692\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 42.66, NNZs: 17371, Bias: 0.000000, T: 40608, Avg. loss: 0.124663\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 42.66, NNZs: 17371, Bias: 0.000000, T: 42864, Avg. loss: 0.124636\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 42.66, NNZs: 17371, Bias: 0.000000, T: 45120, Avg. loss: 0.124609\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 22.66, NNZs: 17371, Bias: 0.000000, T: 2256, Avg. loss: 0.317450\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 29.65, NNZs: 17371, Bias: 0.000000, T: 4512, Avg. loss: 0.178539\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 33.95, NNZs: 17371, Bias: 0.000000, T: 6768, Avg. loss: 0.141133\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 36.73, NNZs: 17371, Bias: 0.000000, T: 9024, Avg. loss: 0.122061\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 38.58, NNZs: 17371, Bias: 0.000000, T: 11280, Avg. loss: 0.111002\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 39.83, NNZs: 17371, Bias: 0.000000, T: 13536, Avg. loss: 0.104156\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 39.97, NNZs: 17371, Bias: 0.000000, T: 15792, Avg. loss: 0.095751\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 40.10, NNZs: 17371, Bias: 0.000000, T: 18048, Avg. loss: 0.094835\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 40.21, NNZs: 17371, Bias: 0.000000, T: 20304, Avg. loss: 0.094269\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 40.32, NNZs: 17371, Bias: 0.000000, T: 22560, Avg. loss: 0.093779\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 40.42, NNZs: 17371, Bias: 0.000000, T: 24816, Avg. loss: 0.093343\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 40.44, NNZs: 17371, Bias: 0.000000, T: 27072, Avg. loss: 0.091976\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 40.45, NNZs: 17371, Bias: 0.000000, T: 29328, Avg. loss: 0.091953\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 40.47, NNZs: 17371, Bias: 0.000000, T: 31584, Avg. loss: 0.091903\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 40.48, NNZs: 17371, Bias: 0.000000, T: 33840, Avg. loss: 0.091841\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 40.50, NNZs: 17371, Bias: 0.000000, T: 36096, Avg. loss: 0.091775\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 40.50, NNZs: 17371, Bias: 0.000000, T: 38352, Avg. loss: 0.091442\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 40.51, NNZs: 17371, Bias: 0.000000, T: 40608, Avg. loss: 0.091439\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 40.51, NNZs: 17371, Bias: 0.000000, T: 42864, Avg. loss: 0.091435\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 40.51, NNZs: 17371, Bias: 0.000000, T: 45120, Avg. loss: 0.091429\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 15.37, NNZs: 17371, Bias: 0.000000, T: 2256, Avg. loss: 0.430311\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 20.68, NNZs: 17371, Bias: 0.000000, T: 4512, Avg. loss: 0.257881\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 23.61, NNZs: 17371, Bias: 0.000000, T: 6768, Avg. loss: 0.209864\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 25.43, NNZs: 17371, Bias: 0.000000, T: 9024, Avg. loss: 0.186565\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 26.64, NNZs: 17371, Bias: 0.000000, T: 11280, Avg. loss: 0.173091\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27.47, NNZs: 17371, Bias: 0.000000, T: 13536, Avg. loss: 0.164599\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 27.59, NNZs: 17371, Bias: 0.000000, T: 15792, Avg. loss: 0.157902\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 27.69, NNZs: 17371, Bias: 0.000000, T: 18048, Avg. loss: 0.156245\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 27.80, NNZs: 17371, Bias: 0.000000, T: 20304, Avg. loss: 0.155101\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 27.89, NNZs: 17371, Bias: 0.000000, T: 22560, Avg. loss: 0.154203\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 27.98, NNZs: 17371, Bias: 0.000000, T: 24816, Avg. loss: 0.153438\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 28.00, NNZs: 17371, Bias: 0.000000, T: 27072, Avg. loss: 0.152818\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 28.01, NNZs: 17371, Bias: 0.000000, T: 29328, Avg. loss: 0.152587\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 28.03, NNZs: 17371, Bias: 0.000000, T: 31584, Avg. loss: 0.152376\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 28.05, NNZs: 17371, Bias: 0.000000, T: 33840, Avg. loss: 0.152179\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 28.06, NNZs: 17371, Bias: 0.000000, T: 36096, Avg. loss: 0.151997\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 28.06, NNZs: 17371, Bias: 0.000000, T: 38352, Avg. loss: 0.151871\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 28.07, NNZs: 17371, Bias: 0.000000, T: 40608, Avg. loss: 0.151832\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 28.07, NNZs: 17371, Bias: 0.000000, T: 42864, Avg. loss: 0.151794\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 28.07, NNZs: 17371, Bias: 0.000000, T: 45120, Avg. loss: 0.151757\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 72.42, NNZs: 17371, Bias: 0.000000, T: 2256, Avg. loss: 0.502897\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 69.61, NNZs: 17371, Bias: 0.000000, T: 4512, Avg. loss: 0.120457\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 61.12, NNZs: 17371, Bias: 0.000000, T: 6768, Avg. loss: 0.063029\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 54.16, NNZs: 17371, Bias: 0.000000, T: 9024, Avg. loss: 0.030578\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 48.74, NNZs: 17371, Bias: 0.000000, T: 11280, Avg. loss: 0.027089\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 44.43, NNZs: 17371, Bias: 0.000000, T: 13536, Avg. loss: 0.027969\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 43.66, NNZs: 17371, Bias: 0.000000, T: 15792, Avg. loss: 0.028249\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 42.94, NNZs: 17371, Bias: 0.000000, T: 18048, Avg. loss: 0.027694\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 42.28, NNZs: 17371, Bias: 0.000000, T: 20304, Avg. loss: 0.027469\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 41.66, NNZs: 17371, Bias: 0.000000, T: 22560, Avg. loss: 0.027468\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 41.08, NNZs: 17371, Bias: 0.000000, T: 24816, Avg. loss: 0.027616\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 40.97, NNZs: 17371, Bias: 0.000000, T: 27072, Avg. loss: 0.027696\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 40.86, NNZs: 17371, Bias: 0.000000, T: 29328, Avg. loss: 0.027717\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 40.75, NNZs: 17371, Bias: 0.000000, T: 31584, Avg. loss: 0.027744\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 40.64, NNZs: 17371, Bias: 0.000000, T: 33840, Avg. loss: 0.027775\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 40.54, NNZs: 17371, Bias: 0.000000, T: 36096, Avg. loss: 0.027810\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 40.51, NNZs: 17371, Bias: 0.000000, T: 38352, Avg. loss: 0.027821\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 40.49, NNZs: 17371, Bias: 0.000000, T: 40608, Avg. loss: 0.027828\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 40.47, NNZs: 17371, Bias: 0.000000, T: 42864, Avg. loss: 0.027835\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 40.45, NNZs: 17371, Bias: 0.000000, T: 45120, Avg. loss: 0.027842\n",
      "Total training time: 0.06 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s finished\n",
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.42493015701647596, clf__eta0=0.6773009699604285, clf__fit_intercept=False, clf__l1_ratio=0.7301998277223162, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.017782879504616322, clf__shuffle=False, clf__tol=0.19519881462597577, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.672 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 23.13, NNZs: 17633, Bias: 0.000000, T: 2256, Avg. loss: 0.389135\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 31.03, NNZs: 17633, Bias: 0.000000, T: 4512, Avg. loss: 0.230841\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 35.64, NNZs: 17633, Bias: 0.000000, T: 6768, Avg. loss: 0.185340\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 38.59, NNZs: 17633, Bias: 0.000000, T: 9024, Avg. loss: 0.162299\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 40.56, NNZs: 17633, Bias: 0.000000, T: 11280, Avg. loss: 0.148870\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 41.91, NNZs: 17633, Bias: 0.000000, T: 13536, Avg. loss: 0.140452\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 42.06, NNZs: 17633, Bias: 0.000000, T: 15792, Avg. loss: 0.130176\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 42.21, NNZs: 17633, Bias: 0.000000, T: 18048, Avg. loss: 0.128971\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 42.35, NNZs: 17633, Bias: 0.000000, T: 20304, Avg. loss: 0.128108\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 42.47, NNZs: 17633, Bias: 0.000000, T: 22560, Avg. loss: 0.127428\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 42.59, NNZs: 17633, Bias: 0.000000, T: 24816, Avg. loss: 0.126838\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 42.61, NNZs: 17633, Bias: 0.000000, T: 27072, Avg. loss: 0.125491\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 42.63, NNZs: 17633, Bias: 0.000000, T: 29328, Avg. loss: 0.125243\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 42.65, NNZs: 17633, Bias: 0.000000, T: 31584, Avg. loss: 0.125064\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 42.67, NNZs: 17633, Bias: 0.000000, T: 33840, Avg. loss: 0.124921\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 42.69, NNZs: 17633, Bias: 0.000000, T: 36096, Avg. loss: 0.124798\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 42.70, NNZs: 17633, Bias: 0.000000, T: 38352, Avg. loss: 0.124592\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 42.70, NNZs: 17633, Bias: 0.000000, T: 40608, Avg. loss: 0.124553\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 42.70, NNZs: 17633, Bias: 0.000000, T: 42864, Avg. loss: 0.124516\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 42.71, NNZs: 17633, Bias: 0.000000, T: 45120, Avg. loss: 0.124482\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 22.83, NNZs: 17633, Bias: 0.000000, T: 2256, Avg. loss: 0.314034\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 29.60, NNZs: 17633, Bias: 0.000000, T: 4512, Avg. loss: 0.178645\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 33.79, NNZs: 17633, Bias: 0.000000, T: 6768, Avg. loss: 0.141360\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 36.53, NNZs: 17633, Bias: 0.000000, T: 9024, Avg. loss: 0.122232\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 38.38, NNZs: 17633, Bias: 0.000000, T: 11280, Avg. loss: 0.111114\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 39.63, NNZs: 17633, Bias: 0.000000, T: 13536, Avg. loss: 0.104213\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 39.76, NNZs: 17633, Bias: 0.000000, T: 15792, Avg. loss: 0.095514\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 39.88, NNZs: 17633, Bias: 0.000000, T: 18048, Avg. loss: 0.094781\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 40.00, NNZs: 17633, Bias: 0.000000, T: 20304, Avg. loss: 0.094313\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 40.11, NNZs: 17633, Bias: 0.000000, T: 22560, Avg. loss: 0.093864\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 40.21, NNZs: 17633, Bias: 0.000000, T: 24816, Avg. loss: 0.093439\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 40.23, NNZs: 17633, Bias: 0.000000, T: 27072, Avg. loss: 0.091624\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 40.25, NNZs: 17633, Bias: 0.000000, T: 29328, Avg. loss: 0.091756\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 40.26, NNZs: 17633, Bias: 0.000000, T: 31584, Avg. loss: 0.091794\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 40.28, NNZs: 17633, Bias: 0.000000, T: 33840, Avg. loss: 0.091784\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 40.30, NNZs: 17633, Bias: 0.000000, T: 36096, Avg. loss: 0.091750\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 40.30, NNZs: 17633, Bias: 0.000000, T: 38352, Avg. loss: 0.091303\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 40.30, NNZs: 17633, Bias: 0.000000, T: 40608, Avg. loss: 0.091316\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 40.31, NNZs: 17633, Bias: 0.000000, T: 42864, Avg. loss: 0.091326\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 40.31, NNZs: 17633, Bias: 0.000000, T: 45120, Avg. loss: 0.091334\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 15.51, NNZs: 17633, Bias: 0.000000, T: 2256, Avg. loss: 0.431919\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 20.80, NNZs: 17633, Bias: 0.000000, T: 4512, Avg. loss: 0.256326\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 23.72, NNZs: 17633, Bias: 0.000000, T: 6768, Avg. loss: 0.207902\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 25.53, NNZs: 17633, Bias: 0.000000, T: 9024, Avg. loss: 0.184526\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 26.73, NNZs: 17633, Bias: 0.000000, T: 11280, Avg. loss: 0.171035\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27.55, NNZs: 17633, Bias: 0.000000, T: 13536, Avg. loss: 0.162542\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 27.66, NNZs: 17633, Bias: 0.000000, T: 15792, Avg. loss: 0.156326\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 27.76, NNZs: 17633, Bias: 0.000000, T: 18048, Avg. loss: 0.154479\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 27.86, NNZs: 17633, Bias: 0.000000, T: 20304, Avg. loss: 0.153249\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 27.96, NNZs: 17633, Bias: 0.000000, T: 22560, Avg. loss: 0.152311\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 28.05, NNZs: 17633, Bias: 0.000000, T: 24816, Avg. loss: 0.151525\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 28.06, NNZs: 17633, Bias: 0.000000, T: 27072, Avg. loss: 0.150690\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 28.08, NNZs: 17633, Bias: 0.000000, T: 29328, Avg. loss: 0.150499\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 28.09, NNZs: 17633, Bias: 0.000000, T: 31584, Avg. loss: 0.150320\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 28.11, NNZs: 17633, Bias: 0.000000, T: 33840, Avg. loss: 0.150150\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 28.13, NNZs: 17633, Bias: 0.000000, T: 36096, Avg. loss: 0.149990\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 28.13, NNZs: 17633, Bias: 0.000000, T: 38352, Avg. loss: 0.149816\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 28.13, NNZs: 17633, Bias: 0.000000, T: 40608, Avg. loss: 0.149784\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 28.13, NNZs: 17633, Bias: 0.000000, T: 42864, Avg. loss: 0.149752\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 28.14, NNZs: 17633, Bias: 0.000000, T: 45120, Avg. loss: 0.149720\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 71.57, NNZs: 17633, Bias: 0.000000, T: 2256, Avg. loss: 0.563472\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 69.96, NNZs: 17633, Bias: 0.000000, T: 4512, Avg. loss: 0.079949\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 67.18, NNZs: 17633, Bias: 0.000000, T: 6768, Avg. loss: 0.059980\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 59.05, NNZs: 17633, Bias: 0.000000, T: 9024, Avg. loss: 0.075700\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 54.12, NNZs: 17633, Bias: 0.000000, T: 11280, Avg. loss: 0.044665\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 48.73, NNZs: 17633, Bias: 0.000000, T: 13536, Avg. loss: 0.026415\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 47.76, NNZs: 17633, Bias: 0.000000, T: 15792, Avg. loss: 0.026243\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 46.83, NNZs: 17633, Bias: 0.000000, T: 18048, Avg. loss: 0.025510\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 45.95, NNZs: 17633, Bias: 0.000000, T: 20304, Avg. loss: 0.025154\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 45.12, NNZs: 17633, Bias: 0.000000, T: 22560, Avg. loss: 0.025051\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 44.34, NNZs: 17633, Bias: 0.000000, T: 24816, Avg. loss: 0.025123\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 44.19, NNZs: 17633, Bias: 0.000000, T: 27072, Avg. loss: 0.025062\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 44.04, NNZs: 17633, Bias: 0.000000, T: 29328, Avg. loss: 0.025098\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 43.89, NNZs: 17633, Bias: 0.000000, T: 31584, Avg. loss: 0.025138\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 43.74, NNZs: 17633, Bias: 0.000000, T: 33840, Avg. loss: 0.025182\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 43.60, NNZs: 17633, Bias: 0.000000, T: 36096, Avg. loss: 0.025230\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 43.57, NNZs: 17633, Bias: 0.000000, T: 38352, Avg. loss: 0.025229\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 43.54, NNZs: 17633, Bias: 0.000000, T: 40608, Avg. loss: 0.025239\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 43.51, NNZs: 17633, Bias: 0.000000, T: 42864, Avg. loss: 0.025249\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 43.48, NNZs: 17633, Bias: 0.000000, T: 45120, Avg. loss: 0.025259\n",
      "Total training time: 0.06 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s finished\n",
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.42493015701647596, clf__eta0=0.6773009699604285, clf__fit_intercept=False, clf__l1_ratio=0.7301998277223162, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.017782879504616322, clf__shuffle=False, clf__tol=0.19519881462597577, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.781 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 22.98, NNZs: 17258, Bias: 0.000000, T: 2256, Avg. loss: 0.393243\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 30.96, NNZs: 17258, Bias: 0.000000, T: 4512, Avg. loss: 0.233740\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 35.61, NNZs: 17258, Bias: 0.000000, T: 6768, Avg. loss: 0.187551\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 38.59, NNZs: 17258, Bias: 0.000000, T: 9024, Avg. loss: 0.164225\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 40.59, NNZs: 17258, Bias: 0.000000, T: 11280, Avg. loss: 0.150604\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 41.96, NNZs: 17258, Bias: 0.000000, T: 13536, Avg. loss: 0.142029\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 42.13, NNZs: 17258, Bias: 0.000000, T: 15792, Avg. loss: 0.131042\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 42.29, NNZs: 17258, Bias: 0.000000, T: 18048, Avg. loss: 0.129989\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 42.43, NNZs: 17258, Bias: 0.000000, T: 20304, Avg. loss: 0.129175\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 42.57, NNZs: 17258, Bias: 0.000000, T: 22560, Avg. loss: 0.128500\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 42.69, NNZs: 17258, Bias: 0.000000, T: 24816, Avg. loss: 0.127899\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 42.72, NNZs: 17258, Bias: 0.000000, T: 27072, Avg. loss: 0.126490\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 42.74, NNZs: 17258, Bias: 0.000000, T: 29328, Avg. loss: 0.126224\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 42.76, NNZs: 17258, Bias: 0.000000, T: 31584, Avg. loss: 0.126036\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 42.78, NNZs: 17258, Bias: 0.000000, T: 33840, Avg. loss: 0.125887\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 42.80, NNZs: 17258, Bias: 0.000000, T: 36096, Avg. loss: 0.125760\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 42.81, NNZs: 17258, Bias: 0.000000, T: 38352, Avg. loss: 0.125507\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 42.81, NNZs: 17258, Bias: 0.000000, T: 40608, Avg. loss: 0.125472\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 42.82, NNZs: 17258, Bias: 0.000000, T: 42864, Avg. loss: 0.125439\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 42.82, NNZs: 17258, Bias: 0.000000, T: 45120, Avg. loss: 0.125407\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 22.99, NNZs: 17258, Bias: 0.000000, T: 2256, Avg. loss: 0.317025\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 29.95, NNZs: 17258, Bias: 0.000000, T: 4512, Avg. loss: 0.177554\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 34.15, NNZs: 17258, Bias: 0.000000, T: 6768, Avg. loss: 0.140192\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 36.86, NNZs: 17258, Bias: 0.000000, T: 9024, Avg. loss: 0.121444\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 38.66, NNZs: 17258, Bias: 0.000000, T: 11280, Avg. loss: 0.110661\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 39.88, NNZs: 17258, Bias: 0.000000, T: 13536, Avg. loss: 0.103995\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 40.00, NNZs: 17258, Bias: 0.000000, T: 15792, Avg. loss: 0.095117\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 40.13, NNZs: 17258, Bias: 0.000000, T: 18048, Avg. loss: 0.094700\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 40.24, NNZs: 17258, Bias: 0.000000, T: 20304, Avg. loss: 0.094226\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 40.35, NNZs: 17258, Bias: 0.000000, T: 22560, Avg. loss: 0.093771\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 40.45, NNZs: 17258, Bias: 0.000000, T: 24816, Avg. loss: 0.093347\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 40.47, NNZs: 17258, Bias: 0.000000, T: 27072, Avg. loss: 0.091551\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 40.49, NNZs: 17258, Bias: 0.000000, T: 29328, Avg. loss: 0.091680\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 40.50, NNZs: 17258, Bias: 0.000000, T: 31584, Avg. loss: 0.091715\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 40.52, NNZs: 17258, Bias: 0.000000, T: 33840, Avg. loss: 0.091703\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 40.54, NNZs: 17258, Bias: 0.000000, T: 36096, Avg. loss: 0.091667\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 40.54, NNZs: 17258, Bias: 0.000000, T: 38352, Avg. loss: 0.091320\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 40.54, NNZs: 17258, Bias: 0.000000, T: 40608, Avg. loss: 0.091321\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 40.54, NNZs: 17258, Bias: 0.000000, T: 42864, Avg. loss: 0.091320\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 40.55, NNZs: 17258, Bias: 0.000000, T: 45120, Avg. loss: 0.091319\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 15.43, NNZs: 17258, Bias: 0.000000, T: 2256, Avg. loss: 0.430645\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 20.76, NNZs: 17258, Bias: 0.000000, T: 4512, Avg. loss: 0.254176\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 23.70, NNZs: 17258, Bias: 0.000000, T: 6768, Avg. loss: 0.205447\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 25.52, NNZs: 17258, Bias: 0.000000, T: 9024, Avg. loss: 0.182157\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 26.71, NNZs: 17258, Bias: 0.000000, T: 11280, Avg. loss: 0.168848\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27.53, NNZs: 17258, Bias: 0.000000, T: 13536, Avg. loss: 0.160540\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 27.64, NNZs: 17258, Bias: 0.000000, T: 15792, Avg. loss: 0.154021\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 27.75, NNZs: 17258, Bias: 0.000000, T: 18048, Avg. loss: 0.152535\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 27.85, NNZs: 17258, Bias: 0.000000, T: 20304, Avg. loss: 0.151470\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 27.94, NNZs: 17258, Bias: 0.000000, T: 22560, Avg. loss: 0.150611\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 28.03, NNZs: 17258, Bias: 0.000000, T: 24816, Avg. loss: 0.149869\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 28.05, NNZs: 17258, Bias: 0.000000, T: 27072, Avg. loss: 0.148949\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 28.06, NNZs: 17258, Bias: 0.000000, T: 29328, Avg. loss: 0.148783\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 28.08, NNZs: 17258, Bias: 0.000000, T: 31584, Avg. loss: 0.148625\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 28.10, NNZs: 17258, Bias: 0.000000, T: 33840, Avg. loss: 0.148475\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 28.11, NNZs: 17258, Bias: 0.000000, T: 36096, Avg. loss: 0.148331\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 28.11, NNZs: 17258, Bias: 0.000000, T: 38352, Avg. loss: 0.148144\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 28.12, NNZs: 17258, Bias: 0.000000, T: 40608, Avg. loss: 0.148115\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 28.12, NNZs: 17258, Bias: 0.000000, T: 42864, Avg. loss: 0.148087\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 28.12, NNZs: 17258, Bias: 0.000000, T: 45120, Avg. loss: 0.148058\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 70.92, NNZs: 17258, Bias: 0.000000, T: 2256, Avg. loss: 0.562350\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 63.06, NNZs: 17258, Bias: 0.000000, T: 4512, Avg. loss: 0.069283\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 56.46, NNZs: 17258, Bias: 0.000000, T: 6768, Avg. loss: 0.033030\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 50.97, NNZs: 17258, Bias: 0.000000, T: 9024, Avg. loss: 0.028574\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 46.55, NNZs: 17258, Bias: 0.000000, T: 11280, Avg. loss: 0.028949\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 43.26, NNZs: 17258, Bias: 0.000000, T: 13536, Avg. loss: 0.029250\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 42.63, NNZs: 17258, Bias: 0.000000, T: 15792, Avg. loss: 0.029848\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 42.03, NNZs: 17258, Bias: 0.000000, T: 18048, Avg. loss: 0.029090\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 41.49, NNZs: 17258, Bias: 0.000000, T: 20304, Avg. loss: 0.028829\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 40.98, NNZs: 17258, Bias: 0.000000, T: 22560, Avg. loss: 0.028858\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 40.52, NNZs: 17258, Bias: 0.000000, T: 24816, Avg. loss: 0.029051\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 40.42, NNZs: 17258, Bias: 0.000000, T: 27072, Avg. loss: 0.028998\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 40.33, NNZs: 17258, Bias: 0.000000, T: 29328, Avg. loss: 0.029035\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 40.24, NNZs: 17258, Bias: 0.000000, T: 31584, Avg. loss: 0.029075\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 40.16, NNZs: 17258, Bias: 0.000000, T: 33840, Avg. loss: 0.029120\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 40.07, NNZs: 17258, Bias: 0.000000, T: 36096, Avg. loss: 0.029168\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 40.05, NNZs: 17258, Bias: 0.000000, T: 38352, Avg. loss: 0.029150\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 40.04, NNZs: 17258, Bias: 0.000000, T: 40608, Avg. loss: 0.029159\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 40.02, NNZs: 17258, Bias: 0.000000, T: 42864, Avg. loss: 0.029169\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 40.00, NNZs: 17258, Bias: 0.000000, T: 45120, Avg. loss: 0.029179\n",
      "Total training time: 0.06 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s finished\n",
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.42493015701647596, clf__eta0=0.6773009699604285, clf__fit_intercept=False, clf__l1_ratio=0.7301998277223162, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.017782879504616322, clf__shuffle=False, clf__tol=0.19519881462597577, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.670 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 23.08, NNZs: 17606, Bias: 0.000000, T: 2256, Avg. loss: 0.386647\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 31.07, NNZs: 17606, Bias: 0.000000, T: 4512, Avg. loss: 0.226591\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 35.68, NNZs: 17606, Bias: 0.000000, T: 6768, Avg. loss: 0.180835\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 38.62, NNZs: 17606, Bias: 0.000000, T: 9024, Avg. loss: 0.157916\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 40.58, NNZs: 17606, Bias: 0.000000, T: 11280, Avg. loss: 0.144633\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 41.92, NNZs: 17606, Bias: 0.000000, T: 13536, Avg. loss: 0.136335\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 42.08, NNZs: 17606, Bias: 0.000000, T: 15792, Avg. loss: 0.125903\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 42.23, NNZs: 17606, Bias: 0.000000, T: 18048, Avg. loss: 0.125172\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 42.37, NNZs: 17606, Bias: 0.000000, T: 20304, Avg. loss: 0.124404\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 42.50, NNZs: 17606, Bias: 0.000000, T: 22560, Avg. loss: 0.123747\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 42.62, NNZs: 17606, Bias: 0.000000, T: 24816, Avg. loss: 0.123160\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 42.64, NNZs: 17606, Bias: 0.000000, T: 27072, Avg. loss: 0.121711\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 42.67, NNZs: 17606, Bias: 0.000000, T: 29328, Avg. loss: 0.121538\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 42.69, NNZs: 17606, Bias: 0.000000, T: 31584, Avg. loss: 0.121394\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 42.71, NNZs: 17606, Bias: 0.000000, T: 33840, Avg. loss: 0.121268\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 42.73, NNZs: 17606, Bias: 0.000000, T: 36096, Avg. loss: 0.121153\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 42.73, NNZs: 17606, Bias: 0.000000, T: 38352, Avg. loss: 0.120915\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 42.74, NNZs: 17606, Bias: 0.000000, T: 40608, Avg. loss: 0.120883\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 42.74, NNZs: 17606, Bias: 0.000000, T: 42864, Avg. loss: 0.120852\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 42.74, NNZs: 17606, Bias: 0.000000, T: 45120, Avg. loss: 0.120823\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 22.79, NNZs: 17606, Bias: 0.000000, T: 2256, Avg. loss: 0.318879\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 29.91, NNZs: 17606, Bias: 0.000000, T: 4512, Avg. loss: 0.177163\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 34.21, NNZs: 17606, Bias: 0.000000, T: 6768, Avg. loss: 0.139225\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 36.97, NNZs: 17606, Bias: 0.000000, T: 9024, Avg. loss: 0.120167\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 38.80, NNZs: 17606, Bias: 0.000000, T: 11280, Avg. loss: 0.109204\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 40.04, NNZs: 17606, Bias: 0.000000, T: 13536, Avg. loss: 0.102447\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 40.18, NNZs: 17606, Bias: 0.000000, T: 15792, Avg. loss: 0.093841\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 40.31, NNZs: 17606, Bias: 0.000000, T: 18048, Avg. loss: 0.093192\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 40.43, NNZs: 17606, Bias: 0.000000, T: 20304, Avg. loss: 0.092649\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 40.54, NNZs: 17606, Bias: 0.000000, T: 22560, Avg. loss: 0.092170\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 40.64, NNZs: 17606, Bias: 0.000000, T: 24816, Avg. loss: 0.091740\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 40.66, NNZs: 17606, Bias: 0.000000, T: 27072, Avg. loss: 0.090320\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 40.68, NNZs: 17606, Bias: 0.000000, T: 29328, Avg. loss: 0.090293\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 40.69, NNZs: 17606, Bias: 0.000000, T: 31584, Avg. loss: 0.090246\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 40.71, NNZs: 17606, Bias: 0.000000, T: 33840, Avg. loss: 0.090192\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 40.73, NNZs: 17606, Bias: 0.000000, T: 36096, Avg. loss: 0.090133\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 40.73, NNZs: 17606, Bias: 0.000000, T: 38352, Avg. loss: 0.089866\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 40.73, NNZs: 17606, Bias: 0.000000, T: 40608, Avg. loss: 0.089855\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 40.74, NNZs: 17606, Bias: 0.000000, T: 42864, Avg. loss: 0.089845\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 40.74, NNZs: 17606, Bias: 0.000000, T: 45120, Avg. loss: 0.089834\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 15.45, NNZs: 17606, Bias: 0.000000, T: 2256, Avg. loss: 0.427663\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 20.76, NNZs: 17606, Bias: 0.000000, T: 4512, Avg. loss: 0.253492\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 23.68, NNZs: 17606, Bias: 0.000000, T: 6768, Avg. loss: 0.205607\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 25.48, NNZs: 17606, Bias: 0.000000, T: 9024, Avg. loss: 0.182595\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 26.67, NNZs: 17606, Bias: 0.000000, T: 11280, Avg. loss: 0.169396\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27.49, NNZs: 17606, Bias: 0.000000, T: 13536, Avg. loss: 0.161134\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 27.59, NNZs: 17606, Bias: 0.000000, T: 15792, Avg. loss: 0.155464\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 27.69, NNZs: 17606, Bias: 0.000000, T: 18048, Avg. loss: 0.153383\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 27.79, NNZs: 17606, Bias: 0.000000, T: 20304, Avg. loss: 0.152087\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 27.88, NNZs: 17606, Bias: 0.000000, T: 22560, Avg. loss: 0.151144\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 27.97, NNZs: 17606, Bias: 0.000000, T: 24816, Avg. loss: 0.150375\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 27.99, NNZs: 17606, Bias: 0.000000, T: 27072, Avg. loss: 0.149767\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 28.00, NNZs: 17606, Bias: 0.000000, T: 29328, Avg. loss: 0.149543\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 28.02, NNZs: 17606, Bias: 0.000000, T: 31584, Avg. loss: 0.149336\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 28.03, NNZs: 17606, Bias: 0.000000, T: 33840, Avg. loss: 0.149146\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 28.05, NNZs: 17606, Bias: 0.000000, T: 36096, Avg. loss: 0.148968\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 28.05, NNZs: 17606, Bias: 0.000000, T: 38352, Avg. loss: 0.148831\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 28.05, NNZs: 17606, Bias: 0.000000, T: 40608, Avg. loss: 0.148795\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 28.06, NNZs: 17606, Bias: 0.000000, T: 42864, Avg. loss: 0.148758\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 28.06, NNZs: 17606, Bias: 0.000000, T: 45120, Avg. loss: 0.148723\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 68.18, NNZs: 17606, Bias: 0.000000, T: 2256, Avg. loss: 0.456643\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 61.06, NNZs: 17606, Bias: 0.000000, T: 4512, Avg. loss: 0.132148\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 54.63, NNZs: 17606, Bias: 0.000000, T: 6768, Avg. loss: 0.043491\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 48.94, NNZs: 17606, Bias: 0.000000, T: 9024, Avg. loss: 0.032284\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 44.59, NNZs: 17606, Bias: 0.000000, T: 11280, Avg. loss: 0.026525\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 41.43, NNZs: 17606, Bias: 0.000000, T: 13536, Avg. loss: 0.027250\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 39.31, NNZs: 17606, Bias: 0.000000, T: 15792, Avg. loss: 0.028717\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 38.89, NNZs: 17606, Bias: 0.000000, T: 18048, Avg. loss: 0.030570\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 38.51, NNZs: 17606, Bias: 0.000000, T: 20304, Avg. loss: 0.029639\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 38.16, NNZs: 17606, Bias: 0.000000, T: 22560, Avg. loss: 0.029282\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 37.85, NNZs: 17606, Bias: 0.000000, T: 24816, Avg. loss: 0.029265\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 37.57, NNZs: 17606, Bias: 0.000000, T: 27072, Avg. loss: 0.029437\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 37.51, NNZs: 17606, Bias: 0.000000, T: 29328, Avg. loss: 0.029677\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 37.45, NNZs: 17606, Bias: 0.000000, T: 31584, Avg. loss: 0.029665\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 37.40, NNZs: 17606, Bias: 0.000000, T: 33840, Avg. loss: 0.029663\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 37.34, NNZs: 17606, Bias: 0.000000, T: 36096, Avg. loss: 0.029669\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 37.29, NNZs: 17606, Bias: 0.000000, T: 38352, Avg. loss: 0.029683\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 37.28, NNZs: 17606, Bias: 0.000000, T: 40608, Avg. loss: 0.029707\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 37.27, NNZs: 17606, Bias: 0.000000, T: 42864, Avg. loss: 0.029709\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 37.26, NNZs: 17606, Bias: 0.000000, T: 45120, Avg. loss: 0.029711\n",
      "Total training time: 0.06 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.3s finished\n",
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.42493015701647596, clf__eta0=0.6773009699604285, clf__fit_intercept=False, clf__l1_ratio=0.7301998277223162, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.017782879504616322, clf__shuffle=False, clf__tol=0.19519881462597577, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.666 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 23.20, NNZs: 17616, Bias: 0.000000, T: 2256, Avg. loss: 0.388791\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 31.25, NNZs: 17616, Bias: 0.000000, T: 4512, Avg. loss: 0.228879\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 35.90, NNZs: 17616, Bias: 0.000000, T: 6768, Avg. loss: 0.182530\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 38.87, NNZs: 17616, Bias: 0.000000, T: 9024, Avg. loss: 0.159280\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 40.84, NNZs: 17616, Bias: 0.000000, T: 11280, Avg. loss: 0.145817\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 42.19, NNZs: 17616, Bias: 0.000000, T: 13536, Avg. loss: 0.137424\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 42.35, NNZs: 17616, Bias: 0.000000, T: 15792, Avg. loss: 0.128586\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 42.49, NNZs: 17616, Bias: 0.000000, T: 18048, Avg. loss: 0.126074\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 42.62, NNZs: 17616, Bias: 0.000000, T: 20304, Avg. loss: 0.125219\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 42.75, NNZs: 17616, Bias: 0.000000, T: 22560, Avg. loss: 0.124571\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 42.86, NNZs: 17616, Bias: 0.000000, T: 24816, Avg. loss: 0.124007\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 42.88, NNZs: 17616, Bias: 0.000000, T: 27072, Avg. loss: 0.123110\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 42.90, NNZs: 17616, Bias: 0.000000, T: 29328, Avg. loss: 0.122623\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 42.92, NNZs: 17616, Bias: 0.000000, T: 31584, Avg. loss: 0.122334\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 42.94, NNZs: 17616, Bias: 0.000000, T: 33840, Avg. loss: 0.122141\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 42.96, NNZs: 17616, Bias: 0.000000, T: 36096, Avg. loss: 0.121996\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 42.97, NNZs: 17616, Bias: 0.000000, T: 38352, Avg. loss: 0.121804\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 42.97, NNZs: 17616, Bias: 0.000000, T: 40608, Avg. loss: 0.121761\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 42.97, NNZs: 17616, Bias: 0.000000, T: 42864, Avg. loss: 0.121721\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 42.98, NNZs: 17616, Bias: 0.000000, T: 45120, Avg. loss: 0.121684\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 22.56, NNZs: 17616, Bias: 0.000000, T: 2256, Avg. loss: 0.317746\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 29.70, NNZs: 17616, Bias: 0.000000, T: 4512, Avg. loss: 0.179036\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 34.03, NNZs: 17616, Bias: 0.000000, T: 6768, Avg. loss: 0.141003\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 36.82, NNZs: 17616, Bias: 0.000000, T: 9024, Avg. loss: 0.121835\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 38.66, NNZs: 17616, Bias: 0.000000, T: 11280, Avg. loss: 0.110830\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 39.90, NNZs: 17616, Bias: 0.000000, T: 13536, Avg. loss: 0.104060\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 40.06, NNZs: 17616, Bias: 0.000000, T: 15792, Avg. loss: 0.094980\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 40.20, NNZs: 17616, Bias: 0.000000, T: 18048, Avg. loss: 0.094899\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 40.32, NNZs: 17616, Bias: 0.000000, T: 20304, Avg. loss: 0.094274\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 40.43, NNZs: 17616, Bias: 0.000000, T: 22560, Avg. loss: 0.093730\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 40.53, NNZs: 17616, Bias: 0.000000, T: 24816, Avg. loss: 0.093258\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 40.55, NNZs: 17616, Bias: 0.000000, T: 27072, Avg. loss: 0.091499\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 40.57, NNZs: 17616, Bias: 0.000000, T: 29328, Avg. loss: 0.091608\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 40.58, NNZs: 17616, Bias: 0.000000, T: 31584, Avg. loss: 0.091629\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 40.60, NNZs: 17616, Bias: 0.000000, T: 33840, Avg. loss: 0.091606\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 40.61, NNZs: 17616, Bias: 0.000000, T: 36096, Avg. loss: 0.091560\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 40.62, NNZs: 17616, Bias: 0.000000, T: 38352, Avg. loss: 0.091226\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 40.62, NNZs: 17616, Bias: 0.000000, T: 40608, Avg. loss: 0.091224\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 40.62, NNZs: 17616, Bias: 0.000000, T: 42864, Avg. loss: 0.091221\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 40.63, NNZs: 17616, Bias: 0.000000, T: 45120, Avg. loss: 0.091216\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 15.40, NNZs: 17616, Bias: 0.000000, T: 2256, Avg. loss: 0.436726\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 20.71, NNZs: 17616, Bias: 0.000000, T: 4512, Avg. loss: 0.264413\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 23.67, NNZs: 17616, Bias: 0.000000, T: 6768, Avg. loss: 0.215166\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 25.52, NNZs: 17616, Bias: 0.000000, T: 9024, Avg. loss: 0.191292\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 26.75, NNZs: 17616, Bias: 0.000000, T: 11280, Avg. loss: 0.177492\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27.60, NNZs: 17616, Bias: 0.000000, T: 13536, Avg. loss: 0.168790\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 27.71, NNZs: 17616, Bias: 0.000000, T: 15792, Avg. loss: 0.163828\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 27.82, NNZs: 17616, Bias: 0.000000, T: 18048, Avg. loss: 0.161007\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 27.92, NNZs: 17616, Bias: 0.000000, T: 20304, Avg. loss: 0.159395\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 28.02, NNZs: 17616, Bias: 0.000000, T: 22560, Avg. loss: 0.158296\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 28.12, NNZs: 17616, Bias: 0.000000, T: 24816, Avg. loss: 0.157435\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 28.13, NNZs: 17616, Bias: 0.000000, T: 27072, Avg. loss: 0.156720\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 28.15, NNZs: 17616, Bias: 0.000000, T: 29328, Avg. loss: 0.156485\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 28.17, NNZs: 17616, Bias: 0.000000, T: 31584, Avg. loss: 0.156269\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 28.18, NNZs: 17616, Bias: 0.000000, T: 33840, Avg. loss: 0.156069\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 28.20, NNZs: 17616, Bias: 0.000000, T: 36096, Avg. loss: 0.155883\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 28.20, NNZs: 17616, Bias: 0.000000, T: 38352, Avg. loss: 0.155712\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 28.21, NNZs: 17616, Bias: 0.000000, T: 40608, Avg. loss: 0.155674\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 28.21, NNZs: 17616, Bias: 0.000000, T: 42864, Avg. loss: 0.155636\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 28.21, NNZs: 17616, Bias: 0.000000, T: 45120, Avg. loss: 0.155600\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 79.68, NNZs: 17616, Bias: 0.000000, T: 2256, Avg. loss: 0.625357\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 70.13, NNZs: 17616, Bias: 0.000000, T: 4512, Avg. loss: 0.096099\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 61.85, NNZs: 17616, Bias: 0.000000, T: 6768, Avg. loss: 0.036273\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 55.04, NNZs: 17616, Bias: 0.000000, T: 9024, Avg. loss: 0.026201\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 49.57, NNZs: 17616, Bias: 0.000000, T: 11280, Avg. loss: 0.026210\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 45.38, NNZs: 17616, Bias: 0.000000, T: 13536, Avg. loss: 0.027117\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 44.61, NNZs: 17616, Bias: 0.000000, T: 15792, Avg. loss: 0.027923\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 43.89, NNZs: 17616, Bias: 0.000000, T: 18048, Avg. loss: 0.027435\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 43.22, NNZs: 17616, Bias: 0.000000, T: 20304, Avg. loss: 0.027322\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 42.58, NNZs: 17616, Bias: 0.000000, T: 22560, Avg. loss: 0.027439\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 42.00, NNZs: 17616, Bias: 0.000000, T: 24816, Avg. loss: 0.027691\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 41.88, NNZs: 17616, Bias: 0.000000, T: 27072, Avg. loss: 0.027777\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 41.77, NNZs: 17616, Bias: 0.000000, T: 29328, Avg. loss: 0.027812\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 41.66, NNZs: 17616, Bias: 0.000000, T: 31584, Avg. loss: 0.027853\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 41.55, NNZs: 17616, Bias: 0.000000, T: 33840, Avg. loss: 0.027899\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 41.44, NNZs: 17616, Bias: 0.000000, T: 36096, Avg. loss: 0.027948\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 41.42, NNZs: 17616, Bias: 0.000000, T: 38352, Avg. loss: 0.027959\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 41.39, NNZs: 17616, Bias: 0.000000, T: 40608, Avg. loss: 0.027968\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 41.37, NNZs: 17616, Bias: 0.000000, T: 42864, Avg. loss: 0.027978\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 41.35, NNZs: 17616, Bias: 0.000000, T: 45120, Avg. loss: 0.027988\n",
      "Total training time: 0.06 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.3s finished\n",
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.42493015701647596, clf__eta0=0.6773009699604285, clf__fit_intercept=False, clf__l1_ratio=0.7301998277223162, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.017782879504616322, clf__shuffle=False, clf__tol=0.19519881462597577, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.677 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 51.50, NNZs: 12665, Bias: -1.419816, T: 2256, Avg. loss: 0.135982\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 34.54, NNZs: 13321, Bias: -1.342640, T: 4512, Avg. loss: 0.010940\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 26.21, NNZs: 13651, Bias: -1.261581, T: 6768, Avg. loss: 0.003786\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 21.37, NNZs: 13784, Bias: -1.203812, T: 9024, Avg. loss: 0.001831\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 18.17, NNZs: 13893, Bias: -1.156767, T: 11280, Avg. loss: 0.001053\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 15.69, NNZs: 13933, Bias: -1.138874, T: 13536, Avg. loss: 0.000457\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 52.62, NNZs: 11899, Bias: -1.102537, T: 2256, Avg. loss: 0.128351\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 33.89, NNZs: 12391, Bias: -1.166610, T: 4512, Avg. loss: 0.008658\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 25.63, NNZs: 12670, Bias: -1.143867, T: 6768, Avg. loss: 0.003126\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 20.32, NNZs: 12758, Bias: -1.146214, T: 9024, Avg. loss: 0.000882\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 17.22, NNZs: 12769, Bias: -1.111642, T: 11280, Avg. loss: 0.000477\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 14.99, NNZs: 12816, Bias: -1.089940, T: 13536, Avg. loss: 0.000136\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 20.67, NNZs: 9712, Bias: 0.663840, T: 2256, Avg. loss: 0.036594\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 13.97, NNZs: 10287, Bias: 0.615262, T: 4512, Avg. loss: 0.004570\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 10.84, NNZs: 10789, Bias: 0.592021, T: 6768, Avg. loss: 0.001559\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 9.02, NNZs: 10908, Bias: 0.551714, T: 9024, Avg. loss: 0.000605\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 7.60, NNZs: 10958, Bias: 0.535636, T: 11280, Avg. loss: 0.000275\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 6.66, NNZs: 11041, Bias: 0.521761, T: 13536, Avg. loss: 0.000205\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 358.97, NNZs: 14035, Bias: -6.299800, T: 2256, Avg. loss: 2.652040\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 247.22, NNZs: 14924, Bias: -7.127180, T: 4512, Avg. loss: 0.664709\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 170.77, NNZs: 15007, Bias: -8.072571, T: 6768, Avg. loss: 0.181536\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 145.69, NNZs: 15007, Bias: -7.611219, T: 9024, Avg. loss: 0.034994\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 116.83, NNZs: 15007, Bias: -7.792396, T: 11280, Avg. loss: 0.083652\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 97.60, NNZs: 15007, Bias: -7.874436, T: 13536, Avg. loss: 0.038002\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "[CV 1/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.21123614325601048, clf__eta0=0.32979731781585486, clf__fit_intercept=True, clf__l1_ratio=0.4775095579144826, clf__learning_rate=optimal, clf__loss=perceptron, clf__max_iter=30, clf__penalty=l2, clf__power_t=0.6427671735097384, clf__shuffle=False, clf__tol=0.2651165400908262, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.676 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 51.40, NNZs: 12569, Bias: -1.504677, T: 2256, Avg. loss: 0.116323\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 34.61, NNZs: 13434, Bias: -1.447882, T: 4512, Avg. loss: 0.012703\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 26.50, NNZs: 13801, Bias: -1.362275, T: 6768, Avg. loss: 0.004116\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 21.30, NNZs: 13922, Bias: -1.314905, T: 9024, Avg. loss: 0.000903\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 18.11, NNZs: 14018, Bias: -1.273146, T: 11280, Avg. loss: 0.000972\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 15.85, NNZs: 14124, Bias: -1.238865, T: 13536, Avg. loss: 0.000266\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 51.27, NNZs: 11863, Bias: -1.121378, T: 2256, Avg. loss: 0.118523\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 34.32, NNZs: 12604, Bias: -1.044542, T: 4512, Avg. loss: 0.017038\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 26.26, NNZs: 12850, Bias: -1.019961, T: 6768, Avg. loss: 0.003706\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 21.21, NNZs: 12961, Bias: -0.998962, T: 9024, Avg. loss: 0.001302\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 17.52, NNZs: 12974, Bias: -0.988823, T: 11280, Avg. loss: 0.000272\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 15.27, NNZs: 13002, Bias: -0.952181, T: 13536, Avg. loss: 0.000276\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 21.06, NNZs: 9652, Bias: 0.654137, T: 2256, Avg. loss: 0.029534\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 13.47, NNZs: 10396, Bias: 0.638563, T: 4512, Avg. loss: 0.002049\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 10.11, NNZs: 10480, Bias: 0.603665, T: 6768, Avg. loss: 0.000135\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 8.12, NNZs: 10596, Bias: 0.589858, T: 9024, Avg. loss: 0.000208\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 7.01, NNZs: 10707, Bias: 0.564076, T: 11280, Avg. loss: 0.000103\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 6.09, NNZs: 10756, Bias: 0.554653, T: 13536, Avg. loss: 0.000051\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 389.75, NNZs: 14716, Bias: -6.548364, T: 2256, Avg. loss: 3.409410\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 280.10, NNZs: 15570, Bias: -7.026850, T: 4512, Avg. loss: 0.855444\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 197.72, NNZs: 15573, Bias: -7.352366, T: 6768, Avg. loss: 0.031385\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 164.93, NNZs: 15573, Bias: -6.835218, T: 9024, Avg. loss: 0.015682\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 133.31, NNZs: 15573, Bias: -6.974375, T: 11280, Avg. loss: 0.066291\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 111.89, NNZs: 15573, Bias: -7.035027, T: 13536, Avg. loss: 0.034482\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "[CV 2/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.21123614325601048, clf__eta0=0.32979731781585486, clf__fit_intercept=True, clf__l1_ratio=0.4775095579144826, clf__learning_rate=optimal, clf__loss=perceptron, clf__max_iter=30, clf__penalty=l2, clf__power_t=0.6427671735097384, clf__shuffle=False, clf__tol=0.2651165400908262, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.784 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 52.51, NNZs: 12684, Bias: -1.425214, T: 2256, Avg. loss: 0.126746\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 35.85, NNZs: 13510, Bias: -1.454719, T: 4512, Avg. loss: 0.014588\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 26.80, NNZs: 13672, Bias: -1.371060, T: 6768, Avg. loss: 0.002345\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 21.45, NNZs: 13777, Bias: -1.344249, T: 9024, Avg. loss: 0.001026\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 18.45, NNZs: 13832, Bias: -1.255748, T: 11280, Avg. loss: 0.000371\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 15.97, NNZs: 13870, Bias: -1.239906, T: 13536, Avg. loss: 0.000368\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 51.92, NNZs: 11572, Bias: -1.187819, T: 2256, Avg. loss: 0.123255\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 35.28, NNZs: 12496, Bias: -1.216898, T: 4512, Avg. loss: 0.014733\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 26.51, NNZs: 12750, Bias: -1.226043, T: 6768, Avg. loss: 0.003598\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 21.19, NNZs: 12802, Bias: -1.185452, T: 9024, Avg. loss: 0.000252\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 17.44, NNZs: 12814, Bias: -1.177680, T: 11280, Avg. loss: 0.000059\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 14.95, NNZs: 12852, Bias: -1.162000, T: 13536, Avg. loss: 0.000229\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 20.30, NNZs: 9472, Bias: 0.641613, T: 2256, Avg. loss: 0.028106\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 13.39, NNZs: 10027, Bias: 0.602023, T: 4512, Avg. loss: 0.001696\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 9.99, NNZs: 10139, Bias: 0.572814, T: 6768, Avg. loss: 0.000344\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 8.07, NNZs: 10279, Bias: 0.547061, T: 9024, Avg. loss: 0.000158\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 6.68, NNZs: 10355, Bias: 0.541645, T: 11280, Avg. loss: 0.000027\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 5.89, NNZs: 10379, Bias: 0.523874, T: 13536, Avg. loss: 0.000134\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 373.04, NNZs: 14607, Bias: -7.808736, T: 2256, Avg. loss: 4.468312\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 234.98, NNZs: 14840, Bias: -8.674797, T: 4512, Avg. loss: 0.323628\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 194.41, NNZs: 14948, Bias: -8.060381, T: 6768, Avg. loss: 0.231370\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 161.32, NNZs: 14969, Bias: -7.785551, T: 9024, Avg. loss: 0.123989\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 127.93, NNZs: 14985, Bias: -8.254754, T: 11280, Avg. loss: 0.135941\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 106.89, NNZs: 14985, Bias: -8.366768, T: 13536, Avg. loss: 0.036898\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "[CV 3/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.21123614325601048, clf__eta0=0.32979731781585486, clf__fit_intercept=True, clf__l1_ratio=0.4775095579144826, clf__learning_rate=optimal, clf__loss=perceptron, clf__max_iter=30, clf__penalty=l2, clf__power_t=0.6427671735097384, clf__shuffle=False, clf__tol=0.2651165400908262, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.679 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 52.13, NNZs: 12658, Bias: -1.529651, T: 2256, Avg. loss: 0.121032\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 35.04, NNZs: 13425, Bias: -1.565275, T: 4512, Avg. loss: 0.010830\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 26.25, NNZs: 13747, Bias: -1.510277, T: 6768, Avg. loss: 0.003223\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 21.22, NNZs: 13895, Bias: -1.473403, T: 9024, Avg. loss: 0.001408\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 18.14, NNZs: 13946, Bias: -1.413172, T: 11280, Avg. loss: 0.000965\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 15.71, NNZs: 14007, Bias: -1.386263, T: 13536, Avg. loss: 0.000502\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 50.99, NNZs: 11911, Bias: -1.402093, T: 2256, Avg. loss: 0.120740\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 34.80, NNZs: 12612, Bias: -1.278764, T: 4512, Avg. loss: 0.012181\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 26.08, NNZs: 12811, Bias: -1.273443, T: 6768, Avg. loss: 0.001530\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 21.02, NNZs: 12945, Bias: -1.241100, T: 9024, Avg. loss: 0.001082\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 17.46, NNZs: 12949, Bias: -1.214344, T: 11280, Avg. loss: 0.000119\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 15.04, NNZs: 12950, Bias: -1.192000, T: 13536, Avg. loss: 0.000060\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 21.41, NNZs: 10220, Bias: 0.635694, T: 2256, Avg. loss: 0.033115\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 13.93, NNZs: 10738, Bias: 0.646880, T: 4512, Avg. loss: 0.004022\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 10.48, NNZs: 10974, Bias: 0.622003, T: 6768, Avg. loss: 0.001187\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 8.43, NNZs: 11068, Bias: 0.604462, T: 9024, Avg. loss: 0.000596\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 7.26, NNZs: 11283, Bias: 0.582446, T: 11280, Avg. loss: 0.000443\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 6.30, NNZs: 11334, Bias: 0.570207, T: 13536, Avg. loss: 0.000043\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 308.71, NNZs: 13329, Bias: -6.447851, T: 2256, Avg. loss: 2.778289\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 238.99, NNZs: 14624, Bias: -6.833263, T: 4512, Avg. loss: 0.926927\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 183.20, NNZs: 14757, Bias: -6.910924, T: 6768, Avg. loss: 0.168561\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 137.94, NNZs: 14852, Bias: -7.467537, T: 9024, Avg. loss: 0.158270\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 111.41, NNZs: 14852, Bias: -7.596905, T: 11280, Avg. loss: 0.037982\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 103.88, NNZs: 14852, Bias: -7.255007, T: 13536, Avg. loss: 0.020469\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "[CV 4/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.21123614325601048, clf__eta0=0.32979731781585486, clf__fit_intercept=True, clf__l1_ratio=0.4775095579144826, clf__learning_rate=optimal, clf__loss=perceptron, clf__max_iter=30, clf__penalty=l2, clf__power_t=0.6427671735097384, clf__shuffle=False, clf__tol=0.2651165400908262, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.681 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 50.95, NNZs: 12640, Bias: -1.389774, T: 2256, Avg. loss: 0.120578\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 34.40, NNZs: 13491, Bias: -1.320655, T: 4512, Avg. loss: 0.011061\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 26.05, NNZs: 13824, Bias: -1.286922, T: 6768, Avg. loss: 0.003103\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 21.44, NNZs: 14037, Bias: -1.242230, T: 9024, Avg. loss: 0.001748\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 17.93, NNZs: 14083, Bias: -1.223721, T: 11280, Avg. loss: 0.000635\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 15.60, NNZs: 14129, Bias: -1.190852, T: 13536, Avg. loss: 0.000147\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 52.69, NNZs: 11643, Bias: -1.297229, T: 2256, Avg. loss: 0.120712\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 35.40, NNZs: 12302, Bias: -1.291195, T: 4512, Avg. loss: 0.008528\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 26.73, NNZs: 12470, Bias: -1.234228, T: 6768, Avg. loss: 0.002862\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 21.11, NNZs: 12564, Bias: -1.223978, T: 9024, Avg. loss: 0.000462\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 17.65, NNZs: 12703, Bias: -1.215479, T: 11280, Avg. loss: 0.000474\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 15.45, NNZs: 12751, Bias: -1.185133, T: 13536, Avg. loss: 0.000354\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 21.80, NNZs: 9863, Bias: 0.571330, T: 2256, Avg. loss: 0.030927\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14.49, NNZs: 10708, Bias: 0.594616, T: 4512, Avg. loss: 0.002383\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 10.77, NNZs: 10986, Bias: 0.573756, T: 6768, Avg. loss: 0.000804\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 8.64, NNZs: 11150, Bias: 0.551776, T: 9024, Avg. loss: 0.000085\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 7.12, NNZs: 11182, Bias: 0.549166, T: 11280, Avg. loss: 0.000049\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 6.33, NNZs: 11296, Bias: 0.527282, T: 13536, Avg. loss: 0.000093\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 427.01, NNZs: 14873, Bias: -5.224929, T: 2256, Avg. loss: 3.255868\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 248.33, NNZs: 15226, Bias: -7.451718, T: 4512, Avg. loss: 0.177124\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 204.94, NNZs: 15511, Bias: -6.978022, T: 6768, Avg. loss: 0.297678\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 157.53, NNZs: 15520, Bias: -7.253539, T: 9024, Avg. loss: 0.033673\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 128.46, NNZs: 15520, Bias: -7.281152, T: 11280, Avg. loss: 0.001265\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 108.52, NNZs: 15520, Bias: -7.281152, T: 13536, Avg. loss: 0.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 93.94, NNZs: 15520, Bias: -7.281152, T: 15792, Avg. loss: 0.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 7 epochs took 0.02 seconds\n",
      "[CV 5/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.21123614325601048, clf__eta0=0.32979731781585486, clf__fit_intercept=True, clf__l1_ratio=0.4775095579144826, clf__learning_rate=optimal, clf__loss=perceptron, clf__max_iter=30, clf__penalty=l2, clf__power_t=0.6427671735097384, clf__shuffle=False, clf__tol=0.2651165400908262, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.670 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 47.26, NNZs: 5312, Bias: 0.000000, T: 2820, Avg. loss: 0.264204\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 60.05, NNZs: 2878, Bias: 0.000000, T: 5640, Avg. loss: 0.093833\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 69.38, NNZs: 2119, Bias: 0.000000, T: 8460, Avg. loss: 0.069963\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 76.90, NNZs: 1743, Bias: 0.000000, T: 11280, Avg. loss: 0.056426\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 83.92, NNZs: 1487, Bias: 0.000000, T: 14100, Avg. loss: 0.050235\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 89.97, NNZs: 1364, Bias: 0.000000, T: 16920, Avg. loss: 0.044144\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 41.19, NNZs: 4455, Bias: 0.000000, T: 2820, Avg. loss: 0.198470\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 54.78, NNZs: 2577, Bias: 0.000000, T: 5640, Avg. loss: 0.066356\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 63.61, NNZs: 1909, Bias: 0.000000, T: 8460, Avg. loss: 0.045921\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 71.04, NNZs: 1620, Bias: 0.000000, T: 11280, Avg. loss: 0.036026\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 77.12, NNZs: 1388, Bias: 0.000000, T: 14100, Avg. loss: 0.031999\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 82.60, NNZs: 1236, Bias: 0.000000, T: 16920, Avg. loss: 0.027834\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 29.13, NNZs: 2601, Bias: 0.000000, T: 2820, Avg. loss: 0.274583\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 37.65, NNZs: 1415, Bias: 0.000000, T: 5640, Avg. loss: 0.116766\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 43.86, NNZs: 1052, Bias: 0.000000, T: 8460, Avg. loss: 0.093371\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 48.98, NNZs: 836, Bias: 0.000000, T: 11280, Avg. loss: 0.081964\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 53.44, NNZs: 744, Bias: 0.000000, T: 14100, Avg. loss: 0.075308\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 57.47, NNZs: 638, Bias: 0.000000, T: 16920, Avg. loss: 0.071418\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 151.32, NNZs: 8990, Bias: 0.000000, T: 2820, Avg. loss: 0.727598\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 167.47, NNZs: 5797, Bias: 0.000000, T: 5640, Avg. loss: 0.274303\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 185.82, NNZs: 4382, Bias: 0.000000, T: 8460, Avg. loss: 0.083712\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 185.07, NNZs: 3492, Bias: 0.000000, T: 11280, Avg. loss: 0.124519\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 185.04, NNZs: 2735, Bias: 0.000000, T: 14100, Avg. loss: 0.020444\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 185.14, NNZs: 2163, Bias: 0.000000, T: 16920, Avg. loss: 0.005354\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "0.9680851063829787\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      precision    recall  f1-score   support\n",
      "\n",
      "      Geen gebruiker       0.85      0.98      0.91       128\n",
      "   Huidige gebruiker       0.97      0.94      0.96       140\n",
      "      Niets gevonden       1.00      0.98      0.99       669\n",
      "Voormalige gebruiker       0.00      0.00      0.00         3\n",
      "\n",
      "            accuracy                           0.97       940\n",
      "           macro avg       0.70      0.72      0.71       940\n",
      "        weighted avg       0.97      0.97      0.97       940\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ngram 2 Less stopwords\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1,2), lowercase=True, token_pattern=r\"(?u)\\b\\w\\w+\\b|\\+|\\-\")),\n",
    "    ('clf', SGDClassifier(early_stopping=True, n_iter_no_change=5, validation_fraction = 0.25, verbose=3)),\n",
    "])\n",
    "random_search = RandomizedSearchCV(estimator=pipeline, param_distributions=parameter_grid, random_state=500, verbose=3, scoring='f1_macro')\n",
    "random_search.fit(X_train, y_train)  \n",
    "predicted_nb = random_search.predict(X_test)\n",
    "print(np.mean(predicted_nb == y_test))\n",
    "cm = confusion_matrix(y_test, predicted_nb)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=random_search.classes_)\n",
    "disp.plot()\n",
    "\n",
    "plt.show()\n",
    "print(metrics.classification_report(y_test, predicted_nb,\n",
    "    target_names=random_search.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fbb9d4",
   "metadata": {},
   "source": [
    "## Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e7795780",
   "metadata": {},
   "outputs": [],
   "source": [
    "alcohol_corpus = alcohol_corpus_backup.copy()\n",
    "stemmer = SnowballStemmer(\"dutch\")\n",
    "alcohol_corpus['text'] = alcohol_corpus['text'].str.lower()\n",
    "alcohol_corpus['text'] = [stemmer.stem(text) for text in alcohol_corpus['text']]\n",
    "alcohol_corpus['label'] = alcohol_corpus['label'].str.replace('Niets gevonden','Geen gebruiker')\n",
    "alcohol_corpus['label'] = alcohol_corpus['label'].str.replace('Voormalige gebruiker','Geen gebruiker')\n",
    "alcohol_corpus = alcohol_corpus.drop(alcohol_corpus[alcohol_corpus.label == '--'].index)\n",
    "alcohol_corpus = alcohol_corpus.drop(alcohol_corpus[alcohol_corpus.label == 'Onbekend'].index)\n",
    "alcohol_corpus_backup = alcohol_corpus.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6cea48b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = alcohol_corpus.loc[indices['index']]\n",
    "train_set = alcohol_corpus.loc[~alcohol_corpus.index.isin(test_set.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cc2865ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = {'clf__loss':              ['hinge', 'log_loss', 'log', 'modified_huber', 'squared_hinge', 'perceptron', 'squared_error', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "                  'clf__penalty':           ['l2', 'l1'],\n",
    "                  'clf__l1_ratio':          sp_randFloat(),\n",
    "                  'clf__fit_intercept':     [True, False],\n",
    "                  'clf__max_iter':          [int(x) for x in np.linspace(start = 10, stop = 100, num = 10)],\n",
    "                  'clf__tol':               sp_randFloat(),\n",
    "                  'clf__shuffle':           [True, False],\n",
    "                  'clf__epsilon':           sp_randFloat(),\n",
    "                  'clf__learning_rate':     ['constant', 'optimal', 'invscaling', 'adaptive'],\n",
    "                  'clf__eta0':              sp_randFloat(),\n",
    "                  'clf__power_t':           sp_randFloat(),\n",
    "                  'clf__class_weight':      ['balanced', None],\n",
    "                  'clf__warm_start':        [True, False],\n",
    "                  'clf__average':           [True, False],\n",
    "                  'tfidf__max_df':          [0.90, 0.95],\n",
    "                  'tfidf__min_df':          [3, 5]\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "61603c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 23.32, NNZs: 4611, Bias: 0.000000, T: 2256, Avg. loss: 0.412179\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 33.50, NNZs: 2286, Bias: 0.000000, T: 4512, Avg. loss: 0.278322\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 41.23, NNZs: 1738, Bias: 0.000000, T: 6768, Avg. loss: 0.232306\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 47.48, NNZs: 1467, Bias: 0.000000, T: 9024, Avg. loss: 0.205351\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 52.82, NNZs: 1233, Bias: 0.000000, T: 11280, Avg. loss: 0.188080\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 57.54, NNZs: 1089, Bias: 0.000000, T: 13536, Avg. loss: 0.175286\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 58.37, NNZs: 1054, Bias: 0.000000, T: 15792, Avg. loss: 0.167702\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 59.18, NNZs: 1036, Bias: 0.000000, T: 18048, Avg. loss: 0.166075\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 59.98, NNZs: 995, Bias: 0.000000, T: 20304, Avg. loss: 0.164501\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 60.77, NNZs: 981, Bias: 0.000000, T: 22560, Avg. loss: 0.162921\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 61.54, NNZs: 955, Bias: 0.000000, T: 24816, Avg. loss: 0.161383\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 61.69, NNZs: 941, Bias: 0.000000, T: 27072, Avg. loss: 0.160152\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 61.85, NNZs: 941, Bias: 0.000000, T: 29328, Avg. loss: 0.159882\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 62.00, NNZs: 941, Bias: 0.000000, T: 31584, Avg. loss: 0.159593\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 62.15, NNZs: 938, Bias: 0.000000, T: 33840, Avg. loss: 0.159311\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 62.30, NNZs: 938, Bias: 0.000000, T: 36096, Avg. loss: 0.159043\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 62.33, NNZs: 935, Bias: 0.000000, T: 38352, Avg. loss: 0.158811\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 62.35, NNZs: 936, Bias: 0.000000, T: 40608, Avg. loss: 0.158757\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 62.38, NNZs: 935, Bias: 0.000000, T: 42864, Avg. loss: 0.158703\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 62.41, NNZs: 934, Bias: 0.000000, T: 45120, Avg. loss: 0.158646\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 24.01, NNZs: 4730, Bias: 0.000000, T: 2256, Avg. loss: 0.338899\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 32.87, NNZs: 2277, Bias: 0.000000, T: 4512, Avg. loss: 0.215749\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 39.53, NNZs: 1681, Bias: 0.000000, T: 6768, Avg. loss: 0.181926\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 44.91, NNZs: 1371, Bias: 0.000000, T: 9024, Avg. loss: 0.163642\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 49.60, NNZs: 1152, Bias: 0.000000, T: 11280, Avg. loss: 0.151129\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 53.68, NNZs: 980, Bias: 0.000000, T: 13536, Avg. loss: 0.142160\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 54.40, NNZs: 952, Bias: 0.000000, T: 15792, Avg. loss: 0.137265\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 55.11, NNZs: 943, Bias: 0.000000, T: 18048, Avg. loss: 0.135865\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 55.81, NNZs: 926, Bias: 0.000000, T: 20304, Avg. loss: 0.134548\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 56.50, NNZs: 902, Bias: 0.000000, T: 22560, Avg. loss: 0.133548\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 57.17, NNZs: 877, Bias: 0.000000, T: 24816, Avg. loss: 0.132416\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 57.31, NNZs: 874, Bias: 0.000000, T: 27072, Avg. loss: 0.131589\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 57.44, NNZs: 874, Bias: 0.000000, T: 29328, Avg. loss: 0.131390\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 57.57, NNZs: 855, Bias: 0.000000, T: 31584, Avg. loss: 0.131188\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 57.70, NNZs: 843, Bias: 0.000000, T: 33840, Avg. loss: 0.130997\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 57.83, NNZs: 842, Bias: 0.000000, T: 36096, Avg. loss: 0.130783\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 57.86, NNZs: 839, Bias: 0.000000, T: 38352, Avg. loss: 0.130626\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 57.89, NNZs: 839, Bias: 0.000000, T: 40608, Avg. loss: 0.130588\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 57.91, NNZs: 839, Bias: 0.000000, T: 42864, Avg. loss: 0.130549\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 57.94, NNZs: 839, Bias: 0.000000, T: 45120, Avg. loss: 0.130509\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 25.19, NNZs: 5462, Bias: 0.000000, T: 2256, Avg. loss: 0.346268\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 35.17, NNZs: 2720, Bias: 0.000000, T: 4512, Avg. loss: 0.203243\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 42.26, NNZs: 2131, Bias: 0.000000, T: 6768, Avg. loss: 0.166648\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 47.93, NNZs: 1767, Bias: 0.000000, T: 9024, Avg. loss: 0.148201\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 52.78, NNZs: 1574, Bias: 0.000000, T: 11280, Avg. loss: 0.136795\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 57.06, NNZs: 1380, Bias: 0.000000, T: 13536, Avg. loss: 0.128525\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 57.83, NNZs: 1322, Bias: 0.000000, T: 15792, Avg. loss: 0.123600\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 58.58, NNZs: 1276, Bias: 0.000000, T: 18048, Avg. loss: 0.122597\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 59.33, NNZs: 1219, Bias: 0.000000, T: 20304, Avg. loss: 0.121468\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 60.05, NNZs: 1168, Bias: 0.000000, T: 22560, Avg. loss: 0.120426\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 60.77, NNZs: 1141, Bias: 0.000000, T: 24816, Avg. loss: 0.119429\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 60.91, NNZs: 1133, Bias: 0.000000, T: 27072, Avg. loss: 0.118618\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 61.05, NNZs: 1131, Bias: 0.000000, T: 29328, Avg. loss: 0.118436\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 61.19, NNZs: 1129, Bias: 0.000000, T: 31584, Avg. loss: 0.118255\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 61.33, NNZs: 1122, Bias: 0.000000, T: 33840, Avg. loss: 0.118071\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 61.47, NNZs: 1114, Bias: 0.000000, T: 36096, Avg. loss: 0.117884\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 61.49, NNZs: 1114, Bias: 0.000000, T: 38352, Avg. loss: 0.117728\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 61.52, NNZs: 1114, Bias: 0.000000, T: 40608, Avg. loss: 0.117697\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 61.55, NNZs: 1114, Bias: 0.000000, T: 42864, Avg. loss: 0.117658\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 61.58, NNZs: 1113, Bias: 0.000000, T: 45120, Avg. loss: 0.117622\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 23.32, NNZs: 2999, Bias: 0.000000, T: 2256, Avg. loss: 0.173464\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 29.54, NNZs: 1260, Bias: 0.000000, T: 4512, Avg. loss: 0.084465\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 33.86, NNZs: 864, Bias: 0.000000, T: 6768, Avg. loss: 0.072610\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 37.11, NNZs: 665, Bias: 0.000000, T: 9024, Avg. loss: 0.066593\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 39.85, NNZs: 554, Bias: 0.000000, T: 11280, Avg. loss: 0.063649\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 42.25, NNZs: 473, Bias: 0.000000, T: 13536, Avg. loss: 0.061627\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 42.68, NNZs: 462, Bias: 0.000000, T: 15792, Avg. loss: 0.060259\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 43.10, NNZs: 451, Bias: 0.000000, T: 18048, Avg. loss: 0.059951\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 43.51, NNZs: 441, Bias: 0.000000, T: 20304, Avg. loss: 0.059719\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 43.91, NNZs: 432, Bias: 0.000000, T: 22560, Avg. loss: 0.059481\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 44.31, NNZs: 418, Bias: 0.000000, T: 24816, Avg. loss: 0.059321\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 44.39, NNZs: 417, Bias: 0.000000, T: 27072, Avg. loss: 0.059068\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 44.47, NNZs: 416, Bias: 0.000000, T: 29328, Avg. loss: 0.059029\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 44.55, NNZs: 414, Bias: 0.000000, T: 31584, Avg. loss: 0.058985\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 44.62, NNZs: 413, Bias: 0.000000, T: 33840, Avg. loss: 0.058941\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 44.70, NNZs: 412, Bias: 0.000000, T: 36096, Avg. loss: 0.058902\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 44.72, NNZs: 412, Bias: 0.000000, T: 38352, Avg. loss: 0.058866\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 44.73, NNZs: 412, Bias: 0.000000, T: 40608, Avg. loss: 0.058860\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 44.75, NNZs: 412, Bias: 0.000000, T: 42864, Avg. loss: 0.058852\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 44.76, NNZs: 412, Bias: 0.000000, T: 45120, Avg. loss: 0.058845\n",
      "Total training time: 0.16 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.7s finished\n",
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.06171699256249541, clf__eta0=0.6666115972798587, clf__fit_intercept=False, clf__l1_ratio=0.9792901432894962, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.15075392531110676, clf__shuffle=True, clf__tol=0.365636830734297, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.615 total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 23.15, NNZs: 4740, Bias: 0.000000, T: 2256, Avg. loss: 0.423806\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 33.60, NNZs: 2408, Bias: 0.000000, T: 4512, Avg. loss: 0.287544\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 41.21, NNZs: 1897, Bias: 0.000000, T: 6768, Avg. loss: 0.242064\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 47.50, NNZs: 1486, Bias: 0.000000, T: 9024, Avg. loss: 0.214269\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 52.93, NNZs: 1271, Bias: 0.000000, T: 11280, Avg. loss: 0.196377\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 57.78, NNZs: 1144, Bias: 0.000000, T: 13536, Avg. loss: 0.183831\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 58.64, NNZs: 1102, Bias: 0.000000, T: 15792, Avg. loss: 0.175097\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 59.48, NNZs: 1085, Bias: 0.000000, T: 18048, Avg. loss: 0.173344\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 60.30, NNZs: 1069, Bias: 0.000000, T: 20304, Avg. loss: 0.171564\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 61.11, NNZs: 1046, Bias: 0.000000, T: 22560, Avg. loss: 0.169938\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 61.90, NNZs: 1023, Bias: 0.000000, T: 24816, Avg. loss: 0.168336\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 62.05, NNZs: 1013, Bias: 0.000000, T: 27072, Avg. loss: 0.167008\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 62.21, NNZs: 1012, Bias: 0.000000, T: 29328, Avg. loss: 0.166728\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 62.36, NNZs: 1002, Bias: 0.000000, T: 31584, Avg. loss: 0.166422\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 62.51, NNZs: 995, Bias: 0.000000, T: 33840, Avg. loss: 0.166128\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 62.67, NNZs: 990, Bias: 0.000000, T: 36096, Avg. loss: 0.165847\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 62.70, NNZs: 988, Bias: 0.000000, T: 38352, Avg. loss: 0.165590\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 62.73, NNZs: 987, Bias: 0.000000, T: 40608, Avg. loss: 0.165532\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 62.76, NNZs: 986, Bias: 0.000000, T: 42864, Avg. loss: 0.165471\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 62.79, NNZs: 984, Bias: 0.000000, T: 45120, Avg. loss: 0.165417\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 23.67, NNZs: 4761, Bias: 0.000000, T: 2256, Avg. loss: 0.347764\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 33.13, NNZs: 2505, Bias: 0.000000, T: 4512, Avg. loss: 0.221861\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 39.85, NNZs: 1857, Bias: 0.000000, T: 6768, Avg. loss: 0.185133\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 45.41, NNZs: 1514, Bias: 0.000000, T: 9024, Avg. loss: 0.167184\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 50.17, NNZs: 1287, Bias: 0.000000, T: 11280, Avg. loss: 0.154003\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 54.30, NNZs: 1130, Bias: 0.000000, T: 13536, Avg. loss: 0.144717\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 55.06, NNZs: 1086, Bias: 0.000000, T: 15792, Avg. loss: 0.139967\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 55.80, NNZs: 1057, Bias: 0.000000, T: 18048, Avg. loss: 0.138750\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 56.52, NNZs: 1032, Bias: 0.000000, T: 20304, Avg. loss: 0.137511\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 57.22, NNZs: 1006, Bias: 0.000000, T: 22560, Avg. loss: 0.136330\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 57.92, NNZs: 993, Bias: 0.000000, T: 24816, Avg. loss: 0.135277\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 58.06, NNZs: 989, Bias: 0.000000, T: 27072, Avg. loss: 0.134461\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 58.19, NNZs: 989, Bias: 0.000000, T: 29328, Avg. loss: 0.134257\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 58.32, NNZs: 985, Bias: 0.000000, T: 31584, Avg. loss: 0.134026\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 58.46, NNZs: 985, Bias: 0.000000, T: 33840, Avg. loss: 0.133852\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 58.59, NNZs: 981, Bias: 0.000000, T: 36096, Avg. loss: 0.133653\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 58.62, NNZs: 981, Bias: 0.000000, T: 38352, Avg. loss: 0.133493\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 58.65, NNZs: 980, Bias: 0.000000, T: 40608, Avg. loss: 0.133453\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 58.67, NNZs: 979, Bias: 0.000000, T: 42864, Avg. loss: 0.133412\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 58.70, NNZs: 980, Bias: 0.000000, T: 45120, Avg. loss: 0.133377\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 25.29, NNZs: 5176, Bias: 0.000000, T: 2256, Avg. loss: 0.358881\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 35.43, NNZs: 2804, Bias: 0.000000, T: 4512, Avg. loss: 0.213381\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 42.70, NNZs: 2165, Bias: 0.000000, T: 6768, Avg. loss: 0.175377\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 48.54, NNZs: 1811, Bias: 0.000000, T: 9024, Avg. loss: 0.155162\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 53.53, NNZs: 1622, Bias: 0.000000, T: 11280, Avg. loss: 0.142383\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 57.95, NNZs: 1489, Bias: 0.000000, T: 13536, Avg. loss: 0.134123\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 58.75, NNZs: 1427, Bias: 0.000000, T: 15792, Avg. loss: 0.128497\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 59.53, NNZs: 1398, Bias: 0.000000, T: 18048, Avg. loss: 0.127297\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 60.29, NNZs: 1380, Bias: 0.000000, T: 20304, Avg. loss: 0.126117\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 61.05, NNZs: 1347, Bias: 0.000000, T: 22560, Avg. loss: 0.124925\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 61.79, NNZs: 1282, Bias: 0.000000, T: 24816, Avg. loss: 0.123984\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 61.93, NNZs: 1272, Bias: 0.000000, T: 27072, Avg. loss: 0.123093\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 62.08, NNZs: 1261, Bias: 0.000000, T: 29328, Avg. loss: 0.122901\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 62.22, NNZs: 1233, Bias: 0.000000, T: 31584, Avg. loss: 0.122696\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 62.36, NNZs: 1231, Bias: 0.000000, T: 33840, Avg. loss: 0.122484\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 62.51, NNZs: 1230, Bias: 0.000000, T: 36096, Avg. loss: 0.122279\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 62.54, NNZs: 1228, Bias: 0.000000, T: 38352, Avg. loss: 0.122116\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 62.56, NNZs: 1228, Bias: 0.000000, T: 40608, Avg. loss: 0.122079\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 62.59, NNZs: 1228, Bias: 0.000000, T: 42864, Avg. loss: 0.122040\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 62.62, NNZs: 1228, Bias: 0.000000, T: 45120, Avg. loss: 0.122000\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 23.18, NNZs: 3000, Bias: 0.000000, T: 2256, Avg. loss: 0.174950\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 29.78, NNZs: 1279, Bias: 0.000000, T: 4512, Avg. loss: 0.086022\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 34.05, NNZs: 911, Bias: 0.000000, T: 6768, Avg. loss: 0.072567\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 37.35, NNZs: 713, Bias: 0.000000, T: 9024, Avg. loss: 0.066973\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 40.17, NNZs: 587, Bias: 0.000000, T: 11280, Avg. loss: 0.063860\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 42.65, NNZs: 515, Bias: 0.000000, T: 13536, Avg. loss: 0.061741\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 43.09, NNZs: 480, Bias: 0.000000, T: 15792, Avg. loss: 0.060348\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 43.53, NNZs: 470, Bias: 0.000000, T: 18048, Avg. loss: 0.060030\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 43.95, NNZs: 460, Bias: 0.000000, T: 20304, Avg. loss: 0.059786\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 44.36, NNZs: 447, Bias: 0.000000, T: 22560, Avg. loss: 0.059536\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 44.77, NNZs: 438, Bias: 0.000000, T: 24816, Avg. loss: 0.059273\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 44.85, NNZs: 436, Bias: 0.000000, T: 27072, Avg. loss: 0.059108\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 44.93, NNZs: 434, Bias: 0.000000, T: 29328, Avg. loss: 0.059064\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 45.01, NNZs: 433, Bias: 0.000000, T: 31584, Avg. loss: 0.059022\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 45.09, NNZs: 432, Bias: 0.000000, T: 33840, Avg. loss: 0.058969\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 45.17, NNZs: 431, Bias: 0.000000, T: 36096, Avg. loss: 0.058927\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 45.18, NNZs: 430, Bias: 0.000000, T: 38352, Avg. loss: 0.058896\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 45.20, NNZs: 430, Bias: 0.000000, T: 40608, Avg. loss: 0.058887\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 45.21, NNZs: 430, Bias: 0.000000, T: 42864, Avg. loss: 0.058878\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 45.23, NNZs: 430, Bias: 0.000000, T: 45120, Avg. loss: 0.058869\n",
      "Total training time: 0.16 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.7s finished\n",
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.06171699256249541, clf__eta0=0.6666115972798587, clf__fit_intercept=False, clf__l1_ratio=0.9792901432894962, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.15075392531110676, clf__shuffle=True, clf__tol=0.365636830734297, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.658 total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 23.01, NNZs: 4745, Bias: 0.000000, T: 2256, Avg. loss: 0.427378\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 33.28, NNZs: 2434, Bias: 0.000000, T: 4512, Avg. loss: 0.294265\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 41.01, NNZs: 1968, Bias: 0.000000, T: 6768, Avg. loss: 0.248194\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 47.37, NNZs: 1606, Bias: 0.000000, T: 9024, Avg. loss: 0.222102\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 52.79, NNZs: 1348, Bias: 0.000000, T: 11280, Avg. loss: 0.203452\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 57.62, NNZs: 1225, Bias: 0.000000, T: 13536, Avg. loss: 0.190540\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 58.46, NNZs: 1112, Bias: 0.000000, T: 15792, Avg. loss: 0.182377\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 59.29, NNZs: 1099, Bias: 0.000000, T: 18048, Avg. loss: 0.180525\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 60.11, NNZs: 1081, Bias: 0.000000, T: 20304, Avg. loss: 0.178780\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 60.92, NNZs: 1053, Bias: 0.000000, T: 22560, Avg. loss: 0.177038\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 61.71, NNZs: 1031, Bias: 0.000000, T: 24816, Avg. loss: 0.175367\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 61.87, NNZs: 1030, Bias: 0.000000, T: 27072, Avg. loss: 0.174097\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 62.02, NNZs: 1025, Bias: 0.000000, T: 29328, Avg. loss: 0.173811\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 62.18, NNZs: 1024, Bias: 0.000000, T: 31584, Avg. loss: 0.173498\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 62.33, NNZs: 1015, Bias: 0.000000, T: 33840, Avg. loss: 0.173199\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 62.48, NNZs: 1012, Bias: 0.000000, T: 36096, Avg. loss: 0.172892\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 62.51, NNZs: 1010, Bias: 0.000000, T: 38352, Avg. loss: 0.172641\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 62.55, NNZs: 1010, Bias: 0.000000, T: 40608, Avg. loss: 0.172581\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 62.58, NNZs: 1009, Bias: 0.000000, T: 42864, Avg. loss: 0.172520\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 62.61, NNZs: 1009, Bias: 0.000000, T: 45120, Avg. loss: 0.172463\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 23.78, NNZs: 4808, Bias: 0.000000, T: 2256, Avg. loss: 0.348025\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 32.79, NNZs: 2543, Bias: 0.000000, T: 4512, Avg. loss: 0.225352\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 39.50, NNZs: 1920, Bias: 0.000000, T: 6768, Avg. loss: 0.192641\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 44.94, NNZs: 1523, Bias: 0.000000, T: 9024, Avg. loss: 0.174124\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 49.70, NNZs: 1326, Bias: 0.000000, T: 11280, Avg. loss: 0.162126\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 53.82, NNZs: 1143, Bias: 0.000000, T: 13536, Avg. loss: 0.153250\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 54.57, NNZs: 1050, Bias: 0.000000, T: 15792, Avg. loss: 0.147750\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 55.29, NNZs: 1031, Bias: 0.000000, T: 18048, Avg. loss: 0.146614\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 56.00, NNZs: 1021, Bias: 0.000000, T: 20304, Avg. loss: 0.145386\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 56.70, NNZs: 1006, Bias: 0.000000, T: 22560, Avg. loss: 0.144240\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 57.38, NNZs: 994, Bias: 0.000000, T: 24816, Avg. loss: 0.143185\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 57.52, NNZs: 986, Bias: 0.000000, T: 27072, Avg. loss: 0.142324\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 57.65, NNZs: 981, Bias: 0.000000, T: 29328, Avg. loss: 0.142119\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 57.79, NNZs: 977, Bias: 0.000000, T: 31584, Avg. loss: 0.141930\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 57.92, NNZs: 975, Bias: 0.000000, T: 33840, Avg. loss: 0.141738\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 58.05, NNZs: 974, Bias: 0.000000, T: 36096, Avg. loss: 0.141525\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 58.08, NNZs: 974, Bias: 0.000000, T: 38352, Avg. loss: 0.141372\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 58.11, NNZs: 973, Bias: 0.000000, T: 40608, Avg. loss: 0.141334\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 58.13, NNZs: 972, Bias: 0.000000, T: 42864, Avg. loss: 0.141295\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 58.16, NNZs: 972, Bias: 0.000000, T: 45120, Avg. loss: 0.141258\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 25.15, NNZs: 5634, Bias: 0.000000, T: 2256, Avg. loss: 0.363615\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 35.24, NNZs: 2862, Bias: 0.000000, T: 4512, Avg. loss: 0.217499\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 42.51, NNZs: 2243, Bias: 0.000000, T: 6768, Avg. loss: 0.181086\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 48.31, NNZs: 1937, Bias: 0.000000, T: 9024, Avg. loss: 0.161102\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 53.30, NNZs: 1666, Bias: 0.000000, T: 11280, Avg. loss: 0.149254\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 57.68, NNZs: 1513, Bias: 0.000000, T: 13536, Avg. loss: 0.140689\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 58.46, NNZs: 1466, Bias: 0.000000, T: 15792, Avg. loss: 0.135631\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 59.24, NNZs: 1430, Bias: 0.000000, T: 18048, Avg. loss: 0.134466\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 60.00, NNZs: 1399, Bias: 0.000000, T: 20304, Avg. loss: 0.133358\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 60.75, NNZs: 1350, Bias: 0.000000, T: 22560, Avg. loss: 0.132268\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 61.48, NNZs: 1253, Bias: 0.000000, T: 24816, Avg. loss: 0.131204\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 61.62, NNZs: 1250, Bias: 0.000000, T: 27072, Avg. loss: 0.130330\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 61.77, NNZs: 1246, Bias: 0.000000, T: 29328, Avg. loss: 0.130141\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 61.91, NNZs: 1243, Bias: 0.000000, T: 31584, Avg. loss: 0.129941\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 62.05, NNZs: 1236, Bias: 0.000000, T: 33840, Avg. loss: 0.129726\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 62.19, NNZs: 1232, Bias: 0.000000, T: 36096, Avg. loss: 0.129534\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 62.22, NNZs: 1231, Bias: 0.000000, T: 38352, Avg. loss: 0.129366\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 62.25, NNZs: 1229, Bias: 0.000000, T: 40608, Avg. loss: 0.129331\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 62.28, NNZs: 1227, Bias: 0.000000, T: 42864, Avg. loss: 0.129291\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 62.31, NNZs: 1227, Bias: 0.000000, T: 45120, Avg. loss: 0.129253\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 23.00, NNZs: 2946, Bias: 0.000000, T: 2256, Avg. loss: 0.179888\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 29.61, NNZs: 1310, Bias: 0.000000, T: 4512, Avg. loss: 0.090954\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 33.94, NNZs: 896, Bias: 0.000000, T: 6768, Avg. loss: 0.077699\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 37.27, NNZs: 707, Bias: 0.000000, T: 9024, Avg. loss: 0.071851\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 40.00, NNZs: 595, Bias: 0.000000, T: 11280, Avg. loss: 0.068565\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 42.48, NNZs: 516, Bias: 0.000000, T: 13536, Avg. loss: 0.066905\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 42.91, NNZs: 494, Bias: 0.000000, T: 15792, Avg. loss: 0.065428\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 43.34, NNZs: 478, Bias: 0.000000, T: 18048, Avg. loss: 0.065158\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 43.76, NNZs: 470, Bias: 0.000000, T: 20304, Avg. loss: 0.064943\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 44.17, NNZs: 462, Bias: 0.000000, T: 22560, Avg. loss: 0.064676\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 44.57, NNZs: 445, Bias: 0.000000, T: 24816, Avg. loss: 0.064436\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 44.65, NNZs: 443, Bias: 0.000000, T: 27072, Avg. loss: 0.064247\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 44.73, NNZs: 443, Bias: 0.000000, T: 29328, Avg. loss: 0.064210\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 44.81, NNZs: 443, Bias: 0.000000, T: 31584, Avg. loss: 0.064169\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 44.89, NNZs: 438, Bias: 0.000000, T: 33840, Avg. loss: 0.064129\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 44.97, NNZs: 436, Bias: 0.000000, T: 36096, Avg. loss: 0.064091\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 44.98, NNZs: 432, Bias: 0.000000, T: 38352, Avg. loss: 0.064053\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 45.00, NNZs: 432, Bias: 0.000000, T: 40608, Avg. loss: 0.064044\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 45.01, NNZs: 432, Bias: 0.000000, T: 42864, Avg. loss: 0.064036\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 45.03, NNZs: 432, Bias: 0.000000, T: 45120, Avg. loss: 0.064027\n",
      "Total training time: 0.16 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.7s finished\n",
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.06171699256249541, clf__eta0=0.6666115972798587, clf__fit_intercept=False, clf__l1_ratio=0.9792901432894962, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.15075392531110676, clf__shuffle=True, clf__tol=0.365636830734297, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.678 total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 23.19, NNZs: 4734, Bias: 0.000000, T: 2256, Avg. loss: 0.420790\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 33.50, NNZs: 2270, Bias: 0.000000, T: 4512, Avg. loss: 0.284531\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 41.31, NNZs: 1816, Bias: 0.000000, T: 6768, Avg. loss: 0.237582\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 47.64, NNZs: 1405, Bias: 0.000000, T: 9024, Avg. loss: 0.210559\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 53.02, NNZs: 1220, Bias: 0.000000, T: 11280, Avg. loss: 0.192923\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 57.80, NNZs: 1068, Bias: 0.000000, T: 13536, Avg. loss: 0.179584\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 58.66, NNZs: 1027, Bias: 0.000000, T: 15792, Avg. loss: 0.171796\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 59.49, NNZs: 1000, Bias: 0.000000, T: 18048, Avg. loss: 0.169919\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 60.31, NNZs: 972, Bias: 0.000000, T: 20304, Avg. loss: 0.168148\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 61.11, NNZs: 955, Bias: 0.000000, T: 22560, Avg. loss: 0.166485\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 61.90, NNZs: 943, Bias: 0.000000, T: 24816, Avg. loss: 0.164853\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 62.05, NNZs: 939, Bias: 0.000000, T: 27072, Avg. loss: 0.163607\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 62.20, NNZs: 934, Bias: 0.000000, T: 29328, Avg. loss: 0.163316\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 62.36, NNZs: 934, Bias: 0.000000, T: 31584, Avg. loss: 0.163002\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 62.51, NNZs: 929, Bias: 0.000000, T: 33840, Avg. loss: 0.162704\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 62.66, NNZs: 924, Bias: 0.000000, T: 36096, Avg. loss: 0.162418\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 62.69, NNZs: 923, Bias: 0.000000, T: 38352, Avg. loss: 0.162175\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 62.72, NNZs: 923, Bias: 0.000000, T: 40608, Avg. loss: 0.162116\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 62.75, NNZs: 922, Bias: 0.000000, T: 42864, Avg. loss: 0.162060\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 62.78, NNZs: 922, Bias: 0.000000, T: 45120, Avg. loss: 0.162001\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 23.76, NNZs: 4601, Bias: 0.000000, T: 2256, Avg. loss: 0.342079\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 32.65, NNZs: 2293, Bias: 0.000000, T: 4512, Avg. loss: 0.219855\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 39.30, NNZs: 1724, Bias: 0.000000, T: 6768, Avg. loss: 0.186084\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 44.83, NNZs: 1316, Bias: 0.000000, T: 9024, Avg. loss: 0.167535\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 49.51, NNZs: 1139, Bias: 0.000000, T: 11280, Avg. loss: 0.155109\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 53.66, NNZs: 997, Bias: 0.000000, T: 13536, Avg. loss: 0.145651\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 54.37, NNZs: 962, Bias: 0.000000, T: 15792, Avg. loss: 0.140659\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 55.08, NNZs: 943, Bias: 0.000000, T: 18048, Avg. loss: 0.139414\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 55.78, NNZs: 928, Bias: 0.000000, T: 20304, Avg. loss: 0.138396\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 56.46, NNZs: 913, Bias: 0.000000, T: 22560, Avg. loss: 0.137232\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 57.13, NNZs: 895, Bias: 0.000000, T: 24816, Avg. loss: 0.136084\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 57.27, NNZs: 891, Bias: 0.000000, T: 27072, Avg. loss: 0.135320\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 57.40, NNZs: 890, Bias: 0.000000, T: 29328, Avg. loss: 0.135128\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 57.53, NNZs: 887, Bias: 0.000000, T: 31584, Avg. loss: 0.134930\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 57.66, NNZs: 886, Bias: 0.000000, T: 33840, Avg. loss: 0.134725\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 57.79, NNZs: 883, Bias: 0.000000, T: 36096, Avg. loss: 0.134522\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 57.82, NNZs: 883, Bias: 0.000000, T: 38352, Avg. loss: 0.134379\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 57.84, NNZs: 883, Bias: 0.000000, T: 40608, Avg. loss: 0.134340\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 57.87, NNZs: 882, Bias: 0.000000, T: 42864, Avg. loss: 0.134301\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 57.90, NNZs: 881, Bias: 0.000000, T: 45120, Avg. loss: 0.134264\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 25.34, NNZs: 5192, Bias: 0.000000, T: 2256, Avg. loss: 0.353538\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 35.33, NNZs: 2700, Bias: 0.000000, T: 4512, Avg. loss: 0.210119\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 42.42, NNZs: 2033, Bias: 0.000000, T: 6768, Avg. loss: 0.173467\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 48.15, NNZs: 1789, Bias: 0.000000, T: 9024, Avg. loss: 0.154833\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 53.03, NNZs: 1510, Bias: 0.000000, T: 11280, Avg. loss: 0.142728\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 57.37, NNZs: 1375, Bias: 0.000000, T: 13536, Avg. loss: 0.134244\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 58.14, NNZs: 1319, Bias: 0.000000, T: 15792, Avg. loss: 0.129432\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 58.90, NNZs: 1275, Bias: 0.000000, T: 18048, Avg. loss: 0.128227\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 59.64, NNZs: 1253, Bias: 0.000000, T: 20304, Avg. loss: 0.127073\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 60.37, NNZs: 1228, Bias: 0.000000, T: 22560, Avg. loss: 0.126032\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 61.09, NNZs: 1185, Bias: 0.000000, T: 24816, Avg. loss: 0.125013\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 61.23, NNZs: 1126, Bias: 0.000000, T: 27072, Avg. loss: 0.124208\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 61.37, NNZs: 1120, Bias: 0.000000, T: 29328, Avg. loss: 0.124017\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 61.51, NNZs: 1116, Bias: 0.000000, T: 31584, Avg. loss: 0.123829\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 61.65, NNZs: 1113, Bias: 0.000000, T: 33840, Avg. loss: 0.123636\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 61.79, NNZs: 1106, Bias: 0.000000, T: 36096, Avg. loss: 0.123447\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 61.82, NNZs: 1105, Bias: 0.000000, T: 38352, Avg. loss: 0.123282\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 61.85, NNZs: 1104, Bias: 0.000000, T: 40608, Avg. loss: 0.123246\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 61.88, NNZs: 1103, Bias: 0.000000, T: 42864, Avg. loss: 0.123208\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 61.90, NNZs: 1103, Bias: 0.000000, T: 45120, Avg. loss: 0.123172\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 23.32, NNZs: 2990, Bias: 0.000000, T: 2256, Avg. loss: 0.172994\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 29.66, NNZs: 1239, Bias: 0.000000, T: 4512, Avg. loss: 0.086243\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 33.74, NNZs: 884, Bias: 0.000000, T: 6768, Avg. loss: 0.074064\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 37.00, NNZs: 681, Bias: 0.000000, T: 9024, Avg. loss: 0.069090\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 39.74, NNZs: 573, Bias: 0.000000, T: 11280, Avg. loss: 0.066075\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 42.13, NNZs: 493, Bias: 0.000000, T: 13536, Avg. loss: 0.064086\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 42.56, NNZs: 479, Bias: 0.000000, T: 15792, Avg. loss: 0.062815\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 42.98, NNZs: 463, Bias: 0.000000, T: 18048, Avg. loss: 0.062544\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 43.40, NNZs: 448, Bias: 0.000000, T: 20304, Avg. loss: 0.062357\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 43.80, NNZs: 430, Bias: 0.000000, T: 22560, Avg. loss: 0.062052\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 44.20, NNZs: 417, Bias: 0.000000, T: 24816, Avg. loss: 0.061879\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 44.28, NNZs: 415, Bias: 0.000000, T: 27072, Avg. loss: 0.061659\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 44.35, NNZs: 414, Bias: 0.000000, T: 29328, Avg. loss: 0.061620\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 44.43, NNZs: 412, Bias: 0.000000, T: 31584, Avg. loss: 0.061590\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 44.51, NNZs: 410, Bias: 0.000000, T: 33840, Avg. loss: 0.061536\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 44.59, NNZs: 410, Bias: 0.000000, T: 36096, Avg. loss: 0.061495\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 44.60, NNZs: 410, Bias: 0.000000, T: 38352, Avg. loss: 0.061460\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 44.62, NNZs: 410, Bias: 0.000000, T: 40608, Avg. loss: 0.061453\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 44.63, NNZs: 410, Bias: 0.000000, T: 42864, Avg. loss: 0.061445\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 44.65, NNZs: 410, Bias: 0.000000, T: 45120, Avg. loss: 0.061434\n",
      "Total training time: 0.17 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.7s finished\n",
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.06171699256249541, clf__eta0=0.6666115972798587, clf__fit_intercept=False, clf__l1_ratio=0.9792901432894962, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.15075392531110676, clf__shuffle=True, clf__tol=0.365636830734297, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.639 total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 23.15, NNZs: 4696, Bias: 0.000000, T: 2256, Avg. loss: 0.423211\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 33.45, NNZs: 2454, Bias: 0.000000, T: 4512, Avg. loss: 0.288431\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 41.13, NNZs: 1950, Bias: 0.000000, T: 6768, Avg. loss: 0.242504\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 47.41, NNZs: 1560, Bias: 0.000000, T: 9024, Avg. loss: 0.216248\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 52.82, NNZs: 1354, Bias: 0.000000, T: 11280, Avg. loss: 0.198491\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 57.63, NNZs: 1219, Bias: 0.000000, T: 13536, Avg. loss: 0.185828\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 58.48, NNZs: 1177, Bias: 0.000000, T: 15792, Avg. loss: 0.177348\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 59.32, NNZs: 1157, Bias: 0.000000, T: 18048, Avg. loss: 0.175627\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 60.14, NNZs: 1138, Bias: 0.000000, T: 20304, Avg. loss: 0.173769\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 60.93, NNZs: 1127, Bias: 0.000000, T: 22560, Avg. loss: 0.172246\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 61.72, NNZs: 1115, Bias: 0.000000, T: 24816, Avg. loss: 0.170609\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 61.88, NNZs: 1103, Bias: 0.000000, T: 27072, Avg. loss: 0.169341\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 62.03, NNZs: 1100, Bias: 0.000000, T: 29328, Avg. loss: 0.169032\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 62.19, NNZs: 1099, Bias: 0.000000, T: 31584, Avg. loss: 0.168739\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 62.34, NNZs: 1094, Bias: 0.000000, T: 33840, Avg. loss: 0.168462\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 62.50, NNZs: 1093, Bias: 0.000000, T: 36096, Avg. loss: 0.168162\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 62.53, NNZs: 1092, Bias: 0.000000, T: 38352, Avg. loss: 0.167910\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 62.56, NNZs: 1091, Bias: 0.000000, T: 40608, Avg. loss: 0.167857\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 62.59, NNZs: 1089, Bias: 0.000000, T: 42864, Avg. loss: 0.167798\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 62.62, NNZs: 1088, Bias: 0.000000, T: 45120, Avg. loss: 0.167742\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 23.52, NNZs: 4609, Bias: 0.000000, T: 2256, Avg. loss: 0.347779\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 32.73, NNZs: 2392, Bias: 0.000000, T: 4512, Avg. loss: 0.223196\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 39.35, NNZs: 1795, Bias: 0.000000, T: 6768, Avg. loss: 0.189258\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 44.93, NNZs: 1477, Bias: 0.000000, T: 9024, Avg. loss: 0.169191\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 49.62, NNZs: 1306, Bias: 0.000000, T: 11280, Avg. loss: 0.157759\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 53.79, NNZs: 1149, Bias: 0.000000, T: 13536, Avg. loss: 0.148787\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 54.52, NNZs: 1112, Bias: 0.000000, T: 15792, Avg. loss: 0.143549\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 55.24, NNZs: 1099, Bias: 0.000000, T: 18048, Avg. loss: 0.142095\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 55.95, NNZs: 1089, Bias: 0.000000, T: 20304, Avg. loss: 0.140968\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 56.65, NNZs: 1066, Bias: 0.000000, T: 22560, Avg. loss: 0.139844\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 57.33, NNZs: 1057, Bias: 0.000000, T: 24816, Avg. loss: 0.138858\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 57.47, NNZs: 1052, Bias: 0.000000, T: 27072, Avg. loss: 0.137942\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 57.60, NNZs: 1049, Bias: 0.000000, T: 29328, Avg. loss: 0.137750\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 57.74, NNZs: 1044, Bias: 0.000000, T: 31584, Avg. loss: 0.137564\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 57.87, NNZs: 1040, Bias: 0.000000, T: 33840, Avg. loss: 0.137365\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 58.01, NNZs: 1033, Bias: 0.000000, T: 36096, Avg. loss: 0.137166\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 58.03, NNZs: 1032, Bias: 0.000000, T: 38352, Avg. loss: 0.137001\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 58.06, NNZs: 1031, Bias: 0.000000, T: 40608, Avg. loss: 0.136961\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 58.09, NNZs: 1030, Bias: 0.000000, T: 42864, Avg. loss: 0.136925\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 58.11, NNZs: 1030, Bias: 0.000000, T: 45120, Avg. loss: 0.136887\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 25.30, NNZs: 5407, Bias: 0.000000, T: 2256, Avg. loss: 0.355078\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 35.28, NNZs: 2743, Bias: 0.000000, T: 4512, Avg. loss: 0.212069\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 42.38, NNZs: 2154, Bias: 0.000000, T: 6768, Avg. loss: 0.175271\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Norm: 48.15, NNZs: 1837, Bias: 0.000000, T: 9024, Avg. loss: 0.156686\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 53.08, NNZs: 1621, Bias: 0.000000, T: 11280, Avg. loss: 0.144743\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 57.45, NNZs: 1452, Bias: 0.000000, T: 13536, Avg. loss: 0.135907\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 58.23, NNZs: 1397, Bias: 0.000000, T: 15792, Avg. loss: 0.130944\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 59.00, NNZs: 1364, Bias: 0.000000, T: 18048, Avg. loss: 0.129766\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 59.75, NNZs: 1310, Bias: 0.000000, T: 20304, Avg. loss: 0.128622\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 60.49, NNZs: 1263, Bias: 0.000000, T: 22560, Avg. loss: 0.127485\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 61.22, NNZs: 1223, Bias: 0.000000, T: 24816, Avg. loss: 0.126433\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 61.37, NNZs: 1216, Bias: 0.000000, T: 27072, Avg. loss: 0.125568\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 61.51, NNZs: 1213, Bias: 0.000000, T: 29328, Avg. loss: 0.125384\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 61.65, NNZs: 1209, Bias: 0.000000, T: 31584, Avg. loss: 0.125183\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 61.80, NNZs: 1205, Bias: 0.000000, T: 33840, Avg. loss: 0.124981\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 61.94, NNZs: 1196, Bias: 0.000000, T: 36096, Avg. loss: 0.124782\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 61.96, NNZs: 1191, Bias: 0.000000, T: 38352, Avg. loss: 0.124621\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 61.99, NNZs: 1191, Bias: 0.000000, T: 40608, Avg. loss: 0.124583\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 62.02, NNZs: 1190, Bias: 0.000000, T: 42864, Avg. loss: 0.124545\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 62.05, NNZs: 1189, Bias: 0.000000, T: 45120, Avg. loss: 0.124504\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 23.35, NNZs: 2959, Bias: 0.000000, T: 2256, Avg. loss: 0.171362\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 29.67, NNZs: 1237, Bias: 0.000000, T: 4512, Avg. loss: 0.082871\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 33.92, NNZs: 897, Bias: 0.000000, T: 6768, Avg. loss: 0.070417\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 37.27, NNZs: 700, Bias: 0.000000, T: 9024, Avg. loss: 0.064945\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 40.07, NNZs: 577, Bias: 0.000000, T: 11280, Avg. loss: 0.061855\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 42.52, NNZs: 509, Bias: 0.000000, T: 13536, Avg. loss: 0.059713\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 42.96, NNZs: 482, Bias: 0.000000, T: 15792, Avg. loss: 0.058418\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 43.39, NNZs: 469, Bias: 0.000000, T: 18048, Avg. loss: 0.058104\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 43.81, NNZs: 456, Bias: 0.000000, T: 20304, Avg. loss: 0.057894\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 44.22, NNZs: 445, Bias: 0.000000, T: 22560, Avg. loss: 0.057660\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 44.63, NNZs: 437, Bias: 0.000000, T: 24816, Avg. loss: 0.057430\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 44.71, NNZs: 435, Bias: 0.000000, T: 27072, Avg. loss: 0.057251\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 44.79, NNZs: 434, Bias: 0.000000, T: 29328, Avg. loss: 0.057216\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 44.86, NNZs: 433, Bias: 0.000000, T: 31584, Avg. loss: 0.057170\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 44.94, NNZs: 431, Bias: 0.000000, T: 33840, Avg. loss: 0.057135\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 45.02, NNZs: 431, Bias: 0.000000, T: 36096, Avg. loss: 0.057091\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 45.04, NNZs: 431, Bias: 0.000000, T: 38352, Avg. loss: 0.057055\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 45.05, NNZs: 431, Bias: 0.000000, T: 40608, Avg. loss: 0.057047\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 45.07, NNZs: 431, Bias: 0.000000, T: 42864, Avg. loss: 0.057037\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 45.08, NNZs: 431, Bias: 0.000000, T: 45120, Avg. loss: 0.057031\n",
      "Total training time: 0.16 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.7s finished\n",
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.06171699256249541, clf__eta0=0.6666115972798587, clf__fit_intercept=False, clf__l1_ratio=0.9792901432894962, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.15075392531110676, clf__shuffle=True, clf__tol=0.365636830734297, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.650 total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 129186261999720.98, NNZs: 24512, Bias: 0.000000, T: 2256, Avg. loss: 2859633071752113228349440.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 86226429823564.64, NNZs: 24513, Bias: 0.000000, T: 4512, Avg. loss: 5787665555746811732295680.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 61350255699662.02, NNZs: 24513, Bias: 0.000000, T: 6768, Avg. loss: 2222895348895482608877568.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 44613346707225.87, NNZs: 24513, Bias: 0.000000, T: 9024, Avg. loss: 1026244400290700453740544.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 33063935170685.93, NNZs: 24513, Bias: 0.000000, T: 11280, Avg. loss: 495460824954132924203008.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 24830393958818.47, NNZs: 24513, Bias: 0.000000, T: 13536, Avg. loss: 248100109707550251810816.000000\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 6 epochs took 0.05 seconds\n",
      "-- Epoch 1\n",
      "Norm: 129229260032540.67, NNZs: 24513, Bias: 0.000000, T: 2256, Avg. loss: 2648942361034013643112448.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 86031354761752.70, NNZs: 24513, Bias: 0.000000, T: 4512, Avg. loss: 5761239298883809712275456.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 60083404489315.14, NNZs: 24513, Bias: 0.000000, T: 6768, Avg. loss: 2285188270559100036710400.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 43446292637715.79, NNZs: 24513, Bias: 0.000000, T: 9024, Avg. loss: 990549134516200037941248.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 31993981926992.12, NNZs: 24513, Bias: 0.000000, T: 11280, Avg. loss: 476843890363557675532288.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 23859284740882.70, NNZs: 24513, Bias: 0.000000, T: 13536, Avg. loss: 235200936945407416598528.000000\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.05 seconds\n",
      "-- Epoch 1\n",
      "Norm: 127535013412716.84, NNZs: 24508, Bias: 0.000000, T: 2256, Avg. loss: 2762952198828772598743040.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 84202450869346.52, NNZs: 24513, Bias: 0.000000, T: 4512, Avg. loss: 5640419147835602871779328.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 58469944742469.24, NNZs: 24513, Bias: 0.000000, T: 6768, Avg. loss: 2184948458396759441276928.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 42103060774772.38, NNZs: 24513, Bias: 0.000000, T: 9024, Avg. loss: 937752874045980257812480.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 30742039166363.69, NNZs: 24513, Bias: 0.000000, T: 11280, Avg. loss: 451983670030311591247872.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 23437580521827.80, NNZs: 24513, Bias: 0.000000, T: 13536, Avg. loss: 208026717407577328582656.000000\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.05 seconds\n",
      "-- Epoch 1\n",
      "Norm: 129908268922463.64, NNZs: 24512, Bias: 0.000000, T: 2256, Avg. loss: 2788403673235821239992320.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 86664014994145.75, NNZs: 24513, Bias: 0.000000, T: 4512, Avg. loss: 5817709347054404038033408.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 61557322513679.77, NNZs: 24513, Bias: 0.000000, T: 6768, Avg. loss: 2253789893798390300409856.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 45564424727404.59, NNZs: 24513, Bias: 0.000000, T: 9024, Avg. loss: 1007696591460380270657536.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 34303272562625.02, NNZs: 24513, Bias: 0.000000, T: 11280, Avg. loss: 508865206714838550577152.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 26375875764022.68, NNZs: 24513, Bias: 0.000000, T: 13536, Avg. loss: 257513573284962786869248.000000\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "[CV 1/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.7915127974877743, clf__eta0=0.05539740212799926, clf__fit_intercept=False, clf__l1_ratio=0.9152680641407671, clf__learning_rate=optimal, clf__loss=squared_epsilon_insensitive, clf__max_iter=80, clf__penalty=l1, clf__power_t=0.6359093112142983, clf__shuffle=True, clf__tol=0.9361199211609239, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.166 total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 132313967709140.36, NNZs: 24341, Bias: 0.000000, T: 2256, Avg. loss: 2981288166881290138681344.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 88921519454639.84, NNZs: 24341, Bias: 0.000000, T: 4512, Avg. loss: 5984018897117751954898944.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 62618881631498.27, NNZs: 24341, Bias: 0.000000, T: 6768, Avg. loss: 2411116396446892265832448.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 45701999808659.17, NNZs: 24341, Bias: 0.000000, T: 9024, Avg. loss: 1054282442348245853143040.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 34556976383115.16, NNZs: 24341, Bias: 0.000000, T: 11280, Avg. loss: 498942836501995753308160.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 26387293573593.15, NNZs: 24341, Bias: 0.000000, T: 13536, Avg. loss: 261855050163536032432128.000000\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 6 epochs took 0.05 seconds\n",
      "-- Epoch 1\n",
      "Norm: 137531408607938.31, NNZs: 24341, Bias: 0.000000, T: 2256, Avg. loss: 3158472575866433349615616.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 91970864700647.75, NNZs: 24341, Bias: 0.000000, T: 4512, Avg. loss: 6470247820783187067404288.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 65114657686822.84, NNZs: 24341, Bias: 0.000000, T: 6768, Avg. loss: 2549624261554306042298368.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 47733901269414.75, NNZs: 24341, Bias: 0.000000, T: 9024, Avg. loss: 1142609170887739969634304.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 35755085853557.16, NNZs: 24341, Bias: 0.000000, T: 11280, Avg. loss: 560741440158161841422336.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 26925804155240.37, NNZs: 24341, Bias: 0.000000, T: 13536, Avg. loss: 294476406802582108897280.000000\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 6 epochs took 0.05 seconds\n",
      "-- Epoch 1\n",
      "Norm: 132517581501785.64, NNZs: 24340, Bias: 0.000000, T: 2256, Avg. loss: 2962355859809905791729664.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 87662221667462.95, NNZs: 24341, Bias: 0.000000, T: 4512, Avg. loss: 6060879071126156495290368.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 62202210123988.16, NNZs: 24341, Bias: 0.000000, T: 6768, Avg. loss: 2306976584916625220698112.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 45176755396400.58, NNZs: 24341, Bias: 0.000000, T: 9024, Avg. loss: 1050463722984526864973824.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 33570401293786.20, NNZs: 24341, Bias: 0.000000, T: 11280, Avg. loss: 502935489242585135841280.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 25228295591792.76, NNZs: 24341, Bias: 0.000000, T: 13536, Avg. loss: 253578455780083791560704.000000\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 6 epochs took 0.05 seconds\n",
      "-- Epoch 1\n",
      "Norm: 42.73, NNZs: 328, Bias: 0.000000, T: 2256, Avg. loss: 0.007994\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 46.96, NNZs: 128, Bias: 0.000000, T: 4512, Avg. loss: 0.010830\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 47.73, NNZs: 93, Bias: 0.000000, T: 6768, Avg. loss: 0.005481\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 48.06, NNZs: 86, Bias: 0.000000, T: 9024, Avg. loss: 0.001961\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 48.29, NNZs: 76, Bias: 0.000000, T: 11280, Avg. loss: 0.001938\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 48.45, NNZs: 78, Bias: 0.000000, T: 13536, Avg. loss: 0.001996\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 2/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.7915127974877743, clf__eta0=0.05539740212799926, clf__fit_intercept=False, clf__l1_ratio=0.9152680641407671, clf__learning_rate=optimal, clf__loss=squared_epsilon_insensitive, clf__max_iter=80, clf__penalty=l1, clf__power_t=0.6359093112142983, clf__shuffle=True, clf__tol=0.9361199211609239, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.191 total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 131842621852249.19, NNZs: 24909, Bias: 0.000000, T: 2256, Avg. loss: 2906381597553637273370624.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 87173574321954.53, NNZs: 24910, Bias: 0.000000, T: 4512, Avg. loss: 6078427471175576253890560.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 61918125212956.53, NNZs: 24910, Bias: 0.000000, T: 6768, Avg. loss: 2290788912247662473904128.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 44946208827573.72, NNZs: 24910, Bias: 0.000000, T: 9024, Avg. loss: 1047541871843348804796416.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 32882397729887.96, NNZs: 24910, Bias: 0.000000, T: 11280, Avg. loss: 522150933061550399815680.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 24620229602453.57, NNZs: 24910, Bias: 0.000000, T: 13536, Avg. loss: 248069582287243214585856.000000\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 6 epochs took 0.05 seconds\n",
      "-- Epoch 1\n",
      "Norm: 129784298002488.22, NNZs: 24910, Bias: 0.000000, T: 2256, Avg. loss: 2697935024850009654820864.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 86621079015130.89, NNZs: 24910, Bias: 0.000000, T: 4512, Avg. loss: 5851660297440484682366976.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 61722024433105.22, NNZs: 24910, Bias: 0.000000, T: 6768, Avg. loss: 2249456950154593885487104.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 45913690892558.27, NNZs: 24910, Bias: 0.000000, T: 9024, Avg. loss: 1006363506825323937267712.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 34602032665823.55, NNZs: 24910, Bias: 0.000000, T: 11280, Avg. loss: 503839182766048316227584.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 26499285126697.62, NNZs: 24910, Bias: 0.000000, T: 13536, Avg. loss: 261595292726105175228416.000000\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 6 epochs took 0.05 seconds\n",
      "-- Epoch 1\n",
      "Norm: 130555562268781.00, NNZs: 24910, Bias: 0.000000, T: 2256, Avg. loss: 2863820681795504183443456.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 86400106163651.48, NNZs: 24910, Bias: 0.000000, T: 4512, Avg. loss: 5889316982486062799519744.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 62141856437417.24, NNZs: 24910, Bias: 0.000000, T: 6768, Avg. loss: 2181221148221367224631296.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 45713132851511.44, NNZs: 24910, Bias: 0.000000, T: 9024, Avg. loss: 1018972008544728988516352.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 34382030621274.64, NNZs: 24910, Bias: 0.000000, T: 11280, Avg. loss: 502532261241704587198464.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 26275802315390.71, NNZs: 24910, Bias: 0.000000, T: 13536, Avg. loss: 255468802037922614214656.000000\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.05 seconds\n",
      "-- Epoch 1\n",
      "Norm: 130393850102551.56, NNZs: 24909, Bias: 0.000000, T: 2256, Avg. loss: 2714116026045059546742784.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 87091333981487.11, NNZs: 24910, Bias: 0.000000, T: 4512, Avg. loss: 5966336023090086035849216.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 62101097952517.05, NNZs: 24910, Bias: 0.000000, T: 6768, Avg. loss: 2301713811267963907473408.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 45447687070222.25, NNZs: 24910, Bias: 0.000000, T: 9024, Avg. loss: 1068765761848569382305792.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 33783212729067.91, NNZs: 24910, Bias: 0.000000, T: 11280, Avg. loss: 514823449717634074935296.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 25156999672579.52, NNZs: 24910, Bias: 0.000000, T: 13536, Avg. loss: 266201048790280911716352.000000\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 6 epochs took 0.05 seconds\n",
      "[CV 3/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.7915127974877743, clf__eta0=0.05539740212799926, clf__fit_intercept=False, clf__l1_ratio=0.9152680641407671, clf__learning_rate=optimal, clf__loss=squared_epsilon_insensitive, clf__max_iter=80, clf__penalty=l1, clf__power_t=0.6359093112142983, clf__shuffle=True, clf__tol=0.9361199211609239, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.118 total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 133453088367785.91, NNZs: 25353, Bias: 0.000000, T: 2256, Avg. loss: 2879425635471321007652864.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 89474048088444.83, NNZs: 25353, Bias: 0.000000, T: 4512, Avg. loss: 5967337283411143974453248.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 64206267655677.79, NNZs: 25353, Bias: 0.000000, T: 6768, Avg. loss: 2350156568019660848496640.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 47171409484245.79, NNZs: 25353, Bias: 0.000000, T: 9024, Avg. loss: 1100340048031304984297472.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 35383580963516.24, NNZs: 25353, Bias: 0.000000, T: 11280, Avg. loss: 541210572317530091683840.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27225939572765.97, NNZs: 25353, Bias: 0.000000, T: 13536, Avg. loss: 267666964367744520159232.000000\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 6 epochs took 0.05 seconds\n",
      "-- Epoch 1\n",
      "Norm: 133294104756172.11, NNZs: 25352, Bias: 0.000000, T: 2256, Avg. loss: 2876911554621367683907584.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 89542399241716.95, NNZs: 25353, Bias: 0.000000, T: 4512, Avg. loss: 6049642989154488928960512.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 64222294551614.02, NNZs: 25353, Bias: 0.000000, T: 6768, Avg. loss: 2367048102180383740657664.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 47320995855462.56, NNZs: 25353, Bias: 0.000000, T: 9024, Avg. loss: 1096915136692572051734528.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 35641770311388.37, NNZs: 25353, Bias: 0.000000, T: 11280, Avg. loss: 535761629551632372989952.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27546482797003.08, NNZs: 25353, Bias: 0.000000, T: 13536, Avg. loss: 269064082696486481035264.000000\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 6 epochs took 0.05 seconds\n",
      "-- Epoch 1\n",
      "Norm: 133661095850558.14, NNZs: 25350, Bias: 0.000000, T: 2256, Avg. loss: 3053202305780647894974464.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 90454441162739.16, NNZs: 25353, Bias: 0.000000, T: 4512, Avg. loss: 6018513047501631291129856.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 65432331300573.18, NNZs: 25353, Bias: 0.000000, T: 6768, Avg. loss: 2394629460277963276681216.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 48392131984157.66, NNZs: 25353, Bias: 0.000000, T: 9024, Avg. loss: 1131317592311553459224576.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 35678730981062.62, NNZs: 25353, Bias: 0.000000, T: 11280, Avg. loss: 593187021861025868677120.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27301663404146.05, NNZs: 25353, Bias: 0.000000, T: 13536, Avg. loss: 281729577119696665182208.000000\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 6 epochs took 0.05 seconds\n",
      "-- Epoch 1\n",
      "Norm: 33.64, NNZs: 119, Bias: 0.000000, T: 2256, Avg. loss: 0.004392\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 112.35, NNZs: 122, Bias: 0.000000, T: 4512, Avg. loss: 0.731677\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 341.62, NNZs: 1070, Bias: 0.000000, T: 6768, Avg. loss: 14.708524\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 464.64, NNZs: 1035, Bias: 0.000000, T: 9024, Avg. loss: 105.924926\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 406.58, NNZs: 1437, Bias: 0.000000, T: 11280, Avg. loss: 85.477957\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 385.99, NNZs: 1622, Bias: 0.000000, T: 13536, Avg. loss: 7.814677\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 4/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.7915127974877743, clf__eta0=0.05539740212799926, clf__fit_intercept=False, clf__l1_ratio=0.9152680641407671, clf__learning_rate=optimal, clf__loss=squared_epsilon_insensitive, clf__max_iter=80, clf__penalty=l1, clf__power_t=0.6359093112142983, clf__shuffle=True, clf__tol=0.9361199211609239, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.167 total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 133264522930756.02, NNZs: 25269, Bias: 0.000000, T: 2256, Avg. loss: 2990736630095626629021696.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 89984364885089.98, NNZs: 25275, Bias: 0.000000, T: 4512, Avg. loss: 6046248534577394369953792.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 64313117162632.30, NNZs: 25275, Bias: 0.000000, T: 6768, Avg. loss: 2412489953549722251689984.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 47830622117259.27, NNZs: 25275, Bias: 0.000000, T: 9024, Avg. loss: 1080105536846388894105600.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 35908178862354.73, NNZs: 25275, Bias: 0.000000, T: 11280, Avg. loss: 553819621359037018275840.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27546820038668.90, NNZs: 25275, Bias: 0.000000, T: 13536, Avg. loss: 282230763705789665247232.000000\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 6 epochs took 0.05 seconds\n",
      "-- Epoch 1\n",
      "Norm: 133602296751498.38, NNZs: 25275, Bias: 0.000000, T: 2256, Avg. loss: 2977804369788683321081856.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 88834270156597.48, NNZs: 25275, Bias: 0.000000, T: 4512, Avg. loss: 6156067409875349771649024.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 63409278260359.41, NNZs: 25275, Bias: 0.000000, T: 6768, Avg. loss: 2362959343648446280105984.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 46432176955155.77, NNZs: 25275, Bias: 0.000000, T: 9024, Avg. loss: 1094525144512074866491392.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 34618886128865.33, NNZs: 25275, Bias: 0.000000, T: 11280, Avg. loss: 539119700280777428172800.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 26112551923842.79, NNZs: 25275, Bias: 0.000000, T: 13536, Avg. loss: 272254907370239023906816.000000\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 6 epochs took 0.05 seconds\n",
      "-- Epoch 1\n",
      "Norm: 129047380251164.36, NNZs: 25275, Bias: 0.000000, T: 2256, Avg. loss: 2678870858099408144171008.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 87299717268539.05, NNZs: 25275, Bias: 0.000000, T: 4512, Avg. loss: 5572859472470236423258112.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 61705659878978.84, NNZs: 25275, Bias: 0.000000, T: 6768, Avg. loss: 2285505253370009980239872.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 45109357319838.21, NNZs: 25275, Bias: 0.000000, T: 9024, Avg. loss: 1027341170074962750341120.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 33605289566995.76, NNZs: 25275, Bias: 0.000000, T: 11280, Avg. loss: 506917733335373631717376.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 25505612398205.11, NNZs: 25275, Bias: 0.000000, T: 13536, Avg. loss: 257540173646786176483328.000000\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 6 epochs took 0.05 seconds\n",
      "-- Epoch 1\n",
      "Norm: 111587079310766.27, NNZs: 25262, Bias: 0.000000, T: 2256, Avg. loss: 1687364066069437311090688.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 73687671601039.53, NNZs: 25275, Bias: 0.000000, T: 4512, Avg. loss: 4522250684573658644480000.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 50324218996440.23, NNZs: 25275, Bias: 0.000000, T: 6768, Avg. loss: 1756153999151054018576384.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 36060701388950.33, NNZs: 25275, Bias: 0.000000, T: 9024, Avg. loss: 731501087629652120305664.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 26359522858123.05, NNZs: 25275, Bias: 0.000000, T: 11280, Avg. loss: 333837388085867050958848.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 19583363660115.23, NNZs: 25275, Bias: 0.000000, T: 13536, Avg. loss: 162904138944465231413248.000000\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 6 epochs took 0.05 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.7915127974877743, clf__eta0=0.05539740212799926, clf__fit_intercept=False, clf__l1_ratio=0.9152680641407671, clf__learning_rate=optimal, clf__loss=squared_epsilon_insensitive, clf__max_iter=80, clf__penalty=l1, clf__power_t=0.6359093112142983, clf__shuffle=True, clf__tol=0.9361199211609239, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.175 total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 39.00, NNZs: 12338, Bias: 0.000000, T: 2256, Avg. loss: 0.255514\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 45.86, NNZs: 4737, Bias: 0.000000, T: 4512, Avg. loss: 0.054850\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 51.59, NNZs: 3085, Bias: 0.000000, T: 6768, Avg. loss: 0.046837\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 56.37, NNZs: 2405, Bias: 0.000000, T: 9024, Avg. loss: 0.042113\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 60.57, NNZs: 1956, Bias: 0.000000, T: 11280, Avg. loss: 0.036877\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 64.23, NNZs: 1713, Bias: 0.000000, T: 13536, Avg. loss: 0.034052\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 34.01, NNZs: 9929, Bias: 0.000000, T: 2256, Avg. loss: 0.191314\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 40.14, NNZs: 3965, Bias: 0.000000, T: 4512, Avg. loss: 0.044262\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 45.58, NNZs: 2681, Bias: 0.000000, T: 6768, Avg. loss: 0.038302\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 49.80, NNZs: 2111, Bias: 0.000000, T: 9024, Avg. loss: 0.032542\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 53.63, NNZs: 1771, Bias: 0.000000, T: 11280, Avg. loss: 0.028746\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 56.97, NNZs: 1454, Bias: 0.000000, T: 13536, Avg. loss: 0.025814\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 33.60, NNZs: 9606, Bias: 0.000000, T: 2256, Avg. loss: 0.159519\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 39.49, NNZs: 3980, Bias: 0.000000, T: 4512, Avg. loss: 0.041981\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 44.60, NNZs: 2725, Bias: 0.000000, T: 6768, Avg. loss: 0.033293\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 48.85, NNZs: 2119, Bias: 0.000000, T: 9024, Avg. loss: 0.028358\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 52.50, NNZs: 1788, Bias: 0.000000, T: 11280, Avg. loss: 0.026284\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 55.78, NNZs: 1545, Bias: 0.000000, T: 13536, Avg. loss: 0.025512\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 20.74, NNZs: 4020, Bias: 0.000000, T: 2256, Avg. loss: 0.057928\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 24.96, NNZs: 1998, Bias: 0.000000, T: 4512, Avg. loss: 0.019935\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 28.47, NNZs: 1413, Bias: 0.000000, T: 6768, Avg. loss: 0.017358\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 31.55, NNZs: 1148, Bias: 0.000000, T: 9024, Avg. loss: 0.014941\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 33.97, NNZs: 905, Bias: 0.000000, T: 11280, Avg. loss: 0.011333\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 36.27, NNZs: 758, Bias: 0.000000, T: 13536, Avg. loss: 0.012754\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "[CV 1/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.03646223783802971, clf__eta0=0.7491267567674796, clf__fit_intercept=False, clf__l1_ratio=0.775818217437024, clf__learning_rate=constant, clf__loss=squared_hinge, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.4028006727705291, clf__shuffle=True, clf__tol=0.1730703028465106, clf__warm_start=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.702 total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 39.82, NNZs: 12775, Bias: 0.000000, T: 2256, Avg. loss: 0.263290\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 47.03, NNZs: 5164, Bias: 0.000000, T: 4512, Avg. loss: 0.063009\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 52.82, NNZs: 3356, Bias: 0.000000, T: 6768, Avg. loss: 0.047251\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 57.72, NNZs: 2582, Bias: 0.000000, T: 9024, Avg. loss: 0.042242\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 62.01, NNZs: 2190, Bias: 0.000000, T: 11280, Avg. loss: 0.037251\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 65.76, NNZs: 1875, Bias: 0.000000, T: 13536, Avg. loss: 0.033863\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 34.05, NNZs: 10111, Bias: 0.000000, T: 2256, Avg. loss: 0.186500\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 40.59, NNZs: 4107, Bias: 0.000000, T: 4512, Avg. loss: 0.045969\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 45.75, NNZs: 2799, Bias: 0.000000, T: 6768, Avg. loss: 0.035093\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 50.12, NNZs: 2215, Bias: 0.000000, T: 9024, Avg. loss: 0.031705\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 53.83, NNZs: 1876, Bias: 0.000000, T: 11280, Avg. loss: 0.027394\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 57.18, NNZs: 1658, Bias: 0.000000, T: 13536, Avg. loss: 0.026249\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 34.22, NNZs: 10142, Bias: 0.000000, T: 2256, Avg. loss: 0.167825\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 40.39, NNZs: 4254, Bias: 0.000000, T: 4512, Avg. loss: 0.039184\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 45.36, NNZs: 2883, Bias: 0.000000, T: 6768, Avg. loss: 0.032354\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 49.76, NNZs: 2236, Bias: 0.000000, T: 9024, Avg. loss: 0.029311\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 53.53, NNZs: 1902, Bias: 0.000000, T: 11280, Avg. loss: 0.026845\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 56.93, NNZs: 1646, Bias: 0.000000, T: 13536, Avg. loss: 0.025160\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 21.14, NNZs: 4233, Bias: 0.000000, T: 2256, Avg. loss: 0.063138\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 25.85, NNZs: 2109, Bias: 0.000000, T: 4512, Avg. loss: 0.019855\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 29.43, NNZs: 1571, Bias: 0.000000, T: 6768, Avg. loss: 0.015842\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 32.37, NNZs: 1170, Bias: 0.000000, T: 9024, Avg. loss: 0.013679\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 34.95, NNZs: 971, Bias: 0.000000, T: 11280, Avg. loss: 0.013484\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 37.34, NNZs: 861, Bias: 0.000000, T: 13536, Avg. loss: 0.012516\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "[CV 2/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.03646223783802971, clf__eta0=0.7491267567674796, clf__fit_intercept=False, clf__l1_ratio=0.775818217437024, clf__learning_rate=constant, clf__loss=squared_hinge, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.4028006727705291, clf__shuffle=True, clf__tol=0.1730703028465106, clf__warm_start=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.717 total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 40.20, NNZs: 13177, Bias: 0.000000, T: 2256, Avg. loss: 0.271818\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 47.37, NNZs: 5278, Bias: 0.000000, T: 4512, Avg. loss: 0.057836\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 53.43, NNZs: 3509, Bias: 0.000000, T: 6768, Avg. loss: 0.047846\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 58.35, NNZs: 2562, Bias: 0.000000, T: 9024, Avg. loss: 0.040449\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 62.59, NNZs: 2234, Bias: 0.000000, T: 11280, Avg. loss: 0.034989\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 66.36, NNZs: 1915, Bias: 0.000000, T: 13536, Avg. loss: 0.032184\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 33.99, NNZs: 9660, Bias: 0.000000, T: 2256, Avg. loss: 0.194721\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 40.57, NNZs: 4006, Bias: 0.000000, T: 4512, Avg. loss: 0.048295\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 46.06, NNZs: 2853, Bias: 0.000000, T: 6768, Avg. loss: 0.040107\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 50.51, NNZs: 2209, Bias: 0.000000, T: 9024, Avg. loss: 0.031913\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 54.33, NNZs: 1908, Bias: 0.000000, T: 11280, Avg. loss: 0.027654\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 57.76, NNZs: 1671, Bias: 0.000000, T: 13536, Avg. loss: 0.026966\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 34.88, NNZs: 10591, Bias: 0.000000, T: 2256, Avg. loss: 0.169988\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 40.88, NNZs: 4481, Bias: 0.000000, T: 4512, Avg. loss: 0.036796\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 46.12, NNZs: 2959, Bias: 0.000000, T: 6768, Avg. loss: 0.031571\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 50.52, NNZs: 2336, Bias: 0.000000, T: 9024, Avg. loss: 0.028249\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 54.42, NNZs: 1967, Bias: 0.000000, T: 11280, Avg. loss: 0.025057\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 57.82, NNZs: 1761, Bias: 0.000000, T: 13536, Avg. loss: 0.022372\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 21.76, NNZs: 4528, Bias: 0.000000, T: 2256, Avg. loss: 0.065816\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 26.18, NNZs: 2132, Bias: 0.000000, T: 4512, Avg. loss: 0.020683\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 29.82, NNZs: 1508, Bias: 0.000000, T: 6768, Avg. loss: 0.015123\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 32.73, NNZs: 1171, Bias: 0.000000, T: 9024, Avg. loss: 0.015457\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 35.51, NNZs: 976, Bias: 0.000000, T: 11280, Avg. loss: 0.014186\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 37.88, NNZs: 855, Bias: 0.000000, T: 13536, Avg. loss: 0.012930\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 3/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.03646223783802971, clf__eta0=0.7491267567674796, clf__fit_intercept=False, clf__l1_ratio=0.775818217437024, clf__learning_rate=constant, clf__loss=squared_hinge, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.4028006727705291, clf__shuffle=True, clf__tol=0.1730703028465106, clf__warm_start=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.712 total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 39.21, NNZs: 12604, Bias: 0.000000, T: 2256, Avg. loss: 0.259195\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 46.63, NNZs: 5068, Bias: 0.000000, T: 4512, Avg. loss: 0.062099\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 52.58, NNZs: 3406, Bias: 0.000000, T: 6768, Avg. loss: 0.051754\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 57.54, NNZs: 2531, Bias: 0.000000, T: 9024, Avg. loss: 0.044646\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 61.76, NNZs: 2067, Bias: 0.000000, T: 11280, Avg. loss: 0.039124\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 65.61, NNZs: 1838, Bias: 0.000000, T: 13536, Avg. loss: 0.036011\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.05 seconds\n",
      "-- Epoch 1\n",
      "Norm: 34.23, NNZs: 10235, Bias: 0.000000, T: 2256, Avg. loss: 0.197218\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 41.17, NNZs: 4211, Bias: 0.000000, T: 4512, Avg. loss: 0.051485\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 46.66, NNZs: 2939, Bias: 0.000000, T: 6768, Avg. loss: 0.046657\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 51.20, NNZs: 2343, Bias: 0.000000, T: 9024, Avg. loss: 0.035563\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 55.19, NNZs: 1937, Bias: 0.000000, T: 11280, Avg. loss: 0.034422\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 58.66, NNZs: 1600, Bias: 0.000000, T: 13536, Avg. loss: 0.030709\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 34.06, NNZs: 10035, Bias: 0.000000, T: 2256, Avg. loss: 0.165342\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 40.04, NNZs: 4024, Bias: 0.000000, T: 4512, Avg. loss: 0.038928\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 45.20, NNZs: 2825, Bias: 0.000000, T: 6768, Avg. loss: 0.033676\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 49.52, NNZs: 2258, Bias: 0.000000, T: 9024, Avg. loss: 0.029294\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 53.24, NNZs: 1791, Bias: 0.000000, T: 11280, Avg. loss: 0.026493\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 56.62, NNZs: 1649, Bias: 0.000000, T: 13536, Avg. loss: 0.025009\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 21.50, NNZs: 4290, Bias: 0.000000, T: 2256, Avg. loss: 0.062874\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 25.79, NNZs: 2066, Bias: 0.000000, T: 4512, Avg. loss: 0.018979\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 29.39, NNZs: 1472, Bias: 0.000000, T: 6768, Avg. loss: 0.016188\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 32.35, NNZs: 1156, Bias: 0.000000, T: 9024, Avg. loss: 0.014595\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 34.98, NNZs: 955, Bias: 0.000000, T: 11280, Avg. loss: 0.013696\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 37.28, NNZs: 839, Bias: 0.000000, T: 13536, Avg. loss: 0.012698\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "[CV 4/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.03646223783802971, clf__eta0=0.7491267567674796, clf__fit_intercept=False, clf__l1_ratio=0.775818217437024, clf__learning_rate=constant, clf__loss=squared_hinge, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.4028006727705291, clf__shuffle=True, clf__tol=0.1730703028465106, clf__warm_start=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.714 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 39.44, NNZs: 12474, Bias: 0.000000, T: 2256, Avg. loss: 0.257779\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 46.25, NNZs: 4727, Bias: 0.000000, T: 4512, Avg. loss: 0.055917\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 51.95, NNZs: 3111, Bias: 0.000000, T: 6768, Avg. loss: 0.044443\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 56.65, NNZs: 2375, Bias: 0.000000, T: 9024, Avg. loss: 0.038239\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 60.81, NNZs: 2042, Bias: 0.000000, T: 11280, Avg. loss: 0.034605\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 64.45, NNZs: 1736, Bias: 0.000000, T: 13536, Avg. loss: 0.032040\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 34.54, NNZs: 10167, Bias: 0.000000, T: 2256, Avg. loss: 0.195474\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 40.69, NNZs: 3874, Bias: 0.000000, T: 4512, Avg. loss: 0.040395\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 45.94, NNZs: 2615, Bias: 0.000000, T: 6768, Avg. loss: 0.034852\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 50.41, NNZs: 2101, Bias: 0.000000, T: 9024, Avg. loss: 0.032372\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 54.19, NNZs: 1813, Bias: 0.000000, T: 11280, Avg. loss: 0.026562\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 57.42, NNZs: 1615, Bias: 0.000000, T: 13536, Avg. loss: 0.025282\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 34.05, NNZs: 9893, Bias: 0.000000, T: 2256, Avg. loss: 0.171976\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 40.11, NNZs: 4223, Bias: 0.000000, T: 4512, Avg. loss: 0.040389\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 45.19, NNZs: 2812, Bias: 0.000000, T: 6768, Avg. loss: 0.032275\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 49.53, NNZs: 2196, Bias: 0.000000, T: 9024, Avg. loss: 0.029141\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 53.23, NNZs: 1836, Bias: 0.000000, T: 11280, Avg. loss: 0.027067\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 56.59, NNZs: 1597, Bias: 0.000000, T: 13536, Avg. loss: 0.023565\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 20.97, NNZs: 4083, Bias: 0.000000, T: 2256, Avg. loss: 0.060423\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 25.28, NNZs: 1866, Bias: 0.000000, T: 4512, Avg. loss: 0.020411\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 28.71, NNZs: 1387, Bias: 0.000000, T: 6768, Avg. loss: 0.018922\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 31.91, NNZs: 1132, Bias: 0.000000, T: 9024, Avg. loss: 0.016146\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 34.47, NNZs: 967, Bias: 0.000000, T: 11280, Avg. loss: 0.013619\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 36.79, NNZs: 823, Bias: 0.000000, T: 13536, Avg. loss: 0.012786\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 5/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.03646223783802971, clf__eta0=0.7491267567674796, clf__fit_intercept=False, clf__l1_ratio=0.775818217437024, clf__learning_rate=constant, clf__loss=squared_hinge, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.4028006727705291, clf__shuffle=True, clf__tol=0.1730703028465106, clf__warm_start=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.707 total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 16.77, NNZs: 7555, Bias: 0.000000, T: 2256, Avg. loss: 0.176930\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 21.69, NNZs: 4413, Bias: 0.000000, T: 4512, Avg. loss: 0.079185\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 25.10, NNZs: 3386, Bias: 0.000000, T: 6768, Avg. loss: 0.063561\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 27.85, NNZs: 2867, Bias: 0.000000, T: 9024, Avg. loss: 0.056945\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 30.27, NNZs: 2497, Bias: 0.000000, T: 11280, Avg. loss: 0.052529\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 32.29, NNZs: 2231, Bias: 0.000000, T: 13536, Avg. loss: 0.049910\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 6 epochs took 0.05 seconds\n",
      "-- Epoch 1\n",
      "Norm: 15.23, NNZs: 7226, Bias: 0.000000, T: 2256, Avg. loss: 0.135066\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 19.84, NNZs: 4379, Bias: 0.000000, T: 4512, Avg. loss: 0.062062\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 23.16, NNZs: 3339, Bias: 0.000000, T: 6768, Avg. loss: 0.049355\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 25.79, NNZs: 2831, Bias: 0.000000, T: 9024, Avg. loss: 0.043394\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 27.96, NNZs: 2422, Bias: 0.000000, T: 11280, Avg. loss: 0.039805\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 30.06, NNZs: 2178, Bias: 0.000000, T: 13536, Avg. loss: 0.037659\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 6 epochs took 0.05 seconds\n",
      "-- Epoch 1\n",
      "Norm: 10.58, NNZs: 3918, Bias: 0.000000, T: 2256, Avg. loss: 0.208120\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 13.94, NNZs: 2197, Bias: 0.000000, T: 4512, Avg. loss: 0.109685\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 16.22, NNZs: 1627, Bias: 0.000000, T: 6768, Avg. loss: 0.092714\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 18.08, NNZs: 1382, Bias: 0.000000, T: 9024, Avg. loss: 0.084951\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 19.74, NNZs: 1239, Bias: 0.000000, T: 11280, Avg. loss: 0.080303\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 21.24, NNZs: 1107, Bias: 0.000000, T: 13536, Avg. loss: 0.077019\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.05 seconds\n",
      "-- Epoch 1\n",
      "Norm: 219.85, NNZs: 17353, Bias: 0.000000, T: 2256, Avg. loss: 3.788642\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 6214.39, NNZs: 23696, Bias: 0.000000, T: 4512, Avg. loss: 2631.303983\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 126230.40, NNZs: 24471, Bias: 0.000000, T: 6768, Avg. loss: 1562181.539208\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4060382.62, NNZs: 24506, Bias: 0.000000, T: 9024, Avg. loss: 553506962.068979\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 65968875.54, NNZs: 24513, Bias: 0.000000, T: 11280, Avg. loss: 437084246807.309387\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1149703956.15, NNZs: 24513, Bias: 0.000000, T: 13536, Avg. loss: 318465140023231.687500\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 6 epochs took 0.05 seconds\n",
      "[CV 1/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.24457156361183285, clf__eta0=0.332929742792607, clf__fit_intercept=False, clf__l1_ratio=0.920539731041378, clf__learning_rate=constant, clf__loss=squared_error, clf__max_iter=100, clf__penalty=l1, clf__power_t=0.5734177157821045, clf__shuffle=True, clf__tol=0.6492274795888617, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.211 total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 16.96, NNZs: 7761, Bias: 0.000000, T: 2256, Avg. loss: 0.184636\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 21.92, NNZs: 4716, Bias: 0.000000, T: 4512, Avg. loss: 0.085541\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 25.57, NNZs: 3603, Bias: 0.000000, T: 6768, Avg. loss: 0.068749\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 28.33, NNZs: 3016, Bias: 0.000000, T: 9024, Avg. loss: 0.061698\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 30.77, NNZs: 2650, Bias: 0.000000, T: 11280, Avg. loss: 0.056639\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 32.93, NNZs: 2408, Bias: 0.000000, T: 13536, Avg. loss: 0.053877\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 15.43, NNZs: 7368, Bias: 0.000000, T: 2256, Avg. loss: 0.135029\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 19.84, NNZs: 4548, Bias: 0.000000, T: 4512, Avg. loss: 0.061800\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 23.20, NNZs: 3374, Bias: 0.000000, T: 6768, Avg. loss: 0.049882\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 25.93, NNZs: 2842, Bias: 0.000000, T: 9024, Avg. loss: 0.044326\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 28.30, NNZs: 2453, Bias: 0.000000, T: 11280, Avg. loss: 0.040219\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 30.39, NNZs: 2222, Bias: 0.000000, T: 13536, Avg. loss: 0.038150\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.05 seconds\n",
      "-- Epoch 1\n",
      "Norm: 10.68, NNZs: 3891, Bias: 0.000000, T: 2256, Avg. loss: 0.220278\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 13.99, NNZs: 2265, Bias: 0.000000, T: 4512, Avg. loss: 0.117510\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 16.40, NNZs: 1784, Bias: 0.000000, T: 6768, Avg. loss: 0.100424\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 18.34, NNZs: 1522, Bias: 0.000000, T: 9024, Avg. loss: 0.092147\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 20.02, NNZs: 1359, Bias: 0.000000, T: 11280, Avg. loss: 0.086274\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 21.56, NNZs: 1255, Bias: 0.000000, T: 13536, Avg. loss: 0.083502\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 76.86, NNZs: 14504, Bias: 0.000000, T: 2256, Avg. loss: 1.114482\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1166.62, NNZs: 21878, Bias: 0.000000, T: 4512, Avg. loss: 219.540149\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 16019.96, NNZs: 24029, Bias: 0.000000, T: 6768, Avg. loss: 48851.032049\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 494506.55, NNZs: 24326, Bias: 0.000000, T: 9024, Avg. loss: 21442526.687057\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 6382303.83, NNZs: 24339, Bias: 0.000000, T: 11280, Avg. loss: 5573381273.884310\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 73579145.40, NNZs: 24342, Bias: 0.000000, T: 13536, Avg. loss: 954726674439.675903\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 6 epochs took 0.05 seconds\n",
      "[CV 2/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.24457156361183285, clf__eta0=0.332929742792607, clf__fit_intercept=False, clf__l1_ratio=0.920539731041378, clf__learning_rate=constant, clf__loss=squared_error, clf__max_iter=100, clf__penalty=l1, clf__power_t=0.5734177157821045, clf__shuffle=True, clf__tol=0.6492274795888617, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.213 total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 17.08, NNZs: 7647, Bias: 0.000000, T: 2256, Avg. loss: 0.187276\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 22.22, NNZs: 4822, Bias: 0.000000, T: 4512, Avg. loss: 0.086695\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 25.86, NNZs: 3700, Bias: 0.000000, T: 6768, Avg. loss: 0.068876\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 28.79, NNZs: 3075, Bias: 0.000000, T: 9024, Avg. loss: 0.060236\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 31.24, NNZs: 2720, Bias: 0.000000, T: 11280, Avg. loss: 0.055622\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 33.46, NNZs: 2507, Bias: 0.000000, T: 13536, Avg. loss: 0.052171\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 15.27, NNZs: 6963, Bias: 0.000000, T: 2256, Avg. loss: 0.138454\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 20.13, NNZs: 4452, Bias: 0.000000, T: 4512, Avg. loss: 0.063374\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 23.45, NNZs: 3308, Bias: 0.000000, T: 6768, Avg. loss: 0.050675\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 26.13, NNZs: 2786, Bias: 0.000000, T: 9024, Avg. loss: 0.044708\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 28.50, NNZs: 2411, Bias: 0.000000, T: 11280, Avg. loss: 0.040759\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 30.50, NNZs: 2202, Bias: 0.000000, T: 13536, Avg. loss: 0.038816\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 10.67, NNZs: 4017, Bias: 0.000000, T: 2256, Avg. loss: 0.225788\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14.01, NNZs: 2393, Bias: 0.000000, T: 4512, Avg. loss: 0.121938\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 16.46, NNZs: 1822, Bias: 0.000000, T: 6768, Avg. loss: 0.105082\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 18.42, NNZs: 1515, Bias: 0.000000, T: 9024, Avg. loss: 0.097083\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 20.13, NNZs: 1390, Bias: 0.000000, T: 11280, Avg. loss: 0.089638\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 21.69, NNZs: 1187, Bias: 0.000000, T: 13536, Avg. loss: 0.086266\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 165.68, NNZs: 16478, Bias: 0.000000, T: 2256, Avg. loss: 3.405557\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 6152.27, NNZs: 24155, Bias: 0.000000, T: 4512, Avg. loss: 3488.886580\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 307088.78, NNZs: 24878, Bias: 0.000000, T: 6768, Avg. loss: 14123513.722426\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4516924.17, NNZs: 24921, Bias: 0.000000, T: 9024, Avg. loss: 4423115229.200987\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 87101628.03, NNZs: 24921, Bias: 0.000000, T: 11280, Avg. loss: 1493086310399.052002\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1212676518.99, NNZs: 24921, Bias: 0.000000, T: 13536, Avg. loss: 259069333791951.593750\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 6 epochs took 0.05 seconds\n",
      "[CV 3/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.24457156361183285, clf__eta0=0.332929742792607, clf__fit_intercept=False, clf__l1_ratio=0.920539731041378, clf__learning_rate=constant, clf__loss=squared_error, clf__max_iter=100, clf__penalty=l1, clf__power_t=0.5734177157821045, clf__shuffle=True, clf__tol=0.6492274795888617, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.183 total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 16.83, NNZs: 7688, Bias: 0.000000, T: 2256, Avg. loss: 0.183215\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 21.71, NNZs: 4546, Bias: 0.000000, T: 4512, Avg. loss: 0.085070\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 25.40, NNZs: 3442, Bias: 0.000000, T: 6768, Avg. loss: 0.067768\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 28.17, NNZs: 2923, Bias: 0.000000, T: 9024, Avg. loss: 0.060015\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 30.75, NNZs: 2605, Bias: 0.000000, T: 11280, Avg. loss: 0.055732\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 32.84, NNZs: 2250, Bias: 0.000000, T: 13536, Avg. loss: 0.052185\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 15.31, NNZs: 7175, Bias: 0.000000, T: 2256, Avg. loss: 0.140399\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 20.33, NNZs: 4332, Bias: 0.000000, T: 4512, Avg. loss: 0.064624\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 23.60, NNZs: 3196, Bias: 0.000000, T: 6768, Avg. loss: 0.052183\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 26.32, NNZs: 2698, Bias: 0.000000, T: 9024, Avg. loss: 0.046396\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 28.57, NNZs: 2425, Bias: 0.000000, T: 11280, Avg. loss: 0.042865\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 30.74, NNZs: 2124, Bias: 0.000000, T: 13536, Avg. loss: 0.041021\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 10.73, NNZs: 3735, Bias: 0.000000, T: 2256, Avg. loss: 0.220000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 13.94, NNZs: 2094, Bias: 0.000000, T: 4512, Avg. loss: 0.118960\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 16.26, NNZs: 1655, Bias: 0.000000, T: 6768, Avg. loss: 0.102370\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 18.15, NNZs: 1391, Bias: 0.000000, T: 9024, Avg. loss: 0.094589\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 19.86, NNZs: 1238, Bias: 0.000000, T: 11280, Avg. loss: 0.090148\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 21.38, NNZs: 1096, Bias: 0.000000, T: 13536, Avg. loss: 0.084645\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1652.57, NNZs: 24295, Bias: 0.000000, T: 2256, Avg. loss: 418.879326\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 34254.80, NNZs: 25227, Bias: 0.000000, T: 4512, Avg. loss: 164652.232035\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 8182501.43, NNZs: 25352, Bias: 0.000000, T: 6768, Avg. loss: 6850744899.214660\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1036449651.43, NNZs: 25353, Bias: 0.000000, T: 9024, Avg. loss: 72378984785832.437500\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 38017039014.72, NNZs: 25353, Bias: 0.000000, T: 11280, Avg. loss: 82452237553229328.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 996261821734.36, NNZs: 25353, Bias: 0.000000, T: 13536, Avg. loss: 144734150869554626560.000000\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 6 epochs took 0.05 seconds\n",
      "[CV 4/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.24457156361183285, clf__eta0=0.332929742792607, clf__fit_intercept=False, clf__l1_ratio=0.920539731041378, clf__learning_rate=constant, clf__loss=squared_error, clf__max_iter=100, clf__penalty=l1, clf__power_t=0.5734177157821045, clf__shuffle=True, clf__tol=0.6492274795888617, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.209 total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 16.70, NNZs: 7947, Bias: 0.000000, T: 2256, Avg. loss: 0.185925\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 21.90, NNZs: 4825, Bias: 0.000000, T: 4512, Avg. loss: 0.086221\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 25.51, NNZs: 3641, Bias: 0.000000, T: 6768, Avg. loss: 0.068865\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 28.38, NNZs: 2985, Bias: 0.000000, T: 9024, Avg. loss: 0.060689\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 30.90, NNZs: 2598, Bias: 0.000000, T: 11280, Avg. loss: 0.056086\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 33.03, NNZs: 2319, Bias: 0.000000, T: 13536, Avg. loss: 0.052721\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 6 epochs took 0.05 seconds\n",
      "-- Epoch 1\n",
      "Norm: 15.60, NNZs: 7219, Bias: 0.000000, T: 2256, Avg. loss: 0.138406\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 20.18, NNZs: 4299, Bias: 0.000000, T: 4512, Avg. loss: 0.064038\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 23.43, NNZs: 3305, Bias: 0.000000, T: 6768, Avg. loss: 0.052090\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 26.21, NNZs: 2808, Bias: 0.000000, T: 9024, Avg. loss: 0.045934\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 28.54, NNZs: 2489, Bias: 0.000000, T: 11280, Avg. loss: 0.042573\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 30.69, NNZs: 2300, Bias: 0.000000, T: 13536, Avg. loss: 0.040153\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 6 epochs took 0.05 seconds\n",
      "-- Epoch 1\n",
      "Norm: 10.58, NNZs: 3897, Bias: 0.000000, T: 2256, Avg. loss: 0.215841\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 13.82, NNZs: 2254, Bias: 0.000000, T: 4512, Avg. loss: 0.117871\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 16.14, NNZs: 1755, Bias: 0.000000, T: 6768, Avg. loss: 0.103308\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 18.08, NNZs: 1527, Bias: 0.000000, T: 9024, Avg. loss: 0.095199\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 19.81, NNZs: 1387, Bias: 0.000000, T: 11280, Avg. loss: 0.089566\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 21.33, NNZs: 1262, Bias: 0.000000, T: 13536, Avg. loss: 0.085979\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.05 seconds\n",
      "-- Epoch 1\n",
      "Norm: 158.01, NNZs: 18321, Bias: 0.000000, T: 2256, Avg. loss: 3.818400\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 3735.35, NNZs: 24153, Bias: 0.000000, T: 4512, Avg. loss: 2262.991211\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 179998.72, NNZs: 25197, Bias: 0.000000, T: 6768, Avg. loss: 6778683.180115\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3243878.56, NNZs: 25269, Bias: 0.000000, T: 9024, Avg. loss: 3062024267.754453\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 42873037.96, NNZs: 25269, Bias: 0.000000, T: 11280, Avg. loss: 552893229944.591919\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 934299336.37, NNZs: 25269, Bias: 0.000000, T: 13536, Avg. loss: 133180022896161.421875\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 6 epochs took 0.06 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.24457156361183285, clf__eta0=0.332929742792607, clf__fit_intercept=False, clf__l1_ratio=0.920539731041378, clf__learning_rate=constant, clf__loss=squared_error, clf__max_iter=100, clf__penalty=l1, clf__power_t=0.5734177157821045, clf__shuffle=True, clf__tol=0.6492274795888617, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.261 total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 1.47, NNZs: 44500, Bias: -0.096013, T: 2256, Avg. loss: 0.186186\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2.03, NNZs: 44500, Bias: -0.134260, T: 4512, Avg. loss: 0.156410\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.44, NNZs: 44500, Bias: -0.162902, T: 6768, Avg. loss: 0.138377\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.74, NNZs: 44500, Bias: -0.185636, T: 9024, Avg. loss: 0.125636\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.98, NNZs: 44500, Bias: -0.204174, T: 11280, Avg. loss: 0.116556\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.16, NNZs: 44500, Bias: -0.219548, T: 13536, Avg. loss: 0.109935\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.53, NNZs: 44500, Bias: -0.099707, T: 2256, Avg. loss: 0.180721\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2.14, NNZs: 44500, Bias: -0.141084, T: 4512, Avg. loss: 0.145922\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.60, NNZs: 44500, Bias: -0.172385, T: 6768, Avg. loss: 0.124098\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.94, NNZs: 44500, Bias: -0.197178, T: 9024, Avg. loss: 0.108510\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3.19, NNZs: 44500, Bias: -0.216889, T: 11280, Avg. loss: 0.097888\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.38, NNZs: 44500, Bias: -0.232707, T: 13536, Avg. loss: 0.090768\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.24, NNZs: 44500, Bias: 0.070150, T: 2256, Avg. loss: 0.198961\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.77, NNZs: 44500, Bias: 0.094877, T: 4512, Avg. loss: 0.175583\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.18, NNZs: 44500, Bias: 0.113565, T: 6768, Avg. loss: 0.160875\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.53, NNZs: 44500, Bias: 0.129267, T: 9024, Avg. loss: 0.148926\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.85, NNZs: 44500, Bias: 0.143170, T: 11280, Avg. loss: 0.138618\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.12, NNZs: 44500, Bias: 0.156060, T: 13536, Avg. loss: 0.129748\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.95, NNZs: 44500, Bias: -0.117505, T: 2256, Avg. loss: 0.148212\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2.62, NNZs: 44500, Bias: -0.163839, T: 4512, Avg. loss: 0.085928\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.99, NNZs: 44500, Bias: -0.194039, T: 6768, Avg. loss: 0.062421\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3.22, NNZs: 44500, Bias: -0.216098, T: 9024, Avg. loss: 0.049834\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3.39, NNZs: 44500, Bias: -0.233265, T: 11280, Avg. loss: 0.041905\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.51, NNZs: 44500, Bias: -0.247171, T: 13536, Avg. loss: 0.036457\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 1/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.2527955528897454, clf__eta0=0.4377192284389271, clf__fit_intercept=True, clf__l1_ratio=0.6515110441465675, clf__learning_rate=invscaling, clf__loss=huber, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.47239053945705856, clf__shuffle=False, clf__tol=0.9089234089706554, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.224 total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 1.29, NNZs: 45400, Bias: -0.090128, T: 2256, Avg. loss: 0.191275\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.83, NNZs: 45400, Bias: -0.128029, T: 4512, Avg. loss: 0.163131\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.24, NNZs: 45400, Bias: -0.156699, T: 6768, Avg. loss: 0.145559\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.54, NNZs: 45400, Bias: -0.179693, T: 9024, Avg. loss: 0.132911\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.77, NNZs: 45400, Bias: -0.198751, T: 11280, Avg. loss: 0.123713\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.96, NNZs: 45400, Bias: -0.214871, T: 13536, Avg. loss: 0.116762\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.31, NNZs: 45400, Bias: -0.092221, T: 2256, Avg. loss: 0.188421\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.90, NNZs: 45400, Bias: -0.133383, T: 4512, Avg. loss: 0.155508\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.35, NNZs: 45400, Bias: -0.165161, T: 6768, Avg. loss: 0.134200\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.71, NNZs: 45400, Bias: -0.191198, T: 9024, Avg. loss: 0.117786\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.99, NNZs: 45400, Bias: -0.212586, T: 11280, Avg. loss: 0.105719\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.21, NNZs: 45400, Bias: -0.230200, T: 13536, Avg. loss: 0.097188\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.17, NNZs: 45400, Bias: 0.059552, T: 2256, Avg. loss: 0.200155\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.68, NNZs: 45400, Bias: 0.083715, T: 4512, Avg. loss: 0.178791\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.09, NNZs: 45400, Bias: 0.102171, T: 6768, Avg. loss: 0.165015\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.43, NNZs: 45400, Bias: 0.117854, T: 9024, Avg. loss: 0.153887\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.71, NNZs: 45400, Bias: 0.132142, T: 11280, Avg. loss: 0.144773\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.96, NNZs: 45400, Bias: 0.145522, T: 13536, Avg. loss: 0.137265\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.98, NNZs: 45400, Bias: -0.119266, T: 2256, Avg. loss: 0.144531\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2.59, NNZs: 45400, Bias: -0.164204, T: 4512, Avg. loss: 0.087908\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.92, NNZs: 45400, Bias: -0.193904, T: 6768, Avg. loss: 0.066766\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3.13, NNZs: 45400, Bias: -0.216069, T: 9024, Avg. loss: 0.054845\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3.29, NNZs: 45400, Bias: -0.233678, T: 11280, Avg. loss: 0.046999\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.41, NNZs: 45400, Bias: -0.248236, T: 13536, Avg. loss: 0.041389\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 2/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.2527955528897454, clf__eta0=0.4377192284389271, clf__fit_intercept=True, clf__l1_ratio=0.6515110441465675, clf__learning_rate=invscaling, clf__loss=huber, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.47239053945705856, clf__shuffle=False, clf__tol=0.9089234089706554, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.324 total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 1.28, NNZs: 45981, Bias: -0.090687, T: 2256, Avg. loss: 0.191351\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.81, NNZs: 45981, Bias: -0.128481, T: 4512, Avg. loss: 0.163752\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.21, NNZs: 45981, Bias: -0.157135, T: 6768, Avg. loss: 0.146464\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.51, NNZs: 45981, Bias: -0.180215, T: 9024, Avg. loss: 0.133958\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.74, NNZs: 45981, Bias: -0.199380, T: 11280, Avg. loss: 0.124770\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.93, NNZs: 45981, Bias: -0.215621, T: 13536, Avg. loss: 0.117796\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.30, NNZs: 45981, Bias: -0.091709, T: 2256, Avg. loss: 0.188273\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.89, NNZs: 45981, Bias: -0.132638, T: 4512, Avg. loss: 0.155401\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.35, NNZs: 45981, Bias: -0.164281, T: 6768, Avg. loss: 0.133964\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.71, NNZs: 45981, Bias: -0.190105, T: 9024, Avg. loss: 0.117552\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.99, NNZs: 45981, Bias: -0.211226, T: 11280, Avg. loss: 0.105680\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.20, NNZs: 45981, Bias: -0.228598, T: 13536, Avg. loss: 0.097365\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.16, NNZs: 45981, Bias: 0.059778, T: 2256, Avg. loss: 0.200234\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.67, NNZs: 45981, Bias: 0.083621, T: 4512, Avg. loss: 0.179390\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.07, NNZs: 45981, Bias: 0.101914, T: 6768, Avg. loss: 0.165891\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.40, NNZs: 45981, Bias: 0.117531, T: 9024, Avg. loss: 0.154995\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.69, NNZs: 45981, Bias: 0.131806, T: 11280, Avg. loss: 0.146111\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.92, NNZs: 45981, Bias: 0.145180, T: 13536, Avg. loss: 0.138788\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.99, NNZs: 45981, Bias: -0.119385, T: 2256, Avg. loss: 0.144362\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2.60, NNZs: 45981, Bias: -0.164308, T: 4512, Avg. loss: 0.087690\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.92, NNZs: 45981, Bias: -0.193813, T: 6768, Avg. loss: 0.066703\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3.13, NNZs: 45981, Bias: -0.215763, T: 9024, Avg. loss: 0.054973\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3.28, NNZs: 45981, Bias: -0.233183, T: 11280, Avg. loss: 0.047283\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.40, NNZs: 45981, Bias: -0.247618, T: 13536, Avg. loss: 0.041779\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 3/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.2527955528897454, clf__eta0=0.4377192284389271, clf__fit_intercept=True, clf__l1_ratio=0.6515110441465675, clf__learning_rate=invscaling, clf__loss=huber, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.47239053945705856, clf__shuffle=False, clf__tol=0.9089234089706554, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.350 total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 1.27, NNZs: 47077, Bias: -0.089977, T: 2256, Avg. loss: 0.191477\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.82, NNZs: 47077, Bias: -0.127797, T: 4512, Avg. loss: 0.163194\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.23, NNZs: 47077, Bias: -0.156688, T: 6768, Avg. loss: 0.145258\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.54, NNZs: 47077, Bias: -0.179979, T: 9024, Avg. loss: 0.131974\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.79, NNZs: 47077, Bias: -0.199295, T: 11280, Avg. loss: 0.122205\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.99, NNZs: 47077, Bias: -0.215591, T: 13536, Avg. loss: 0.114801\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.32, NNZs: 47077, Bias: -0.092564, T: 2256, Avg. loss: 0.187378\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.92, NNZs: 47077, Bias: -0.133566, T: 4512, Avg. loss: 0.153754\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.39, NNZs: 47077, Bias: -0.165230, T: 6768, Avg. loss: 0.131818\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.75, NNZs: 47077, Bias: -0.190985, T: 9024, Avg. loss: 0.115110\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3.03, NNZs: 47077, Bias: -0.212008, T: 11280, Avg. loss: 0.103023\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.24, NNZs: 47077, Bias: -0.229194, T: 13536, Avg. loss: 0.094578\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.18, NNZs: 47077, Bias: 0.059604, T: 2256, Avg. loss: 0.199256\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.71, NNZs: 47077, Bias: 0.083496, T: 4512, Avg. loss: 0.177100\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.13, NNZs: 47077, Bias: 0.101830, T: 6768, Avg. loss: 0.162675\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.47, NNZs: 47077, Bias: 0.117622, T: 9024, Avg. loss: 0.151136\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.76, NNZs: 47077, Bias: 0.132108, T: 11280, Avg. loss: 0.141881\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.00, NNZs: 47077, Bias: 0.145708, T: 13536, Avg. loss: 0.134264\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.98, NNZs: 47077, Bias: -0.119113, T: 2256, Avg. loss: 0.144156\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2.59, NNZs: 47077, Bias: -0.163736, T: 4512, Avg. loss: 0.087067\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.92, NNZs: 47077, Bias: -0.193298, T: 6768, Avg. loss: 0.065669\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3.14, NNZs: 47077, Bias: -0.215387, T: 9024, Avg. loss: 0.053362\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3.30, NNZs: 47077, Bias: -0.232904, T: 11280, Avg. loss: 0.045222\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.43, NNZs: 47077, Bias: -0.247314, T: 13536, Avg. loss: 0.039442\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 4/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.2527955528897454, clf__eta0=0.4377192284389271, clf__fit_intercept=True, clf__l1_ratio=0.6515110441465675, clf__learning_rate=invscaling, clf__loss=huber, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.47239053945705856, clf__shuffle=False, clf__tol=0.9089234089706554, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.361 total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 1.27, NNZs: 46144, Bias: -0.091760, T: 2256, Avg. loss: 0.192085\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.80, NNZs: 46144, Bias: -0.129776, T: 4512, Avg. loss: 0.164610\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.20, NNZs: 46144, Bias: -0.158752, T: 6768, Avg. loss: 0.147374\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.50, NNZs: 46144, Bias: -0.182242, T: 9024, Avg. loss: 0.134478\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.75, NNZs: 46144, Bias: -0.201844, T: 11280, Avg. loss: 0.124871\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.94, NNZs: 46144, Bias: -0.218491, T: 13536, Avg. loss: 0.117507\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.30, NNZs: 46144, Bias: -0.093071, T: 2256, Avg. loss: 0.188371\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.89, NNZs: 46144, Bias: -0.134218, T: 4512, Avg. loss: 0.155461\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.34, NNZs: 46144, Bias: -0.165956, T: 6768, Avg. loss: 0.134090\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.70, NNZs: 46144, Bias: -0.191902, T: 9024, Avg. loss: 0.117730\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.98, NNZs: 46144, Bias: -0.213202, T: 11280, Avg. loss: 0.105788\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.20, NNZs: 46144, Bias: -0.230792, T: 13536, Avg. loss: 0.097313\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.15, NNZs: 46144, Bias: 0.062108, T: 2256, Avg. loss: 0.200080\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.67, NNZs: 46144, Bias: 0.086398, T: 4512, Avg. loss: 0.178215\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.08, NNZs: 46144, Bias: 0.104929, T: 6768, Avg. loss: 0.163963\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.43, NNZs: 46144, Bias: 0.120674, T: 9024, Avg. loss: 0.152422\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.72, NNZs: 46144, Bias: 0.134942, T: 11280, Avg. loss: 0.142896\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.97, NNZs: 46144, Bias: 0.148272, T: 13536, Avg. loss: 0.135007\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.95, NNZs: 46144, Bias: -0.119490, T: 2256, Avg. loss: 0.145853\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2.55, NNZs: 46144, Bias: -0.164627, T: 4512, Avg. loss: 0.088732\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.89, NNZs: 46144, Bias: -0.194542, T: 6768, Avg. loss: 0.067424\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3.11, NNZs: 46144, Bias: -0.216970, T: 9024, Avg. loss: 0.055299\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3.27, NNZs: 46144, Bias: -0.234894, T: 11280, Avg. loss: 0.047183\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.40, NNZs: 46144, Bias: -0.249759, T: 13536, Avg. loss: 0.041305\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 5/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.2527955528897454, clf__eta0=0.4377192284389271, clf__fit_intercept=True, clf__l1_ratio=0.6515110441465675, clf__learning_rate=invscaling, clf__loss=huber, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.47239053945705856, clf__shuffle=False, clf__tol=0.9089234089706554, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.357 total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 92.82, NNZs: 43873, Bias: -0.967746, T: 2256, Avg. loss: 0.871099\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 42.03, NNZs: 44209, Bias: -0.911249, T: 4512, Avg. loss: 0.925158\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 36.00, NNZs: 44372, Bias: -1.050408, T: 6768, Avg. loss: 0.270582\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 29.09, NNZs: 44396, Bias: -0.989677, T: 9024, Avg. loss: 0.167988\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 26.20, NNZs: 44395, Bias: -0.989998, T: 11280, Avg. loss: 0.076183\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 24.45, NNZs: 44410, Bias: -0.975975, T: 13536, Avg. loss: 0.028493\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 90.68, NNZs: 43755, Bias: -0.889104, T: 2256, Avg. loss: 0.846967\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 42.67, NNZs: 44236, Bias: -0.782093, T: 4512, Avg. loss: 0.895064\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 33.09, NNZs: 44353, Bias: -0.932642, T: 6768, Avg. loss: 0.287933\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 26.39, NNZs: 44363, Bias: -0.911903, T: 9024, Avg. loss: 0.171977\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 23.41, NNZs: 44351, Bias: -0.919990, T: 11280, Avg. loss: 0.070969\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 21.11, NNZs: 44365, Bias: -0.904783, T: 13536, Avg. loss: 0.028041\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 91.30, NNZs: 43722, Bias: 1.270618, T: 2256, Avg. loss: 0.855407\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 40.82, NNZs: 44286, Bias: 0.855904, T: 4512, Avg. loss: 0.937268\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 33.67, NNZs: 44375, Bias: 1.022254, T: 6768, Avg. loss: 0.274745\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 25.40, NNZs: 44376, Bias: 0.957692, T: 9024, Avg. loss: 0.164815\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 22.11, NNZs: 44385, Bias: 1.030806, T: 11280, Avg. loss: 0.066986\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 19.94, NNZs: 44405, Bias: 0.986601, T: 13536, Avg. loss: 0.023795\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 90.01, NNZs: 43716, Bias: -0.890552, T: 2256, Avg. loss: 0.783497\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 38.30, NNZs: 44214, Bias: -0.798696, T: 4512, Avg. loss: 0.938694\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 27.47, NNZs: 44307, Bias: -0.896273, T: 6768, Avg. loss: 0.251600\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 18.56, NNZs: 44300, Bias: -0.926368, T: 9024, Avg. loss: 0.150915\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 13.00, NNZs: 44238, Bias: -0.933580, T: 11280, Avg. loss: 0.060429\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 9.88, NNZs: 44241, Bias: -0.937775, T: 13536, Avg. loss: 0.020148\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 8.63, NNZs: 44209, Bias: -0.909949, T: 15792, Avg. loss: 0.004781\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 7 epochs took 0.03 seconds\n",
      "[CV 1/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.3241670976844645, clf__eta0=0.9631840511405841, clf__fit_intercept=True, clf__l1_ratio=0.5912641309775509, clf__learning_rate=optimal, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.6710686638981408, clf__shuffle=True, clf__tol=0.09654933943827881, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.684 total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 91.47, NNZs: 44347, Bias: -0.901867, T: 2256, Avg. loss: 0.875592\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 43.13, NNZs: 45071, Bias: -1.083904, T: 4512, Avg. loss: 0.889152\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 35.79, NNZs: 45222, Bias: -1.065603, T: 6768, Avg. loss: 0.306739\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 28.08, NNZs: 45201, Bias: -0.941546, T: 9024, Avg. loss: 0.167685\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 26.40, NNZs: 45206, Bias: -1.030148, T: 11280, Avg. loss: 0.070846\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 24.63, NNZs: 45234, Bias: -1.004267, T: 13536, Avg. loss: 0.026518\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 23.86, NNZs: 45237, Bias: -1.014786, T: 15792, Avg. loss: 0.010351\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 7 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 90.51, NNZs: 44694, Bias: -0.884272, T: 2256, Avg. loss: 0.849136\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 41.89, NNZs: 45203, Bias: -0.970506, T: 4512, Avg. loss: 0.925187\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 32.56, NNZs: 45347, Bias: -0.872891, T: 6768, Avg. loss: 0.266210\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 25.92, NNZs: 45329, Bias: -0.915577, T: 9024, Avg. loss: 0.164720\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 22.00, NNZs: 45317, Bias: -0.905425, T: 11280, Avg. loss: 0.066199\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 20.48, NNZs: 45336, Bias: -0.965729, T: 13536, Avg. loss: 0.022228\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 91.34, NNZs: 44499, Bias: 0.984020, T: 2256, Avg. loss: 0.867800\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 40.46, NNZs: 45136, Bias: 0.927769, T: 4512, Avg. loss: 0.918868\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 32.48, NNZs: 45336, Bias: 1.011327, T: 6768, Avg. loss: 0.266630\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 25.14, NNZs: 45355, Bias: 0.908476, T: 9024, Avg. loss: 0.162139\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 21.48, NNZs: 45352, Bias: 1.037552, T: 11280, Avg. loss: 0.068693\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 19.89, NNZs: 45351, Bias: 0.985177, T: 13536, Avg. loss: 0.024432\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 89.05, NNZs: 44592, Bias: -0.907212, T: 2256, Avg. loss: 0.804157\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 39.46, NNZs: 45146, Bias: -0.873236, T: 4512, Avg. loss: 0.923901\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 27.95, NNZs: 45248, Bias: -0.997243, T: 6768, Avg. loss: 0.252616\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 18.81, NNZs: 45230, Bias: -0.945286, T: 9024, Avg. loss: 0.152473\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 13.11, NNZs: 45221, Bias: -0.884226, T: 11280, Avg. loss: 0.057849\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 10.22, NNZs: 45221, Bias: -0.926963, T: 13536, Avg. loss: 0.017143\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 8.83, NNZs: 45203, Bias: -0.893300, T: 15792, Avg. loss: 0.006164\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 8.23, NNZs: 45200, Bias: -0.883501, T: 18048, Avg. loss: 0.001412\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 7.65, NNZs: 45202, Bias: -0.894424, T: 20304, Avg. loss: 0.000283\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 7.36, NNZs: 45204, Bias: -0.890088, T: 22560, Avg. loss: 0.000422\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 7.13, NNZs: 45206, Bias: -0.890164, T: 24816, Avg. loss: 0.000531\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 11 epochs took 0.05 seconds\n",
      "[CV 2/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.3241670976844645, clf__eta0=0.9631840511405841, clf__fit_intercept=True, clf__l1_ratio=0.5912641309775509, clf__learning_rate=optimal, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.6710686638981408, clf__shuffle=True, clf__tol=0.09654933943827881, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.703 total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 92.72, NNZs: 45285, Bias: -1.224134, T: 2256, Avg. loss: 0.871268\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 41.82, NNZs: 45850, Bias: -0.867184, T: 4512, Avg. loss: 0.929433\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 35.69, NNZs: 45970, Bias: -1.020781, T: 6768, Avg. loss: 0.282831\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 29.03, NNZs: 45934, Bias: -1.052589, T: 9024, Avg. loss: 0.166274\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 26.76, NNZs: 45950, Bias: -1.008664, T: 11280, Avg. loss: 0.071804\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 24.34, NNZs: 45964, Bias: -1.067937, T: 13536, Avg. loss: 0.028482\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 91.57, NNZs: 45287, Bias: -0.826728, T: 2256, Avg. loss: 0.852205\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 42.14, NNZs: 45783, Bias: -0.742047, T: 4512, Avg. loss: 0.914541\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 32.77, NNZs: 45919, Bias: -0.977303, T: 6768, Avg. loss: 0.285459\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 26.46, NNZs: 45948, Bias: -0.894615, T: 9024, Avg. loss: 0.166648\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 23.13, NNZs: 45958, Bias: -0.947554, T: 11280, Avg. loss: 0.069170\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 21.12, NNZs: 45955, Bias: -0.896798, T: 13536, Avg. loss: 0.027249\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 20.07, NNZs: 45959, Bias: -0.904930, T: 15792, Avg. loss: 0.008206\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 19.53, NNZs: 45962, Bias: -0.911043, T: 18048, Avg. loss: 0.003754\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 8 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 89.66, NNZs: 45178, Bias: 0.985698, T: 2256, Avg. loss: 0.850512\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 41.51, NNZs: 45883, Bias: 0.917509, T: 4512, Avg. loss: 0.895623\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 33.89, NNZs: 45953, Bias: 1.113638, T: 6768, Avg. loss: 0.286891\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 25.63, NNZs: 45917, Bias: 1.018347, T: 9024, Avg. loss: 0.170014\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 22.12, NNZs: 45964, Bias: 1.007315, T: 11280, Avg. loss: 0.063761\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 20.44, NNZs: 45981, Bias: 1.042519, T: 13536, Avg. loss: 0.024563\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 88.28, NNZs: 44518, Bias: -1.139605, T: 2256, Avg. loss: 0.806131\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 40.15, NNZs: 45762, Bias: -0.963799, T: 4512, Avg. loss: 0.892082\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 27.05, NNZs: 45863, Bias: -0.980375, T: 6768, Avg. loss: 0.259752\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 17.77, NNZs: 45855, Bias: -0.949561, T: 9024, Avg. loss: 0.151855\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 12.31, NNZs: 45821, Bias: -0.957692, T: 11280, Avg. loss: 0.056518\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 9.58, NNZs: 45804, Bias: -0.936128, T: 13536, Avg. loss: 0.017384\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 8.00, NNZs: 45780, Bias: -0.925272, T: 15792, Avg. loss: 0.004556\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 7 epochs took 0.03 seconds\n",
      "[CV 3/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.3241670976844645, clf__eta0=0.9631840511405841, clf__fit_intercept=True, clf__l1_ratio=0.5912641309775509, clf__learning_rate=optimal, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.6710686638981408, clf__shuffle=True, clf__tol=0.09654933943827881, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.703 total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 91.93, NNZs: 46474, Bias: -1.130912, T: 2256, Avg. loss: 0.875835\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 42.35, NNZs: 46972, Bias: -0.848376, T: 4512, Avg. loss: 0.931504\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 36.33, NNZs: 47082, Bias: -1.066728, T: 6768, Avg. loss: 0.289186\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 29.02, NNZs: 47110, Bias: -1.035353, T: 9024, Avg. loss: 0.172162\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 26.09, NNZs: 47096, Bias: -1.014404, T: 11280, Avg. loss: 0.070269\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 24.49, NNZs: 47110, Bias: -1.001397, T: 13536, Avg. loss: 0.029974\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 90.74, NNZs: 46417, Bias: -1.007793, T: 2256, Avg. loss: 0.855228\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 42.08, NNZs: 46884, Bias: -0.601085, T: 4512, Avg. loss: 0.904027\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 32.88, NNZs: 47001, Bias: -0.865728, T: 6768, Avg. loss: 0.268605\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 26.39, NNZs: 47013, Bias: -0.937195, T: 9024, Avg. loss: 0.170858\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 23.23, NNZs: 47035, Bias: -0.882290, T: 11280, Avg. loss: 0.071774\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 21.59, NNZs: 47033, Bias: -0.913646, T: 13536, Avg. loss: 0.027013\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 91.14, NNZs: 46359, Bias: 0.772927, T: 2256, Avg. loss: 0.852262\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 41.77, NNZs: 46917, Bias: 0.816602, T: 4512, Avg. loss: 0.900113\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 32.89, NNZs: 47054, Bias: 1.020574, T: 6768, Avg. loss: 0.289973\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 25.51, NNZs: 47048, Bias: 0.978139, T: 9024, Avg. loss: 0.164014\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 21.97, NNZs: 47083, Bias: 0.983435, T: 11280, Avg. loss: 0.072750\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 19.82, NNZs: 47085, Bias: 1.019737, T: 13536, Avg. loss: 0.027085\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 89.62, NNZs: 46178, Bias: -0.959005, T: 2256, Avg. loss: 0.783501\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 39.06, NNZs: 46784, Bias: -0.794297, T: 4512, Avg. loss: 0.919754\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 28.02, NNZs: 46984, Bias: -0.936169, T: 6768, Avg. loss: 0.247428\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 18.31, NNZs: 46945, Bias: -0.957123, T: 9024, Avg. loss: 0.161439\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 12.50, NNZs: 46890, Bias: -0.945951, T: 11280, Avg. loss: 0.062550\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 9.97, NNZs: 46891, Bias: -0.905722, T: 13536, Avg. loss: 0.018208\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 4/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.3241670976844645, clf__eta0=0.9631840511405841, clf__fit_intercept=True, clf__l1_ratio=0.5912641309775509, clf__learning_rate=optimal, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.6710686638981408, clf__shuffle=True, clf__tol=0.09654933943827881, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.716 total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 93.42, NNZs: 45428, Bias: -0.893555, T: 2256, Avg. loss: 0.872670\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 42.19, NNZs: 45876, Bias: -1.037317, T: 4512, Avg. loss: 0.932646\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 36.25, NNZs: 46027, Bias: -0.996327, T: 6768, Avg. loss: 0.273939\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 28.47, NNZs: 46038, Bias: -0.956558, T: 9024, Avg. loss: 0.170355\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 25.84, NNZs: 46049, Bias: -1.010600, T: 11280, Avg. loss: 0.070464\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 24.37, NNZs: 46048, Bias: -1.015966, T: 13536, Avg. loss: 0.028869\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 90.57, NNZs: 45179, Bias: -1.039606, T: 2256, Avg. loss: 0.864622\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 41.16, NNZs: 45808, Bias: -0.815602, T: 4512, Avg. loss: 0.906787\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 32.99, NNZs: 45925, Bias: -0.913444, T: 6768, Avg. loss: 0.270989\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 26.02, NNZs: 45920, Bias: -0.971875, T: 9024, Avg. loss: 0.166380\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 22.96, NNZs: 45954, Bias: -0.946007, T: 11280, Avg. loss: 0.070893\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 21.08, NNZs: 45951, Bias: -0.909223, T: 13536, Avg. loss: 0.026421\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 20.10, NNZs: 45952, Bias: -0.929202, T: 15792, Avg. loss: 0.009697\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 19.72, NNZs: 45962, Bias: -0.934595, T: 18048, Avg. loss: 0.004898\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 19.23, NNZs: 45965, Bias: -0.919939, T: 20304, Avg. loss: 0.003148\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 9 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 91.21, NNZs: 45165, Bias: 0.907870, T: 2256, Avg. loss: 0.866104\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 42.08, NNZs: 45866, Bias: 0.965134, T: 4512, Avg. loss: 0.901855\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 34.41, NNZs: 45967, Bias: 0.963759, T: 6768, Avg. loss: 0.282313\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 25.39, NNZs: 45994, Bias: 0.974982, T: 9024, Avg. loss: 0.168164\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 22.45, NNZs: 46028, Bias: 1.002375, T: 11280, Avg. loss: 0.073252\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 20.09, NNZs: 46025, Bias: 1.023592, T: 13536, Avg. loss: 0.023787\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 88.28, NNZs: 45229, Bias: -0.799408, T: 2256, Avg. loss: 0.783143\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 39.39, NNZs: 45858, Bias: -0.897815, T: 4512, Avg. loss: 0.909569\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 28.70, NNZs: 45984, Bias: -0.972143, T: 6768, Avg. loss: 0.255578\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 18.17, NNZs: 45953, Bias: -0.962558, T: 9024, Avg. loss: 0.161395\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 12.67, NNZs: 45904, Bias: -0.910036, T: 11280, Avg. loss: 0.055771\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 9.82, NNZs: 45884, Bias: -0.941041, T: 13536, Avg. loss: 0.018900\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 8.46, NNZs: 45868, Bias: -0.919832, T: 15792, Avg. loss: 0.004717\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 7.72, NNZs: 45871, Bias: -0.913606, T: 18048, Avg. loss: 0.001137\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 7.30, NNZs: 45871, Bias: -0.923547, T: 20304, Avg. loss: 0.000394\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 7.16, NNZs: 45881, Bias: -0.919214, T: 22560, Avg. loss: 0.000629\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 6.90, NNZs: 45883, Bias: -0.919158, T: 24816, Avg. loss: 0.000157\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 11 epochs took 0.05 seconds\n",
      "[CV 5/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.3241670976844645, clf__eta0=0.9631840511405841, clf__fit_intercept=True, clf__l1_ratio=0.5912641309775509, clf__learning_rate=optimal, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.6710686638981408, clf__shuffle=True, clf__tol=0.09654933943827881, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.694 total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 40.95, NNZs: 6009, Bias: 0.000000, T: 2256, Avg. loss: 0.230761\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 52.01, NNZs: 3282, Bias: 0.000000, T: 4512, Avg. loss: 0.085832\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 59.89, NNZs: 2472, Bias: 0.000000, T: 6768, Avg. loss: 0.059161\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 66.34, NNZs: 1933, Bias: 0.000000, T: 9024, Avg. loss: 0.048367\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 72.18, NNZs: 1692, Bias: 0.000000, T: 11280, Avg. loss: 0.041537\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 77.40, NNZs: 1495, Bias: 0.000000, T: 13536, Avg. loss: 0.036217\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 36.66, NNZs: 5264, Bias: 0.000000, T: 2256, Avg. loss: 0.175609\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 47.46, NNZs: 2929, Bias: 0.000000, T: 4512, Avg. loss: 0.064783\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 55.82, NNZs: 2320, Bias: 0.000000, T: 6768, Avg. loss: 0.045396\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 62.27, NNZs: 1892, Bias: 0.000000, T: 9024, Avg. loss: 0.035329\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 67.76, NNZs: 1608, Bias: 0.000000, T: 11280, Avg. loss: 0.029556\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 72.71, NNZs: 1453, Bias: 0.000000, T: 13536, Avg. loss: 0.024242\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 24.84, NNZs: 3242, Bias: 0.000000, T: 2256, Avg. loss: 0.221083\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 32.88, NNZs: 1769, Bias: 0.000000, T: 4512, Avg. loss: 0.114195\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 38.37, NNZs: 1347, Bias: 0.000000, T: 6768, Avg. loss: 0.091344\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 43.09, NNZs: 1138, Bias: 0.000000, T: 9024, Avg. loss: 0.077889\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 47.08, NNZs: 997, Bias: 0.000000, T: 11280, Avg. loss: 0.069758\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 50.69, NNZs: 848, Bias: 0.000000, T: 13536, Avg. loss: 0.064058\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 116.37, NNZs: 8523, Bias: 0.000000, T: 2256, Avg. loss: 0.654516\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 148.79, NNZs: 6147, Bias: 0.000000, T: 4512, Avg. loss: 0.315173\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 158.79, NNZs: 4562, Bias: 0.000000, T: 6768, Avg. loss: 0.087926\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 167.97, NNZs: 4085, Bias: 0.000000, T: 9024, Avg. loss: 0.194969\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 167.89, NNZs: 3104, Bias: 0.000000, T: 11280, Avg. loss: 0.034433\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 167.94, NNZs: 2440, Bias: 0.000000, T: 13536, Avg. loss: 0.012978\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 1/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.3509613152086368, clf__eta0=0.9934401124631351, clf__fit_intercept=False, clf__l1_ratio=0.5204998682261415, clf__learning_rate=constant, clf__loss=hinge, clf__max_iter=40, clf__penalty=l1, clf__power_t=0.5098574122392232, clf__shuffle=False, clf__tol=0.5563103350645606, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.690 total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 40.23, NNZs: 5768, Bias: 0.000000, T: 2256, Avg. loss: 0.217333\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 51.46, NNZs: 3237, Bias: 0.000000, T: 4512, Avg. loss: 0.085410\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 59.65, NNZs: 2428, Bias: 0.000000, T: 6768, Avg. loss: 0.063583\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 66.33, NNZs: 1957, Bias: 0.000000, T: 9024, Avg. loss: 0.051862\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 72.20, NNZs: 1666, Bias: 0.000000, T: 11280, Avg. loss: 0.044582\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 77.36, NNZs: 1489, Bias: 0.000000, T: 13536, Avg. loss: 0.038513\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 37.30, NNZs: 5524, Bias: 0.000000, T: 2256, Avg. loss: 0.174615\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 46.97, NNZs: 3054, Bias: 0.000000, T: 4512, Avg. loss: 0.055474\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 54.36, NNZs: 2303, Bias: 0.000000, T: 6768, Avg. loss: 0.040999\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 60.97, NNZs: 2004, Bias: 0.000000, T: 9024, Avg. loss: 0.034919\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 65.93, NNZs: 1637, Bias: 0.000000, T: 11280, Avg. loss: 0.029129\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 70.84, NNZs: 1464, Bias: 0.000000, T: 13536, Avg. loss: 0.025777\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 25.47, NNZs: 3149, Bias: 0.000000, T: 2256, Avg. loss: 0.246701\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 33.42, NNZs: 1746, Bias: 0.000000, T: 4512, Avg. loss: 0.110565\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 39.00, NNZs: 1288, Bias: 0.000000, T: 6768, Avg. loss: 0.086482\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 43.53, NNZs: 1079, Bias: 0.000000, T: 9024, Avg. loss: 0.074413\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 47.56, NNZs: 923, Bias: 0.000000, T: 11280, Avg. loss: 0.068008\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 51.11, NNZs: 815, Bias: 0.000000, T: 13536, Avg. loss: 0.063541\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 144.71, NNZs: 12756, Bias: 0.000000, T: 2256, Avg. loss: 1.287697\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 152.97, NNZs: 7085, Bias: 0.000000, T: 4512, Avg. loss: 0.151630\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 152.85, NNZs: 4996, Bias: 0.000000, T: 6768, Avg. loss: 0.051621\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 162.59, NNZs: 3860, Bias: 0.000000, T: 9024, Avg. loss: 0.076927\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 161.89, NNZs: 3033, Bias: 0.000000, T: 11280, Avg. loss: 0.068848\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 170.26, NNZs: 2891, Bias: 0.000000, T: 13536, Avg. loss: 0.176637\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 2/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.3509613152086368, clf__eta0=0.9934401124631351, clf__fit_intercept=False, clf__l1_ratio=0.5204998682261415, clf__learning_rate=constant, clf__loss=hinge, clf__max_iter=40, clf__penalty=l1, clf__power_t=0.5098574122392232, clf__shuffle=False, clf__tol=0.5563103350645606, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.712 total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 41.35, NNZs: 6269, Bias: 0.000000, T: 2256, Avg. loss: 0.237577\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 53.29, NNZs: 3603, Bias: 0.000000, T: 4512, Avg. loss: 0.093371\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 61.16, NNZs: 2633, Bias: 0.000000, T: 6768, Avg. loss: 0.062841\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 68.13, NNZs: 2076, Bias: 0.000000, T: 9024, Avg. loss: 0.055795\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 73.93, NNZs: 1823, Bias: 0.000000, T: 11280, Avg. loss: 0.046535\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 79.35, NNZs: 1646, Bias: 0.000000, T: 13536, Avg. loss: 0.041691\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 35.66, NNZs: 5474, Bias: 0.000000, T: 2256, Avg. loss: 0.188279\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 46.93, NNZs: 3039, Bias: 0.000000, T: 4512, Avg. loss: 0.068713\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 54.98, NNZs: 2333, Bias: 0.000000, T: 6768, Avg. loss: 0.046927\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 61.56, NNZs: 1916, Bias: 0.000000, T: 9024, Avg. loss: 0.038689\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 67.46, NNZs: 1697, Bias: 0.000000, T: 11280, Avg. loss: 0.031639\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 72.17, NNZs: 1476, Bias: 0.000000, T: 13536, Avg. loss: 0.028366\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 26.28, NNZs: 3559, Bias: 0.000000, T: 2256, Avg. loss: 0.263915\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 34.25, NNZs: 1881, Bias: 0.000000, T: 4512, Avg. loss: 0.122132\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 40.15, NNZs: 1399, Bias: 0.000000, T: 6768, Avg. loss: 0.096358\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 44.70, NNZs: 1162, Bias: 0.000000, T: 9024, Avg. loss: 0.086119\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 49.01, NNZs: 1045, Bias: 0.000000, T: 11280, Avg. loss: 0.078165\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 52.71, NNZs: 953, Bias: 0.000000, T: 13536, Avg. loss: 0.074180\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 126.67, NNZs: 10289, Bias: 0.000000, T: 2256, Avg. loss: 0.804892\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 144.66, NNZs: 6418, Bias: 0.000000, T: 4512, Avg. loss: 0.223658\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 155.11, NNZs: 4647, Bias: 0.000000, T: 6768, Avg. loss: 0.050511\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 154.90, NNZs: 3719, Bias: 0.000000, T: 9024, Avg. loss: 0.076198\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 165.16, NNZs: 3002, Bias: 0.000000, T: 11280, Avg. loss: 0.066033\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 164.53, NNZs: 2514, Bias: 0.000000, T: 13536, Avg. loss: 0.072526\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "[CV 3/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.3509613152086368, clf__eta0=0.9934401124631351, clf__fit_intercept=False, clf__l1_ratio=0.5204998682261415, clf__learning_rate=constant, clf__loss=hinge, clf__max_iter=40, clf__penalty=l1, clf__power_t=0.5098574122392232, clf__shuffle=False, clf__tol=0.5563103350645606, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.703 total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 41.37, NNZs: 6113, Bias: 0.000000, T: 2256, Avg. loss: 0.225719\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 52.32, NNZs: 3275, Bias: 0.000000, T: 4512, Avg. loss: 0.083196\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 60.30, NNZs: 2389, Bias: 0.000000, T: 6768, Avg. loss: 0.059091\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 66.69, NNZs: 1946, Bias: 0.000000, T: 9024, Avg. loss: 0.049690\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 72.65, NNZs: 1706, Bias: 0.000000, T: 11280, Avg. loss: 0.043318\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 77.88, NNZs: 1501, Bias: 0.000000, T: 13536, Avg. loss: 0.038383\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 36.17, NNZs: 5195, Bias: 0.000000, T: 2256, Avg. loss: 0.184760\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 47.15, NNZs: 2828, Bias: 0.000000, T: 4512, Avg. loss: 0.064286\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 54.99, NNZs: 2094, Bias: 0.000000, T: 6768, Avg. loss: 0.045433\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 61.35, NNZs: 1764, Bias: 0.000000, T: 9024, Avg. loss: 0.036714\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 67.12, NNZs: 1532, Bias: 0.000000, T: 11280, Avg. loss: 0.032002\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 72.10, NNZs: 1373, Bias: 0.000000, T: 13536, Avg. loss: 0.028396\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 26.58, NNZs: 3321, Bias: 0.000000, T: 2256, Avg. loss: 0.251191\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 34.06, NNZs: 1719, Bias: 0.000000, T: 4512, Avg. loss: 0.105873\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 39.53, NNZs: 1291, Bias: 0.000000, T: 6768, Avg. loss: 0.085459\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 44.05, NNZs: 1096, Bias: 0.000000, T: 9024, Avg. loss: 0.074203\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 47.89, NNZs: 877, Bias: 0.000000, T: 11280, Avg. loss: 0.068677\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 51.36, NNZs: 778, Bias: 0.000000, T: 13536, Avg. loss: 0.064619\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 128.88, NNZs: 10403, Bias: 0.000000, T: 2256, Avg. loss: 0.825198\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 148.20, NNZs: 6585, Bias: 0.000000, T: 4512, Avg. loss: 0.218664\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 168.62, NNZs: 5504, Bias: 0.000000, T: 6768, Avg. loss: 0.143814\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 168.08, NNZs: 4313, Bias: 0.000000, T: 9024, Avg. loss: 0.102799\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 168.06, NNZs: 3457, Bias: 0.000000, T: 11280, Avg. loss: 0.024570\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 168.15, NNZs: 2739, Bias: 0.000000, T: 13536, Avg. loss: 0.007504\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "[CV 4/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.3509613152086368, clf__eta0=0.9934401124631351, clf__fit_intercept=False, clf__l1_ratio=0.5204998682261415, clf__learning_rate=constant, clf__loss=hinge, clf__max_iter=40, clf__penalty=l1, clf__power_t=0.5098574122392232, clf__shuffle=False, clf__tol=0.5563103350645606, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.697 total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 41.43, NNZs: 6184, Bias: 0.000000, T: 2256, Avg. loss: 0.225840\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 52.75, NNZs: 3401, Bias: 0.000000, T: 4512, Avg. loss: 0.085810\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 60.86, NNZs: 2417, Bias: 0.000000, T: 6768, Avg. loss: 0.061649\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 67.35, NNZs: 1854, Bias: 0.000000, T: 9024, Avg. loss: 0.049423\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 73.14, NNZs: 1712, Bias: 0.000000, T: 11280, Avg. loss: 0.042904\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 78.39, NNZs: 1466, Bias: 0.000000, T: 13536, Avg. loss: 0.036862\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 36.76, NNZs: 5297, Bias: 0.000000, T: 2256, Avg. loss: 0.184684\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 47.92, NNZs: 2998, Bias: 0.000000, T: 4512, Avg. loss: 0.062945\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 55.45, NNZs: 2189, Bias: 0.000000, T: 6768, Avg. loss: 0.046351\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 62.00, NNZs: 1816, Bias: 0.000000, T: 9024, Avg. loss: 0.036764\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 67.55, NNZs: 1572, Bias: 0.000000, T: 11280, Avg. loss: 0.030626\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 72.16, NNZs: 1363, Bias: 0.000000, T: 13536, Avg. loss: 0.026899\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 25.54, NNZs: 3319, Bias: 0.000000, T: 2256, Avg. loss: 0.248503\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 33.39, NNZs: 1706, Bias: 0.000000, T: 4512, Avg. loss: 0.117744\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 38.78, NNZs: 1279, Bias: 0.000000, T: 6768, Avg. loss: 0.095832\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 43.41, NNZs: 1059, Bias: 0.000000, T: 9024, Avg. loss: 0.083084\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 47.35, NNZs: 928, Bias: 0.000000, T: 11280, Avg. loss: 0.075210\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 51.04, NNZs: 835, Bias: 0.000000, T: 13536, Avg. loss: 0.070284\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 145.70, NNZs: 11814, Bias: 0.000000, T: 2256, Avg. loss: 1.206310\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 155.13, NNZs: 7039, Bias: 0.000000, T: 4512, Avg. loss: 0.240644\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 163.81, NNZs: 5365, Bias: 0.000000, T: 6768, Avg. loss: 0.111714\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 163.81, NNZs: 4166, Bias: 0.000000, T: 9024, Avg. loss: 0.013667\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 163.89, NNZs: 3281, Bias: 0.000000, T: 11280, Avg. loss: 0.007812\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 163.96, NNZs: 2613, Bias: 0.000000, T: 13536, Avg. loss: 0.004734\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "[CV 5/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.3509613152086368, clf__eta0=0.9934401124631351, clf__fit_intercept=False, clf__l1_ratio=0.5204998682261415, clf__learning_rate=constant, clf__loss=hinge, clf__max_iter=40, clf__penalty=l1, clf__power_t=0.5098574122392232, clf__shuffle=False, clf__tol=0.5563103350645606, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.684 total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.25, NNZs: 24505, Bias: 0.000000, T: 2256, Avg. loss: 0.696591\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.33, NNZs: 24505, Bias: 0.000000, T: 4512, Avg. loss: 0.683292\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.40, NNZs: 24505, Bias: 0.000000, T: 6768, Avg. loss: 0.675593\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.45, NNZs: 24505, Bias: 0.000000, T: 9024, Avg. loss: 0.669180\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.50, NNZs: 24505, Bias: 0.000000, T: 11280, Avg. loss: 0.663806\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.54, NNZs: 24505, Bias: 0.000000, T: 13536, Avg. loss: 0.659206\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.31, NNZs: 24505, Bias: 0.000000, T: 2256, Avg. loss: 0.689617\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.41, NNZs: 24505, Bias: 0.000000, T: 4512, Avg. loss: 0.672809\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.49, NNZs: 24505, Bias: 0.000000, T: 6768, Avg. loss: 0.662605\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.56, NNZs: 24505, Bias: 0.000000, T: 9024, Avg. loss: 0.654526\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.62, NNZs: 24505, Bias: 0.000000, T: 11280, Avg. loss: 0.647647\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.67, NNZs: 24505, Bias: 0.000000, T: 13536, Avg. loss: 0.641619\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.25, NNZs: 24505, Bias: 0.000000, T: 2256, Avg. loss: 0.700277\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.34, NNZs: 24505, Bias: 0.000000, T: 4512, Avg. loss: 0.689683\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.40, NNZs: 24505, Bias: 0.000000, T: 6768, Avg. loss: 0.683295\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.46, NNZs: 24505, Bias: 0.000000, T: 9024, Avg. loss: 0.678356\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.51, NNZs: 24505, Bias: 0.000000, T: 11280, Avg. loss: 0.674088\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.55, NNZs: 24505, Bias: 0.000000, T: 13536, Avg. loss: 0.670365\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.35, NNZs: 24505, Bias: 0.000000, T: 2256, Avg. loss: 0.674084\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.48, NNZs: 24505, Bias: 0.000000, T: 4512, Avg. loss: 0.645111\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.58, NNZs: 24505, Bias: 0.000000, T: 6768, Avg. loss: 0.630047\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.66, NNZs: 24505, Bias: 0.000000, T: 9024, Avg. loss: 0.615489\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.73, NNZs: 24505, Bias: 0.000000, T: 11280, Avg. loss: 0.602537\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.79, NNZs: 24505, Bias: 0.000000, T: 13536, Avg. loss: 0.594174\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 1/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.28658617296069355, clf__eta0=0.03398405924608927, clf__fit_intercept=False, clf__l1_ratio=0.08227014493927165, clf__learning_rate=invscaling, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.5467473202425025, clf__shuffle=True, clf__tol=0.9099604695658384, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.494 total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.23, NNZs: 24342, Bias: 0.000000, T: 2256, Avg. loss: 0.698741\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.31, NNZs: 24342, Bias: 0.000000, T: 4512, Avg. loss: 0.686121\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.37, NNZs: 24342, Bias: 0.000000, T: 6768, Avg. loss: 0.678688\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.42, NNZs: 24342, Bias: 0.000000, T: 9024, Avg. loss: 0.672748\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.47, NNZs: 24342, Bias: 0.000000, T: 11280, Avg. loss: 0.667705\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.51, NNZs: 24342, Bias: 0.000000, T: 13536, Avg. loss: 0.663276\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.30, NNZs: 24342, Bias: 0.000000, T: 2256, Avg. loss: 0.695803\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.40, NNZs: 24342, Bias: 0.000000, T: 4512, Avg. loss: 0.679280\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.48, NNZs: 24342, Bias: 0.000000, T: 6768, Avg. loss: 0.669412\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.54, NNZs: 24342, Bias: 0.000000, T: 9024, Avg. loss: 0.661491\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.60, NNZs: 24342, Bias: 0.000000, T: 11280, Avg. loss: 0.654901\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.65, NNZs: 24342, Bias: 0.000000, T: 13536, Avg. loss: 0.649007\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.25, NNZs: 24342, Bias: 0.000000, T: 2256, Avg. loss: 0.700834\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.33, NNZs: 24342, Bias: 0.000000, T: 4512, Avg. loss: 0.691328\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.40, NNZs: 24342, Bias: 0.000000, T: 6768, Avg. loss: 0.685580\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.45, NNZs: 24342, Bias: 0.000000, T: 9024, Avg. loss: 0.680920\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.50, NNZs: 24342, Bias: 0.000000, T: 11280, Avg. loss: 0.677014\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.54, NNZs: 24342, Bias: 0.000000, T: 13536, Avg. loss: 0.673555\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.39, NNZs: 24342, Bias: 0.000000, T: 2256, Avg. loss: 0.662915\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.52, NNZs: 24342, Bias: 0.000000, T: 4512, Avg. loss: 0.630551\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.62, NNZs: 24342, Bias: 0.000000, T: 6768, Avg. loss: 0.612852\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.70, NNZs: 24342, Bias: 0.000000, T: 9024, Avg. loss: 0.599853\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.78, NNZs: 24342, Bias: 0.000000, T: 11280, Avg. loss: 0.587112\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.84, NNZs: 24342, Bias: 0.000000, T: 13536, Avg. loss: 0.576039\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 2/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.28658617296069355, clf__eta0=0.03398405924608927, clf__fit_intercept=False, clf__l1_ratio=0.08227014493927165, clf__learning_rate=invscaling, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.5467473202425025, clf__shuffle=True, clf__tol=0.9099604695658384, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.523 total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.24, NNZs: 24916, Bias: 0.000000, T: 2256, Avg. loss: 0.697793\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.32, NNZs: 24916, Bias: 0.000000, T: 4512, Avg. loss: 0.684932\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.38, NNZs: 24916, Bias: 0.000000, T: 6768, Avg. loss: 0.677322\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.43, NNZs: 24916, Bias: 0.000000, T: 9024, Avg. loss: 0.671342\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.48, NNZs: 24916, Bias: 0.000000, T: 11280, Avg. loss: 0.666222\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.52, NNZs: 24916, Bias: 0.000000, T: 13536, Avg. loss: 0.661724\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.30, NNZs: 24916, Bias: 0.000000, T: 2256, Avg. loss: 0.691679\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.41, NNZs: 24916, Bias: 0.000000, T: 4512, Avg. loss: 0.675038\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.48, NNZs: 24916, Bias: 0.000000, T: 6768, Avg. loss: 0.665260\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.55, NNZs: 24916, Bias: 0.000000, T: 9024, Avg. loss: 0.657413\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.61, NNZs: 24916, Bias: 0.000000, T: 11280, Avg. loss: 0.650696\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.66, NNZs: 24916, Bias: 0.000000, T: 13536, Avg. loss: 0.644855\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.23, NNZs: 24916, Bias: 0.000000, T: 2256, Avg. loss: 0.701692\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.31, NNZs: 24916, Bias: 0.000000, T: 4512, Avg. loss: 0.692032\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.38, NNZs: 24916, Bias: 0.000000, T: 6768, Avg. loss: 0.686155\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.43, NNZs: 24916, Bias: 0.000000, T: 9024, Avg. loss: 0.681475\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.48, NNZs: 24916, Bias: 0.000000, T: 11280, Avg. loss: 0.677628\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.52, NNZs: 24916, Bias: 0.000000, T: 13536, Avg. loss: 0.674168\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.36, NNZs: 24916, Bias: 0.000000, T: 2256, Avg. loss: 0.678129\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.49, NNZs: 24916, Bias: 0.000000, T: 4512, Avg. loss: 0.644999\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.59, NNZs: 24916, Bias: 0.000000, T: 6768, Avg. loss: 0.627699\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.67, NNZs: 24916, Bias: 0.000000, T: 9024, Avg. loss: 0.614260\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.74, NNZs: 24916, Bias: 0.000000, T: 11280, Avg. loss: 0.602216\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.81, NNZs: 24916, Bias: 0.000000, T: 13536, Avg. loss: 0.589947\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 3/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.28658617296069355, clf__eta0=0.03398405924608927, clf__fit_intercept=False, clf__l1_ratio=0.08227014493927165, clf__learning_rate=invscaling, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.5467473202425025, clf__shuffle=True, clf__tol=0.9099604695658384, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.484 total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.23, NNZs: 25354, Bias: 0.000000, T: 2256, Avg. loss: 0.699679\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.31, NNZs: 25354, Bias: 0.000000, T: 4512, Avg. loss: 0.686721\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.37, NNZs: 25354, Bias: 0.000000, T: 6768, Avg. loss: 0.678896\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.42, NNZs: 25354, Bias: 0.000000, T: 9024, Avg. loss: 0.672825\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.47, NNZs: 25354, Bias: 0.000000, T: 11280, Avg. loss: 0.667537\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.51, NNZs: 25354, Bias: 0.000000, T: 13536, Avg. loss: 0.663002\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.31, NNZs: 25354, Bias: 0.000000, T: 2256, Avg. loss: 0.695711\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.41, NNZs: 25354, Bias: 0.000000, T: 4512, Avg. loss: 0.678724\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.49, NNZs: 25354, Bias: 0.000000, T: 6768, Avg. loss: 0.668578\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.56, NNZs: 25354, Bias: 0.000000, T: 9024, Avg. loss: 0.660648\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.62, NNZs: 25354, Bias: 0.000000, T: 11280, Avg. loss: 0.653804\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.67, NNZs: 25354, Bias: 0.000000, T: 13536, Avg. loss: 0.647785\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.22, NNZs: 25354, Bias: 0.000000, T: 2256, Avg. loss: 0.701710\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.31, NNZs: 25354, Bias: 0.000000, T: 4512, Avg. loss: 0.692132\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.38, NNZs: 25354, Bias: 0.000000, T: 6768, Avg. loss: 0.686003\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.43, NNZs: 25354, Bias: 0.000000, T: 9024, Avg. loss: 0.681085\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.48, NNZs: 25354, Bias: 0.000000, T: 11280, Avg. loss: 0.676987\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.52, NNZs: 25354, Bias: 0.000000, T: 13536, Avg. loss: 0.673384\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.39, NNZs: 25354, Bias: 0.000000, T: 2256, Avg. loss: 0.675701\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.51, NNZs: 25354, Bias: 0.000000, T: 4512, Avg. loss: 0.650115\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.61, NNZs: 25354, Bias: 0.000000, T: 6768, Avg. loss: 0.630095\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.69, NNZs: 25354, Bias: 0.000000, T: 9024, Avg. loss: 0.615768\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.76, NNZs: 25354, Bias: 0.000000, T: 11280, Avg. loss: 0.603528\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.83, NNZs: 25354, Bias: 0.000000, T: 13536, Avg. loss: 0.594519\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 4/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.28658617296069355, clf__eta0=0.03398405924608927, clf__fit_intercept=False, clf__l1_ratio=0.08227014493927165, clf__learning_rate=invscaling, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.5467473202425025, clf__shuffle=True, clf__tol=0.9099604695658384, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.522 total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.24, NNZs: 25278, Bias: 0.000000, T: 2256, Avg. loss: 0.697888\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.32, NNZs: 25278, Bias: 0.000000, T: 4512, Avg. loss: 0.685114\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.38, NNZs: 25278, Bias: 0.000000, T: 6768, Avg. loss: 0.677453\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.44, NNZs: 25278, Bias: 0.000000, T: 9024, Avg. loss: 0.671252\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.48, NNZs: 25278, Bias: 0.000000, T: 11280, Avg. loss: 0.666129\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.52, NNZs: 25278, Bias: 0.000000, T: 13536, Avg. loss: 0.661559\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.29, NNZs: 25278, Bias: 0.000000, T: 2256, Avg. loss: 0.692109\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.39, NNZs: 25278, Bias: 0.000000, T: 4512, Avg. loss: 0.675782\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.47, NNZs: 25278, Bias: 0.000000, T: 6768, Avg. loss: 0.665694\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.53, NNZs: 25278, Bias: 0.000000, T: 9024, Avg. loss: 0.657891\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.59, NNZs: 25278, Bias: 0.000000, T: 11280, Avg. loss: 0.651193\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.64, NNZs: 25278, Bias: 0.000000, T: 13536, Avg. loss: 0.645195\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.23, NNZs: 25278, Bias: 0.000000, T: 2256, Avg. loss: 0.701265\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.32, NNZs: 25278, Bias: 0.000000, T: 4512, Avg. loss: 0.691361\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.38, NNZs: 25278, Bias: 0.000000, T: 6768, Avg. loss: 0.685322\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.44, NNZs: 25278, Bias: 0.000000, T: 9024, Avg. loss: 0.680594\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.48, NNZs: 25278, Bias: 0.000000, T: 11280, Avg. loss: 0.676498\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.53, NNZs: 25278, Bias: 0.000000, T: 13536, Avg. loss: 0.672933\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.36, NNZs: 25278, Bias: 0.000000, T: 2256, Avg. loss: 0.678303\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.48, NNZs: 25278, Bias: 0.000000, T: 4512, Avg. loss: 0.651685\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.57, NNZs: 25278, Bias: 0.000000, T: 6768, Avg. loss: 0.631414\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.65, NNZs: 25278, Bias: 0.000000, T: 9024, Avg. loss: 0.617671\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.72, NNZs: 25278, Bias: 0.000000, T: 11280, Avg. loss: 0.608237\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.78, NNZs: 25278, Bias: 0.000000, T: 13536, Avg. loss: 0.596491\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 5/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.28658617296069355, clf__eta0=0.03398405924608927, clf__fit_intercept=False, clf__l1_ratio=0.08227014493927165, clf__learning_rate=invscaling, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.5467473202425025, clf__shuffle=True, clf__tol=0.9099604695658384, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.546 total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 22.66, NNZs: 24511, Bias: 0.000000, T: 2256, Avg. loss: 0.357293\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 31.29, NNZs: 24511, Bias: 0.000000, T: 4512, Avg. loss: 0.209770\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 36.06, NNZs: 24511, Bias: 0.000000, T: 6768, Avg. loss: 0.163211\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 38.99, NNZs: 24511, Bias: 0.000000, T: 9024, Avg. loss: 0.141007\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 40.90, NNZs: 24511, Bias: 0.000000, T: 11280, Avg. loss: 0.128510\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 42.17, NNZs: 24511, Bias: 0.000000, T: 13536, Avg. loss: 0.120869\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 42.35, NNZs: 24511, Bias: 0.000000, T: 15792, Avg. loss: 0.116638\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 42.49, NNZs: 24511, Bias: 0.000000, T: 18048, Avg. loss: 0.111656\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 42.61, NNZs: 24511, Bias: 0.000000, T: 20304, Avg. loss: 0.110284\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 42.72, NNZs: 24511, Bias: 0.000000, T: 22560, Avg. loss: 0.109448\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 42.82, NNZs: 24511, Bias: 0.000000, T: 24816, Avg. loss: 0.108815\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 42.84, NNZs: 24511, Bias: 0.000000, T: 27072, Avg. loss: 0.108944\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 42.86, NNZs: 24511, Bias: 0.000000, T: 29328, Avg. loss: 0.108171\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 42.88, NNZs: 24511, Bias: 0.000000, T: 31584, Avg. loss: 0.107692\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 42.89, NNZs: 24511, Bias: 0.000000, T: 33840, Avg. loss: 0.107371\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 42.91, NNZs: 24511, Bias: 0.000000, T: 36096, Avg. loss: 0.107140\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 42.91, NNZs: 24511, Bias: 0.000000, T: 38352, Avg. loss: 0.107134\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 42.91, NNZs: 24511, Bias: 0.000000, T: 40608, Avg. loss: 0.107065\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 42.92, NNZs: 24511, Bias: 0.000000, T: 42864, Avg. loss: 0.107001\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 42.92, NNZs: 24511, Bias: 0.000000, T: 45120, Avg. loss: 0.106942\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 22.68, NNZs: 24511, Bias: 0.000000, T: 2256, Avg. loss: 0.300080\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 30.00, NNZs: 24511, Bias: 0.000000, T: 4512, Avg. loss: 0.163500\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 34.23, NNZs: 24511, Bias: 0.000000, T: 6768, Avg. loss: 0.127848\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 36.89, NNZs: 24511, Bias: 0.000000, T: 9024, Avg. loss: 0.110185\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 38.62, NNZs: 24511, Bias: 0.000000, T: 11280, Avg. loss: 0.100184\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 39.77, NNZs: 24511, Bias: 0.000000, T: 13536, Avg. loss: 0.094110\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 39.92, NNZs: 24511, Bias: 0.000000, T: 15792, Avg. loss: 0.088112\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 40.03, NNZs: 24511, Bias: 0.000000, T: 18048, Avg. loss: 0.086418\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 40.13, NNZs: 24511, Bias: 0.000000, T: 20304, Avg. loss: 0.085391\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 40.21, NNZs: 24511, Bias: 0.000000, T: 22560, Avg. loss: 0.084768\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 40.29, NNZs: 24511, Bias: 0.000000, T: 24816, Avg. loss: 0.084332\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 40.30, NNZs: 24511, Bias: 0.000000, T: 27072, Avg. loss: 0.083447\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 40.31, NNZs: 24511, Bias: 0.000000, T: 29328, Avg. loss: 0.083328\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 40.32, NNZs: 24511, Bias: 0.000000, T: 31584, Avg. loss: 0.083214\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 40.34, NNZs: 24511, Bias: 0.000000, T: 33840, Avg. loss: 0.083108\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 40.35, NNZs: 24511, Bias: 0.000000, T: 36096, Avg. loss: 0.083009\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 40.35, NNZs: 24511, Bias: 0.000000, T: 38352, Avg. loss: 0.082819\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 40.35, NNZs: 24511, Bias: 0.000000, T: 40608, Avg. loss: 0.082798\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 40.35, NNZs: 24511, Bias: 0.000000, T: 42864, Avg. loss: 0.082778\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 40.36, NNZs: 24511, Bias: 0.000000, T: 45120, Avg. loss: 0.082758\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 15.70, NNZs: 24511, Bias: 0.000000, T: 2256, Avg. loss: 0.383941\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 20.94, NNZs: 24511, Bias: 0.000000, T: 4512, Avg. loss: 0.248022\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 23.88, NNZs: 24511, Bias: 0.000000, T: 6768, Avg. loss: 0.195751\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 25.70, NNZs: 24511, Bias: 0.000000, T: 9024, Avg. loss: 0.171448\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 26.88, NNZs: 24511, Bias: 0.000000, T: 11280, Avg. loss: 0.157804\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27.68, NNZs: 24511, Bias: 0.000000, T: 13536, Avg. loss: 0.149402\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 27.75, NNZs: 24511, Bias: 0.000000, T: 15792, Avg. loss: 0.158734\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 27.84, NNZs: 24511, Bias: 0.000000, T: 18048, Avg. loss: 0.149625\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 27.93, NNZs: 24511, Bias: 0.000000, T: 20304, Avg. loss: 0.145005\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 28.02, NNZs: 24511, Bias: 0.000000, T: 22560, Avg. loss: 0.142424\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 28.10, NNZs: 24511, Bias: 0.000000, T: 24816, Avg. loss: 0.140820\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 28.12, NNZs: 24511, Bias: 0.000000, T: 27072, Avg. loss: 0.142581\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 28.13, NNZs: 24511, Bias: 0.000000, T: 29328, Avg. loss: 0.141955\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 28.14, NNZs: 24511, Bias: 0.000000, T: 31584, Avg. loss: 0.141398\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 28.16, NNZs: 24511, Bias: 0.000000, T: 33840, Avg. loss: 0.140902\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 28.17, NNZs: 24511, Bias: 0.000000, T: 36096, Avg. loss: 0.140459\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 28.17, NNZs: 24511, Bias: 0.000000, T: 38352, Avg. loss: 0.140670\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 28.18, NNZs: 24511, Bias: 0.000000, T: 40608, Avg. loss: 0.140575\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 28.18, NNZs: 24511, Bias: 0.000000, T: 42864, Avg. loss: 0.140482\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 28.18, NNZs: 24511, Bias: 0.000000, T: 45120, Avg. loss: 0.140391\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 60.15, NNZs: 24511, Bias: 0.000000, T: 2256, Avg. loss: 0.339832\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 64.17, NNZs: 24511, Bias: 0.000000, T: 4512, Avg. loss: 0.140085\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 58.73, NNZs: 24511, Bias: 0.000000, T: 6768, Avg. loss: 0.080200\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 54.67, NNZs: 24511, Bias: 0.000000, T: 9024, Avg. loss: 0.040845\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 50.17, NNZs: 24511, Bias: 0.000000, T: 11280, Avg. loss: 0.034069\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 46.35, NNZs: 24511, Bias: 0.000000, T: 13536, Avg. loss: 0.030758\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 45.61, NNZs: 24511, Bias: 0.000000, T: 15792, Avg. loss: 0.028196\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 44.90, NNZs: 24511, Bias: 0.000000, T: 18048, Avg. loss: 0.028475\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 44.25, NNZs: 24511, Bias: 0.000000, T: 20304, Avg. loss: 0.028749\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 43.63, NNZs: 24511, Bias: 0.000000, T: 22560, Avg. loss: 0.029043\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 43.05, NNZs: 24511, Bias: 0.000000, T: 24816, Avg. loss: 0.029361\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 42.94, NNZs: 24511, Bias: 0.000000, T: 27072, Avg. loss: 0.028975\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 42.82, NNZs: 24511, Bias: 0.000000, T: 29328, Avg. loss: 0.029072\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 42.71, NNZs: 24511, Bias: 0.000000, T: 31584, Avg. loss: 0.029166\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 42.60, NNZs: 24511, Bias: 0.000000, T: 33840, Avg. loss: 0.029257\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 42.50, NNZs: 24511, Bias: 0.000000, T: 36096, Avg. loss: 0.029345\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 42.48, NNZs: 24511, Bias: 0.000000, T: 38352, Avg. loss: 0.029266\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 42.45, NNZs: 24511, Bias: 0.000000, T: 40608, Avg. loss: 0.029284\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 42.43, NNZs: 24511, Bias: 0.000000, T: 42864, Avg. loss: 0.029302\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 42.41, NNZs: 24511, Bias: 0.000000, T: 45120, Avg. loss: 0.029321\n",
      "Total training time: 0.07 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.3s finished\n",
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.42493015701647596, clf__eta0=0.6773009699604285, clf__fit_intercept=False, clf__l1_ratio=0.7301998277223162, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.017782879504616322, clf__shuffle=False, clf__tol=0.19519881462597577, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.666 total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 22.59, NNZs: 24335, Bias: 0.000000, T: 2256, Avg. loss: 0.360225\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 31.12, NNZs: 24335, Bias: 0.000000, T: 4512, Avg. loss: 0.214498\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 35.90, NNZs: 24335, Bias: 0.000000, T: 6768, Avg. loss: 0.168621\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 38.87, NNZs: 24335, Bias: 0.000000, T: 9024, Avg. loss: 0.146385\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 40.81, NNZs: 24335, Bias: 0.000000, T: 11280, Avg. loss: 0.133728\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 42.11, NNZs: 24335, Bias: 0.000000, T: 13536, Avg. loss: 0.125913\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 42.31, NNZs: 24335, Bias: 0.000000, T: 15792, Avg. loss: 0.126089\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 42.47, NNZs: 24335, Bias: 0.000000, T: 18048, Avg. loss: 0.119141\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 42.62, NNZs: 24335, Bias: 0.000000, T: 20304, Avg. loss: 0.117312\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 42.75, NNZs: 24335, Bias: 0.000000, T: 22560, Avg. loss: 0.116277\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 42.87, NNZs: 24335, Bias: 0.000000, T: 24816, Avg. loss: 0.115500\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 42.89, NNZs: 24335, Bias: 0.000000, T: 27072, Avg. loss: 0.116274\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 42.91, NNZs: 24335, Bias: 0.000000, T: 29328, Avg. loss: 0.115274\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 42.94, NNZs: 24335, Bias: 0.000000, T: 31584, Avg. loss: 0.114649\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 42.96, NNZs: 24335, Bias: 0.000000, T: 33840, Avg. loss: 0.114226\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 42.98, NNZs: 24335, Bias: 0.000000, T: 36096, Avg. loss: 0.113920\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 42.98, NNZs: 24335, Bias: 0.000000, T: 38352, Avg. loss: 0.113942\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 42.98, NNZs: 24335, Bias: 0.000000, T: 40608, Avg. loss: 0.113857\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 42.99, NNZs: 24335, Bias: 0.000000, T: 42864, Avg. loss: 0.113778\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 42.99, NNZs: 24335, Bias: 0.000000, T: 45120, Avg. loss: 0.113705\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 22.64, NNZs: 24335, Bias: 0.000000, T: 2256, Avg. loss: 0.301670\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 29.86, NNZs: 24335, Bias: 0.000000, T: 4512, Avg. loss: 0.161687\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 34.04, NNZs: 24335, Bias: 0.000000, T: 6768, Avg. loss: 0.126148\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 36.66, NNZs: 24335, Bias: 0.000000, T: 9024, Avg. loss: 0.108699\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 38.37, NNZs: 24335, Bias: 0.000000, T: 11280, Avg. loss: 0.098824\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 39.50, NNZs: 24335, Bias: 0.000000, T: 13536, Avg. loss: 0.092827\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 39.65, NNZs: 24335, Bias: 0.000000, T: 15792, Avg. loss: 0.086051\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 39.77, NNZs: 24335, Bias: 0.000000, T: 18048, Avg. loss: 0.085422\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 39.88, NNZs: 24335, Bias: 0.000000, T: 20304, Avg. loss: 0.084755\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 39.98, NNZs: 24335, Bias: 0.000000, T: 22560, Avg. loss: 0.084227\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 40.07, NNZs: 24335, Bias: 0.000000, T: 24816, Avg. loss: 0.083791\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 40.08, NNZs: 24335, Bias: 0.000000, T: 27072, Avg. loss: 0.082694\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 40.10, NNZs: 24335, Bias: 0.000000, T: 29328, Avg. loss: 0.082622\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 40.11, NNZs: 24335, Bias: 0.000000, T: 31584, Avg. loss: 0.082547\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 40.12, NNZs: 24335, Bias: 0.000000, T: 33840, Avg. loss: 0.082473\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 40.14, NNZs: 24335, Bias: 0.000000, T: 36096, Avg. loss: 0.082401\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 40.14, NNZs: 24335, Bias: 0.000000, T: 38352, Avg. loss: 0.082160\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 40.14, NNZs: 24335, Bias: 0.000000, T: 40608, Avg. loss: 0.082148\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 40.15, NNZs: 24335, Bias: 0.000000, T: 42864, Avg. loss: 0.082136\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 40.15, NNZs: 24335, Bias: 0.000000, T: 45120, Avg. loss: 0.082124\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 15.71, NNZs: 24335, Bias: 0.000000, T: 2256, Avg. loss: 0.403986\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 20.96, NNZs: 24335, Bias: 0.000000, T: 4512, Avg. loss: 0.260900\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 23.97, NNZs: 24335, Bias: 0.000000, T: 6768, Avg. loss: 0.208484\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 25.85, NNZs: 24335, Bias: 0.000000, T: 9024, Avg. loss: 0.183358\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 27.09, NNZs: 24335, Bias: 0.000000, T: 11280, Avg. loss: 0.169056\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27.92, NNZs: 24335, Bias: 0.000000, T: 13536, Avg. loss: 0.160177\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 27.99, NNZs: 24335, Bias: 0.000000, T: 15792, Avg. loss: 0.170117\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 28.09, NNZs: 24335, Bias: 0.000000, T: 18048, Avg. loss: 0.160707\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 28.19, NNZs: 24335, Bias: 0.000000, T: 20304, Avg. loss: 0.156073\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 28.28, NNZs: 24335, Bias: 0.000000, T: 22560, Avg. loss: 0.153510\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 28.38, NNZs: 24335, Bias: 0.000000, T: 24816, Avg. loss: 0.151901\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 28.39, NNZs: 24335, Bias: 0.000000, T: 27072, Avg. loss: 0.153279\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 28.41, NNZs: 24335, Bias: 0.000000, T: 29328, Avg. loss: 0.152679\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 28.42, NNZs: 24335, Bias: 0.000000, T: 31584, Avg. loss: 0.152146\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 28.44, NNZs: 24335, Bias: 0.000000, T: 33840, Avg. loss: 0.151671\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 28.45, NNZs: 24335, Bias: 0.000000, T: 36096, Avg. loss: 0.151245\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 28.46, NNZs: 24335, Bias: 0.000000, T: 38352, Avg. loss: 0.151370\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 28.46, NNZs: 24335, Bias: 0.000000, T: 40608, Avg. loss: 0.151280\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 28.46, NNZs: 24335, Bias: 0.000000, T: 42864, Avg. loss: 0.151191\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 28.47, NNZs: 24335, Bias: 0.000000, T: 45120, Avg. loss: 0.151105\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 78.82, NNZs: 24335, Bias: 0.000000, T: 2256, Avg. loss: 0.683402\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 81.70, NNZs: 24335, Bias: 0.000000, T: 4512, Avg. loss: 0.181235\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 71.66, NNZs: 24335, Bias: 0.000000, T: 6768, Avg. loss: 0.063054\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 63.29, NNZs: 24335, Bias: 0.000000, T: 9024, Avg. loss: 0.030834\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 56.33, NNZs: 24335, Bias: 0.000000, T: 11280, Avg. loss: 0.027353\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 50.81, NNZs: 24335, Bias: 0.000000, T: 13536, Avg. loss: 0.027814\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 49.83, NNZs: 24335, Bias: 0.000000, T: 15792, Avg. loss: 0.027057\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 48.89, NNZs: 24335, Bias: 0.000000, T: 18048, Avg. loss: 0.027338\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 48.01, NNZs: 24335, Bias: 0.000000, T: 20304, Avg. loss: 0.027661\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 47.18, NNZs: 24335, Bias: 0.000000, T: 22560, Avg. loss: 0.028010\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 46.40, NNZs: 24335, Bias: 0.000000, T: 24816, Avg. loss: 0.028377\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 46.24, NNZs: 24335, Bias: 0.000000, T: 27072, Avg. loss: 0.028269\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 46.09, NNZs: 24335, Bias: 0.000000, T: 29328, Avg. loss: 0.028349\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 45.94, NNZs: 24335, Bias: 0.000000, T: 31584, Avg. loss: 0.028429\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 45.80, NNZs: 24335, Bias: 0.000000, T: 33840, Avg. loss: 0.028508\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 45.65, NNZs: 24335, Bias: 0.000000, T: 36096, Avg. loss: 0.028588\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 45.62, NNZs: 24335, Bias: 0.000000, T: 38352, Avg. loss: 0.028568\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 45.59, NNZs: 24335, Bias: 0.000000, T: 40608, Avg. loss: 0.028584\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 45.56, NNZs: 24335, Bias: 0.000000, T: 42864, Avg. loss: 0.028600\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 45.53, NNZs: 24335, Bias: 0.000000, T: 45120, Avg. loss: 0.028616\n",
      "Total training time: 0.07 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.3s finished\n",
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.42493015701647596, clf__eta0=0.6773009699604285, clf__fit_intercept=False, clf__l1_ratio=0.7301998277223162, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.017782879504616322, clf__shuffle=False, clf__tol=0.19519881462597577, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.692 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 23.19, NNZs: 24923, Bias: 0.000000, T: 2256, Avg. loss: 0.374759\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 31.64, NNZs: 24923, Bias: 0.000000, T: 4512, Avg. loss: 0.218666\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 36.39, NNZs: 24923, Bias: 0.000000, T: 6768, Avg. loss: 0.172063\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 39.36, NNZs: 24923, Bias: 0.000000, T: 9024, Avg. loss: 0.149391\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 41.31, NNZs: 24923, Bias: 0.000000, T: 11280, Avg. loss: 0.136430\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 42.62, NNZs: 24923, Bias: 0.000000, T: 13536, Avg. loss: 0.128408\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 42.80, NNZs: 24923, Bias: 0.000000, T: 15792, Avg. loss: 0.125302\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 42.94, NNZs: 24923, Bias: 0.000000, T: 18048, Avg. loss: 0.120067\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 43.07, NNZs: 24923, Bias: 0.000000, T: 20304, Avg. loss: 0.118773\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 43.19, NNZs: 24923, Bias: 0.000000, T: 22560, Avg. loss: 0.117943\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 43.30, NNZs: 24923, Bias: 0.000000, T: 24816, Avg. loss: 0.117273\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 43.32, NNZs: 24923, Bias: 0.000000, T: 27072, Avg. loss: 0.117393\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 43.34, NNZs: 24923, Bias: 0.000000, T: 29328, Avg. loss: 0.116524\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 43.36, NNZs: 24923, Bias: 0.000000, T: 31584, Avg. loss: 0.116015\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 43.38, NNZs: 24923, Bias: 0.000000, T: 33840, Avg. loss: 0.115689\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 43.39, NNZs: 24923, Bias: 0.000000, T: 36096, Avg. loss: 0.115461\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 43.40, NNZs: 24923, Bias: 0.000000, T: 38352, Avg. loss: 0.115415\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 43.40, NNZs: 24923, Bias: 0.000000, T: 40608, Avg. loss: 0.115346\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 43.40, NNZs: 24923, Bias: 0.000000, T: 42864, Avg. loss: 0.115283\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 43.41, NNZs: 24923, Bias: 0.000000, T: 45120, Avg. loss: 0.115225\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 22.49, NNZs: 24923, Bias: 0.000000, T: 2256, Avg. loss: 0.309006\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 29.75, NNZs: 24923, Bias: 0.000000, T: 4512, Avg. loss: 0.171034\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 34.04, NNZs: 24923, Bias: 0.000000, T: 6768, Avg. loss: 0.134514\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 36.79, NNZs: 24923, Bias: 0.000000, T: 9024, Avg. loss: 0.116101\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 38.60, NNZs: 24923, Bias: 0.000000, T: 11280, Avg. loss: 0.105491\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 39.82, NNZs: 24923, Bias: 0.000000, T: 13536, Avg. loss: 0.098951\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 39.98, NNZs: 24923, Bias: 0.000000, T: 15792, Avg. loss: 0.092149\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 40.11, NNZs: 24923, Bias: 0.000000, T: 18048, Avg. loss: 0.091028\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 40.23, NNZs: 24923, Bias: 0.000000, T: 20304, Avg. loss: 0.090244\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 40.34, NNZs: 24923, Bias: 0.000000, T: 22560, Avg. loss: 0.089658\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 40.43, NNZs: 24923, Bias: 0.000000, T: 24816, Avg. loss: 0.089179\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 40.45, NNZs: 24923, Bias: 0.000000, T: 27072, Avg. loss: 0.087468\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 40.46, NNZs: 24923, Bias: 0.000000, T: 29328, Avg. loss: 0.087608\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 40.48, NNZs: 24923, Bias: 0.000000, T: 31584, Avg. loss: 0.087653\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 40.50, NNZs: 24923, Bias: 0.000000, T: 33840, Avg. loss: 0.087643\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 40.51, NNZs: 24923, Bias: 0.000000, T: 36096, Avg. loss: 0.087603\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 40.51, NNZs: 24923, Bias: 0.000000, T: 38352, Avg. loss: 0.087214\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 40.52, NNZs: 24923, Bias: 0.000000, T: 40608, Avg. loss: 0.087219\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 40.52, NNZs: 24923, Bias: 0.000000, T: 42864, Avg. loss: 0.087222\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 40.52, NNZs: 24923, Bias: 0.000000, T: 45120, Avg. loss: 0.087224\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 15.77, NNZs: 24923, Bias: 0.000000, T: 2256, Avg. loss: 0.418062\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 20.97, NNZs: 24923, Bias: 0.000000, T: 4512, Avg. loss: 0.263784\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 23.94, NNZs: 24923, Bias: 0.000000, T: 6768, Avg. loss: 0.211234\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 25.80, NNZs: 24923, Bias: 0.000000, T: 9024, Avg. loss: 0.186182\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 27.03, NNZs: 24923, Bias: 0.000000, T: 11280, Avg. loss: 0.171899\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27.87, NNZs: 24923, Bias: 0.000000, T: 13536, Avg. loss: 0.162996\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 27.95, NNZs: 24923, Bias: 0.000000, T: 15792, Avg. loss: 0.167076\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 28.04, NNZs: 24923, Bias: 0.000000, T: 18048, Avg. loss: 0.159944\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 28.14, NNZs: 24923, Bias: 0.000000, T: 20304, Avg. loss: 0.156342\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 28.24, NNZs: 24923, Bias: 0.000000, T: 22560, Avg. loss: 0.154283\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 28.33, NNZs: 24923, Bias: 0.000000, T: 24816, Avg. loss: 0.152941\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 28.35, NNZs: 24923, Bias: 0.000000, T: 27072, Avg. loss: 0.153403\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 28.36, NNZs: 24923, Bias: 0.000000, T: 29328, Avg. loss: 0.152958\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 28.38, NNZs: 24923, Bias: 0.000000, T: 31584, Avg. loss: 0.152559\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 28.39, NNZs: 24923, Bias: 0.000000, T: 33840, Avg. loss: 0.152201\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 28.41, NNZs: 24923, Bias: 0.000000, T: 36096, Avg. loss: 0.151876\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 28.41, NNZs: 24923, Bias: 0.000000, T: 38352, Avg. loss: 0.151880\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 28.41, NNZs: 24923, Bias: 0.000000, T: 40608, Avg. loss: 0.151812\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 28.42, NNZs: 24923, Bias: 0.000000, T: 42864, Avg. loss: 0.151745\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 28.42, NNZs: 24923, Bias: 0.000000, T: 45120, Avg. loss: 0.151680\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 73.57, NNZs: 24923, Bias: 0.000000, T: 2256, Avg. loss: 0.554771\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 71.36, NNZs: 24923, Bias: 0.000000, T: 4512, Avg. loss: 0.178123\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 63.60, NNZs: 24923, Bias: 0.000000, T: 6768, Avg. loss: 0.042431\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 56.45, NNZs: 24923, Bias: 0.000000, T: 9024, Avg. loss: 0.033223\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 50.72, NNZs: 24923, Bias: 0.000000, T: 11280, Avg. loss: 0.028217\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 46.41, NNZs: 24923, Bias: 0.000000, T: 13536, Avg. loss: 0.028428\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 45.62, NNZs: 24923, Bias: 0.000000, T: 15792, Avg. loss: 0.029340\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 44.88, NNZs: 24923, Bias: 0.000000, T: 18048, Avg. loss: 0.029096\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 44.19, NNZs: 24923, Bias: 0.000000, T: 20304, Avg. loss: 0.029055\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 43.54, NNZs: 24923, Bias: 0.000000, T: 22560, Avg. loss: 0.029164\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 42.94, NNZs: 24923, Bias: 0.000000, T: 24816, Avg. loss: 0.029378\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 42.82, NNZs: 24923, Bias: 0.000000, T: 27072, Avg. loss: 0.029471\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 42.70, NNZs: 24923, Bias: 0.000000, T: 29328, Avg. loss: 0.029511\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 42.59, NNZs: 24923, Bias: 0.000000, T: 31584, Avg. loss: 0.029554\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 42.48, NNZs: 24923, Bias: 0.000000, T: 33840, Avg. loss: 0.029600\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 42.36, NNZs: 24923, Bias: 0.000000, T: 36096, Avg. loss: 0.029649\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 42.34, NNZs: 24923, Bias: 0.000000, T: 38352, Avg. loss: 0.029663\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 42.32, NNZs: 24923, Bias: 0.000000, T: 40608, Avg. loss: 0.029673\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 42.30, NNZs: 24923, Bias: 0.000000, T: 42864, Avg. loss: 0.029683\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 42.28, NNZs: 24923, Bias: 0.000000, T: 45120, Avg. loss: 0.029693\n",
      "Total training time: 0.08 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.3s finished\n",
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.42493015701647596, clf__eta0=0.6773009699604285, clf__fit_intercept=False, clf__l1_ratio=0.7301998277223162, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.017782879504616322, clf__shuffle=False, clf__tol=0.19519881462597577, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.701 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 23.30, NNZs: 25350, Bias: 0.000000, T: 2256, Avg. loss: 0.370857\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 31.54, NNZs: 25350, Bias: 0.000000, T: 4512, Avg. loss: 0.212829\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 36.17, NNZs: 25350, Bias: 0.000000, T: 6768, Avg. loss: 0.166956\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 39.04, NNZs: 25350, Bias: 0.000000, T: 9024, Avg. loss: 0.144972\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 40.91, NNZs: 25350, Bias: 0.000000, T: 11280, Avg. loss: 0.132564\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 42.17, NNZs: 25350, Bias: 0.000000, T: 13536, Avg. loss: 0.124961\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 42.33, NNZs: 25350, Bias: 0.000000, T: 15792, Avg. loss: 0.119136\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 42.46, NNZs: 25350, Bias: 0.000000, T: 18048, Avg. loss: 0.115925\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 42.59, NNZs: 25350, Bias: 0.000000, T: 20304, Avg. loss: 0.114903\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 42.70, NNZs: 25350, Bias: 0.000000, T: 22560, Avg. loss: 0.114191\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 42.80, NNZs: 25350, Bias: 0.000000, T: 24816, Avg. loss: 0.113603\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 42.82, NNZs: 25350, Bias: 0.000000, T: 27072, Avg. loss: 0.113225\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 42.84, NNZs: 25350, Bias: 0.000000, T: 29328, Avg. loss: 0.112725\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 42.86, NNZs: 25350, Bias: 0.000000, T: 31584, Avg. loss: 0.112392\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 42.88, NNZs: 25350, Bias: 0.000000, T: 33840, Avg. loss: 0.112153\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 42.89, NNZs: 25350, Bias: 0.000000, T: 36096, Avg. loss: 0.111969\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 42.90, NNZs: 25350, Bias: 0.000000, T: 38352, Avg. loss: 0.111929\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 42.90, NNZs: 25350, Bias: 0.000000, T: 40608, Avg. loss: 0.111870\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 42.90, NNZs: 25350, Bias: 0.000000, T: 42864, Avg. loss: 0.111815\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 42.91, NNZs: 25350, Bias: 0.000000, T: 45120, Avg. loss: 0.111764\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 22.54, NNZs: 25350, Bias: 0.000000, T: 2256, Avg. loss: 0.306170\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 29.76, NNZs: 25350, Bias: 0.000000, T: 4512, Avg. loss: 0.166039\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 33.98, NNZs: 25350, Bias: 0.000000, T: 6768, Avg. loss: 0.130223\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 36.64, NNZs: 25350, Bias: 0.000000, T: 9024, Avg. loss: 0.112431\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 38.38, NNZs: 25350, Bias: 0.000000, T: 11280, Avg. loss: 0.102274\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 39.54, NNZs: 25350, Bias: 0.000000, T: 13536, Avg. loss: 0.096059\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 39.70, NNZs: 25350, Bias: 0.000000, T: 15792, Avg. loss: 0.089270\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 39.82, NNZs: 25350, Bias: 0.000000, T: 18048, Avg. loss: 0.088350\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 39.93, NNZs: 25350, Bias: 0.000000, T: 20304, Avg. loss: 0.087588\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 40.03, NNZs: 25350, Bias: 0.000000, T: 22560, Avg. loss: 0.087036\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 40.12, NNZs: 25350, Bias: 0.000000, T: 24816, Avg. loss: 0.086594\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 40.13, NNZs: 25350, Bias: 0.000000, T: 27072, Avg. loss: 0.084950\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 40.15, NNZs: 25350, Bias: 0.000000, T: 29328, Avg. loss: 0.085096\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 40.16, NNZs: 25350, Bias: 0.000000, T: 31584, Avg. loss: 0.085146\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 40.18, NNZs: 25350, Bias: 0.000000, T: 33840, Avg. loss: 0.085142\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 40.19, NNZs: 25350, Bias: 0.000000, T: 36096, Avg. loss: 0.085108\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 40.19, NNZs: 25350, Bias: 0.000000, T: 38352, Avg. loss: 0.084756\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 40.19, NNZs: 25350, Bias: 0.000000, T: 40608, Avg. loss: 0.084760\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 40.20, NNZs: 25350, Bias: 0.000000, T: 42864, Avg. loss: 0.084763\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 40.20, NNZs: 25350, Bias: 0.000000, T: 45120, Avg. loss: 0.084764\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 15.73, NNZs: 25350, Bias: 0.000000, T: 2256, Avg. loss: 0.414856\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 20.91, NNZs: 25350, Bias: 0.000000, T: 4512, Avg. loss: 0.254926\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 23.81, NNZs: 25350, Bias: 0.000000, T: 6768, Avg. loss: 0.203801\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 25.60, NNZs: 25350, Bias: 0.000000, T: 9024, Avg. loss: 0.179704\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 26.78, NNZs: 25350, Bias: 0.000000, T: 11280, Avg. loss: 0.166084\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27.58, NNZs: 25350, Bias: 0.000000, T: 13536, Avg. loss: 0.157654\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 27.66, NNZs: 25350, Bias: 0.000000, T: 15792, Avg. loss: 0.158881\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 27.76, NNZs: 25350, Bias: 0.000000, T: 18048, Avg. loss: 0.153351\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 27.86, NNZs: 25350, Bias: 0.000000, T: 20304, Avg. loss: 0.150404\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 27.96, NNZs: 25350, Bias: 0.000000, T: 22560, Avg. loss: 0.148635\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 28.04, NNZs: 25350, Bias: 0.000000, T: 24816, Avg. loss: 0.147437\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 28.06, NNZs: 25350, Bias: 0.000000, T: 27072, Avg. loss: 0.147951\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 28.08, NNZs: 25350, Bias: 0.000000, T: 29328, Avg. loss: 0.147527\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 28.09, NNZs: 25350, Bias: 0.000000, T: 31584, Avg. loss: 0.147147\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 28.11, NNZs: 25350, Bias: 0.000000, T: 33840, Avg. loss: 0.146803\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 28.12, NNZs: 25350, Bias: 0.000000, T: 36096, Avg. loss: 0.146491\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 28.12, NNZs: 25350, Bias: 0.000000, T: 38352, Avg. loss: 0.146527\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 28.13, NNZs: 25350, Bias: 0.000000, T: 40608, Avg. loss: 0.146460\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 28.13, NNZs: 25350, Bias: 0.000000, T: 42864, Avg. loss: 0.146395\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 28.13, NNZs: 25350, Bias: 0.000000, T: 45120, Avg. loss: 0.146332\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 63.62, NNZs: 25350, Bias: 0.000000, T: 2256, Avg. loss: 0.553867\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 65.98, NNZs: 25350, Bias: 0.000000, T: 4512, Avg. loss: 0.264229\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 64.30, NNZs: 25350, Bias: 0.000000, T: 6768, Avg. loss: 0.069705\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 57.18, NNZs: 25350, Bias: 0.000000, T: 9024, Avg. loss: 0.036432\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 51.56, NNZs: 25350, Bias: 0.000000, T: 11280, Avg. loss: 0.029926\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 47.10, NNZs: 25350, Bias: 0.000000, T: 13536, Avg. loss: 0.028855\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 46.31, NNZs: 25350, Bias: 0.000000, T: 15792, Avg. loss: 0.029329\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 45.56, NNZs: 25350, Bias: 0.000000, T: 18048, Avg. loss: 0.029242\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 44.86, NNZs: 25350, Bias: 0.000000, T: 20304, Avg. loss: 0.029323\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 44.21, NNZs: 25350, Bias: 0.000000, T: 22560, Avg. loss: 0.029516\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 43.60, NNZs: 25350, Bias: 0.000000, T: 24816, Avg. loss: 0.029785\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 43.48, NNZs: 25350, Bias: 0.000000, T: 27072, Avg. loss: 0.029704\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 43.36, NNZs: 25350, Bias: 0.000000, T: 29328, Avg. loss: 0.029764\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 43.24, NNZs: 25350, Bias: 0.000000, T: 31584, Avg. loss: 0.029826\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 43.13, NNZs: 25350, Bias: 0.000000, T: 33840, Avg. loss: 0.029890\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 43.02, NNZs: 25350, Bias: 0.000000, T: 36096, Avg. loss: 0.029956\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 42.99, NNZs: 25350, Bias: 0.000000, T: 38352, Avg. loss: 0.029939\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 42.97, NNZs: 25350, Bias: 0.000000, T: 40608, Avg. loss: 0.029952\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 42.95, NNZs: 25350, Bias: 0.000000, T: 42864, Avg. loss: 0.029966\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 42.93, NNZs: 25350, Bias: 0.000000, T: 45120, Avg. loss: 0.029979\n",
      "Total training time: 0.07 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.3s finished\n",
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.42493015701647596, clf__eta0=0.6773009699604285, clf__fit_intercept=False, clf__l1_ratio=0.7301998277223162, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.017782879504616322, clf__shuffle=False, clf__tol=0.19519881462597577, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.708 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 23.13, NNZs: 25275, Bias: 0.000000, T: 2256, Avg. loss: 0.360170\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 31.27, NNZs: 25275, Bias: 0.000000, T: 4512, Avg. loss: 0.213405\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 35.88, NNZs: 25275, Bias: 0.000000, T: 6768, Avg. loss: 0.167737\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 38.77, NNZs: 25275, Bias: 0.000000, T: 9024, Avg. loss: 0.145590\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 40.66, NNZs: 25275, Bias: 0.000000, T: 11280, Avg. loss: 0.132991\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 41.94, NNZs: 25275, Bias: 0.000000, T: 13536, Avg. loss: 0.125228\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 42.11, NNZs: 25275, Bias: 0.000000, T: 15792, Avg. loss: 0.126400\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 42.26, NNZs: 25275, Bias: 0.000000, T: 18048, Avg. loss: 0.116647\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 42.39, NNZs: 25275, Bias: 0.000000, T: 20304, Avg. loss: 0.114779\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 42.51, NNZs: 25275, Bias: 0.000000, T: 22560, Avg. loss: 0.113836\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 42.62, NNZs: 25275, Bias: 0.000000, T: 24816, Avg. loss: 0.113168\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 42.64, NNZs: 25275, Bias: 0.000000, T: 27072, Avg. loss: 0.114462\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 42.66, NNZs: 25275, Bias: 0.000000, T: 29328, Avg. loss: 0.113167\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 42.68, NNZs: 25275, Bias: 0.000000, T: 31584, Avg. loss: 0.112417\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 42.70, NNZs: 25275, Bias: 0.000000, T: 33840, Avg. loss: 0.111944\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 42.72, NNZs: 25275, Bias: 0.000000, T: 36096, Avg. loss: 0.111624\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 42.72, NNZs: 25275, Bias: 0.000000, T: 38352, Avg. loss: 0.111740\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 42.72, NNZs: 25275, Bias: 0.000000, T: 40608, Avg. loss: 0.111643\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 42.73, NNZs: 25275, Bias: 0.000000, T: 42864, Avg. loss: 0.111555\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 42.73, NNZs: 25275, Bias: 0.000000, T: 45120, Avg. loss: 0.111474\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 22.52, NNZs: 25275, Bias: 0.000000, T: 2256, Avg. loss: 0.307971\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 29.93, NNZs: 25275, Bias: 0.000000, T: 4512, Avg. loss: 0.168597\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 34.26, NNZs: 25275, Bias: 0.000000, T: 6768, Avg. loss: 0.131996\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 37.00, NNZs: 25275, Bias: 0.000000, T: 9024, Avg. loss: 0.113817\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 38.79, NNZs: 25275, Bias: 0.000000, T: 11280, Avg. loss: 0.103417\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 39.98, NNZs: 25275, Bias: 0.000000, T: 13536, Avg. loss: 0.097051\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 40.13, NNZs: 25275, Bias: 0.000000, T: 15792, Avg. loss: 0.089977\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 40.26, NNZs: 25275, Bias: 0.000000, T: 18048, Avg. loss: 0.089133\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 40.36, NNZs: 25275, Bias: 0.000000, T: 20304, Avg. loss: 0.088315\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 40.46, NNZs: 25275, Bias: 0.000000, T: 22560, Avg. loss: 0.087720\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 40.54, NNZs: 25275, Bias: 0.000000, T: 24816, Avg. loss: 0.087252\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 40.56, NNZs: 25275, Bias: 0.000000, T: 27072, Avg. loss: 0.085707\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 40.57, NNZs: 25275, Bias: 0.000000, T: 29328, Avg. loss: 0.085762\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 40.59, NNZs: 25275, Bias: 0.000000, T: 31584, Avg. loss: 0.085763\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 40.60, NNZs: 25275, Bias: 0.000000, T: 33840, Avg. loss: 0.085733\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 40.61, NNZs: 25275, Bias: 0.000000, T: 36096, Avg. loss: 0.085687\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 40.62, NNZs: 25275, Bias: 0.000000, T: 38352, Avg. loss: 0.085336\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 40.62, NNZs: 25275, Bias: 0.000000, T: 40608, Avg. loss: 0.085337\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 40.62, NNZs: 25275, Bias: 0.000000, T: 42864, Avg. loss: 0.085336\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 40.62, NNZs: 25275, Bias: 0.000000, T: 45120, Avg. loss: 0.085334\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 15.98, NNZs: 25275, Bias: 0.000000, T: 2256, Avg. loss: 0.398852\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 20.97, NNZs: 25275, Bias: 0.000000, T: 4512, Avg. loss: 0.252820\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 23.81, NNZs: 25275, Bias: 0.000000, T: 6768, Avg. loss: 0.201538\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 25.58, NNZs: 25275, Bias: 0.000000, T: 9024, Avg. loss: 0.177540\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 26.75, NNZs: 25275, Bias: 0.000000, T: 11280, Avg. loss: 0.163972\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27.54, NNZs: 25275, Bias: 0.000000, T: 13536, Avg. loss: 0.155559\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 27.60, NNZs: 25275, Bias: 0.000000, T: 15792, Avg. loss: 0.165808\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 27.69, NNZs: 25275, Bias: 0.000000, T: 18048, Avg. loss: 0.155837\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 27.78, NNZs: 25275, Bias: 0.000000, T: 20304, Avg. loss: 0.150968\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 27.88, NNZs: 25275, Bias: 0.000000, T: 22560, Avg. loss: 0.148325\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 27.96, NNZs: 25275, Bias: 0.000000, T: 24816, Avg. loss: 0.146710\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 27.98, NNZs: 25275, Bias: 0.000000, T: 27072, Avg. loss: 0.147901\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 27.99, NNZs: 25275, Bias: 0.000000, T: 29328, Avg. loss: 0.147340\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 28.01, NNZs: 25275, Bias: 0.000000, T: 31584, Avg. loss: 0.146842\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 28.02, NNZs: 25275, Bias: 0.000000, T: 33840, Avg. loss: 0.146397\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 28.04, NNZs: 25275, Bias: 0.000000, T: 36096, Avg. loss: 0.145998\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 28.04, NNZs: 25275, Bias: 0.000000, T: 38352, Avg. loss: 0.146105\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 28.04, NNZs: 25275, Bias: 0.000000, T: 40608, Avg. loss: 0.146021\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 28.05, NNZs: 25275, Bias: 0.000000, T: 42864, Avg. loss: 0.145939\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 28.05, NNZs: 25275, Bias: 0.000000, T: 45120, Avg. loss: 0.145858\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 72.37, NNZs: 25275, Bias: 0.000000, T: 2256, Avg. loss: 0.462505\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 74.95, NNZs: 25275, Bias: 0.000000, T: 4512, Avg. loss: 0.299847\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 66.05, NNZs: 25275, Bias: 0.000000, T: 6768, Avg. loss: 0.040638\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 58.52, NNZs: 25275, Bias: 0.000000, T: 9024, Avg. loss: 0.028231\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 52.38, NNZs: 25275, Bias: 0.000000, T: 11280, Avg. loss: 0.027062\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 47.62, NNZs: 25275, Bias: 0.000000, T: 13536, Avg. loss: 0.027780\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 46.75, NNZs: 25275, Bias: 0.000000, T: 15792, Avg. loss: 0.027166\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 45.94, NNZs: 25275, Bias: 0.000000, T: 18048, Avg. loss: 0.027282\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 45.18, NNZs: 25275, Bias: 0.000000, T: 20304, Avg. loss: 0.027528\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 44.47, NNZs: 25275, Bias: 0.000000, T: 22560, Avg. loss: 0.027852\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 43.80, NNZs: 25275, Bias: 0.000000, T: 24816, Avg. loss: 0.028224\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 43.67, NNZs: 25275, Bias: 0.000000, T: 27072, Avg. loss: 0.028237\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 43.54, NNZs: 25275, Bias: 0.000000, T: 29328, Avg. loss: 0.028303\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 43.41, NNZs: 25275, Bias: 0.000000, T: 31584, Avg. loss: 0.028371\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 43.29, NNZs: 25275, Bias: 0.000000, T: 33840, Avg. loss: 0.028441\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 43.16, NNZs: 25275, Bias: 0.000000, T: 36096, Avg. loss: 0.028514\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 43.14, NNZs: 25275, Bias: 0.000000, T: 38352, Avg. loss: 0.028516\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 43.11, NNZs: 25275, Bias: 0.000000, T: 40608, Avg. loss: 0.028530\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 43.09, NNZs: 25275, Bias: 0.000000, T: 42864, Avg. loss: 0.028545\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 43.06, NNZs: 25275, Bias: 0.000000, T: 45120, Avg. loss: 0.028559\n",
      "Total training time: 0.08 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.3s finished\n",
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.42493015701647596, clf__eta0=0.6773009699604285, clf__fit_intercept=False, clf__l1_ratio=0.7301998277223162, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.017782879504616322, clf__shuffle=False, clf__tol=0.19519881462597577, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.674 total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 48.19, NNZs: 15678, Bias: -0.939376, T: 2256, Avg. loss: 0.077634\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 31.82, NNZs: 16977, Bias: -1.014419, T: 4512, Avg. loss: 0.008911\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 24.06, NNZs: 17442, Bias: -0.962049, T: 6768, Avg. loss: 0.002398\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 19.25, NNZs: 17713, Bias: -0.942589, T: 9024, Avg. loss: 0.001454\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 16.33, NNZs: 17908, Bias: -0.912337, T: 11280, Avg. loss: 0.001130\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 14.08, NNZs: 17957, Bias: -0.888857, T: 13536, Avg. loss: 0.000655\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 48.68, NNZs: 15148, Bias: -0.901907, T: 2256, Avg. loss: 0.080069\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 32.55, NNZs: 16409, Bias: -0.939977, T: 4512, Avg. loss: 0.010636\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 23.73, NNZs: 16736, Bias: -0.992071, T: 6768, Avg. loss: 0.001657\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 18.97, NNZs: 16792, Bias: -0.961208, T: 9024, Avg. loss: 0.000885\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 15.82, NNZs: 16863, Bias: -0.962402, T: 11280, Avg. loss: 0.000317\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 13.85, NNZs: 16917, Bias: -0.933783, T: 13536, Avg. loss: 0.000218\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 18.69, NNZs: 10863, Bias: 0.508458, T: 2256, Avg. loss: 0.019238\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 12.81, NNZs: 12313, Bias: 0.512439, T: 4512, Avg. loss: 0.004156\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 9.54, NNZs: 12601, Bias: 0.505755, T: 6768, Avg. loss: 0.001379\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 7.63, NNZs: 12826, Bias: 0.489286, T: 9024, Avg. loss: 0.000564\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 6.42, NNZs: 12978, Bias: 0.479783, T: 11280, Avg. loss: 0.000628\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 5.64, NNZs: 12989, Bias: 0.463682, T: 13536, Avg. loss: 0.000400\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 263.69, NNZs: 18058, Bias: -8.928265, T: 2256, Avg. loss: 2.199919\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 203.67, NNZs: 19488, Bias: -8.802439, T: 4512, Avg. loss: 0.512588\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 174.28, NNZs: 20193, Bias: -8.716549, T: 6768, Avg. loss: 0.228730\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 138.36, NNZs: 20474, Bias: -9.257892, T: 9024, Avg. loss: 0.356414\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 122.99, NNZs: 20516, Bias: -9.086316, T: 11280, Avg. loss: 0.034939\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 112.28, NNZs: 20516, Bias: -8.795843, T: 13536, Avg. loss: 0.028110\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "[CV 1/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.21123614325601048, clf__eta0=0.32979731781585486, clf__fit_intercept=True, clf__l1_ratio=0.4775095579144826, clf__learning_rate=optimal, clf__loss=perceptron, clf__max_iter=30, clf__penalty=l2, clf__power_t=0.6427671735097384, clf__shuffle=False, clf__tol=0.2651165400908262, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.670 total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 46.48, NNZs: 16247, Bias: -1.061542, T: 2256, Avg. loss: 0.096148\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 31.05, NNZs: 17461, Bias: -1.092155, T: 4512, Avg. loss: 0.007935\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 23.56, NNZs: 17992, Bias: -1.068019, T: 6768, Avg. loss: 0.003477\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 19.10, NNZs: 18301, Bias: -1.036303, T: 9024, Avg. loss: 0.001472\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 16.33, NNZs: 18497, Bias: -1.002556, T: 11280, Avg. loss: 0.001157\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 14.35, NNZs: 18618, Bias: -0.968855, T: 13536, Avg. loss: 0.000712\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 48.11, NNZs: 15031, Bias: -1.255261, T: 2256, Avg. loss: 0.091576\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 32.86, NNZs: 16163, Bias: -1.238855, T: 4512, Avg. loss: 0.010757\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 23.86, NNZs: 16496, Bias: -1.253938, T: 6768, Avg. loss: 0.001749\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 19.20, NNZs: 16673, Bias: -1.217758, T: 9024, Avg. loss: 0.001044\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 15.95, NNZs: 16720, Bias: -1.197934, T: 11280, Avg. loss: 0.000240\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 14.03, NNZs: 16761, Bias: -1.161554, T: 13536, Avg. loss: 0.000310\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 18.61, NNZs: 10773, Bias: 0.556632, T: 2256, Avg. loss: 0.023780\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 12.74, NNZs: 12518, Bias: 0.576601, T: 4512, Avg. loss: 0.004763\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 9.88, NNZs: 12987, Bias: 0.544516, T: 6768, Avg. loss: 0.001641\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 8.08, NNZs: 13229, Bias: 0.523148, T: 9024, Avg. loss: 0.000898\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 7.01, NNZs: 13430, Bias: 0.507454, T: 11280, Avg. loss: 0.000727\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 6.15, NNZs: 13476, Bias: 0.498047, T: 13536, Avg. loss: 0.000439\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 352.06, NNZs: 19830, Bias: -4.535068, T: 2256, Avg. loss: 2.786515\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 263.59, NNZs: 20574, Bias: -5.152830, T: 4512, Avg. loss: 0.601946\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 193.44, NNZs: 20958, Bias: -5.971108, T: 6768, Avg. loss: 0.346852\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 147.74, NNZs: 20999, Bias: -6.483294, T: 9024, Avg. loss: 0.063594\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 129.99, NNZs: 21008, Bias: -6.139213, T: 11280, Avg. loss: 0.055557\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 108.75, NNZs: 21008, Bias: -6.237524, T: 13536, Avg. loss: 0.047629\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "[CV 2/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.21123614325601048, clf__eta0=0.32979731781585486, clf__fit_intercept=True, clf__l1_ratio=0.4775095579144826, clf__learning_rate=optimal, clf__loss=perceptron, clf__max_iter=30, clf__penalty=l2, clf__power_t=0.6427671735097384, clf__shuffle=False, clf__tol=0.2651165400908262, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.698 total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 47.92, NNZs: 16730, Bias: -1.209963, T: 2256, Avg. loss: 0.086620\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 32.28, NNZs: 17911, Bias: -1.256117, T: 4512, Avg. loss: 0.007900\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 24.24, NNZs: 18361, Bias: -1.229977, T: 6768, Avg. loss: 0.002586\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 19.97, NNZs: 18613, Bias: -1.172493, T: 9024, Avg. loss: 0.001198\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 16.98, NNZs: 18836, Bias: -1.144356, T: 11280, Avg. loss: 0.000868\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 14.94, NNZs: 18960, Bias: -1.109205, T: 13536, Avg. loss: 0.000409\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 49.33, NNZs: 15362, Bias: -1.270680, T: 2256, Avg. loss: 0.095814\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 32.41, NNZs: 16666, Bias: -1.283729, T: 4512, Avg. loss: 0.008415\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 24.07, NNZs: 16982, Bias: -1.301266, T: 6768, Avg. loss: 0.001302\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 19.42, NNZs: 17120, Bias: -1.269960, T: 9024, Avg. loss: 0.000675\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 16.65, NNZs: 17309, Bias: -1.225487, T: 11280, Avg. loss: 0.000827\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 14.40, NNZs: 17353, Bias: -1.212819, T: 13536, Avg. loss: 0.000421\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 19.88, NNZs: 11884, Bias: 0.577528, T: 2256, Avg. loss: 0.025665\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 13.60, NNZs: 13180, Bias: 0.591231, T: 4512, Avg. loss: 0.004118\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 10.38, NNZs: 13742, Bias: 0.577981, T: 6768, Avg. loss: 0.000961\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 8.64, NNZs: 14094, Bias: 0.540737, T: 9024, Avg. loss: 0.000344\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 7.21, NNZs: 14133, Bias: 0.533889, T: 11280, Avg. loss: 0.000162\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 6.46, NNZs: 14336, Bias: 0.513864, T: 13536, Avg. loss: 0.000145\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 379.62, NNZs: 20516, Bias: -6.769552, T: 2256, Avg. loss: 3.828034\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 260.16, NNZs: 21359, Bias: -7.903643, T: 4512, Avg. loss: 0.454532\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 209.72, NNZs: 21835, Bias: -7.783427, T: 6768, Avg. loss: 0.221513\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 160.21, NNZs: 21896, Bias: -8.270437, T: 9024, Avg. loss: 0.061873\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 130.43, NNZs: 21896, Bias: -8.336321, T: 11280, Avg. loss: 0.004459\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 110.18, NNZs: 21896, Bias: -8.336321, T: 13536, Avg. loss: 0.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 3/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.21123614325601048, clf__eta0=0.32979731781585486, clf__fit_intercept=True, clf__l1_ratio=0.4775095579144826, clf__learning_rate=optimal, clf__loss=perceptron, clf__max_iter=30, clf__penalty=l2, clf__power_t=0.6427671735097384, clf__shuffle=False, clf__tol=0.2651165400908262, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.696 total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 46.10, NNZs: 15976, Bias: -1.049545, T: 2256, Avg. loss: 0.090801\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 31.68, NNZs: 17575, Bias: -1.079956, T: 4512, Avg. loss: 0.009997\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 23.89, NNZs: 18006, Bias: -1.025889, T: 6768, Avg. loss: 0.002393\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 19.38, NNZs: 18314, Bias: -0.993080, T: 9024, Avg. loss: 0.000714\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 16.38, NNZs: 18478, Bias: -0.977337, T: 11280, Avg. loss: 0.000726\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 14.08, NNZs: 18563, Bias: -0.965719, T: 13536, Avg. loss: 0.000171\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 49.74, NNZs: 15506, Bias: -1.103249, T: 2256, Avg. loss: 0.102359\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 32.81, NNZs: 16684, Bias: -1.139538, T: 4512, Avg. loss: 0.009562\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 24.37, NNZs: 17208, Bias: -1.111448, T: 6768, Avg. loss: 0.001361\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 19.55, NNZs: 17446, Bias: -1.086206, T: 9024, Avg. loss: 0.000919\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 16.23, NNZs: 17494, Bias: -1.068663, T: 11280, Avg. loss: 0.000205\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 13.88, NNZs: 17510, Bias: -1.054768, T: 13536, Avg. loss: 0.000004\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 19.33, NNZs: 11394, Bias: 0.558643, T: 2256, Avg. loss: 0.026877\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 12.74, NNZs: 12395, Bias: 0.556082, T: 4512, Avg. loss: 0.001652\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 9.69, NNZs: 12647, Bias: 0.530585, T: 6768, Avg. loss: 0.000466\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 7.90, NNZs: 13155, Bias: 0.517394, T: 9024, Avg. loss: 0.000296\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 6.68, NNZs: 13255, Bias: 0.510923, T: 11280, Avg. loss: 0.000160\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 5.84, NNZs: 13294, Bias: 0.496627, T: 13536, Avg. loss: 0.000023\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 350.54, NNZs: 20510, Bias: -6.402131, T: 2256, Avg. loss: 3.630161\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 258.70, NNZs: 21786, Bias: -7.356206, T: 4512, Avg. loss: 0.903401\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 196.46, NNZs: 21829, Bias: -7.277845, T: 6768, Avg. loss: 0.097345\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 150.38, NNZs: 21841, Bias: -7.646818, T: 9024, Avg. loss: 0.054755\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 122.41, NNZs: 21841, Bias: -7.713882, T: 11280, Avg. loss: 0.004758\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 110.85, NNZs: 21862, Bias: -7.572705, T: 13536, Avg. loss: 0.043533\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "[CV 4/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.21123614325601048, clf__eta0=0.32979731781585486, clf__fit_intercept=True, clf__l1_ratio=0.4775095579144826, clf__learning_rate=optimal, clf__loss=perceptron, clf__max_iter=30, clf__penalty=l2, clf__power_t=0.6427671735097384, clf__shuffle=False, clf__tol=0.2651165400908262, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.701 total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 47.51, NNZs: 16888, Bias: -1.029198, T: 2256, Avg. loss: 0.097703\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 33.20, NNZs: 18351, Bias: -1.188721, T: 4512, Avg. loss: 0.013147\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 25.05, NNZs: 18875, Bias: -1.215392, T: 6768, Avg. loss: 0.003741\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 20.21, NNZs: 18991, Bias: -1.167489, T: 9024, Avg. loss: 0.001216\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 16.96, NNZs: 19169, Bias: -1.138272, T: 11280, Avg. loss: 0.000983\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 14.85, NNZs: 19269, Bias: -1.103739, T: 13536, Avg. loss: 0.000952\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 47.17, NNZs: 14592, Bias: -1.199581, T: 2256, Avg. loss: 0.098369\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 32.06, NNZs: 15921, Bias: -1.160170, T: 4512, Avg. loss: 0.010266\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 24.06, NNZs: 16405, Bias: -1.121476, T: 6768, Avg. loss: 0.002884\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 19.38, NNZs: 16512, Bias: -1.092462, T: 9024, Avg. loss: 0.000815\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 16.19, NNZs: 16657, Bias: -1.076850, T: 11280, Avg. loss: 0.000464\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 13.90, NNZs: 16700, Bias: -1.070571, T: 13536, Avg. loss: 0.000181\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 17.56, NNZs: 9789, Bias: 0.476725, T: 2256, Avg. loss: 0.021511\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 11.82, NNZs: 11194, Bias: 0.511837, T: 4512, Avg. loss: 0.003514\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 9.12, NNZs: 11748, Bias: 0.497168, T: 6768, Avg. loss: 0.001521\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 7.48, NNZs: 12020, Bias: 0.485629, T: 9024, Avg. loss: 0.000994\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 6.47, NNZs: 12289, Bias: 0.468857, T: 11280, Avg. loss: 0.000655\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 5.62, NNZs: 12480, Bias: 0.460741, T: 13536, Avg. loss: 0.000471\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 375.53, NNZs: 19819, Bias: -7.042230, T: 2256, Avg. loss: 3.964433\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 252.68, NNZs: 22399, Bias: -9.682215, T: 4512, Avg. loss: 1.117082\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 190.42, NNZs: 22480, Bias: -9.518573, T: 6768, Avg. loss: 0.152300\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 159.39, NNZs: 22504, Bias: -9.134369, T: 9024, Avg. loss: 0.080642\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 128.25, NNZs: 22506, Bias: -9.290748, T: 11280, Avg. loss: 0.080942\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 107.27, NNZs: 22506, Bias: -9.381964, T: 13536, Avg. loss: 0.033815\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 5/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.21123614325601048, clf__eta0=0.32979731781585486, clf__fit_intercept=True, clf__l1_ratio=0.4775095579144826, clf__learning_rate=optimal, clf__loss=perceptron, clf__max_iter=30, clf__penalty=l2, clf__power_t=0.6427671735097384, clf__shuffle=False, clf__tol=0.2651165400908262, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.688 total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 43.18, NNZs: 10898, Bias: 0.000000, T: 2820, Avg. loss: 0.242089\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 51.64, NNZs: 3824, Bias: 0.000000, T: 5640, Avg. loss: 0.060067\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 58.45, NNZs: 2572, Bias: 0.000000, T: 8460, Avg. loss: 0.051217\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 64.01, NNZs: 2062, Bias: 0.000000, T: 11280, Avg. loss: 0.043640\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 68.80, NNZs: 1727, Bias: 0.000000, T: 14100, Avg. loss: 0.039597\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 73.10, NNZs: 1491, Bias: 0.000000, T: 16920, Avg. loss: 0.036835\n",
      "Total training time: 0.06 seconds.\n",
      "Convergence after 6 epochs took 0.06 seconds\n",
      "-- Epoch 1\n",
      "Norm: 36.97, NNZs: 8570, Bias: 0.000000, T: 2820, Avg. loss: 0.174234\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 44.75, NNZs: 3189, Bias: 0.000000, T: 5640, Avg. loss: 0.048570\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 50.82, NNZs: 2247, Bias: 0.000000, T: 8460, Avg. loss: 0.041107\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 55.74, NNZs: 1695, Bias: 0.000000, T: 11280, Avg. loss: 0.035242\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 60.11, NNZs: 1449, Bias: 0.000000, T: 14100, Avg. loss: 0.031966\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 64.01, NNZs: 1288, Bias: 0.000000, T: 16920, Avg. loss: 0.030670\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 6 epochs took 0.05 seconds\n",
      "-- Epoch 1\n",
      "Norm: 37.57, NNZs: 8935, Bias: 0.000000, T: 2820, Avg. loss: 0.157796\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 44.82, NNZs: 3486, Bias: 0.000000, T: 5640, Avg. loss: 0.042752\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 50.99, NNZs: 2427, Bias: 0.000000, T: 8460, Avg. loss: 0.039915\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 55.96, NNZs: 1925, Bias: 0.000000, T: 11280, Avg. loss: 0.032757\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 60.39, NNZs: 1606, Bias: 0.000000, T: 14100, Avg. loss: 0.029411\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 64.30, NNZs: 1394, Bias: 0.000000, T: 16920, Avg. loss: 0.026920\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 6 epochs took 0.05 seconds\n",
      "-- Epoch 1\n",
      "Norm: 23.39, NNZs: 3439, Bias: 0.000000, T: 2820, Avg. loss: 0.056459\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 28.45, NNZs: 1568, Bias: 0.000000, T: 5640, Avg. loss: 0.023150\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 32.78, NNZs: 1145, Bias: 0.000000, T: 8460, Avg. loss: 0.018109\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 36.22, NNZs: 946, Bias: 0.000000, T: 11280, Avg. loss: 0.016870\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 39.21, NNZs: 802, Bias: 0.000000, T: 14100, Avg. loss: 0.015528\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 41.96, NNZs: 693, Bias: 0.000000, T: 16920, Avg. loss: 0.013631\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.05 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9691489361702128\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      precision    recall  f1-score   support\n",
      "\n",
      "      Geen gebruiker       0.89      0.99      0.94       147\n",
      "   Huidige gebruiker       0.98      0.89      0.93       142\n",
      "      Niets gevonden       0.99      0.99      0.99       648\n",
      "Voormalige gebruiker       0.00      0.00      0.00         3\n",
      "\n",
      "            accuracy                           0.97       940\n",
      "           macro avg       0.71      0.72      0.71       940\n",
      "        weighted avg       0.97      0.97      0.97       940\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Ngram 3 Stopwords kept\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1,3), lowercase=True, token_pattern=r\"(?u)\\b\\w\\w+\\b|\\+|\\-\")),\n",
    "    ('clf', SGDClassifier(early_stopping=True, n_iter_no_change=5, validation_fraction = 0.25, verbose=3)),\n",
    "])\n",
    "random_search = RandomizedSearchCV(estimator=pipeline, param_distributions=parameter_grid, random_state=500, verbose=3, scoring='f1_macro')\n",
    "random_search.fit(train_set['text'], train_set['label'])  \n",
    "predicted_nb = random_search.predict(test_set['text'])\n",
    "print(np.mean(predicted_nb == test_set['label']))\n",
    "cm = confusion_matrix(test_set['label'], predicted_nb)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=random_search.classes_)\n",
    "disp.plot()\n",
    "\n",
    "plt.show()\n",
    "print(metrics.classification_report(test_set['label'], predicted_nb,\n",
    "    target_names=random_search.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8dbe93",
   "metadata": {},
   "source": [
    "# Drugs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7edb90",
   "metadata": {},
   "source": [
    "## Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "850b4031",
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs_corpus = Corpus[[\"text\", \"Drugs\"]].rename(columns={\"Drugs\":\"label\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "781ca55f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beloop: \\tPatiÃ«nte heeft 10 minuten van te vo...</td>\n",
       "      <td>Niets gevonden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beloop: \\tG5P4 36 wkGrav 1e lijnALL geen Hb Pa...</td>\n",
       "      <td>Niets gevonden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Conclusie: \\tNormale nacontrole. Kijkt goed te...</td>\n",
       "      <td>Niets gevonden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beleid: \\tAlgemeen: Dagopname voor 3x PC  a 2....</td>\n",
       "      <td>Niets gevonden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anamnese: \\t34W4D</td>\n",
       "      <td>Niets gevonden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4695</th>\n",
       "      <td>Beloop: \\tCONSULTENKAMERGezien door co-ass Y. ...</td>\n",
       "      <td>Geen gebruiker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4696</th>\n",
       "      <td>Reden van komst / Verwijzing: \\tReden verwijzi...</td>\n",
       "      <td>Geen gebruiker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4697</th>\n",
       "      <td>Beloop: \\tMR CPG7P4M4 //  MI: 4x sectio ia, 1x...</td>\n",
       "      <td>Geen gebruiker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4698</th>\n",
       "      <td>Reden van komst / Verwijzing: \\tReden van koms...</td>\n",
       "      <td>Geen gebruiker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4699</th>\n",
       "      <td>Reden van komst / Verwijzing: \\tReden van koms...</td>\n",
       "      <td>Geen gebruiker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4700 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text           label\n",
       "0     Beloop: \\tPatiÃ«nte heeft 10 minuten van te vo...  Niets gevonden\n",
       "1     Beloop: \\tG5P4 36 wkGrav 1e lijnALL geen Hb Pa...  Niets gevonden\n",
       "2     Conclusie: \\tNormale nacontrole. Kijkt goed te...  Niets gevonden\n",
       "3     Beleid: \\tAlgemeen: Dagopname voor 3x PC  a 2....  Niets gevonden\n",
       "4                                     Anamnese: \\t34W4D  Niets gevonden\n",
       "...                                                 ...             ...\n",
       "4695  Beloop: \\tCONSULTENKAMERGezien door co-ass Y. ...  Geen gebruiker\n",
       "4696  Reden van komst / Verwijzing: \\tReden verwijzi...  Geen gebruiker\n",
       "4697  Beloop: \\tMR CPG7P4M4 //  MI: 4x sectio ia, 1x...  Geen gebruiker\n",
       "4698  Reden van komst / Verwijzing: \\tReden van koms...  Geen gebruiker\n",
       "4699  Reden van komst / Verwijzing: \\tReden van koms...  Geen gebruiker\n",
       "\n",
       "[4700 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drugs_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b9f05b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs_corpus['text'] = drugs_corpus['text'].str.replace('\\t',' ')\n",
    "drugs_corpus.drop_duplicates(inplace=True)\n",
    "drugs_corpus['text'] = drugs_corpus['text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f644180b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"dutch\")\n",
    "drugs_corpus['text'] = drugs_corpus['text'].str.lower()\n",
    "drugs_corpus['text'] = [stemmer.stem(text) for text in drugs_corpus['text']]\n",
    "drugs_corpus = drugs_corpus.drop(drugs_corpus[drugs_corpus.label == '--'].index)\n",
    "drugs_corpus_backup = drugs_corpus.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "50615714",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = drugs_corpus.loc[indices['index']]\n",
    "train_set = drugs_corpus.loc[~drugs_corpus.index.isin(test_set.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dfe31bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = {'clf__loss':              ['hinge', 'log_loss', 'log', 'modified_huber', 'squared_hinge', 'perceptron', 'squared_error', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "                  'clf__penalty':           ['l2', 'l1'],\n",
    "                  'clf__l1_ratio':          sp_randFloat(),\n",
    "                  'clf__fit_intercept':     [True, False],\n",
    "                  'clf__max_iter':          [int(x) for x in np.linspace(start = 10, stop = 100, num = 10)],\n",
    "                  'clf__tol':               sp_randFloat(),\n",
    "                  'clf__shuffle':           [True, False],\n",
    "                  'clf__epsilon':           sp_randFloat(),\n",
    "                  'clf__learning_rate':     ['constant', 'optimal', 'invscaling', 'adaptive'],\n",
    "                  'clf__eta0':              sp_randFloat(),\n",
    "                  'clf__power_t':           sp_randFloat(),\n",
    "                  'clf__class_weight':      ['balanced', None],\n",
    "                  'clf__warm_start':        [True, False],\n",
    "                  'clf__average':           [True, False],\n",
    "                  'tfidf__max_df':          [0.90, 0.95],\n",
    "                  'tfidf__min_df':          [3, 5]\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9bb5bd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 24.21, NNZs: 4615, Bias: 0.000000, T: 2256, Avg. loss: 0.372406\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 33.69, NNZs: 2438, Bias: 0.000000, T: 4512, Avg. loss: 0.242599\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 40.62, NNZs: 1850, Bias: 0.000000, T: 6768, Avg. loss: 0.207252\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 46.30, NNZs: 1527, Bias: 0.000000, T: 9024, Avg. loss: 0.187163\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 51.09, NNZs: 1305, Bias: 0.000000, T: 11280, Avg. loss: 0.174724\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 55.42, NNZs: 1167, Bias: 0.000000, T: 13536, Avg. loss: 0.165470\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 56.17, NNZs: 1121, Bias: 0.000000, T: 15792, Avg. loss: 0.158781\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 56.90, NNZs: 1103, Bias: 0.000000, T: 18048, Avg. loss: 0.157306\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 57.63, NNZs: 1088, Bias: 0.000000, T: 20304, Avg. loss: 0.156231\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 58.35, NNZs: 1075, Bias: 0.000000, T: 22560, Avg. loss: 0.155070\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 59.06, NNZs: 1025, Bias: 0.000000, T: 24816, Avg. loss: 0.153883\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 59.20, NNZs: 1017, Bias: 0.000000, T: 27072, Avg. loss: 0.152790\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 59.34, NNZs: 1014, Bias: 0.000000, T: 29328, Avg. loss: 0.152561\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 59.48, NNZs: 1012, Bias: 0.000000, T: 31584, Avg. loss: 0.152348\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 59.61, NNZs: 1010, Bias: 0.000000, T: 33840, Avg. loss: 0.152134\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 59.75, NNZs: 1001, Bias: 0.000000, T: 36096, Avg. loss: 0.151916\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 59.78, NNZs: 1000, Bias: 0.000000, T: 38352, Avg. loss: 0.151700\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 59.81, NNZs: 997, Bias: 0.000000, T: 40608, Avg. loss: 0.151658\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 59.83, NNZs: 996, Bias: 0.000000, T: 42864, Avg. loss: 0.151615\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 59.86, NNZs: 996, Bias: 0.000000, T: 45120, Avg. loss: 0.151572\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 21.08, NNZs: 2279, Bias: 0.000000, T: 2256, Avg. loss: 0.182784\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 26.27, NNZs: 1212, Bias: 0.000000, T: 4512, Avg. loss: 0.114281\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 30.35, NNZs: 924, Bias: 0.000000, T: 6768, Avg. loss: 0.100028\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 34.01, NNZs: 775, Bias: 0.000000, T: 9024, Avg. loss: 0.092276\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 36.91, NNZs: 691, Bias: 0.000000, T: 11280, Avg. loss: 0.087551\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 39.55, NNZs: 600, Bias: 0.000000, T: 13536, Avg. loss: 0.083979\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 40.06, NNZs: 577, Bias: 0.000000, T: 15792, Avg. loss: 0.081252\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 40.55, NNZs: 569, Bias: 0.000000, T: 18048, Avg. loss: 0.080720\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 41.03, NNZs: 557, Bias: 0.000000, T: 20304, Avg. loss: 0.080265\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 41.50, NNZs: 546, Bias: 0.000000, T: 22560, Avg. loss: 0.079805\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 41.96, NNZs: 533, Bias: 0.000000, T: 24816, Avg. loss: 0.079325\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 42.06, NNZs: 528, Bias: 0.000000, T: 27072, Avg. loss: 0.078852\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 42.15, NNZs: 527, Bias: 0.000000, T: 29328, Avg. loss: 0.078782\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 42.24, NNZs: 524, Bias: 0.000000, T: 31584, Avg. loss: 0.078686\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 42.32, NNZs: 523, Bias: 0.000000, T: 33840, Avg. loss: 0.078608\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 42.41, NNZs: 522, Bias: 0.000000, T: 36096, Avg. loss: 0.078527\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 42.43, NNZs: 522, Bias: 0.000000, T: 38352, Avg. loss: 0.078434\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 42.45, NNZs: 522, Bias: 0.000000, T: 40608, Avg. loss: 0.078422\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 42.47, NNZs: 522, Bias: 0.000000, T: 42864, Avg. loss: 0.078401\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 42.49, NNZs: 522, Bias: 0.000000, T: 45120, Avg. loss: 0.078386\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 25.02, NNZs: 4550, Bias: 0.000000, T: 2256, Avg. loss: 0.343003\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 34.65, NNZs: 2385, Bias: 0.000000, T: 4512, Avg. loss: 0.204716\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 41.60, NNZs: 1870, Bias: 0.000000, T: 6768, Avg. loss: 0.170442\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 47.17, NNZs: 1581, Bias: 0.000000, T: 9024, Avg. loss: 0.151260\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 51.94, NNZs: 1393, Bias: 0.000000, T: 11280, Avg. loss: 0.139857\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 56.17, NNZs: 1243, Bias: 0.000000, T: 13536, Avg. loss: 0.131350\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 56.93, NNZs: 1207, Bias: 0.000000, T: 15792, Avg. loss: 0.126389\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 57.68, NNZs: 1181, Bias: 0.000000, T: 18048, Avg. loss: 0.125243\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 58.41, NNZs: 1159, Bias: 0.000000, T: 20304, Avg. loss: 0.124100\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 59.13, NNZs: 1146, Bias: 0.000000, T: 22560, Avg. loss: 0.123112\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 59.84, NNZs: 1104, Bias: 0.000000, T: 24816, Avg. loss: 0.122072\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 59.98, NNZs: 1100, Bias: 0.000000, T: 27072, Avg. loss: 0.121209\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 60.11, NNZs: 1090, Bias: 0.000000, T: 29328, Avg. loss: 0.121032\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 60.25, NNZs: 1087, Bias: 0.000000, T: 31584, Avg. loss: 0.120842\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 60.39, NNZs: 1083, Bias: 0.000000, T: 33840, Avg. loss: 0.120649\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 60.53, NNZs: 1078, Bias: 0.000000, T: 36096, Avg. loss: 0.120453\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 60.56, NNZs: 1075, Bias: 0.000000, T: 38352, Avg. loss: 0.120292\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 60.58, NNZs: 1074, Bias: 0.000000, T: 40608, Avg. loss: 0.120257\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 60.61, NNZs: 1072, Bias: 0.000000, T: 42864, Avg. loss: 0.120221\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 60.64, NNZs: 1066, Bias: 0.000000, T: 45120, Avg. loss: 0.120183\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 21.81, NNZs: 2083, Bias: 0.000000, T: 2256, Avg. loss: 0.139005\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 27.48, NNZs: 928, Bias: 0.000000, T: 4512, Avg. loss: 0.064409\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 31.28, NNZs: 636, Bias: 0.000000, T: 6768, Avg. loss: 0.054618\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 34.22, NNZs: 525, Bias: 0.000000, T: 9024, Avg. loss: 0.050182\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 36.68, NNZs: 447, Bias: 0.000000, T: 11280, Avg. loss: 0.047731\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 38.86, NNZs: 379, Bias: 0.000000, T: 13536, Avg. loss: 0.046133\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 39.24, NNZs: 373, Bias: 0.000000, T: 15792, Avg. loss: 0.044996\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 39.63, NNZs: 362, Bias: 0.000000, T: 18048, Avg. loss: 0.044868\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 40.00, NNZs: 352, Bias: 0.000000, T: 20304, Avg. loss: 0.044650\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 40.37, NNZs: 346, Bias: 0.000000, T: 22560, Avg. loss: 0.044455\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 40.73, NNZs: 339, Bias: 0.000000, T: 24816, Avg. loss: 0.044285\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 40.80, NNZs: 338, Bias: 0.000000, T: 27072, Avg. loss: 0.044143\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 40.87, NNZs: 334, Bias: 0.000000, T: 29328, Avg. loss: 0.044115\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 40.94, NNZs: 334, Bias: 0.000000, T: 31584, Avg. loss: 0.044085\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 41.01, NNZs: 333, Bias: 0.000000, T: 33840, Avg. loss: 0.044046\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 41.08, NNZs: 331, Bias: 0.000000, T: 36096, Avg. loss: 0.044012\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 41.10, NNZs: 331, Bias: 0.000000, T: 38352, Avg. loss: 0.043996\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 41.11, NNZs: 330, Bias: 0.000000, T: 40608, Avg. loss: 0.043989\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 41.12, NNZs: 330, Bias: 0.000000, T: 42864, Avg. loss: 0.043984\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 41.14, NNZs: 330, Bias: 0.000000, T: 45120, Avg. loss: 0.043977\n",
      "Total training time: 0.13 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.6s finished\n",
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.06171699256249541, clf__eta0=0.6666115972798587, clf__fit_intercept=False, clf__l1_ratio=0.9792901432894962, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.15075392531110676, clf__shuffle=True, clf__tol=0.365636830734297, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.454 total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 24.06, NNZs: 4502, Bias: 0.000000, T: 2256, Avg. loss: 0.378823\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 33.69, NNZs: 2376, Bias: 0.000000, T: 4512, Avg. loss: 0.247574\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 40.67, NNZs: 1855, Bias: 0.000000, T: 6768, Avg. loss: 0.210898\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 46.30, NNZs: 1589, Bias: 0.000000, T: 9024, Avg. loss: 0.192550\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 51.25, NNZs: 1344, Bias: 0.000000, T: 11280, Avg. loss: 0.179227\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 55.55, NNZs: 1190, Bias: 0.000000, T: 13536, Avg. loss: 0.169114\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 56.33, NNZs: 1138, Bias: 0.000000, T: 15792, Avg. loss: 0.162885\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 57.09, NNZs: 1120, Bias: 0.000000, T: 18048, Avg. loss: 0.161492\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 57.84, NNZs: 1111, Bias: 0.000000, T: 20304, Avg. loss: 0.160153\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 58.57, NNZs: 1098, Bias: 0.000000, T: 22560, Avg. loss: 0.158788\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 59.30, NNZs: 1070, Bias: 0.000000, T: 24816, Avg. loss: 0.157683\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 59.44, NNZs: 1064, Bias: 0.000000, T: 27072, Avg. loss: 0.156522\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 59.58, NNZs: 1063, Bias: 0.000000, T: 29328, Avg. loss: 0.156287\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 59.72, NNZs: 1059, Bias: 0.000000, T: 31584, Avg. loss: 0.156058\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 59.86, NNZs: 1058, Bias: 0.000000, T: 33840, Avg. loss: 0.155838\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 60.00, NNZs: 1053, Bias: 0.000000, T: 36096, Avg. loss: 0.155602\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 60.03, NNZs: 1053, Bias: 0.000000, T: 38352, Avg. loss: 0.155384\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 60.06, NNZs: 1053, Bias: 0.000000, T: 40608, Avg. loss: 0.155340\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 60.09, NNZs: 1052, Bias: 0.000000, T: 42864, Avg. loss: 0.155296\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 60.11, NNZs: 1050, Bias: 0.000000, T: 45120, Avg. loss: 0.155254\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 20.68, NNZs: 2307, Bias: 0.000000, T: 2256, Avg. loss: 0.190499\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 26.79, NNZs: 1229, Bias: 0.000000, T: 4512, Avg. loss: 0.118091\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 30.49, NNZs: 970, Bias: 0.000000, T: 6768, Avg. loss: 0.104143\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 34.28, NNZs: 826, Bias: 0.000000, T: 9024, Avg. loss: 0.096678\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 37.52, NNZs: 689, Bias: 0.000000, T: 11280, Avg. loss: 0.091721\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 39.97, NNZs: 631, Bias: 0.000000, T: 13536, Avg. loss: 0.088368\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 40.47, NNZs: 607, Bias: 0.000000, T: 15792, Avg. loss: 0.085753\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 40.96, NNZs: 593, Bias: 0.000000, T: 18048, Avg. loss: 0.085290\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 41.43, NNZs: 579, Bias: 0.000000, T: 20304, Avg. loss: 0.084822\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 41.93, NNZs: 565, Bias: 0.000000, T: 22560, Avg. loss: 0.084307\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 42.38, NNZs: 560, Bias: 0.000000, T: 24816, Avg. loss: 0.083923\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 42.47, NNZs: 557, Bias: 0.000000, T: 27072, Avg. loss: 0.083490\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 42.56, NNZs: 555, Bias: 0.000000, T: 29328, Avg. loss: 0.083413\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 42.65, NNZs: 552, Bias: 0.000000, T: 31584, Avg. loss: 0.083337\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 42.74, NNZs: 549, Bias: 0.000000, T: 33840, Avg. loss: 0.083242\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 42.83, NNZs: 548, Bias: 0.000000, T: 36096, Avg. loss: 0.083156\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 42.85, NNZs: 543, Bias: 0.000000, T: 38352, Avg. loss: 0.083078\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 42.87, NNZs: 542, Bias: 0.000000, T: 40608, Avg. loss: 0.083063\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 42.89, NNZs: 540, Bias: 0.000000, T: 42864, Avg. loss: 0.083045\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 42.90, NNZs: 540, Bias: 0.000000, T: 45120, Avg. loss: 0.083029\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 24.85, NNZs: 4696, Bias: 0.000000, T: 2256, Avg. loss: 0.350641\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 34.58, NNZs: 2402, Bias: 0.000000, T: 4512, Avg. loss: 0.213865\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 41.61, NNZs: 1898, Bias: 0.000000, T: 6768, Avg. loss: 0.178019\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 47.28, NNZs: 1606, Bias: 0.000000, T: 9024, Avg. loss: 0.158202\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 52.16, NNZs: 1419, Bias: 0.000000, T: 11280, Avg. loss: 0.146243\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 56.47, NNZs: 1243, Bias: 0.000000, T: 13536, Avg. loss: 0.136670\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 57.24, NNZs: 1196, Bias: 0.000000, T: 15792, Avg. loss: 0.131363\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 58.00, NNZs: 1151, Bias: 0.000000, T: 18048, Avg. loss: 0.130258\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 58.74, NNZs: 1137, Bias: 0.000000, T: 20304, Avg. loss: 0.128999\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 59.48, NNZs: 1119, Bias: 0.000000, T: 22560, Avg. loss: 0.127858\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 60.20, NNZs: 1107, Bias: 0.000000, T: 24816, Avg. loss: 0.126770\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 60.34, NNZs: 1098, Bias: 0.000000, T: 27072, Avg. loss: 0.125871\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 60.48, NNZs: 1091, Bias: 0.000000, T: 29328, Avg. loss: 0.125662\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 60.62, NNZs: 1085, Bias: 0.000000, T: 31584, Avg. loss: 0.125469\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 60.76, NNZs: 1083, Bias: 0.000000, T: 33840, Avg. loss: 0.125261\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 60.90, NNZs: 1077, Bias: 0.000000, T: 36096, Avg. loss: 0.125056\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 60.92, NNZs: 1076, Bias: 0.000000, T: 38352, Avg. loss: 0.124888\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 60.95, NNZs: 1076, Bias: 0.000000, T: 40608, Avg. loss: 0.124849\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 60.98, NNZs: 1074, Bias: 0.000000, T: 42864, Avg. loss: 0.124811\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 61.01, NNZs: 1074, Bias: 0.000000, T: 45120, Avg. loss: 0.124770\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 22.06, NNZs: 2206, Bias: 0.000000, T: 2256, Avg. loss: 0.143931\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 27.83, NNZs: 935, Bias: 0.000000, T: 4512, Avg. loss: 0.067662\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 31.72, NNZs: 673, Bias: 0.000000, T: 6768, Avg. loss: 0.057403\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 34.70, NNZs: 534, Bias: 0.000000, T: 9024, Avg. loss: 0.052476\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 37.19, NNZs: 470, Bias: 0.000000, T: 11280, Avg. loss: 0.049746\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 39.39, NNZs: 406, Bias: 0.000000, T: 13536, Avg. loss: 0.048310\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 39.80, NNZs: 389, Bias: 0.000000, T: 15792, Avg. loss: 0.047263\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 40.19, NNZs: 381, Bias: 0.000000, T: 18048, Avg. loss: 0.047079\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 40.58, NNZs: 370, Bias: 0.000000, T: 20304, Avg. loss: 0.046862\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 40.95, NNZs: 364, Bias: 0.000000, T: 22560, Avg. loss: 0.046644\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 41.33, NNZs: 356, Bias: 0.000000, T: 24816, Avg. loss: 0.046498\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 41.40, NNZs: 354, Bias: 0.000000, T: 27072, Avg. loss: 0.046316\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 41.47, NNZs: 353, Bias: 0.000000, T: 29328, Avg. loss: 0.046278\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 41.54, NNZs: 353, Bias: 0.000000, T: 31584, Avg. loss: 0.046235\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 41.62, NNZs: 352, Bias: 0.000000, T: 33840, Avg. loss: 0.046210\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 41.69, NNZs: 352, Bias: 0.000000, T: 36096, Avg. loss: 0.046173\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 41.70, NNZs: 352, Bias: 0.000000, T: 38352, Avg. loss: 0.046145\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 41.72, NNZs: 352, Bias: 0.000000, T: 40608, Avg. loss: 0.046139\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 41.73, NNZs: 352, Bias: 0.000000, T: 42864, Avg. loss: 0.046131\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 41.75, NNZs: 352, Bias: 0.000000, T: 45120, Avg. loss: 0.046126\n",
      "Total training time: 0.13 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.6s finished\n",
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.06171699256249541, clf__eta0=0.6666115972798587, clf__fit_intercept=False, clf__l1_ratio=0.9792901432894962, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.15075392531110676, clf__shuffle=True, clf__tol=0.365636830734297, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.465 total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 23.90, NNZs: 4759, Bias: 0.000000, T: 2256, Avg. loss: 0.390999\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 33.38, NNZs: 2435, Bias: 0.000000, T: 4512, Avg. loss: 0.264020\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 40.30, NNZs: 1889, Bias: 0.000000, T: 6768, Avg. loss: 0.227788\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 46.07, NNZs: 1566, Bias: 0.000000, T: 9024, Avg. loss: 0.208517\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 51.01, NNZs: 1353, Bias: 0.000000, T: 11280, Avg. loss: 0.194129\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 55.36, NNZs: 1212, Bias: 0.000000, T: 13536, Avg. loss: 0.184516\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 56.15, NNZs: 1180, Bias: 0.000000, T: 15792, Avg. loss: 0.177806\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 56.92, NNZs: 1152, Bias: 0.000000, T: 18048, Avg. loss: 0.176255\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 57.69, NNZs: 1135, Bias: 0.000000, T: 20304, Avg. loss: 0.174859\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 58.44, NNZs: 1120, Bias: 0.000000, T: 22560, Avg. loss: 0.173260\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 59.17, NNZs: 1108, Bias: 0.000000, T: 24816, Avg. loss: 0.172045\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 59.31, NNZs: 1103, Bias: 0.000000, T: 27072, Avg. loss: 0.170801\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 59.46, NNZs: 1101, Bias: 0.000000, T: 29328, Avg. loss: 0.170586\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 59.60, NNZs: 1099, Bias: 0.000000, T: 31584, Avg. loss: 0.170294\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 59.74, NNZs: 1097, Bias: 0.000000, T: 33840, Avg. loss: 0.170067\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 59.88, NNZs: 1091, Bias: 0.000000, T: 36096, Avg. loss: 0.169839\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 59.91, NNZs: 1090, Bias: 0.000000, T: 38352, Avg. loss: 0.169594\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 59.94, NNZs: 1090, Bias: 0.000000, T: 40608, Avg. loss: 0.169553\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 59.97, NNZs: 1089, Bias: 0.000000, T: 42864, Avg. loss: 0.169506\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 60.00, NNZs: 1088, Bias: 0.000000, T: 45120, Avg. loss: 0.169455\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 20.55, NNZs: 2263, Bias: 0.000000, T: 2256, Avg. loss: 0.190613\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 26.50, NNZs: 1240, Bias: 0.000000, T: 4512, Avg. loss: 0.116571\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 31.00, NNZs: 1000, Bias: 0.000000, T: 6768, Avg. loss: 0.100712\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 34.29, NNZs: 842, Bias: 0.000000, T: 9024, Avg. loss: 0.093019\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 37.63, NNZs: 732, Bias: 0.000000, T: 11280, Avg. loss: 0.087780\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 40.61, NNZs: 613, Bias: 0.000000, T: 13536, Avg. loss: 0.082972\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 41.02, NNZs: 605, Bias: 0.000000, T: 15792, Avg. loss: 0.082096\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 41.47, NNZs: 592, Bias: 0.000000, T: 18048, Avg. loss: 0.081185\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 41.92, NNZs: 585, Bias: 0.000000, T: 20304, Avg. loss: 0.080622\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 42.37, NNZs: 577, Bias: 0.000000, T: 22560, Avg. loss: 0.079979\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 42.84, NNZs: 567, Bias: 0.000000, T: 24816, Avg. loss: 0.079471\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 42.93, NNZs: 558, Bias: 0.000000, T: 27072, Avg. loss: 0.078975\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 43.02, NNZs: 556, Bias: 0.000000, T: 29328, Avg. loss: 0.078883\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 43.11, NNZs: 555, Bias: 0.000000, T: 31584, Avg. loss: 0.078783\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 43.21, NNZs: 554, Bias: 0.000000, T: 33840, Avg. loss: 0.078699\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 43.30, NNZs: 554, Bias: 0.000000, T: 36096, Avg. loss: 0.078629\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 43.31, NNZs: 553, Bias: 0.000000, T: 38352, Avg. loss: 0.078515\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 43.33, NNZs: 553, Bias: 0.000000, T: 40608, Avg. loss: 0.078503\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 43.35, NNZs: 553, Bias: 0.000000, T: 42864, Avg. loss: 0.078486\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 43.37, NNZs: 553, Bias: 0.000000, T: 45120, Avg. loss: 0.078467\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 24.84, NNZs: 4696, Bias: 0.000000, T: 2256, Avg. loss: 0.358303\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 34.48, NNZs: 2489, Bias: 0.000000, T: 4512, Avg. loss: 0.222698\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 41.50, NNZs: 1959, Bias: 0.000000, T: 6768, Avg. loss: 0.186331\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 47.16, NNZs: 1633, Bias: 0.000000, T: 9024, Avg. loss: 0.167410\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 52.05, NNZs: 1417, Bias: 0.000000, T: 11280, Avg. loss: 0.154975\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 56.40, NNZs: 1276, Bias: 0.000000, T: 13536, Avg. loss: 0.145932\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 57.17, NNZs: 1236, Bias: 0.000000, T: 15792, Avg. loss: 0.139958\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 57.93, NNZs: 1207, Bias: 0.000000, T: 18048, Avg. loss: 0.138784\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 58.68, NNZs: 1178, Bias: 0.000000, T: 20304, Avg. loss: 0.137587\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 59.41, NNZs: 1136, Bias: 0.000000, T: 22560, Avg. loss: 0.136468\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 60.14, NNZs: 1119, Bias: 0.000000, T: 24816, Avg. loss: 0.135290\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 60.28, NNZs: 1114, Bias: 0.000000, T: 27072, Avg. loss: 0.134378\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 60.42, NNZs: 1111, Bias: 0.000000, T: 29328, Avg. loss: 0.134185\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 60.56, NNZs: 1107, Bias: 0.000000, T: 31584, Avg. loss: 0.133977\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 60.70, NNZs: 1101, Bias: 0.000000, T: 33840, Avg. loss: 0.133766\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 60.84, NNZs: 1095, Bias: 0.000000, T: 36096, Avg. loss: 0.133555\n",
      "Total training time: 0.11 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 17\n",
      "Norm: 60.87, NNZs: 1094, Bias: 0.000000, T: 38352, Avg. loss: 0.133378\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 60.89, NNZs: 1092, Bias: 0.000000, T: 40608, Avg. loss: 0.133341\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 60.92, NNZs: 1091, Bias: 0.000000, T: 42864, Avg. loss: 0.133299\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 60.95, NNZs: 1088, Bias: 0.000000, T: 45120, Avg. loss: 0.133260\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 22.03, NNZs: 2167, Bias: 0.000000, T: 2256, Avg. loss: 0.143248\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 27.66, NNZs: 933, Bias: 0.000000, T: 4512, Avg. loss: 0.067566\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 31.52, NNZs: 660, Bias: 0.000000, T: 6768, Avg. loss: 0.057583\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 34.57, NNZs: 538, Bias: 0.000000, T: 9024, Avg. loss: 0.052913\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 37.08, NNZs: 440, Bias: 0.000000, T: 11280, Avg. loss: 0.050061\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 39.27, NNZs: 390, Bias: 0.000000, T: 13536, Avg. loss: 0.048351\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 39.67, NNZs: 377, Bias: 0.000000, T: 15792, Avg. loss: 0.047197\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 40.05, NNZs: 370, Bias: 0.000000, T: 18048, Avg. loss: 0.047030\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 40.44, NNZs: 365, Bias: 0.000000, T: 20304, Avg. loss: 0.046830\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 40.81, NNZs: 353, Bias: 0.000000, T: 22560, Avg. loss: 0.046604\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 41.18, NNZs: 344, Bias: 0.000000, T: 24816, Avg. loss: 0.046381\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 41.25, NNZs: 340, Bias: 0.000000, T: 27072, Avg. loss: 0.046263\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 41.32, NNZs: 339, Bias: 0.000000, T: 29328, Avg. loss: 0.046227\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 41.39, NNZs: 338, Bias: 0.000000, T: 31584, Avg. loss: 0.046188\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 41.46, NNZs: 338, Bias: 0.000000, T: 33840, Avg. loss: 0.046154\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 41.54, NNZs: 334, Bias: 0.000000, T: 36096, Avg. loss: 0.046121\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 41.55, NNZs: 334, Bias: 0.000000, T: 38352, Avg. loss: 0.046093\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 41.56, NNZs: 334, Bias: 0.000000, T: 40608, Avg. loss: 0.046085\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 41.58, NNZs: 334, Bias: 0.000000, T: 42864, Avg. loss: 0.046079\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 41.59, NNZs: 334, Bias: 0.000000, T: 45120, Avg. loss: 0.046073\n",
      "Total training time: 0.13 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.6s finished\n",
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.06171699256249541, clf__eta0=0.6666115972798587, clf__fit_intercept=False, clf__l1_ratio=0.9792901432894962, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.15075392531110676, clf__shuffle=True, clf__tol=0.365636830734297, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.483 total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 24.19, NNZs: 4449, Bias: 0.000000, T: 2256, Avg. loss: 0.371827\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 33.43, NNZs: 2241, Bias: 0.000000, T: 4512, Avg. loss: 0.244003\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 40.27, NNZs: 1740, Bias: 0.000000, T: 6768, Avg. loss: 0.209746\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 45.89, NNZs: 1439, Bias: 0.000000, T: 9024, Avg. loss: 0.191518\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 50.72, NNZs: 1257, Bias: 0.000000, T: 11280, Avg. loss: 0.178344\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 55.02, NNZs: 1110, Bias: 0.000000, T: 13536, Avg. loss: 0.168571\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 55.77, NNZs: 1069, Bias: 0.000000, T: 15792, Avg. loss: 0.162098\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 56.50, NNZs: 1045, Bias: 0.000000, T: 18048, Avg. loss: 0.160692\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 57.23, NNZs: 1030, Bias: 0.000000, T: 20304, Avg. loss: 0.159522\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 57.95, NNZs: 1010, Bias: 0.000000, T: 22560, Avg. loss: 0.158292\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 58.65, NNZs: 997, Bias: 0.000000, T: 24816, Avg. loss: 0.157103\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 58.79, NNZs: 993, Bias: 0.000000, T: 27072, Avg. loss: 0.156043\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 58.93, NNZs: 993, Bias: 0.000000, T: 29328, Avg. loss: 0.155829\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 59.06, NNZs: 986, Bias: 0.000000, T: 31584, Avg. loss: 0.155595\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 59.20, NNZs: 986, Bias: 0.000000, T: 33840, Avg. loss: 0.155398\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 59.34, NNZs: 982, Bias: 0.000000, T: 36096, Avg. loss: 0.155182\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 59.36, NNZs: 981, Bias: 0.000000, T: 38352, Avg. loss: 0.154958\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 59.39, NNZs: 980, Bias: 0.000000, T: 40608, Avg. loss: 0.154917\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 59.42, NNZs: 980, Bias: 0.000000, T: 42864, Avg. loss: 0.154874\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 59.44, NNZs: 980, Bias: 0.000000, T: 45120, Avg. loss: 0.154831\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 20.82, NNZs: 2225, Bias: 0.000000, T: 2256, Avg. loss: 0.183262\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 26.02, NNZs: 1098, Bias: 0.000000, T: 4512, Avg. loss: 0.115336\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 30.14, NNZs: 889, Bias: 0.000000, T: 6768, Avg. loss: 0.101613\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 33.47, NNZs: 749, Bias: 0.000000, T: 9024, Avg. loss: 0.095468\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 36.30, NNZs: 657, Bias: 0.000000, T: 11280, Avg. loss: 0.090400\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 39.00, NNZs: 578, Bias: 0.000000, T: 13536, Avg. loss: 0.086836\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 39.51, NNZs: 555, Bias: 0.000000, T: 15792, Avg. loss: 0.084285\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 40.01, NNZs: 540, Bias: 0.000000, T: 18048, Avg. loss: 0.083761\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 40.50, NNZs: 534, Bias: 0.000000, T: 20304, Avg. loss: 0.083179\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 40.98, NNZs: 528, Bias: 0.000000, T: 22560, Avg. loss: 0.082644\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 41.44, NNZs: 525, Bias: 0.000000, T: 24816, Avg. loss: 0.082202\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 41.53, NNZs: 522, Bias: 0.000000, T: 27072, Avg. loss: 0.081762\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 41.62, NNZs: 520, Bias: 0.000000, T: 29328, Avg. loss: 0.081690\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 41.71, NNZs: 519, Bias: 0.000000, T: 31584, Avg. loss: 0.081589\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 41.80, NNZs: 517, Bias: 0.000000, T: 33840, Avg. loss: 0.081510\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 41.88, NNZs: 513, Bias: 0.000000, T: 36096, Avg. loss: 0.081425\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 41.90, NNZs: 511, Bias: 0.000000, T: 38352, Avg. loss: 0.081334\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 41.92, NNZs: 511, Bias: 0.000000, T: 40608, Avg. loss: 0.081319\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 41.94, NNZs: 511, Bias: 0.000000, T: 42864, Avg. loss: 0.081303\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 41.95, NNZs: 511, Bias: 0.000000, T: 45120, Avg. loss: 0.081286\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 24.80, NNZs: 4538, Bias: 0.000000, T: 2256, Avg. loss: 0.345248\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 34.49, NNZs: 2261, Bias: 0.000000, T: 4512, Avg. loss: 0.207257\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 41.35, NNZs: 1746, Bias: 0.000000, T: 6768, Avg. loss: 0.172404\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 46.94, NNZs: 1484, Bias: 0.000000, T: 9024, Avg. loss: 0.154366\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 51.72, NNZs: 1292, Bias: 0.000000, T: 11280, Avg. loss: 0.142401\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 55.96, NNZs: 1141, Bias: 0.000000, T: 13536, Avg. loss: 0.134158\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 56.71, NNZs: 1096, Bias: 0.000000, T: 15792, Avg. loss: 0.128406\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 57.45, NNZs: 1056, Bias: 0.000000, T: 18048, Avg. loss: 0.127205\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 58.18, NNZs: 1023, Bias: 0.000000, T: 20304, Avg. loss: 0.126050\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 58.89, NNZs: 1012, Bias: 0.000000, T: 22560, Avg. loss: 0.124918\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 59.60, NNZs: 998, Bias: 0.000000, T: 24816, Avg. loss: 0.123968\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 59.73, NNZs: 992, Bias: 0.000000, T: 27072, Avg. loss: 0.123040\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 59.87, NNZs: 989, Bias: 0.000000, T: 29328, Avg. loss: 0.122864\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 60.01, NNZs: 987, Bias: 0.000000, T: 31584, Avg. loss: 0.122661\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 60.14, NNZs: 981, Bias: 0.000000, T: 33840, Avg. loss: 0.122469\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 60.28, NNZs: 978, Bias: 0.000000, T: 36096, Avg. loss: 0.122290\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 60.31, NNZs: 977, Bias: 0.000000, T: 38352, Avg. loss: 0.122112\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 60.33, NNZs: 977, Bias: 0.000000, T: 40608, Avg. loss: 0.122076\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 60.36, NNZs: 974, Bias: 0.000000, T: 42864, Avg. loss: 0.122039\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 60.39, NNZs: 973, Bias: 0.000000, T: 45120, Avg. loss: 0.122002\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 22.00, NNZs: 2144, Bias: 0.000000, T: 2256, Avg. loss: 0.140352\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 27.69, NNZs: 960, Bias: 0.000000, T: 4512, Avg. loss: 0.064491\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 31.31, NNZs: 667, Bias: 0.000000, T: 6768, Avg. loss: 0.054771\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 34.32, NNZs: 528, Bias: 0.000000, T: 9024, Avg. loss: 0.051258\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 36.74, NNZs: 420, Bias: 0.000000, T: 11280, Avg. loss: 0.048352\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 38.86, NNZs: 378, Bias: 0.000000, T: 13536, Avg. loss: 0.046832\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 39.25, NNZs: 374, Bias: 0.000000, T: 15792, Avg. loss: 0.045864\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 39.63, NNZs: 371, Bias: 0.000000, T: 18048, Avg. loss: 0.045674\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 40.01, NNZs: 361, Bias: 0.000000, T: 20304, Avg. loss: 0.045452\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 40.38, NNZs: 348, Bias: 0.000000, T: 22560, Avg. loss: 0.045296\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 40.74, NNZs: 336, Bias: 0.000000, T: 24816, Avg. loss: 0.045115\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 40.81, NNZs: 336, Bias: 0.000000, T: 27072, Avg. loss: 0.044974\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 40.88, NNZs: 334, Bias: 0.000000, T: 29328, Avg. loss: 0.044937\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 40.95, NNZs: 334, Bias: 0.000000, T: 31584, Avg. loss: 0.044899\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 41.02, NNZs: 332, Bias: 0.000000, T: 33840, Avg. loss: 0.044865\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 41.09, NNZs: 330, Bias: 0.000000, T: 36096, Avg. loss: 0.044840\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 41.11, NNZs: 330, Bias: 0.000000, T: 38352, Avg. loss: 0.044806\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 41.12, NNZs: 328, Bias: 0.000000, T: 40608, Avg. loss: 0.044801\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 41.13, NNZs: 328, Bias: 0.000000, T: 42864, Avg. loss: 0.044792\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 41.15, NNZs: 327, Bias: 0.000000, T: 45120, Avg. loss: 0.044785\n",
      "Total training time: 0.13 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.6s finished\n",
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.06171699256249541, clf__eta0=0.6666115972798587, clf__fit_intercept=False, clf__l1_ratio=0.9792901432894962, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.15075392531110676, clf__shuffle=True, clf__tol=0.365636830734297, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.456 total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 23.98, NNZs: 4687, Bias: 0.000000, T: 2256, Avg. loss: 0.368798\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 33.34, NNZs: 2347, Bias: 0.000000, T: 4512, Avg. loss: 0.240981\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 40.30, NNZs: 1857, Bias: 0.000000, T: 6768, Avg. loss: 0.207760\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 45.83, NNZs: 1580, Bias: 0.000000, T: 9024, Avg. loss: 0.188489\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 50.53, NNZs: 1370, Bias: 0.000000, T: 11280, Avg. loss: 0.176599\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 54.78, NNZs: 1196, Bias: 0.000000, T: 13536, Avg. loss: 0.167920\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 55.53, NNZs: 1149, Bias: 0.000000, T: 15792, Avg. loss: 0.161530\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 56.27, NNZs: 1128, Bias: 0.000000, T: 18048, Avg. loss: 0.160219\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 56.99, NNZs: 1112, Bias: 0.000000, T: 20304, Avg. loss: 0.158926\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 57.70, NNZs: 1084, Bias: 0.000000, T: 22560, Avg. loss: 0.157688\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 58.41, NNZs: 1063, Bias: 0.000000, T: 24816, Avg. loss: 0.156610\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 58.55, NNZs: 1056, Bias: 0.000000, T: 27072, Avg. loss: 0.155565\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 58.68, NNZs: 1048, Bias: 0.000000, T: 29328, Avg. loss: 0.155384\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 58.82, NNZs: 1046, Bias: 0.000000, T: 31584, Avg. loss: 0.155150\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 58.96, NNZs: 1044, Bias: 0.000000, T: 33840, Avg. loss: 0.154928\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 59.09, NNZs: 1039, Bias: 0.000000, T: 36096, Avg. loss: 0.154712\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 59.12, NNZs: 1037, Bias: 0.000000, T: 38352, Avg. loss: 0.154509\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 59.15, NNZs: 1037, Bias: 0.000000, T: 40608, Avg. loss: 0.154461\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 59.18, NNZs: 1037, Bias: 0.000000, T: 42864, Avg. loss: 0.154423\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 59.20, NNZs: 1037, Bias: 0.000000, T: 45120, Avg. loss: 0.154379\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 20.74, NNZs: 2200, Bias: 0.000000, T: 2256, Avg. loss: 0.185468\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 26.29, NNZs: 1078, Bias: 0.000000, T: 4512, Avg. loss: 0.116931\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 30.23, NNZs: 853, Bias: 0.000000, T: 6768, Avg. loss: 0.103726\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 33.72, NNZs: 710, Bias: 0.000000, T: 9024, Avg. loss: 0.096277\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 36.50, NNZs: 632, Bias: 0.000000, T: 11280, Avg. loss: 0.091692\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 39.13, NNZs: 566, Bias: 0.000000, T: 13536, Avg. loss: 0.087803\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 39.65, NNZs: 548, Bias: 0.000000, T: 15792, Avg. loss: 0.085271\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 40.14, NNZs: 534, Bias: 0.000000, T: 18048, Avg. loss: 0.084625\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 40.64, NNZs: 522, Bias: 0.000000, T: 20304, Avg. loss: 0.084120\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 41.11, NNZs: 511, Bias: 0.000000, T: 22560, Avg. loss: 0.083547\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 41.58, NNZs: 507, Bias: 0.000000, T: 24816, Avg. loss: 0.083098\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 41.67, NNZs: 495, Bias: 0.000000, T: 27072, Avg. loss: 0.082602\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 41.76, NNZs: 494, Bias: 0.000000, T: 29328, Avg. loss: 0.082503\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 41.86, NNZs: 492, Bias: 0.000000, T: 31584, Avg. loss: 0.082421\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 41.95, NNZs: 491, Bias: 0.000000, T: 33840, Avg. loss: 0.082317\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 42.04, NNZs: 492, Bias: 0.000000, T: 36096, Avg. loss: 0.082226\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 42.05, NNZs: 492, Bias: 0.000000, T: 38352, Avg. loss: 0.082136\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 42.07, NNZs: 491, Bias: 0.000000, T: 40608, Avg. loss: 0.082118\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 42.09, NNZs: 490, Bias: 0.000000, T: 42864, Avg. loss: 0.082102\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 42.11, NNZs: 490, Bias: 0.000000, T: 45120, Avg. loss: 0.082083\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 24.94, NNZs: 4485, Bias: 0.000000, T: 2256, Avg. loss: 0.340763\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 34.46, NNZs: 2358, Bias: 0.000000, T: 4512, Avg. loss: 0.204977\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 41.25, NNZs: 1874, Bias: 0.000000, T: 6768, Avg. loss: 0.171958\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 46.78, NNZs: 1601, Bias: 0.000000, T: 9024, Avg. loss: 0.154677\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 51.50, NNZs: 1385, Bias: 0.000000, T: 11280, Avg. loss: 0.143031\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 55.69, NNZs: 1241, Bias: 0.000000, T: 13536, Avg. loss: 0.134890\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 56.43, NNZs: 1189, Bias: 0.000000, T: 15792, Avg. loss: 0.129539\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 57.16, NNZs: 1169, Bias: 0.000000, T: 18048, Avg. loss: 0.128372\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 57.89, NNZs: 1146, Bias: 0.000000, T: 20304, Avg. loss: 0.127362\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 58.60, NNZs: 1128, Bias: 0.000000, T: 22560, Avg. loss: 0.126345\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 59.30, NNZs: 1108, Bias: 0.000000, T: 24816, Avg. loss: 0.125306\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 59.43, NNZs: 1102, Bias: 0.000000, T: 27072, Avg. loss: 0.124487\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 59.57, NNZs: 1098, Bias: 0.000000, T: 29328, Avg. loss: 0.124296\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 59.71, NNZs: 1091, Bias: 0.000000, T: 31584, Avg. loss: 0.124099\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 59.84, NNZs: 1087, Bias: 0.000000, T: 33840, Avg. loss: 0.123923\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 59.98, NNZs: 1086, Bias: 0.000000, T: 36096, Avg. loss: 0.123746\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 60.00, NNZs: 1085, Bias: 0.000000, T: 38352, Avg. loss: 0.123578\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 60.03, NNZs: 1085, Bias: 0.000000, T: 40608, Avg. loss: 0.123546\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 60.06, NNZs: 1084, Bias: 0.000000, T: 42864, Avg. loss: 0.123509\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 60.09, NNZs: 1083, Bias: 0.000000, T: 45120, Avg. loss: 0.123472\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 21.91, NNZs: 2097, Bias: 0.000000, T: 2256, Avg. loss: 0.139690\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 27.55, NNZs: 927, Bias: 0.000000, T: 4512, Avg. loss: 0.065050\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 31.35, NNZs: 651, Bias: 0.000000, T: 6768, Avg. loss: 0.055387\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 34.23, NNZs: 508, Bias: 0.000000, T: 9024, Avg. loss: 0.050420\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 36.77, NNZs: 428, Bias: 0.000000, T: 11280, Avg. loss: 0.048504\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 38.89, NNZs: 375, Bias: 0.000000, T: 13536, Avg. loss: 0.046418\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 39.29, NNZs: 359, Bias: 0.000000, T: 15792, Avg. loss: 0.045622\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 39.67, NNZs: 354, Bias: 0.000000, T: 18048, Avg. loss: 0.045395\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 40.05, NNZs: 345, Bias: 0.000000, T: 20304, Avg. loss: 0.045190\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 40.42, NNZs: 339, Bias: 0.000000, T: 22560, Avg. loss: 0.044979\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 40.79, NNZs: 335, Bias: 0.000000, T: 24816, Avg. loss: 0.044829\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 40.86, NNZs: 333, Bias: 0.000000, T: 27072, Avg. loss: 0.044661\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 40.93, NNZs: 331, Bias: 0.000000, T: 29328, Avg. loss: 0.044631\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 41.00, NNZs: 329, Bias: 0.000000, T: 31584, Avg. loss: 0.044597\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 41.08, NNZs: 327, Bias: 0.000000, T: 33840, Avg. loss: 0.044568\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 41.15, NNZs: 325, Bias: 0.000000, T: 36096, Avg. loss: 0.044520\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 41.16, NNZs: 324, Bias: 0.000000, T: 38352, Avg. loss: 0.044500\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 41.17, NNZs: 324, Bias: 0.000000, T: 40608, Avg. loss: 0.044493\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 41.19, NNZs: 324, Bias: 0.000000, T: 42864, Avg. loss: 0.044487\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 41.20, NNZs: 324, Bias: 0.000000, T: 45120, Avg. loss: 0.044480\n",
      "Total training time: 0.15 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.6s finished\n",
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.06171699256249541, clf__eta0=0.6666115972798587, clf__fit_intercept=False, clf__l1_ratio=0.9792901432894962, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.15075392531110676, clf__shuffle=True, clf__tol=0.365636830734297, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.460 total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 136399865443107.08, NNZs: 20242, Bias: 0.000000, T: 2256, Avg. loss: 2895400461871134374100992.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 90253939288077.56, NNZs: 20242, Bias: 0.000000, T: 4512, Avg. loss: 6470054885660864720928768.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 64926105156142.91, NNZs: 20242, Bias: 0.000000, T: 6768, Avg. loss: 2378694738842177998159872.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 47404580578558.70, NNZs: 20242, Bias: 0.000000, T: 9024, Avg. loss: 1139663001965593026887680.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 35104471567215.73, NNZs: 20242, Bias: 0.000000, T: 11280, Avg. loss: 565081641414579388940288.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 26596769544535.94, NNZs: 20242, Bias: 0.000000, T: 13536, Avg. loss: 281985318063253091254272.000000\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 134288384560208.77, NNZs: 20242, Bias: 0.000000, T: 2256, Avg. loss: 2665450098951144643493888.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 90630299452462.56, NNZs: 20242, Bias: 0.000000, T: 4512, Avg. loss: 6165810319618458230194176.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 64866306289275.55, NNZs: 20242, Bias: 0.000000, T: 6768, Avg. loss: 2444065882050943885770752.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 47069916383370.66, NNZs: 20242, Bias: 0.000000, T: 9024, Avg. loss: 1160228417933573126881280.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 34971810735611.38, NNZs: 20242, Bias: 0.000000, T: 11280, Avg. loss: 551946817388779778605056.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 26418426818583.07, NNZs: 20242, Bias: 0.000000, T: 13536, Avg. loss: 278442815036763270021120.000000\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 141618053124051.22, NNZs: 20242, Bias: 0.000000, T: 2256, Avg. loss: 3180974256272436478607360.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 94109480086109.50, NNZs: 20242, Bias: 0.000000, T: 4512, Avg. loss: 6920695665132805537398784.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 67855133525005.03, NNZs: 20242, Bias: 0.000000, T: 6768, Avg. loss: 2592911403527177618063360.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 50046016733591.30, NNZs: 20242, Bias: 0.000000, T: 9024, Avg. loss: 1244801926125950865506304.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 37425793218874.55, NNZs: 20242, Bias: 0.000000, T: 11280, Avg. loss: 620661504031914165534720.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 28200499299428.57, NNZs: 20242, Bias: 0.000000, T: 13536, Avg. loss: 322219256484729702055936.000000\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 128225698878167.09, NNZs: 20241, Bias: 0.000000, T: 2256, Avg. loss: 2372694923190371686023168.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 84909550516075.19, NNZs: 20242, Bias: 0.000000, T: 4512, Avg. loss: 5752818506412589978746880.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 58467044469622.50, NNZs: 20242, Bias: 0.000000, T: 6768, Avg. loss: 2239363504571305359835136.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 42278614457434.16, NNZs: 20242, Bias: 0.000000, T: 9024, Avg. loss: 960574892481434194280448.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 30777271464573.00, NNZs: 20242, Bias: 0.000000, T: 11280, Avg. loss: 463867440053394090229760.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 23144991084196.22, NNZs: 20242, Bias: 0.000000, T: 13536, Avg. loss: 215118949567765076246528.000000\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "[CV 1/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.7915127974877743, clf__eta0=0.05539740212799926, clf__fit_intercept=False, clf__l1_ratio=0.9152680641407671, clf__learning_rate=optimal, clf__loss=squared_epsilon_insensitive, clf__max_iter=80, clf__penalty=l1, clf__power_t=0.6359093112142983, clf__shuffle=True, clf__tol=0.9361199211609239, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.122 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 138736941360665.23, NNZs: 20286, Bias: 0.000000, T: 2256, Avg. loss: 3091199460552712474591232.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 93775082255068.39, NNZs: 20286, Bias: 0.000000, T: 4512, Avg. loss: 6498660853219750114754560.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 67909811850776.91, NNZs: 20286, Bias: 0.000000, T: 6768, Avg. loss: 2568693420288364433637376.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 49760411591814.72, NNZs: 20286, Bias: 0.000000, T: 9024, Avg. loss: 1244134251871307424595968.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 37477426708862.99, NNZs: 20286, Bias: 0.000000, T: 11280, Avg. loss: 602709387862436407672832.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 28730913957719.48, NNZs: 20286, Bias: 0.000000, T: 13536, Avg. loss: 306194120902529494548480.000000\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 131033236252963.11, NNZs: 20286, Bias: 0.000000, T: 2256, Avg. loss: 2710872718962820483383296.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 87528390390375.97, NNZs: 20286, Bias: 0.000000, T: 4512, Avg. loss: 5939619933548584359690240.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 62631891218900.87, NNZs: 20286, Bias: 0.000000, T: 6768, Avg. loss: 2276425525667490688925696.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 45985828993977.23, NNZs: 20286, Bias: 0.000000, T: 9024, Avg. loss: 1054790462800253413228544.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 34229950477963.64, NNZs: 20286, Bias: 0.000000, T: 11280, Avg. loss: 519833601399395572514816.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 26344130382590.57, NNZs: 20286, Bias: 0.000000, T: 13536, Avg. loss: 250494762346126782758912.000000\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 131327965567866.45, NNZs: 20286, Bias: 0.000000, T: 2256, Avg. loss: 2832230354889710925512704.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 88463254258735.05, NNZs: 20286, Bias: 0.000000, T: 4512, Avg. loss: 5916545203811403094294528.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 63595672642641.19, NNZs: 20286, Bias: 0.000000, T: 6768, Avg. loss: 2298169881031793354735616.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 46745400962481.31, NNZs: 20286, Bias: 0.000000, T: 9024, Avg. loss: 1090259570988239470723072.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 35043485294626.54, NNZs: 20286, Bias: 0.000000, T: 11280, Avg. loss: 533687188819586559508480.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 26803124286104.22, NNZs: 20286, Bias: 0.000000, T: 13536, Avg. loss: 271289060890238712283136.000000\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 131684292177098.62, NNZs: 20285, Bias: 0.000000, T: 2256, Avg. loss: 2892690887593680196075520.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 88982872206433.34, NNZs: 20286, Bias: 0.000000, T: 4512, Avg. loss: 5883329934122526514872320.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 63429592801902.76, NNZs: 20286, Bias: 0.000000, T: 6768, Avg. loss: 2378379456357979402534912.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 46537365623373.07, NNZs: 20286, Bias: 0.000000, T: 9024, Avg. loss: 1076629211908955055325184.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 34693471027570.98, NNZs: 20286, Bias: 0.000000, T: 11280, Avg. loss: 533025418004032705789952.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 26701738788946.10, NNZs: 20286, Bias: 0.000000, T: 13536, Avg. loss: 258204448871251861045248.000000\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "[CV 2/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.7915127974877743, clf__eta0=0.05539740212799926, clf__fit_intercept=False, clf__l1_ratio=0.9152680641407671, clf__learning_rate=optimal, clf__loss=squared_epsilon_insensitive, clf__max_iter=80, clf__penalty=l1, clf__power_t=0.6359093112142983, clf__shuffle=True, clf__tol=0.9361199211609239, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.202 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 138701538809020.58, NNZs: 20900, Bias: 0.000000, T: 2256, Avg. loss: 3201125591850014549737472.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 92870407106674.84, NNZs: 20902, Bias: 0.000000, T: 4512, Avg. loss: 6522787196941336695537664.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 66809418903469.48, NNZs: 20902, Bias: 0.000000, T: 6768, Avg. loss: 2555205038689255153467392.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 48861484742868.33, NNZs: 20902, Bias: 0.000000, T: 9024, Avg. loss: 1213730362028606361698304.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 36603505400237.48, NNZs: 20902, Bias: 0.000000, T: 11280, Avg. loss: 587676206180344390483968.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27851171464522.94, NNZs: 20902, Bias: 0.000000, T: 13536, Avg. loss: 300670480780760807636992.000000\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.05 seconds\n",
      "-- Epoch 1\n",
      "Norm: 136138593029610.50, NNZs: 20901, Bias: 0.000000, T: 2256, Avg. loss: 2837024644053162705027072.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 90901777269365.78, NNZs: 20902, Bias: 0.000000, T: 4512, Avg. loss: 6367626285921337310445568.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 64835694982078.39, NNZs: 20902, Bias: 0.000000, T: 6768, Avg. loss: 2461074188642925787742208.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 47060756855070.51, NNZs: 20902, Bias: 0.000000, T: 9024, Avg. loss: 1154252948427920027680768.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 34673226045854.61, NNZs: 20902, Bias: 0.000000, T: 11280, Avg. loss: 560449059680011734220800.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 25786222558180.30, NNZs: 20902, Bias: 0.000000, T: 13536, Avg. loss: 282677854475445130493952.000000\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 139415444786665.72, NNZs: 20902, Bias: 0.000000, T: 2256, Avg. loss: 3132804839581091725574144.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 94108869897139.27, NNZs: 20902, Bias: 0.000000, T: 4512, Avg. loss: 6613721963673027239477248.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 67455060726100.82, NNZs: 20902, Bias: 0.000000, T: 6768, Avg. loss: 2634042256605897627271168.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 50032108634321.68, NNZs: 20902, Bias: 0.000000, T: 9024, Avg. loss: 1223763089906362679820288.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 37309993707102.87, NNZs: 20902, Bias: 0.000000, T: 11280, Avg. loss: 625868203907530933403648.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 28202475823840.21, NNZs: 20902, Bias: 0.000000, T: 13536, Avg. loss: 318795541683631793635328.000000\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.05 seconds\n",
      "-- Epoch 1\n",
      "Norm: 107583966627042.52, NNZs: 20873, Bias: 0.000000, T: 2256, Avg. loss: 1569631671886477787136000.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 71271534537120.48, NNZs: 20902, Bias: 0.000000, T: 4512, Avg. loss: 4238055202898256039247872.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 48912132478547.01, NNZs: 20902, Bias: 0.000000, T: 6768, Avg. loss: 1649516919664400322789376.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 35520814140800.25, NNZs: 20902, Bias: 0.000000, T: 9024, Avg. loss: 682493551907333163974656.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 25781049790772.27, NNZs: 20902, Bias: 0.000000, T: 11280, Avg. loss: 336425190040851877724160.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 18911594558069.98, NNZs: 20902, Bias: 0.000000, T: 13536, Avg. loss: 161579585400755019841536.000000\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.05 seconds\n",
      "[CV 3/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.7915127974877743, clf__eta0=0.05539740212799926, clf__fit_intercept=False, clf__l1_ratio=0.9152680641407671, clf__learning_rate=optimal, clf__loss=squared_epsilon_insensitive, clf__max_iter=80, clf__penalty=l1, clf__power_t=0.6359093112142983, clf__shuffle=True, clf__tol=0.9361199211609239, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.187 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 142116275295509.31, NNZs: 21041, Bias: 0.000000, T: 2256, Avg. loss: 3120160307470367260147712.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 95186628493537.77, NNZs: 21041, Bias: 0.000000, T: 4512, Avg. loss: 6966363887813215075172352.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 67789653372968.30, NNZs: 21041, Bias: 0.000000, T: 6768, Avg. loss: 2715140556950613354610688.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 49733569905113.89, NNZs: 21041, Bias: 0.000000, T: 9024, Avg. loss: 1240439039670108083453952.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 37440021840072.22, NNZs: 21041, Bias: 0.000000, T: 11280, Avg. loss: 611157662970076723150848.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 28402547914545.73, NNZs: 21041, Bias: 0.000000, T: 13536, Avg. loss: 318320130340711022198784.000000\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.05 seconds\n",
      "-- Epoch 1\n",
      "Norm: 135841634898177.17, NNZs: 21041, Bias: 0.000000, T: 2256, Avg. loss: 2903365325894178335358976.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 91894399200269.02, NNZs: 21041, Bias: 0.000000, T: 4512, Avg. loss: 6229626121086427098775552.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 65927241912352.74, NNZs: 21041, Bias: 0.000000, T: 6768, Avg. loss: 2463812601345418775756800.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 48038437226037.80, NNZs: 21041, Bias: 0.000000, T: 9024, Avg. loss: 1191032654186238338662400.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 35618800922109.82, NNZs: 21041, Bias: 0.000000, T: 11280, Avg. loss: 574132905143194745831424.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27078351002298.12, NNZs: 21041, Bias: 0.000000, T: 13536, Avg. loss: 281904791585188118265856.000000\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 6 epochs took 0.05 seconds\n",
      "-- Epoch 1\n",
      "Norm: 137261009980142.14, NNZs: 21041, Bias: 0.000000, T: 2256, Avg. loss: 2933714629516514516008960.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 91751961015177.92, NNZs: 21041, Bias: 0.000000, T: 4512, Avg. loss: 6440870208888654903902208.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 65471605304109.08, NNZs: 21041, Bias: 0.000000, T: 6768, Avg. loss: 2538945004170874309312512.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 47786636033947.61, NNZs: 21041, Bias: 0.000000, T: 9024, Avg. loss: 1172991342961063595343872.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 35603540943855.04, NNZs: 21041, Bias: 0.000000, T: 11280, Avg. loss: 565380030165117017522176.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 26975574157614.68, NNZs: 21041, Bias: 0.000000, T: 13536, Avg. loss: 285064004510623759073280.000000\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.05 seconds\n",
      "-- Epoch 1\n",
      "Norm: 121113369404980.92, NNZs: 21036, Bias: 0.000000, T: 2256, Avg. loss: 2205213697923407788638208.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 80306222610264.00, NNZs: 21041, Bias: 0.000000, T: 4512, Avg. loss: 5177289420033214606475264.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 55465926792693.66, NNZs: 21041, Bias: 0.000000, T: 6768, Avg. loss: 2023070630967892485603328.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 40070893364441.91, NNZs: 21041, Bias: 0.000000, T: 9024, Avg. loss: 849077075131213803421696.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 29380401700489.77, NNZs: 21041, Bias: 0.000000, T: 11280, Avg. loss: 404905596255547414282240.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 21974103868230.51, NNZs: 21041, Bias: 0.000000, T: 13536, Avg. loss: 193879639587189633843200.000000\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "[CV 4/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.7915127974877743, clf__eta0=0.05539740212799926, clf__fit_intercept=False, clf__l1_ratio=0.9152680641407671, clf__learning_rate=optimal, clf__loss=squared_epsilon_insensitive, clf__max_iter=80, clf__penalty=l1, clf__power_t=0.6359093112142983, clf__shuffle=True, clf__tol=0.9361199211609239, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.187 total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 136502481989103.17, NNZs: 20998, Bias: 0.000000, T: 2256, Avg. loss: 3042205183279164850962432.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 91989882388820.97, NNZs: 20998, Bias: 0.000000, T: 4512, Avg. loss: 6343251388010779658682368.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 66004242828396.64, NNZs: 20998, Bias: 0.000000, T: 6768, Avg. loss: 2467341477170261128118272.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 48793307890851.83, NNZs: 20998, Bias: 0.000000, T: 9024, Avg. loss: 1158091325051283783548928.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 36532640390954.74, NNZs: 20998, Bias: 0.000000, T: 11280, Avg. loss: 584218370232888443535360.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27645113885334.36, NNZs: 20998, Bias: 0.000000, T: 13536, Avg. loss: 299681169753429589884928.000000\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 6 epochs took 0.05 seconds\n",
      "-- Epoch 1\n",
      "Norm: 108111439907693.12, NNZs: 20990, Bias: 0.000000, T: 2256, Avg. loss: 1480329054256491715887104.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 72218847640596.38, NNZs: 20998, Bias: 0.000000, T: 4512, Avg. loss: 4242091219815104570720256.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 48688323158595.79, NNZs: 20998, Bias: 0.000000, T: 6768, Avg. loss: 1719598824840377344720896.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 35317802722623.51, NNZs: 20998, Bias: 0.000000, T: 9024, Avg. loss: 673230667631893311127552.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 25577135509602.81, NNZs: 20998, Bias: 0.000000, T: 11280, Avg. loss: 332216174013259255382016.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 18936028446838.05, NNZs: 20998, Bias: 0.000000, T: 13536, Avg. loss: 153388888095023437971456.000000\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.05 seconds\n",
      "-- Epoch 1\n",
      "Norm: 129402424925426.92, NNZs: 20998, Bias: 0.000000, T: 2256, Avg. loss: 2611994616778539967447040.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 86125457106999.33, NNZs: 20998, Bias: 0.000000, T: 4512, Avg. loss: 5714324750858401167179776.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 60972522097618.42, NNZs: 20998, Bias: 0.000000, T: 6768, Avg. loss: 2227675229368079299379200.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 44292813656534.20, NNZs: 20998, Bias: 0.000000, T: 9024, Avg. loss: 1020730670151407392260096.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 32668959679422.61, NNZs: 20998, Bias: 0.000000, T: 11280, Avg. loss: 490827104035633616650240.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 24423784467045.41, NNZs: 20998, Bias: 0.000000, T: 13536, Avg. loss: 244655704838751022743552.000000\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 123640183112175.50, NNZs: 20992, Bias: 0.000000, T: 2256, Avg. loss: 2402252079480930960408576.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 82625810369947.61, NNZs: 20998, Bias: 0.000000, T: 4512, Avg. loss: 5314432320522379052711936.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 58043749990168.38, NNZs: 20998, Bias: 0.000000, T: 6768, Avg. loss: 2074329159047613956227072.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 42209099051929.30, NNZs: 20998, Bias: 0.000000, T: 9024, Avg. loss: 923351635147061200945152.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 31542086914796.05, NNZs: 20998, Bias: 0.000000, T: 11280, Avg. loss: 430945852282785251721216.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 23760883733667.17, NNZs: 20998, Bias: 0.000000, T: 13536, Avg. loss: 222324716226736717561856.000000\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 6 epochs took 0.05 seconds\n",
      "[CV 5/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.7915127974877743, clf__eta0=0.05539740212799926, clf__fit_intercept=False, clf__l1_ratio=0.9152680641407671, clf__learning_rate=optimal, clf__loss=squared_epsilon_insensitive, clf__max_iter=80, clf__penalty=l1, clf__power_t=0.6359093112142983, clf__shuffle=True, clf__tol=0.9361199211609239, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.178 total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 36.20, NNZs: 10520, Bias: 0.000000, T: 2256, Avg. loss: 0.215204\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 43.26, NNZs: 4546, Bias: 0.000000, T: 4512, Avg. loss: 0.058325\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 49.00, NNZs: 3097, Bias: 0.000000, T: 6768, Avg. loss: 0.042961\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 53.82, NNZs: 2436, Bias: 0.000000, T: 9024, Avg. loss: 0.036726\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 57.89, NNZs: 2048, Bias: 0.000000, T: 11280, Avg. loss: 0.030955\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 61.51, NNZs: 1761, Bias: 0.000000, T: 13536, Avg. loss: 0.030026\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 23.15, NNZs: 4546, Bias: 0.000000, T: 2256, Avg. loss: 0.095755\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 28.39, NNZs: 2233, Bias: 0.000000, T: 4512, Avg. loss: 0.025659\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 32.12, NNZs: 1577, Bias: 0.000000, T: 6768, Avg. loss: 0.018655\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 35.41, NNZs: 1203, Bias: 0.000000, T: 9024, Avg. loss: 0.016490\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 38.27, NNZs: 995, Bias: 0.000000, T: 11280, Avg. loss: 0.016601\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 40.81, NNZs: 850, Bias: 0.000000, T: 13536, Avg. loss: 0.013325\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 33.96, NNZs: 9279, Bias: 0.000000, T: 2256, Avg. loss: 0.168735\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 39.66, NNZs: 3911, Bias: 0.000000, T: 4512, Avg. loss: 0.033212\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 44.81, NNZs: 2676, Bias: 0.000000, T: 6768, Avg. loss: 0.030197\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 48.98, NNZs: 2126, Bias: 0.000000, T: 9024, Avg. loss: 0.025603\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 52.56, NNZs: 1760, Bias: 0.000000, T: 11280, Avg. loss: 0.022998\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 55.96, NNZs: 1524, Bias: 0.000000, T: 13536, Avg. loss: 0.021694\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 18.58, NNZs: 2688, Bias: 0.000000, T: 2256, Avg. loss: 0.046910\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 21.74, NNZs: 1366, Bias: 0.000000, T: 4512, Avg. loss: 0.017185\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 25.11, NNZs: 1005, Bias: 0.000000, T: 6768, Avg. loss: 0.011547\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 27.84, NNZs: 860, Bias: 0.000000, T: 9024, Avg. loss: 0.009543\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 29.94, NNZs: 699, Bias: 0.000000, T: 11280, Avg. loss: 0.008113\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 31.96, NNZs: 602, Bias: 0.000000, T: 13536, Avg. loss: 0.008017\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 1/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.03646223783802971, clf__eta0=0.7491267567674796, clf__fit_intercept=False, clf__l1_ratio=0.775818217437024, clf__learning_rate=constant, clf__loss=squared_hinge, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.4028006727705291, clf__shuffle=True, clf__tol=0.1730703028465106, clf__warm_start=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.552 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 38.09, NNZs: 11641, Bias: 0.000000, T: 2256, Avg. loss: 0.253667\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 44.85, NNZs: 5007, Bias: 0.000000, T: 4512, Avg. loss: 0.050801\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 50.64, NNZs: 3340, Bias: 0.000000, T: 6768, Avg. loss: 0.045174\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 55.56, NNZs: 2583, Bias: 0.000000, T: 9024, Avg. loss: 0.037367\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 59.78, NNZs: 2084, Bias: 0.000000, T: 11280, Avg. loss: 0.034118\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 63.51, NNZs: 1791, Bias: 0.000000, T: 13536, Avg. loss: 0.029936\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 23.80, NNZs: 4596, Bias: 0.000000, T: 2256, Avg. loss: 0.101806\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 28.90, NNZs: 2366, Bias: 0.000000, T: 4512, Avg. loss: 0.027015\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 32.96, NNZs: 1654, Bias: 0.000000, T: 6768, Avg. loss: 0.021925\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 36.37, NNZs: 1281, Bias: 0.000000, T: 9024, Avg. loss: 0.016206\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 39.28, NNZs: 1066, Bias: 0.000000, T: 11280, Avg. loss: 0.015527\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 41.89, NNZs: 947, Bias: 0.000000, T: 13536, Avg. loss: 0.014581\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 35.45, NNZs: 9864, Bias: 0.000000, T: 2256, Avg. loss: 0.187292\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 41.21, NNZs: 4249, Bias: 0.000000, T: 4512, Avg. loss: 0.034574\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 46.38, NNZs: 2802, Bias: 0.000000, T: 6768, Avg. loss: 0.032222\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 50.77, NNZs: 2149, Bias: 0.000000, T: 9024, Avg. loss: 0.027243\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 54.58, NNZs: 1830, Bias: 0.000000, T: 11280, Avg. loss: 0.024671\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 57.95, NNZs: 1580, Bias: 0.000000, T: 13536, Avg. loss: 0.022383\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 19.02, NNZs: 2935, Bias: 0.000000, T: 2256, Avg. loss: 0.050025\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 22.76, NNZs: 1542, Bias: 0.000000, T: 4512, Avg. loss: 0.014434\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 25.54, NNZs: 1050, Bias: 0.000000, T: 6768, Avg. loss: 0.011668\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 28.50, NNZs: 903, Bias: 0.000000, T: 9024, Avg. loss: 0.011813\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 30.85, NNZs: 777, Bias: 0.000000, T: 11280, Avg. loss: 0.008101\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 32.70, NNZs: 680, Bias: 0.000000, T: 13536, Avg. loss: 0.007983\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 2/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.03646223783802971, clf__eta0=0.7491267567674796, clf__fit_intercept=False, clf__l1_ratio=0.775818217437024, clf__learning_rate=constant, clf__loss=squared_hinge, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.4028006727705291, clf__shuffle=True, clf__tol=0.1730703028465106, clf__warm_start=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.652 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 38.27, NNZs: 11413, Bias: 0.000000, T: 2256, Avg. loss: 0.258320\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 45.34, NNZs: 5129, Bias: 0.000000, T: 4512, Avg. loss: 0.054948\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 51.31, NNZs: 3482, Bias: 0.000000, T: 6768, Avg. loss: 0.043819\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 56.21, NNZs: 2657, Bias: 0.000000, T: 9024, Avg. loss: 0.037954\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 60.53, NNZs: 2183, Bias: 0.000000, T: 11280, Avg. loss: 0.032527\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 64.30, NNZs: 1862, Bias: 0.000000, T: 13536, Avg. loss: 0.029909\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 23.19, NNZs: 4440, Bias: 0.000000, T: 2256, Avg. loss: 0.092596\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 28.18, NNZs: 2220, Bias: 0.000000, T: 4512, Avg. loss: 0.023301\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 32.29, NNZs: 1553, Bias: 0.000000, T: 6768, Avg. loss: 0.020935\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 35.52, NNZs: 1256, Bias: 0.000000, T: 9024, Avg. loss: 0.016389\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 38.35, NNZs: 1043, Bias: 0.000000, T: 11280, Avg. loss: 0.013452\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 40.89, NNZs: 898, Bias: 0.000000, T: 13536, Avg. loss: 0.014081\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 35.52, NNZs: 10123, Bias: 0.000000, T: 2256, Avg. loss: 0.191538\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 41.58, NNZs: 4512, Bias: 0.000000, T: 4512, Avg. loss: 0.038097\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 46.81, NNZs: 3032, Bias: 0.000000, T: 6768, Avg. loss: 0.032822\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 51.27, NNZs: 2342, Bias: 0.000000, T: 9024, Avg. loss: 0.028435\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 55.03, NNZs: 1935, Bias: 0.000000, T: 11280, Avg. loss: 0.024580\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 58.49, NNZs: 1677, Bias: 0.000000, T: 13536, Avg. loss: 0.022924\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 18.60, NNZs: 2628, Bias: 0.000000, T: 2256, Avg. loss: 0.047571\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 22.45, NNZs: 1507, Bias: 0.000000, T: 4512, Avg. loss: 0.014066\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 25.43, NNZs: 1107, Bias: 0.000000, T: 6768, Avg. loss: 0.010942\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 27.92, NNZs: 794, Bias: 0.000000, T: 9024, Avg. loss: 0.009405\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 30.17, NNZs: 690, Bias: 0.000000, T: 11280, Avg. loss: 0.007720\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 32.10, NNZs: 597, Bias: 0.000000, T: 13536, Avg. loss: 0.007387\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 3/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.03646223783802971, clf__eta0=0.7491267567674796, clf__fit_intercept=False, clf__l1_ratio=0.775818217437024, clf__learning_rate=constant, clf__loss=squared_hinge, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.4028006727705291, clf__shuffle=True, clf__tol=0.1730703028465106, clf__warm_start=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.660 total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 36.97, NNZs: 10768, Bias: 0.000000, T: 2256, Avg. loss: 0.228775\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 43.80, NNZs: 4792, Bias: 0.000000, T: 4512, Avg. loss: 0.049572\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 49.51, NNZs: 3089, Bias: 0.000000, T: 6768, Avg. loss: 0.040310\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 54.13, NNZs: 2373, Bias: 0.000000, T: 9024, Avg. loss: 0.033546\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 58.25, NNZs: 1956, Bias: 0.000000, T: 11280, Avg. loss: 0.031503\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 61.85, NNZs: 1713, Bias: 0.000000, T: 13536, Avg. loss: 0.027429\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 22.98, NNZs: 4451, Bias: 0.000000, T: 2256, Avg. loss: 0.090596\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 28.23, NNZs: 2117, Bias: 0.000000, T: 4512, Avg. loss: 0.026515\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 32.08, NNZs: 1447, Bias: 0.000000, T: 6768, Avg. loss: 0.020934\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 35.27, NNZs: 1169, Bias: 0.000000, T: 9024, Avg. loss: 0.016099\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 38.19, NNZs: 994, Bias: 0.000000, T: 11280, Avg. loss: 0.014893\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 40.71, NNZs: 875, Bias: 0.000000, T: 13536, Avg. loss: 0.014433\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 34.36, NNZs: 9524, Bias: 0.000000, T: 2256, Avg. loss: 0.176393\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 40.12, NNZs: 3976, Bias: 0.000000, T: 4512, Avg. loss: 0.032655\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 45.23, NNZs: 2725, Bias: 0.000000, T: 6768, Avg. loss: 0.031822\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 49.51, NNZs: 2075, Bias: 0.000000, T: 9024, Avg. loss: 0.025450\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 53.15, NNZs: 1738, Bias: 0.000000, T: 11280, Avg. loss: 0.023607\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 56.49, NNZs: 1517, Bias: 0.000000, T: 13536, Avg. loss: 0.022244\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 17.94, NNZs: 2485, Bias: 0.000000, T: 2256, Avg. loss: 0.045702\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 21.86, NNZs: 1381, Bias: 0.000000, T: 4512, Avg. loss: 0.012564\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 24.71, NNZs: 1015, Bias: 0.000000, T: 6768, Avg. loss: 0.010014\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 27.24, NNZs: 843, Bias: 0.000000, T: 9024, Avg. loss: 0.008882\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 29.39, NNZs: 696, Bias: 0.000000, T: 11280, Avg. loss: 0.008181\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 31.36, NNZs: 609, Bias: 0.000000, T: 13536, Avg. loss: 0.007975\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 4/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.03646223783802971, clf__eta0=0.7491267567674796, clf__fit_intercept=False, clf__l1_ratio=0.775818217437024, clf__learning_rate=constant, clf__loss=squared_hinge, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.4028006727705291, clf__shuffle=True, clf__tol=0.1730703028465106, clf__warm_start=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.623 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 36.65, NNZs: 10904, Bias: 0.000000, T: 2256, Avg. loss: 0.229098\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 43.41, NNZs: 4637, Bias: 0.000000, T: 4512, Avg. loss: 0.049269\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 49.11, NNZs: 3114, Bias: 0.000000, T: 6768, Avg. loss: 0.039842\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 53.72, NNZs: 2429, Bias: 0.000000, T: 9024, Avg. loss: 0.032619\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 57.86, NNZs: 1993, Bias: 0.000000, T: 11280, Avg. loss: 0.030765\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 61.51, NNZs: 1673, Bias: 0.000000, T: 13536, Avg. loss: 0.028061\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 23.07, NNZs: 4342, Bias: 0.000000, T: 2256, Avg. loss: 0.090867\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 27.88, NNZs: 2094, Bias: 0.000000, T: 4512, Avg. loss: 0.023668\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 31.82, NNZs: 1531, Bias: 0.000000, T: 6768, Avg. loss: 0.020902\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 34.85, NNZs: 1173, Bias: 0.000000, T: 9024, Avg. loss: 0.014211\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 37.70, NNZs: 999, Bias: 0.000000, T: 11280, Avg. loss: 0.014607\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 40.22, NNZs: 895, Bias: 0.000000, T: 13536, Avg. loss: 0.013727\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 33.68, NNZs: 9276, Bias: 0.000000, T: 2256, Avg. loss: 0.162819\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 39.32, NNZs: 3938, Bias: 0.000000, T: 4512, Avg. loss: 0.033075\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 44.34, NNZs: 2600, Bias: 0.000000, T: 6768, Avg. loss: 0.028277\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 48.64, NNZs: 2034, Bias: 0.000000, T: 9024, Avg. loss: 0.025450\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 52.29, NNZs: 1725, Bias: 0.000000, T: 11280, Avg. loss: 0.022218\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 55.49, NNZs: 1509, Bias: 0.000000, T: 13536, Avg. loss: 0.020701\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 18.54, NNZs: 2544, Bias: 0.000000, T: 2256, Avg. loss: 0.044944\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 21.94, NNZs: 1374, Bias: 0.000000, T: 4512, Avg. loss: 0.014359\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 24.99, NNZs: 981, Bias: 0.000000, T: 6768, Avg. loss: 0.010710\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 27.45, NNZs: 777, Bias: 0.000000, T: 9024, Avg. loss: 0.009475\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 29.60, NNZs: 658, Bias: 0.000000, T: 11280, Avg. loss: 0.008285\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 31.40, NNZs: 593, Bias: 0.000000, T: 13536, Avg. loss: 0.008309\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 5/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.03646223783802971, clf__eta0=0.7491267567674796, clf__fit_intercept=False, clf__l1_ratio=0.775818217437024, clf__learning_rate=constant, clf__loss=squared_hinge, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.4028006727705291, clf__shuffle=True, clf__tol=0.1730703028465106, clf__warm_start=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.614 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 13.58, NNZs: 5779, Bias: 0.000000, T: 2256, Avg. loss: 0.157410\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 17.75, NNZs: 3514, Bias: 0.000000, T: 4512, Avg. loss: 0.089114\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 20.81, NNZs: 2759, Bias: 0.000000, T: 6768, Avg. loss: 0.075131\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 23.39, NNZs: 2314, Bias: 0.000000, T: 9024, Avg. loss: 0.065945\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 25.73, NNZs: 2072, Bias: 0.000000, T: 11280, Avg. loss: 0.061376\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27.70, NNZs: 1865, Bias: 0.000000, T: 13536, Avg. loss: 0.057527\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 70.32, NNZs: 9438, Bias: 0.000000, T: 2256, Avg. loss: 0.565286\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 334.59, NNZs: 13208, Bias: 0.000000, T: 4512, Avg. loss: 27.411078\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1274.37, NNZs: 16899, Bias: 0.000000, T: 6768, Avg. loss: 357.370855\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4189.29, NNZs: 19272, Bias: 0.000000, T: 9024, Avg. loss: 6936.674165\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 50834.08, NNZs: 20059, Bias: 0.000000, T: 11280, Avg. loss: 462042.086408\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 608332.09, NNZs: 20224, Bias: 0.000000, T: 13536, Avg. loss: 120926683.897827\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 10.44, NNZs: 3535, Bias: 0.000000, T: 2256, Avg. loss: 0.214530\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 13.58, NNZs: 1987, Bias: 0.000000, T: 4512, Avg. loss: 0.115728\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 15.97, NNZs: 1562, Bias: 0.000000, T: 6768, Avg. loss: 0.101495\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 17.87, NNZs: 1325, Bias: 0.000000, T: 9024, Avg. loss: 0.093543\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 19.48, NNZs: 1166, Bias: 0.000000, T: 11280, Avg. loss: 0.088666\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 20.98, NNZs: 1063, Bias: 0.000000, T: 13536, Avg. loss: 0.083891\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 680.53, NNZs: 13690, Bias: 0.000000, T: 2256, Avg. loss: 140.490098\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 20009.67, NNZs: 19951, Bias: 0.000000, T: 4512, Avg. loss: 139357.922391\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 554381.45, NNZs: 20241, Bias: 0.000000, T: 6768, Avg. loss: 130201834.407599\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 11988221.21, NNZs: 20244, Bias: 0.000000, T: 9024, Avg. loss: 58822476492.182442\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 415731281.08, NNZs: 20245, Bias: 0.000000, T: 11280, Avg. loss: 45435423695460.773438\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 10570411710.72, NNZs: 20245, Bias: 0.000000, T: 13536, Avg. loss: 44656570952176856.000000\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "[CV 1/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.24457156361183285, clf__eta0=0.332929742792607, clf__fit_intercept=False, clf__l1_ratio=0.920539731041378, clf__learning_rate=constant, clf__loss=squared_error, clf__max_iter=100, clf__penalty=l1, clf__power_t=0.5734177157821045, clf__shuffle=True, clf__tol=0.6492274795888617, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.112 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 13.74, NNZs: 5931, Bias: 0.000000, T: 2256, Avg. loss: 0.167412\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 17.79, NNZs: 3709, Bias: 0.000000, T: 4512, Avg. loss: 0.097293\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 21.05, NNZs: 3001, Bias: 0.000000, T: 6768, Avg. loss: 0.082196\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 23.70, NNZs: 2510, Bias: 0.000000, T: 9024, Avg. loss: 0.073602\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 26.05, NNZs: 2212, Bias: 0.000000, T: 11280, Avg. loss: 0.068056\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 28.27, NNZs: 2028, Bias: 0.000000, T: 13536, Avg. loss: 0.063707\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 42.53, NNZs: 9652, Bias: 0.000000, T: 2256, Avg. loss: 0.382372\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 161.15, NNZs: 9861, Bias: 0.000000, T: 4512, Avg. loss: 4.964868\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 761.77, NNZs: 15971, Bias: 0.000000, T: 6768, Avg. loss: 116.459178\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3713.59, NNZs: 19055, Bias: 0.000000, T: 9024, Avg. loss: 2543.907236\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 23978.53, NNZs: 20045, Bias: 0.000000, T: 11280, Avg. loss: 129775.175466\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 113658.38, NNZs: 20228, Bias: 0.000000, T: 13536, Avg. loss: 3000260.760791\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 10.48, NNZs: 3518, Bias: 0.000000, T: 2256, Avg. loss: 0.226168\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 13.73, NNZs: 2104, Bias: 0.000000, T: 4512, Avg. loss: 0.129911\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 15.94, NNZs: 1675, Bias: 0.000000, T: 6768, Avg. loss: 0.113733\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 17.88, NNZs: 1412, Bias: 0.000000, T: 9024, Avg. loss: 0.105980\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 19.56, NNZs: 1258, Bias: 0.000000, T: 11280, Avg. loss: 0.101217\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 21.07, NNZs: 1165, Bias: 0.000000, T: 13536, Avg. loss: 0.096348\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 145.18, NNZs: 13760, Bias: 0.000000, T: 2256, Avg. loss: 7.067436\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2365.84, NNZs: 19273, Bias: 0.000000, T: 4512, Avg. loss: 1151.487927\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 71709.16, NNZs: 20198, Bias: 0.000000, T: 6768, Avg. loss: 795004.734461\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2487068.30, NNZs: 20282, Bias: 0.000000, T: 9024, Avg. loss: 1213952935.490006\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 92388004.00, NNZs: 20286, Bias: 0.000000, T: 11280, Avg. loss: 1112786120985.300049\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2796261902.94, NNZs: 20286, Bias: 0.000000, T: 13536, Avg. loss: 510273064354752.437500\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "[CV 2/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.24457156361183285, clf__eta0=0.332929742792607, clf__fit_intercept=False, clf__l1_ratio=0.920539731041378, clf__learning_rate=constant, clf__loss=squared_error, clf__max_iter=100, clf__penalty=l1, clf__power_t=0.5734177157821045, clf__shuffle=True, clf__tol=0.6492274795888617, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.176 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 13.81, NNZs: 5863, Bias: 0.000000, T: 2256, Avg. loss: 0.171529\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 18.02, NNZs: 3765, Bias: 0.000000, T: 4512, Avg. loss: 0.097947\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 21.20, NNZs: 2992, Bias: 0.000000, T: 6768, Avg. loss: 0.083633\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 23.97, NNZs: 2532, Bias: 0.000000, T: 9024, Avg. loss: 0.075272\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 26.49, NNZs: 2268, Bias: 0.000000, T: 11280, Avg. loss: 0.068322\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 28.64, NNZs: 2080, Bias: 0.000000, T: 13536, Avg. loss: 0.064681\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 87.10, NNZs: 12046, Bias: 0.000000, T: 2256, Avg. loss: 1.751067\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1886.18, NNZs: 17512, Bias: 0.000000, T: 4512, Avg. loss: 752.531552\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 14160.86, NNZs: 20650, Bias: 0.000000, T: 6768, Avg. loss: 44248.356684\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 92690.37, NNZs: 20840, Bias: 0.000000, T: 9024, Avg. loss: 1961739.554070\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 808056.97, NNZs: 20888, Bias: 0.000000, T: 11280, Avg. loss: 199675658.363437\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3319981.51, NNZs: 20897, Bias: 0.000000, T: 13536, Avg. loss: 3769043026.638753\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 10.45, NNZs: 3655, Bias: 0.000000, T: 2256, Avg. loss: 0.229521\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 13.80, NNZs: 2110, Bias: 0.000000, T: 4512, Avg. loss: 0.132508\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 16.11, NNZs: 1692, Bias: 0.000000, T: 6768, Avg. loss: 0.115037\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 18.12, NNZs: 1424, Bias: 0.000000, T: 9024, Avg. loss: 0.107112\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 19.87, NNZs: 1256, Bias: 0.000000, T: 11280, Avg. loss: 0.100625\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 21.35, NNZs: 1165, Bias: 0.000000, T: 13536, Avg. loss: 0.096555\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 513.99, NNZs: 16180, Bias: 0.000000, T: 2256, Avg. loss: 95.452936\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 12272.60, NNZs: 20110, Bias: 0.000000, T: 4512, Avg. loss: 33002.889751\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 142680.57, NNZs: 20866, Bias: 0.000000, T: 6768, Avg. loss: 6603097.339658\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4545836.24, NNZs: 20898, Bias: 0.000000, T: 9024, Avg. loss: 6986755548.930045\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 232782076.28, NNZs: 20901, Bias: 0.000000, T: 11280, Avg. loss: 9028934808201.656250\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 6261845068.76, NNZs: 20901, Bias: 0.000000, T: 13536, Avg. loss: 7599952856266739.000000\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "[CV 3/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.24457156361183285, clf__eta0=0.332929742792607, clf__fit_intercept=False, clf__l1_ratio=0.920539731041378, clf__learning_rate=constant, clf__loss=squared_error, clf__max_iter=100, clf__penalty=l1, clf__power_t=0.5734177157821045, clf__shuffle=True, clf__tol=0.6492274795888617, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.104 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 13.69, NNZs: 5812, Bias: 0.000000, T: 2256, Avg. loss: 0.163631\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 17.63, NNZs: 3622, Bias: 0.000000, T: 4512, Avg. loss: 0.093694\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 20.85, NNZs: 2846, Bias: 0.000000, T: 6768, Avg. loss: 0.080266\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 23.58, NNZs: 2422, Bias: 0.000000, T: 9024, Avg. loss: 0.071614\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 25.91, NNZs: 2166, Bias: 0.000000, T: 11280, Avg. loss: 0.066287\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 28.02, NNZs: 1949, Bias: 0.000000, T: 13536, Avg. loss: 0.061975\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 176.64, NNZs: 10618, Bias: 0.000000, T: 2256, Avg. loss: 1.693567\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 911.87, NNZs: 17441, Bias: 0.000000, T: 4512, Avg. loss: 172.258195\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 8706.87, NNZs: 20550, Bias: 0.000000, T: 6768, Avg. loss: 18753.944490\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 43069.57, NNZs: 20938, Bias: 0.000000, T: 9024, Avg. loss: 512540.330528\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 196046.56, NNZs: 20997, Bias: 0.000000, T: 11280, Avg. loss: 9948556.308854\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1006380.45, NNZs: 21029, Bias: 0.000000, T: 13536, Avg. loss: 373064046.959431\n",
      "Total training time: 0.06 seconds.\n",
      "Convergence after 6 epochs took 0.06 seconds\n",
      "-- Epoch 1\n",
      "Norm: 10.49, NNZs: 3503, Bias: 0.000000, T: 2256, Avg. loss: 0.218087\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 13.64, NNZs: 1994, Bias: 0.000000, T: 4512, Avg. loss: 0.119723\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 15.99, NNZs: 1522, Bias: 0.000000, T: 6768, Avg. loss: 0.105341\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 17.83, NNZs: 1295, Bias: 0.000000, T: 9024, Avg. loss: 0.097744\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 19.45, NNZs: 1133, Bias: 0.000000, T: 11280, Avg. loss: 0.092714\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 20.96, NNZs: 1043, Bias: 0.000000, T: 13536, Avg. loss: 0.089022\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 509.13, NNZs: 17318, Bias: 0.000000, T: 2256, Avg. loss: 50.505245\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 29281.24, NNZs: 20661, Bias: 0.000000, T: 4512, Avg. loss: 220749.744377\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2335695.49, NNZs: 21029, Bias: 0.000000, T: 6768, Avg. loss: 2244197682.695968\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 151486836.05, NNZs: 21036, Bias: 0.000000, T: 9024, Avg. loss: 8310249850956.707031\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2535417510.19, NNZs: 21036, Bias: 0.000000, T: 11280, Avg. loss: 3223461861146269.500000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 134154812084.81, NNZs: 21036, Bias: 0.000000, T: 13536, Avg. loss: 7219341375532559360.000000\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 6 epochs took 0.05 seconds\n",
      "[CV 4/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.24457156361183285, clf__eta0=0.332929742792607, clf__fit_intercept=False, clf__l1_ratio=0.920539731041378, clf__learning_rate=constant, clf__loss=squared_error, clf__max_iter=100, clf__penalty=l1, clf__power_t=0.5734177157821045, clf__shuffle=True, clf__tol=0.6492274795888617, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.122 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 13.68, NNZs: 5788, Bias: 0.000000, T: 2256, Avg. loss: 0.160613\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 17.65, NNZs: 3728, Bias: 0.000000, T: 4512, Avg. loss: 0.093908\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 20.78, NNZs: 2952, Bias: 0.000000, T: 6768, Avg. loss: 0.079661\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 23.42, NNZs: 2508, Bias: 0.000000, T: 9024, Avg. loss: 0.070997\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 25.79, NNZs: 2248, Bias: 0.000000, T: 11280, Avg. loss: 0.065659\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27.87, NNZs: 2047, Bias: 0.000000, T: 13536, Avg. loss: 0.061373\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 40.16, NNZs: 9913, Bias: 0.000000, T: 2256, Avg. loss: 0.418924\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 134.85, NNZs: 9587, Bias: 0.000000, T: 4512, Avg. loss: 2.933631\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 813.73, NNZs: 17046, Bias: 0.000000, T: 6768, Avg. loss: 160.817609\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 5242.43, NNZs: 19887, Bias: 0.000000, T: 9024, Avg. loss: 5478.263195\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 38294.47, NNZs: 20769, Bias: 0.000000, T: 11280, Avg. loss: 251691.868577\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 149734.62, NNZs: 20949, Bias: 0.000000, T: 13536, Avg. loss: 6207587.165879\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 10.38, NNZs: 3573, Bias: 0.000000, T: 2256, Avg. loss: 0.216243\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 13.52, NNZs: 2081, Bias: 0.000000, T: 4512, Avg. loss: 0.120689\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 15.73, NNZs: 1664, Bias: 0.000000, T: 6768, Avg. loss: 0.107289\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 17.53, NNZs: 1440, Bias: 0.000000, T: 9024, Avg. loss: 0.098528\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 19.24, NNZs: 1312, Bias: 0.000000, T: 11280, Avg. loss: 0.095009\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 20.79, NNZs: 1200, Bias: 0.000000, T: 13536, Avg. loss: 0.092255\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 175.95, NNZs: 14261, Bias: 0.000000, T: 2256, Avg. loss: 5.498612\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 4353.54, NNZs: 19990, Bias: 0.000000, T: 4512, Avg. loss: 3511.757116\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 105614.06, NNZs: 20946, Bias: 0.000000, T: 6768, Avg. loss: 3174276.694290\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3755922.30, NNZs: 20996, Bias: 0.000000, T: 9024, Avg. loss: 5382644675.308121\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 154814533.13, NNZs: 20999, Bias: 0.000000, T: 11280, Avg. loss: 8572222625557.993164\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 990205293.17, NNZs: 20999, Bias: 0.000000, T: 13536, Avg. loss: 409983417759313.562500\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "[CV 5/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.24457156361183285, clf__eta0=0.332929742792607, clf__fit_intercept=False, clf__l1_ratio=0.920539731041378, clf__learning_rate=constant, clf__loss=squared_error, clf__max_iter=100, clf__penalty=l1, clf__power_t=0.5734177157821045, clf__shuffle=True, clf__tol=0.6492274795888617, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.134 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 1.33, NNZs: 35570, Bias: -0.076996, T: 2256, Avg. loss: 0.197509\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.83, NNZs: 35570, Bias: -0.104205, T: 4512, Avg. loss: 0.174577\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.22, NNZs: 35570, Bias: -0.124866, T: 6768, Avg. loss: 0.160627\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.56, NNZs: 35570, Bias: -0.142259, T: 9024, Avg. loss: 0.149357\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.85, NNZs: 35570, Bias: -0.157573, T: 11280, Avg. loss: 0.139611\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.12, NNZs: 35570, Bias: -0.171296, T: 13536, Avg. loss: 0.130957\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2.22, NNZs: 35570, Bias: -0.116717, T: 2256, Avg. loss: 0.129167\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2.76, NNZs: 35570, Bias: -0.154974, T: 4512, Avg. loss: 0.070549\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 3.02, NNZs: 35570, Bias: -0.178611, T: 6768, Avg. loss: 0.054498\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3.19, NNZs: 35570, Bias: -0.195841, T: 9024, Avg. loss: 0.046290\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3.31, NNZs: 35570, Bias: -0.209445, T: 11280, Avg. loss: 0.041019\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.40, NNZs: 35570, Bias: -0.220671, T: 13536, Avg. loss: 0.037291\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.33, NNZs: 35570, Bias: 0.074537, T: 2256, Avg. loss: 0.198029\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.85, NNZs: 35570, Bias: 0.100140, T: 4512, Avg. loss: 0.173886\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.26, NNZs: 35570, Bias: 0.119508, T: 6768, Avg. loss: 0.158986\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.61, NNZs: 35570, Bias: 0.135787, T: 9024, Avg. loss: 0.146907\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.92, NNZs: 35570, Bias: 0.150129, T: 11280, Avg. loss: 0.136439\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.20, NNZs: 35570, Bias: 0.163084, T: 13536, Avg. loss: 0.127070\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2.24, NNZs: 35570, Bias: -0.117551, T: 2256, Avg. loss: 0.124552\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2.77, NNZs: 35570, Bias: -0.155564, T: 4512, Avg. loss: 0.065164\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 3.03, NNZs: 35570, Bias: -0.179094, T: 6768, Avg. loss: 0.049332\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3.20, NNZs: 35570, Bias: -0.196286, T: 9024, Avg. loss: 0.041186\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3.32, NNZs: 35570, Bias: -0.209876, T: 11280, Avg. loss: 0.035952\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.41, NNZs: 35570, Bias: -0.221099, T: 13536, Avg. loss: 0.032255\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 1/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.2527955528897454, clf__eta0=0.4377192284389271, clf__fit_intercept=True, clf__l1_ratio=0.6515110441465675, clf__learning_rate=invscaling, clf__loss=huber, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.47239053945705856, clf__shuffle=False, clf__tol=0.9089234089706554, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.352 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 1.15, NNZs: 36165, Bias: -0.066329, T: 2256, Avg. loss: 0.200336\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.65, NNZs: 36165, Bias: -0.093064, T: 4512, Avg. loss: 0.179000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.05, NNZs: 36165, Bias: -0.113527, T: 6768, Avg. loss: 0.165518\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.38, NNZs: 36165, Bias: -0.130806, T: 9024, Avg. loss: 0.154593\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.67, NNZs: 36165, Bias: -0.146068, T: 11280, Avg. loss: 0.145130\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.94, NNZs: 36165, Bias: -0.159902, T: 13536, Avg. loss: 0.136650\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2.13, NNZs: 36165, Bias: -0.114993, T: 2256, Avg. loss: 0.131619\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2.65, NNZs: 36165, Bias: -0.153194, T: 4512, Avg. loss: 0.075931\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.90, NNZs: 36165, Bias: -0.177249, T: 6768, Avg. loss: 0.060159\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3.06, NNZs: 36165, Bias: -0.195130, T: 9024, Avg. loss: 0.051755\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3.18, NNZs: 36165, Bias: -0.209492, T: 11280, Avg. loss: 0.046175\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.27, NNZs: 36165, Bias: -0.221559, T: 13536, Avg. loss: 0.042091\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.18, NNZs: 36165, Bias: 0.063195, T: 2256, Avg. loss: 0.199769\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.70, NNZs: 36165, Bias: 0.088291, T: 4512, Avg. loss: 0.177627\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.11, NNZs: 36165, Bias: 0.107448, T: 6768, Avg. loss: 0.163492\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.46, NNZs: 36165, Bias: 0.123605, T: 9024, Avg. loss: 0.152008\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.76, NNZs: 36165, Bias: 0.137975, T: 11280, Avg. loss: 0.142142\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.03, NNZs: 36165, Bias: 0.151280, T: 13536, Avg. loss: 0.133669\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2.17, NNZs: 36165, Bias: -0.116176, T: 2256, Avg. loss: 0.126214\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2.67, NNZs: 36165, Bias: -0.154071, T: 4512, Avg. loss: 0.070415\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.92, NNZs: 36165, Bias: -0.177993, T: 6768, Avg. loss: 0.054893\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3.07, NNZs: 36165, Bias: -0.195816, T: 9024, Avg. loss: 0.046556\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3.19, NNZs: 36165, Bias: -0.210153, T: 11280, Avg. loss: 0.041015\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.28, NNZs: 36165, Bias: -0.222206, T: 13536, Avg. loss: 0.036962\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 2/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.2527955528897454, clf__eta0=0.4377192284389271, clf__fit_intercept=True, clf__l1_ratio=0.6515110441465675, clf__learning_rate=invscaling, clf__loss=huber, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.47239053945705856, clf__shuffle=False, clf__tol=0.9089234089706554, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.419 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 1.11, NNZs: 37176, Bias: -0.064631, T: 2256, Avg. loss: 0.201480\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.58, NNZs: 37176, Bias: -0.090977, T: 4512, Avg. loss: 0.182101\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.95, NNZs: 37176, Bias: -0.111253, T: 6768, Avg. loss: 0.169783\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.27, NNZs: 37176, Bias: -0.128416, T: 9024, Avg. loss: 0.159787\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.55, NNZs: 37176, Bias: -0.143597, T: 11280, Avg. loss: 0.151124\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.80, NNZs: 37176, Bias: -0.157372, T: 13536, Avg. loss: 0.143360\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2.17, NNZs: 37176, Bias: -0.115162, T: 2256, Avg. loss: 0.130955\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2.68, NNZs: 37176, Bias: -0.153063, T: 4512, Avg. loss: 0.075350\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.92, NNZs: 37176, Bias: -0.176724, T: 6768, Avg. loss: 0.060169\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3.07, NNZs: 37176, Bias: -0.194315, T: 9024, Avg. loss: 0.052052\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3.18, NNZs: 37176, Bias: -0.208502, T: 11280, Avg. loss: 0.046567\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.27, NNZs: 37176, Bias: -0.220461, T: 13536, Avg. loss: 0.042487\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.15, NNZs: 37176, Bias: 0.061105, T: 2256, Avg. loss: 0.200402\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.65, NNZs: 37176, Bias: 0.085770, T: 4512, Avg. loss: 0.179886\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.05, NNZs: 37176, Bias: 0.104720, T: 6768, Avg. loss: 0.166711\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.38, NNZs: 37176, Bias: 0.120749, T: 9024, Avg. loss: 0.155998\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.68, NNZs: 37176, Bias: 0.134979, T: 11280, Avg. loss: 0.146742\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.94, NNZs: 37176, Bias: 0.148082, T: 13536, Avg. loss: 0.138652\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2.21, NNZs: 37176, Bias: -0.116242, T: 2256, Avg. loss: 0.124887\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2.69, NNZs: 37176, Bias: -0.153600, T: 4512, Avg. loss: 0.069775\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.93, NNZs: 37176, Bias: -0.177064, T: 6768, Avg. loss: 0.054980\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3.07, NNZs: 37176, Bias: -0.194588, T: 9024, Avg. loss: 0.046933\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3.19, NNZs: 37176, Bias: -0.208756, T: 11280, Avg. loss: 0.041474\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.27, NNZs: 37176, Bias: -0.220717, T: 13536, Avg. loss: 0.037414\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 3/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.2527955528897454, clf__eta0=0.4377192284389271, clf__fit_intercept=True, clf__l1_ratio=0.6515110441465675, clf__learning_rate=invscaling, clf__loss=huber, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.47239053945705856, clf__shuffle=False, clf__tol=0.9089234089706554, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.432 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 1.14, NNZs: 37234, Bias: -0.066421, T: 2256, Avg. loss: 0.200452\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.63, NNZs: 37234, Bias: -0.092901, T: 4512, Avg. loss: 0.179557\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.02, NNZs: 37234, Bias: -0.113232, T: 6768, Avg. loss: 0.166221\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.35, NNZs: 37234, Bias: -0.130428, T: 9024, Avg. loss: 0.155389\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.65, NNZs: 37234, Bias: -0.145631, T: 11280, Avg. loss: 0.145995\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.92, NNZs: 37234, Bias: -0.159419, T: 13536, Avg. loss: 0.137575\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2.15, NNZs: 37234, Bias: -0.114957, T: 2256, Avg. loss: 0.130901\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2.66, NNZs: 37234, Bias: -0.152855, T: 4512, Avg. loss: 0.075618\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.91, NNZs: 37234, Bias: -0.176926, T: 6768, Avg. loss: 0.059776\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3.08, NNZs: 37234, Bias: -0.194919, T: 9024, Avg. loss: 0.050979\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3.20, NNZs: 37234, Bias: -0.209378, T: 11280, Avg. loss: 0.045011\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.30, NNZs: 37234, Bias: -0.221470, T: 13536, Avg. loss: 0.040633\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.17, NNZs: 37234, Bias: 0.063160, T: 2256, Avg. loss: 0.199562\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.70, NNZs: 37234, Bias: 0.087975, T: 4512, Avg. loss: 0.177442\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.11, NNZs: 37234, Bias: 0.106988, T: 6768, Avg. loss: 0.163162\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.46, NNZs: 37234, Bias: 0.123056, T: 9024, Avg. loss: 0.151538\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.76, NNZs: 37234, Bias: 0.137396, T: 11280, Avg. loss: 0.141556\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.03, NNZs: 37234, Bias: 0.150684, T: 13536, Avg. loss: 0.132976\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2.19, NNZs: 37234, Bias: -0.116103, T: 2256, Avg. loss: 0.125621\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2.68, NNZs: 37234, Bias: -0.153716, T: 4512, Avg. loss: 0.070180\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.92, NNZs: 37234, Bias: -0.177663, T: 6768, Avg. loss: 0.054589\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3.09, NNZs: 37234, Bias: -0.195604, T: 9024, Avg. loss: 0.045863\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3.21, NNZs: 37234, Bias: -0.210039, T: 11280, Avg. loss: 0.039937\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.31, NNZs: 37234, Bias: -0.222121, T: 13536, Avg. loss: 0.035591\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 4/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.2527955528897454, clf__eta0=0.4377192284389271, clf__fit_intercept=True, clf__l1_ratio=0.6515110441465675, clf__learning_rate=invscaling, clf__loss=huber, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.47239053945705856, clf__shuffle=False, clf__tol=0.9089234089706554, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.418 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 1.15, NNZs: 37169, Bias: -0.066392, T: 2256, Avg. loss: 0.200258\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.65, NNZs: 37169, Bias: -0.093052, T: 4512, Avg. loss: 0.178854\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.04, NNZs: 37169, Bias: -0.113483, T: 6768, Avg. loss: 0.165204\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.38, NNZs: 37169, Bias: -0.130744, T: 9024, Avg. loss: 0.154124\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.68, NNZs: 37169, Bias: -0.145994, T: 11280, Avg. loss: 0.144519\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.95, NNZs: 37169, Bias: -0.159816, T: 13536, Avg. loss: 0.135909\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2.14, NNZs: 37169, Bias: -0.114392, T: 2256, Avg. loss: 0.129807\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2.65, NNZs: 37169, Bias: -0.151881, T: 4512, Avg. loss: 0.074412\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.89, NNZs: 37169, Bias: -0.175518, T: 6768, Avg. loss: 0.059065\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3.06, NNZs: 37169, Bias: -0.193183, T: 9024, Avg. loss: 0.050686\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3.18, NNZs: 37169, Bias: -0.207416, T: 11280, Avg. loss: 0.045014\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.27, NNZs: 37169, Bias: -0.219352, T: 13536, Avg. loss: 0.040837\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.18, NNZs: 37169, Bias: 0.063306, T: 2256, Avg. loss: 0.199244\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.71, NNZs: 37169, Bias: 0.088341, T: 4512, Avg. loss: 0.176574\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.13, NNZs: 37169, Bias: 0.107474, T: 6768, Avg. loss: 0.161947\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.49, NNZs: 37169, Bias: 0.123619, T: 9024, Avg. loss: 0.150043\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.80, NNZs: 37169, Bias: 0.137969, T: 11280, Avg. loss: 0.139798\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.07, NNZs: 37169, Bias: 0.151210, T: 13536, Avg. loss: 0.130932\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2.17, NNZs: 37169, Bias: -0.115402, T: 2256, Avg. loss: 0.124157\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2.66, NNZs: 37169, Bias: -0.152520, T: 4512, Avg. loss: 0.068981\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.90, NNZs: 37169, Bias: -0.176026, T: 6768, Avg. loss: 0.053887\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3.06, NNZs: 37169, Bias: -0.193649, T: 9024, Avg. loss: 0.045552\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3.18, NNZs: 37169, Bias: -0.207870, T: 11280, Avg. loss: 0.039903\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.28, NNZs: 37169, Bias: -0.219805, T: 13536, Avg. loss: 0.035748\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 5/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.2527955528897454, clf__eta0=0.4377192284389271, clf__fit_intercept=True, clf__l1_ratio=0.6515110441465675, clf__learning_rate=invscaling, clf__loss=huber, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.47239053945705856, clf__shuffle=False, clf__tol=0.9089234089706554, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.374 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 90.44, NNZs: 34955, Bias: -1.032679, T: 2256, Avg. loss: 0.855511\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 42.19, NNZs: 35379, Bias: -0.920046, T: 4512, Avg. loss: 0.911686\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 34.83, NNZs: 35503, Bias: -1.119673, T: 6768, Avg. loss: 0.291173\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 27.68, NNZs: 35519, Bias: -1.030261, T: 9024, Avg. loss: 0.168345\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 24.66, NNZs: 35524, Bias: -1.071113, T: 11280, Avg. loss: 0.069140\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 22.57, NNZs: 35533, Bias: -1.077115, T: 13536, Avg. loss: 0.030761\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 90.24, NNZs: 34992, Bias: -0.916491, T: 2256, Avg. loss: 0.835617\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 39.62, NNZs: 35396, Bias: -0.913356, T: 4512, Avg. loss: 0.931306\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 29.60, NNZs: 35465, Bias: -0.948953, T: 6768, Avg. loss: 0.258039\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 20.30, NNZs: 35463, Bias: -0.942903, T: 9024, Avg. loss: 0.170709\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 15.98, NNZs: 35447, Bias: -0.941773, T: 11280, Avg. loss: 0.063727\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 13.32, NNZs: 35426, Bias: -0.884828, T: 13536, Avg. loss: 0.024569\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 91.30, NNZs: 35007, Bias: 0.867742, T: 2256, Avg. loss: 0.873233\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 42.39, NNZs: 35355, Bias: 0.934523, T: 4512, Avg. loss: 0.868842\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 33.67, NNZs: 35478, Bias: 1.074835, T: 6768, Avg. loss: 0.291552\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 25.25, NNZs: 35508, Bias: 0.986634, T: 9024, Avg. loss: 0.164596\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 22.68, NNZs: 35528, Bias: 1.073992, T: 11280, Avg. loss: 0.068557\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 21.11, NNZs: 35532, Bias: 1.052326, T: 13536, Avg. loss: 0.023074\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 19.96, NNZs: 35534, Bias: 1.077923, T: 15792, Avg. loss: 0.007227\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 7 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 90.81, NNZs: 34928, Bias: -0.943292, T: 2256, Avg. loss: 0.808427\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 38.10, NNZs: 35338, Bias: -0.864810, T: 4512, Avg. loss: 0.956146\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 27.26, NNZs: 35444, Bias: -0.951503, T: 6768, Avg. loss: 0.245755\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 17.98, NNZs: 35424, Bias: -0.937754, T: 9024, Avg. loss: 0.148723\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 11.89, NNZs: 35409, Bias: -0.902369, T: 11280, Avg. loss: 0.061602\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 8.48, NNZs: 35381, Bias: -0.909317, T: 13536, Avg. loss: 0.020509\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 7.19, NNZs: 35370, Bias: -0.896729, T: 15792, Avg. loss: 0.005302\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 6.61, NNZs: 35367, Bias: -0.880378, T: 18048, Avg. loss: 0.001865\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 8 epochs took 0.03 seconds\n",
      "[CV 1/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.3241670976844645, clf__eta0=0.9631840511405841, clf__fit_intercept=True, clf__l1_ratio=0.5912641309775509, clf__learning_rate=optimal, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.6710686638981408, clf__shuffle=True, clf__tol=0.09654933943827881, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.471 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 92.56, NNZs: 35675, Bias: -0.989206, T: 2256, Avg. loss: 0.876532\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 41.83, NNZs: 35988, Bias: -0.900625, T: 4512, Avg. loss: 0.911511\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 34.38, NNZs: 36085, Bias: -1.038024, T: 6768, Avg. loss: 0.291798\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 27.39, NNZs: 36101, Bias: -1.098941, T: 9024, Avg. loss: 0.166786\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 24.96, NNZs: 36111, Bias: -1.069799, T: 11280, Avg. loss: 0.074231\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 23.61, NNZs: 36123, Bias: -1.099825, T: 13536, Avg. loss: 0.029320\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 88.99, NNZs: 35444, Bias: -1.004355, T: 2256, Avg. loss: 0.811183\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 40.41, NNZs: 35909, Bias: -0.947239, T: 4512, Avg. loss: 0.896840\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 29.08, NNZs: 36041, Bias: -0.893358, T: 6768, Avg. loss: 0.261793\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 20.74, NNZs: 36025, Bias: -0.965512, T: 9024, Avg. loss: 0.157763\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 15.81, NNZs: 35996, Bias: -0.913981, T: 11280, Avg. loss: 0.064834\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 13.59, NNZs: 35999, Bias: -0.898135, T: 13536, Avg. loss: 0.021083\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 90.95, NNZs: 35506, Bias: 1.110261, T: 2256, Avg. loss: 0.863207\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 40.68, NNZs: 35934, Bias: 0.849427, T: 4512, Avg. loss: 0.918569\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 33.48, NNZs: 36094, Bias: 1.074725, T: 6768, Avg. loss: 0.283578\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 26.41, NNZs: 36111, Bias: 1.069332, T: 9024, Avg. loss: 0.159213\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 22.64, NNZs: 36124, Bias: 1.049355, T: 11280, Avg. loss: 0.068479\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 20.74, NNZs: 36129, Bias: 1.099032, T: 13536, Avg. loss: 0.024699\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 89.69, NNZs: 35515, Bias: -0.934065, T: 2256, Avg. loss: 0.821407\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 39.81, NNZs: 35916, Bias: -0.954035, T: 4512, Avg. loss: 0.906374\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 27.90, NNZs: 36002, Bias: -0.907301, T: 6768, Avg. loss: 0.258590\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 17.80, NNZs: 36006, Bias: -0.893451, T: 9024, Avg. loss: 0.156705\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 11.96, NNZs: 35970, Bias: -0.971089, T: 11280, Avg. loss: 0.060706\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 8.49, NNZs: 35957, Bias: -0.896023, T: 13536, Avg. loss: 0.019373\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 7.18, NNZs: 35948, Bias: -0.909847, T: 15792, Avg. loss: 0.004633\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 7 epochs took 0.03 seconds\n",
      "[CV 2/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.3241670976844645, clf__eta0=0.9631840511405841, clf__fit_intercept=True, clf__l1_ratio=0.5912641309775509, clf__learning_rate=optimal, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.6710686638981408, clf__shuffle=True, clf__tol=0.09654933943827881, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.570 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 91.85, NNZs: 36708, Bias: -1.086944, T: 2256, Avg. loss: 0.893491\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 42.63, NNZs: 36923, Bias: -0.932296, T: 4512, Avg. loss: 0.909407\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 35.06, NNZs: 37050, Bias: -1.066485, T: 6768, Avg. loss: 0.283805\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 27.44, NNZs: 37068, Bias: -1.129551, T: 9024, Avg. loss: 0.169872\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 24.46, NNZs: 37075, Bias: -1.093610, T: 11280, Avg. loss: 0.076167\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 23.15, NNZs: 37081, Bias: -1.121571, T: 13536, Avg. loss: 0.029155\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 89.27, NNZs: 36352, Bias: -0.746552, T: 2256, Avg. loss: 0.812179\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 39.54, NNZs: 36487, Bias: -0.820964, T: 4512, Avg. loss: 0.918142\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 28.25, NNZs: 36585, Bias: -0.986830, T: 6768, Avg. loss: 0.255322\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 19.78, NNZs: 36601, Bias: -0.923796, T: 9024, Avg. loss: 0.159759\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 15.27, NNZs: 36588, Bias: -0.923400, T: 11280, Avg. loss: 0.061449\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 13.13, NNZs: 36585, Bias: -0.907234, T: 13536, Avg. loss: 0.020015\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 12.39, NNZs: 36578, Bias: -0.918690, T: 15792, Avg. loss: 0.006377\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 11.71, NNZs: 36583, Bias: -0.912724, T: 18048, Avg. loss: 0.003041\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 8 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 91.64, NNZs: 36105, Bias: 0.997406, T: 2256, Avg. loss: 0.862417\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 41.20, NNZs: 36499, Bias: 1.048237, T: 4512, Avg. loss: 0.890728\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 34.06, NNZs: 36641, Bias: 1.097113, T: 6768, Avg. loss: 0.284130\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 25.35, NNZs: 36663, Bias: 1.056557, T: 9024, Avg. loss: 0.161776\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 22.62, NNZs: 36675, Bias: 1.092524, T: 11280, Avg. loss: 0.065294\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 21.09, NNZs: 36691, Bias: 1.085422, T: 13536, Avg. loss: 0.024373\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 89.93, NNZs: 36033, Bias: -0.815236, T: 2256, Avg. loss: 0.805750\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 37.99, NNZs: 36547, Bias: -0.874606, T: 4512, Avg. loss: 0.945934\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 27.25, NNZs: 36645, Bias: -0.929666, T: 6768, Avg. loss: 0.244756\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 18.16, NNZs: 36633, Bias: -0.939239, T: 9024, Avg. loss: 0.147282\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 12.42, NNZs: 36600, Bias: -0.924161, T: 11280, Avg. loss: 0.062911\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 8.94, NNZs: 36560, Bias: -0.938826, T: 13536, Avg. loss: 0.020678\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 3/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.3241670976844645, clf__eta0=0.9631840511405841, clf__fit_intercept=True, clf__l1_ratio=0.5912641309775509, clf__learning_rate=optimal, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.6710686638981408, clf__shuffle=True, clf__tol=0.09654933943827881, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.488 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 92.29, NNZs: 36766, Bias: -0.874410, T: 2256, Avg. loss: 0.877945\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 42.48, NNZs: 36845, Bias: -0.748548, T: 4512, Avg. loss: 0.923787\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 35.06, NNZs: 37196, Bias: -1.045464, T: 6768, Avg. loss: 0.293798\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 27.64, NNZs: 37207, Bias: -0.959359, T: 9024, Avg. loss: 0.172137\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 24.75, NNZs: 37226, Bias: -1.051193, T: 11280, Avg. loss: 0.075358\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 23.79, NNZs: 37228, Bias: -1.019978, T: 13536, Avg. loss: 0.030080\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 90.17, NNZs: 36725, Bias: -1.018573, T: 2256, Avg. loss: 0.833043\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 38.50, NNZs: 37066, Bias: -0.835251, T: 4512, Avg. loss: 0.944721\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 28.55, NNZs: 37133, Bias: -0.943405, T: 6768, Avg. loss: 0.241472\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 20.15, NNZs: 37091, Bias: -0.904303, T: 9024, Avg. loss: 0.155650\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 15.48, NNZs: 37011, Bias: -0.896894, T: 11280, Avg. loss: 0.061436\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 13.27, NNZs: 37017, Bias: -0.897916, T: 13536, Avg. loss: 0.020996\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 12.32, NNZs: 37015, Bias: -0.887343, T: 15792, Avg. loss: 0.006163\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 7 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 90.97, NNZs: 36729, Bias: 1.146472, T: 2256, Avg. loss: 0.876498\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 41.52, NNZs: 37098, Bias: 0.906721, T: 4512, Avg. loss: 0.887813\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 34.18, NNZs: 37226, Bias: 0.993139, T: 6768, Avg. loss: 0.299435\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 26.34, NNZs: 37215, Bias: 1.000928, T: 9024, Avg. loss: 0.169753\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 23.24, NNZs: 37228, Bias: 1.037864, T: 11280, Avg. loss: 0.067939\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 21.33, NNZs: 37235, Bias: 1.002949, T: 13536, Avg. loss: 0.024024\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 90.17, NNZs: 36561, Bias: -0.779901, T: 2256, Avg. loss: 0.790744\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 38.35, NNZs: 36948, Bias: -0.719523, T: 4512, Avg. loss: 0.937354\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 27.49, NNZs: 37065, Bias: -0.889715, T: 6768, Avg. loss: 0.240506\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 18.14, NNZs: 37055, Bias: -0.909458, T: 9024, Avg. loss: 0.153686\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 12.42, NNZs: 37053, Bias: -0.921088, T: 11280, Avg. loss: 0.061394\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 9.05, NNZs: 37038, Bias: -0.845872, T: 13536, Avg. loss: 0.020848\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 7.79, NNZs: 37032, Bias: -0.866194, T: 15792, Avg. loss: 0.005885\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 7.07, NNZs: 37026, Bias: -0.848507, T: 18048, Avg. loss: 0.001401\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 6.83, NNZs: 37025, Bias: -0.858250, T: 20304, Avg. loss: 0.000735\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 6.68, NNZs: 37025, Bias: -0.858002, T: 22560, Avg. loss: 0.000361\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 10 epochs took 0.04 seconds\n",
      "[CV 4/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.3241670976844645, clf__eta0=0.9631840511405841, clf__fit_intercept=True, clf__l1_ratio=0.5912641309775509, clf__learning_rate=optimal, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.6710686638981408, clf__shuffle=True, clf__tol=0.09654933943827881, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.485 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 92.34, NNZs: 36550, Bias: -1.220703, T: 2256, Avg. loss: 0.862201\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 40.97, NNZs: 36934, Bias: -0.857185, T: 4512, Avg. loss: 0.928839\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 34.94, NNZs: 37071, Bias: -1.158575, T: 6768, Avg. loss: 0.278136\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 27.05, NNZs: 37079, Bias: -1.075293, T: 9024, Avg. loss: 0.169830\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 24.08, NNZs: 37086, Bias: -1.095330, T: 11280, Avg. loss: 0.067211\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 22.22, NNZs: 37093, Bias: -1.071491, T: 13536, Avg. loss: 0.026464\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 89.03, NNZs: 36483, Bias: -0.883139, T: 2256, Avg. loss: 0.818370\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 38.40, NNZs: 36871, Bias: -0.912821, T: 4512, Avg. loss: 0.943398\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 28.35, NNZs: 36982, Bias: -0.947272, T: 6768, Avg. loss: 0.244865\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 20.45, NNZs: 36966, Bias: -0.961247, T: 9024, Avg. loss: 0.149835\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 15.65, NNZs: 36965, Bias: -0.910013, T: 11280, Avg. loss: 0.067259\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 13.07, NNZs: 36946, Bias: -0.894746, T: 13536, Avg. loss: 0.022519\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 12.05, NNZs: 36949, Bias: -0.881017, T: 15792, Avg. loss: 0.004697\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 11.65, NNZs: 36946, Bias: -0.903821, T: 18048, Avg. loss: 0.002169\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 11.45, NNZs: 36947, Bias: -0.908684, T: 20304, Avg. loss: 0.001672\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 9 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 91.19, NNZs: 36451, Bias: 1.212697, T: 2256, Avg. loss: 0.873433\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 41.68, NNZs: 36942, Bias: 0.968215, T: 4512, Avg. loss: 0.886815\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 32.90, NNZs: 37035, Bias: 1.085677, T: 6768, Avg. loss: 0.283545\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 25.76, NNZs: 37077, Bias: 1.081872, T: 9024, Avg. loss: 0.155973\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 22.09, NNZs: 37083, Bias: 1.065908, T: 11280, Avg. loss: 0.064641\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 20.01, NNZs: 37093, Bias: 1.070438, T: 13536, Avg. loss: 0.027709\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 89.72, NNZs: 36515, Bias: -0.885213, T: 2256, Avg. loss: 0.814286\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 39.80, NNZs: 36943, Bias: -0.958306, T: 4512, Avg. loss: 0.912370\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 27.36, NNZs: 36992, Bias: -0.963961, T: 6768, Avg. loss: 0.255621\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 17.97, NNZs: 37001, Bias: -0.902219, T: 9024, Avg. loss: 0.153107\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 12.52, NNZs: 36976, Bias: -0.930001, T: 11280, Avg. loss: 0.057677\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 9.35, NNZs: 36960, Bias: -0.907972, T: 13536, Avg. loss: 0.021664\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 7.63, NNZs: 36957, Bias: -0.901801, T: 15792, Avg. loss: 0.005525\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 7 epochs took 0.03 seconds\n",
      "[CV 5/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.3241670976844645, clf__eta0=0.9631840511405841, clf__fit_intercept=True, clf__l1_ratio=0.5912641309775509, clf__learning_rate=optimal, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.6710686638981408, clf__shuffle=True, clf__tol=0.09654933943827881, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.516 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 31.88, NNZs: 4254, Bias: 0.000000, T: 2256, Avg. loss: 0.206276\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 42.04, NNZs: 2488, Bias: 0.000000, T: 4512, Avg. loss: 0.100195\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 49.43, NNZs: 1857, Bias: 0.000000, T: 6768, Avg. loss: 0.073817\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 55.69, NNZs: 1560, Bias: 0.000000, T: 9024, Avg. loss: 0.061981\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 61.16, NNZs: 1389, Bias: 0.000000, T: 11280, Avg. loss: 0.053222\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 66.05, NNZs: 1257, Bias: 0.000000, T: 13536, Avg. loss: 0.046279\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 68.12, NNZs: 6163, Bias: 0.000000, T: 2256, Avg. loss: 0.338413\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 80.52, NNZs: 3957, Bias: 0.000000, T: 4512, Avg. loss: 0.142355\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 82.99, NNZs: 2547, Bias: 0.000000, T: 6768, Avg. loss: 0.031471\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 89.78, NNZs: 2075, Bias: 0.000000, T: 9024, Avg. loss: 0.038884\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 96.78, NNZs: 1727, Bias: 0.000000, T: 11280, Avg. loss: 0.027501\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 101.27, NNZs: 1561, Bias: 0.000000, T: 13536, Avg. loss: 0.019081\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 24.51, NNZs: 2745, Bias: 0.000000, T: 2256, Avg. loss: 0.228316\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 32.66, NNZs: 1530, Bias: 0.000000, T: 4512, Avg. loss: 0.126719\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 38.45, NNZs: 1169, Bias: 0.000000, T: 6768, Avg. loss: 0.096365\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 43.05, NNZs: 1002, Bias: 0.000000, T: 9024, Avg. loss: 0.079904\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 47.06, NNZs: 845, Bias: 0.000000, T: 11280, Avg. loss: 0.071113\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 50.44, NNZs: 711, Bias: 0.000000, T: 13536, Avg. loss: 0.066107\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 107.31, NNZs: 4877, Bias: 0.000000, T: 2256, Avg. loss: 1.302818\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 168.94, NNZs: 4730, Bias: 0.000000, T: 4512, Avg. loss: 1.387998\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 186.18, NNZs: 3731, Bias: 0.000000, T: 6768, Avg. loss: 0.246543\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 186.06, NNZs: 3029, Bias: 0.000000, T: 9024, Avg. loss: 0.079203\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 186.09, NNZs: 2394, Bias: 0.000000, T: 11280, Avg. loss: 0.020694\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 186.16, NNZs: 1986, Bias: 0.000000, T: 13536, Avg. loss: 0.010841\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 1/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.3509613152086368, clf__eta0=0.9934401124631351, clf__fit_intercept=False, clf__l1_ratio=0.5204998682261415, clf__learning_rate=constant, clf__loss=hinge, clf__max_iter=40, clf__penalty=l1, clf__power_t=0.5098574122392232, clf__shuffle=False, clf__tol=0.5563103350645606, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.621 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 31.84, NNZs: 4266, Bias: 0.000000, T: 2256, Avg. loss: 0.199187\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 41.64, NNZs: 2427, Bias: 0.000000, T: 4512, Avg. loss: 0.098707\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 49.08, NNZs: 1863, Bias: 0.000000, T: 6768, Avg. loss: 0.076321\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 55.19, NNZs: 1512, Bias: 0.000000, T: 9024, Avg. loss: 0.064964\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 60.52, NNZs: 1363, Bias: 0.000000, T: 11280, Avg. loss: 0.057359\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 65.34, NNZs: 1176, Bias: 0.000000, T: 13536, Avg. loss: 0.051824\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 74.36, NNZs: 7184, Bias: 0.000000, T: 2256, Avg. loss: 0.332937\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 87.07, NNZs: 4482, Bias: 0.000000, T: 4512, Avg. loss: 0.117159\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 92.90, NNZs: 3182, Bias: 0.000000, T: 6768, Avg. loss: 0.044663\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 99.27, NNZs: 2576, Bias: 0.000000, T: 9024, Avg. loss: 0.029608\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 101.78, NNZs: 1930, Bias: 0.000000, T: 11280, Avg. loss: 0.020502\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 104.04, NNZs: 1465, Bias: 0.000000, T: 13536, Avg. loss: 0.010366\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 24.76, NNZs: 2848, Bias: 0.000000, T: 2256, Avg. loss: 0.249434\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 32.65, NNZs: 1568, Bias: 0.000000, T: 4512, Avg. loss: 0.125181\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 38.41, NNZs: 1211, Bias: 0.000000, T: 6768, Avg. loss: 0.095805\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 43.06, NNZs: 995, Bias: 0.000000, T: 9024, Avg. loss: 0.081483\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 47.12, NNZs: 880, Bias: 0.000000, T: 11280, Avg. loss: 0.075197\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 50.70, NNZs: 784, Bias: 0.000000, T: 13536, Avg. loss: 0.070743\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 159.95, NNZs: 8759, Bias: 0.000000, T: 2256, Avg. loss: 1.530950\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 192.48, NNZs: 6048, Bias: 0.000000, T: 4512, Avg. loss: 0.887334\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 189.05, NNZs: 4451, Bias: 0.000000, T: 6768, Avg. loss: 0.379972\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 188.45, NNZs: 3500, Bias: 0.000000, T: 9024, Avg. loss: 0.073499\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 188.35, NNZs: 2854, Bias: 0.000000, T: 11280, Avg. loss: 0.018243\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 188.32, NNZs: 2407, Bias: 0.000000, T: 13536, Avg. loss: 0.009595\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 2/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.3509613152086368, clf__eta0=0.9934401124631351, clf__fit_intercept=False, clf__l1_ratio=0.5204998682261415, clf__learning_rate=constant, clf__loss=hinge, clf__max_iter=40, clf__penalty=l1, clf__power_t=0.5098574122392232, clf__shuffle=False, clf__tol=0.5563103350645606, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.696 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 32.61, NNZs: 4405, Bias: 0.000000, T: 2256, Avg. loss: 0.209384\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 42.67, NNZs: 2619, Bias: 0.000000, T: 4512, Avg. loss: 0.105113\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 50.43, NNZs: 1968, Bias: 0.000000, T: 6768, Avg. loss: 0.080683\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 57.04, NNZs: 1645, Bias: 0.000000, T: 9024, Avg. loss: 0.067844\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 62.64, NNZs: 1439, Bias: 0.000000, T: 11280, Avg. loss: 0.060000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 67.81, NNZs: 1318, Bias: 0.000000, T: 13536, Avg. loss: 0.052325\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 72.50, NNZs: 6666, Bias: 0.000000, T: 2256, Avg. loss: 0.326433\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 82.93, NNZs: 4149, Bias: 0.000000, T: 4512, Avg. loss: 0.128645\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 88.97, NNZs: 3011, Bias: 0.000000, T: 6768, Avg. loss: 0.037389\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 91.78, NNZs: 2248, Bias: 0.000000, T: 9024, Avg. loss: 0.013792\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 98.38, NNZs: 1799, Bias: 0.000000, T: 11280, Avg. loss: 0.023454\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 100.63, NNZs: 1375, Bias: 0.000000, T: 13536, Avg. loss: 0.010997\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 25.57, NNZs: 3039, Bias: 0.000000, T: 2256, Avg. loss: 0.257513\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 33.39, NNZs: 1607, Bias: 0.000000, T: 4512, Avg. loss: 0.132449\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 39.23, NNZs: 1225, Bias: 0.000000, T: 6768, Avg. loss: 0.106583\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 44.04, NNZs: 1038, Bias: 0.000000, T: 9024, Avg. loss: 0.093806\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 48.26, NNZs: 874, Bias: 0.000000, T: 11280, Avg. loss: 0.083851\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 52.05, NNZs: 775, Bias: 0.000000, T: 13536, Avg. loss: 0.077590\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 178.72, NNZs: 10124, Bias: 0.000000, T: 2256, Avg. loss: 2.455202\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 188.05, NNZs: 6392, Bias: 0.000000, T: 4512, Avg. loss: 0.941708\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 187.82, NNZs: 4393, Bias: 0.000000, T: 6768, Avg. loss: 0.044914\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 187.84, NNZs: 3362, Bias: 0.000000, T: 9024, Avg. loss: 0.012126\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 187.89, NNZs: 2712, Bias: 0.000000, T: 11280, Avg. loss: 0.005063\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 187.99, NNZs: 2280, Bias: 0.000000, T: 13536, Avg. loss: 0.002181\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 3/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.3509613152086368, clf__eta0=0.9934401124631351, clf__fit_intercept=False, clf__l1_ratio=0.5204998682261415, clf__learning_rate=constant, clf__loss=hinge, clf__max_iter=40, clf__penalty=l1, clf__power_t=0.5098574122392232, clf__shuffle=False, clf__tol=0.5563103350645606, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.668 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 32.17, NNZs: 4407, Bias: 0.000000, T: 2256, Avg. loss: 0.210986\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 42.18, NNZs: 2604, Bias: 0.000000, T: 4512, Avg. loss: 0.097338\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 49.84, NNZs: 1970, Bias: 0.000000, T: 6768, Avg. loss: 0.074112\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 55.86, NNZs: 1616, Bias: 0.000000, T: 9024, Avg. loss: 0.061901\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 61.74, NNZs: 1441, Bias: 0.000000, T: 11280, Avg. loss: 0.054071\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 66.40, NNZs: 1277, Bias: 0.000000, T: 13536, Avg. loss: 0.047994\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 70.21, NNZs: 6918, Bias: 0.000000, T: 2256, Avg. loss: 0.360722\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 82.75, NNZs: 4379, Bias: 0.000000, T: 4512, Avg. loss: 0.104592\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 87.26, NNZs: 2950, Bias: 0.000000, T: 6768, Avg. loss: 0.028389\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 92.28, NNZs: 2374, Bias: 0.000000, T: 9024, Avg. loss: 0.023655\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 98.91, NNZs: 1915, Bias: 0.000000, T: 11280, Avg. loss: 0.023973\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 101.49, NNZs: 1492, Bias: 0.000000, T: 13536, Avg. loss: 0.014017\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 25.85, NNZs: 3040, Bias: 0.000000, T: 2256, Avg. loss: 0.258942\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 33.62, NNZs: 1611, Bias: 0.000000, T: 4512, Avg. loss: 0.124545\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 39.21, NNZs: 1216, Bias: 0.000000, T: 6768, Avg. loss: 0.100003\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 44.03, NNZs: 1006, Bias: 0.000000, T: 9024, Avg. loss: 0.085884\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 47.91, NNZs: 844, Bias: 0.000000, T: 11280, Avg. loss: 0.076780\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 51.49, NNZs: 756, Bias: 0.000000, T: 13536, Avg. loss: 0.072119\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 176.22, NNZs: 10066, Bias: 0.000000, T: 2256, Avg. loss: 2.330126\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 187.78, NNZs: 5781, Bias: 0.000000, T: 4512, Avg. loss: 0.512930\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 186.84, NNZs: 4014, Bias: 0.000000, T: 6768, Avg. loss: 0.123378\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 186.77, NNZs: 3007, Bias: 0.000000, T: 9024, Avg. loss: 0.018055\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 186.84, NNZs: 2460, Bias: 0.000000, T: 11280, Avg. loss: 0.007032\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 186.89, NNZs: 2095, Bias: 0.000000, T: 13536, Avg. loss: 0.004124\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 4/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.3509613152086368, clf__eta0=0.9934401124631351, clf__fit_intercept=False, clf__l1_ratio=0.5204998682261415, clf__learning_rate=constant, clf__loss=hinge, clf__max_iter=40, clf__penalty=l1, clf__power_t=0.5098574122392232, clf__shuffle=False, clf__tol=0.5563103350645606, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.474 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 30.82, NNZs: 3924, Bias: 0.000000, T: 2256, Avg. loss: 0.188541\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 41.04, NNZs: 2363, Bias: 0.000000, T: 4512, Avg. loss: 0.099872\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 48.78, NNZs: 1841, Bias: 0.000000, T: 6768, Avg. loss: 0.075367\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 55.26, NNZs: 1551, Bias: 0.000000, T: 9024, Avg. loss: 0.062742\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 60.89, NNZs: 1377, Bias: 0.000000, T: 11280, Avg. loss: 0.052266\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 65.70, NNZs: 1222, Bias: 0.000000, T: 13536, Avg. loss: 0.046153\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 72.71, NNZs: 6413, Bias: 0.000000, T: 2256, Avg. loss: 0.305998\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 86.20, NNZs: 4528, Bias: 0.000000, T: 4512, Avg. loss: 0.108880\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 92.11, NNZs: 3199, Bias: 0.000000, T: 6768, Avg. loss: 0.045885\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 96.74, NNZs: 2352, Bias: 0.000000, T: 9024, Avg. loss: 0.025735\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 101.53, NNZs: 1925, Bias: 0.000000, T: 11280, Avg. loss: 0.017557\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 106.00, NNZs: 1648, Bias: 0.000000, T: 13536, Avg. loss: 0.014886\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 25.14, NNZs: 2912, Bias: 0.000000, T: 2256, Avg. loss: 0.229676\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 32.57, NNZs: 1537, Bias: 0.000000, T: 4512, Avg. loss: 0.124298\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 38.14, NNZs: 1181, Bias: 0.000000, T: 6768, Avg. loss: 0.097573\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 42.86, NNZs: 986, Bias: 0.000000, T: 9024, Avg. loss: 0.087454\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 46.92, NNZs: 851, Bias: 0.000000, T: 11280, Avg. loss: 0.079748\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 50.54, NNZs: 776, Bias: 0.000000, T: 13536, Avg. loss: 0.073824\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 157.09, NNZs: 9337, Bias: 0.000000, T: 2256, Avg. loss: 2.013517\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 190.52, NNZs: 5383, Bias: 0.000000, T: 4512, Avg. loss: 0.417366\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 183.34, NNZs: 4191, Bias: 0.000000, T: 6768, Avg. loss: 0.718530\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 183.28, NNZs: 3171, Bias: 0.000000, T: 9024, Avg. loss: 0.015072\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 183.27, NNZs: 2514, Bias: 0.000000, T: 11280, Avg. loss: 0.008051\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 183.30, NNZs: 2047, Bias: 0.000000, T: 13536, Avg. loss: 0.004922\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 5/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.3509613152086368, clf__eta0=0.9934401124631351, clf__fit_intercept=False, clf__l1_ratio=0.5204998682261415, clf__learning_rate=constant, clf__loss=hinge, clf__max_iter=40, clf__penalty=l1, clf__power_t=0.5098574122392232, clf__shuffle=False, clf__tol=0.5563103350645606, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.546 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.25, NNZs: 20243, Bias: 0.000000, T: 2256, Avg. loss: 0.697439\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.34, NNZs: 20243, Bias: 0.000000, T: 4512, Avg. loss: 0.684023\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.41, NNZs: 20243, Bias: 0.000000, T: 6768, Avg. loss: 0.675866\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.47, NNZs: 20243, Bias: 0.000000, T: 9024, Avg. loss: 0.669409\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.52, NNZs: 20243, Bias: 0.000000, T: 11280, Avg. loss: 0.663930\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.56, NNZs: 20243, Bias: 0.000000, T: 13536, Avg. loss: 0.659102\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.36, NNZs: 20243, Bias: 0.000000, T: 2256, Avg. loss: 0.666324\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.49, NNZs: 20243, Bias: 0.000000, T: 4512, Avg. loss: 0.632238\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.59, NNZs: 20243, Bias: 0.000000, T: 6768, Avg. loss: 0.613835\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.67, NNZs: 20243, Bias: 0.000000, T: 9024, Avg. loss: 0.597194\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.74, NNZs: 20243, Bias: 0.000000, T: 11280, Avg. loss: 0.583585\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.80, NNZs: 20243, Bias: 0.000000, T: 13536, Avg. loss: 0.573186\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.25, NNZs: 20243, Bias: 0.000000, T: 2256, Avg. loss: 0.701395\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.34, NNZs: 20243, Bias: 0.000000, T: 4512, Avg. loss: 0.692005\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.41, NNZs: 20243, Bias: 0.000000, T: 6768, Avg. loss: 0.686347\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.46, NNZs: 20243, Bias: 0.000000, T: 9024, Avg. loss: 0.681794\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.51, NNZs: 20243, Bias: 0.000000, T: 11280, Avg. loss: 0.677907\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.56, NNZs: 20243, Bias: 0.000000, T: 13536, Avg. loss: 0.674531\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.42, NNZs: 20243, Bias: 0.000000, T: 2256, Avg. loss: 0.655536\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.56, NNZs: 20243, Bias: 0.000000, T: 4512, Avg. loss: 0.619521\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.67, NNZs: 20243, Bias: 0.000000, T: 6768, Avg. loss: 0.602888\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.76, NNZs: 20243, Bias: 0.000000, T: 9024, Avg. loss: 0.583408\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.84, NNZs: 20243, Bias: 0.000000, T: 11280, Avg. loss: 0.569082\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.91, NNZs: 20243, Bias: 0.000000, T: 13536, Avg. loss: 0.558023\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 1/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.28658617296069355, clf__eta0=0.03398405924608927, clf__fit_intercept=False, clf__l1_ratio=0.08227014493927165, clf__learning_rate=invscaling, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.5467473202425025, clf__shuffle=True, clf__tol=0.9099604695658384, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.407 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.26, NNZs: 20285, Bias: 0.000000, T: 2256, Avg. loss: 0.697503\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.35, NNZs: 20285, Bias: 0.000000, T: 4512, Avg. loss: 0.684566\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.41, NNZs: 20285, Bias: 0.000000, T: 6768, Avg. loss: 0.676844\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.47, NNZs: 20285, Bias: 0.000000, T: 9024, Avg. loss: 0.670722\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.51, NNZs: 20285, Bias: 0.000000, T: 11280, Avg. loss: 0.665512\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.56, NNZs: 20285, Bias: 0.000000, T: 13536, Avg. loss: 0.660915\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.37, NNZs: 20285, Bias: 0.000000, T: 2256, Avg. loss: 0.665268\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.50, NNZs: 20285, Bias: 0.000000, T: 4512, Avg. loss: 0.631727\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.60, NNZs: 20285, Bias: 0.000000, T: 6768, Avg. loss: 0.614117\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.68, NNZs: 20285, Bias: 0.000000, T: 9024, Avg. loss: 0.598018\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.75, NNZs: 20285, Bias: 0.000000, T: 11280, Avg. loss: 0.583719\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.82, NNZs: 20285, Bias: 0.000000, T: 13536, Avg. loss: 0.571597\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.23, NNZs: 20285, Bias: 0.000000, T: 2256, Avg. loss: 0.703140\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.32, NNZs: 20285, Bias: 0.000000, T: 4512, Avg. loss: 0.694473\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.39, NNZs: 20285, Bias: 0.000000, T: 6768, Avg. loss: 0.689241\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.45, NNZs: 20285, Bias: 0.000000, T: 9024, Avg. loss: 0.685149\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.49, NNZs: 20285, Bias: 0.000000, T: 11280, Avg. loss: 0.681572\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.54, NNZs: 20285, Bias: 0.000000, T: 13536, Avg. loss: 0.678476\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.43, NNZs: 20285, Bias: 0.000000, T: 2256, Avg. loss: 0.652969\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.58, NNZs: 20285, Bias: 0.000000, T: 4512, Avg. loss: 0.614839\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.68, NNZs: 20285, Bias: 0.000000, T: 6768, Avg. loss: 0.596522\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.78, NNZs: 20285, Bias: 0.000000, T: 9024, Avg. loss: 0.575205\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.86, NNZs: 20285, Bias: 0.000000, T: 11280, Avg. loss: 0.563852\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.93, NNZs: 20285, Bias: 0.000000, T: 13536, Avg. loss: 0.547392\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 2/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.28658617296069355, clf__eta0=0.03398405924608927, clf__fit_intercept=False, clf__l1_ratio=0.08227014493927165, clf__learning_rate=invscaling, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.5467473202425025, clf__shuffle=True, clf__tol=0.9099604695658384, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.461 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.24, NNZs: 20900, Bias: 0.000000, T: 2256, Avg. loss: 0.698534\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.33, NNZs: 20900, Bias: 0.000000, T: 4512, Avg. loss: 0.685955\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.39, NNZs: 20900, Bias: 0.000000, T: 6768, Avg. loss: 0.678398\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.45, NNZs: 20900, Bias: 0.000000, T: 9024, Avg. loss: 0.672404\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.50, NNZs: 20900, Bias: 0.000000, T: 11280, Avg. loss: 0.667326\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.54, NNZs: 20900, Bias: 0.000000, T: 13536, Avg. loss: 0.662833\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.36, NNZs: 20900, Bias: 0.000000, T: 2256, Avg. loss: 0.673155\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.48, NNZs: 20900, Bias: 0.000000, T: 4512, Avg. loss: 0.640021\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.58, NNZs: 20900, Bias: 0.000000, T: 6768, Avg. loss: 0.618919\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.66, NNZs: 20900, Bias: 0.000000, T: 9024, Avg. loss: 0.603398\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.73, NNZs: 20900, Bias: 0.000000, T: 11280, Avg. loss: 0.590336\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.79, NNZs: 20900, Bias: 0.000000, T: 13536, Avg. loss: 0.577695\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.25, NNZs: 20900, Bias: 0.000000, T: 2256, Avg. loss: 0.703141\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.34, NNZs: 20900, Bias: 0.000000, T: 4512, Avg. loss: 0.694402\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.41, NNZs: 20900, Bias: 0.000000, T: 6768, Avg. loss: 0.689201\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.46, NNZs: 20900, Bias: 0.000000, T: 9024, Avg. loss: 0.685102\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.51, NNZs: 20900, Bias: 0.000000, T: 11280, Avg. loss: 0.681632\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.55, NNZs: 20900, Bias: 0.000000, T: 13536, Avg. loss: 0.678503\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.44, NNZs: 20900, Bias: 0.000000, T: 2256, Avg. loss: 0.639878\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.58, NNZs: 20900, Bias: 0.000000, T: 4512, Avg. loss: 0.608310\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.68, NNZs: 20900, Bias: 0.000000, T: 6768, Avg. loss: 0.588786\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.77, NNZs: 20900, Bias: 0.000000, T: 9024, Avg. loss: 0.570012\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.85, NNZs: 20900, Bias: 0.000000, T: 11280, Avg. loss: 0.558408\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.92, NNZs: 20900, Bias: 0.000000, T: 13536, Avg. loss: 0.542074\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 3/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.28658617296069355, clf__eta0=0.03398405924608927, clf__fit_intercept=False, clf__l1_ratio=0.08227014493927165, clf__learning_rate=invscaling, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.5467473202425025, clf__shuffle=True, clf__tol=0.9099604695658384, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.434 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.25, NNZs: 21038, Bias: 0.000000, T: 2256, Avg. loss: 0.697414\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.34, NNZs: 21038, Bias: 0.000000, T: 4512, Avg. loss: 0.684099\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.41, NNZs: 21038, Bias: 0.000000, T: 6768, Avg. loss: 0.676051\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.46, NNZs: 21038, Bias: 0.000000, T: 9024, Avg. loss: 0.669691\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.51, NNZs: 21038, Bias: 0.000000, T: 11280, Avg. loss: 0.664283\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.56, NNZs: 21038, Bias: 0.000000, T: 13536, Avg. loss: 0.659510\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.41, NNZs: 21038, Bias: 0.000000, T: 2256, Avg. loss: 0.679766\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.52, NNZs: 21038, Bias: 0.000000, T: 4512, Avg. loss: 0.642762\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.62, NNZs: 21038, Bias: 0.000000, T: 6768, Avg. loss: 0.625276\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.69, NNZs: 21038, Bias: 0.000000, T: 9024, Avg. loss: 0.605932\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.76, NNZs: 21038, Bias: 0.000000, T: 11280, Avg. loss: 0.591828\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.83, NNZs: 21038, Bias: 0.000000, T: 13536, Avg. loss: 0.577474\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.23, NNZs: 21038, Bias: 0.000000, T: 2256, Avg. loss: 0.702905\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.32, NNZs: 21038, Bias: 0.000000, T: 4512, Avg. loss: 0.693929\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.38, NNZs: 21038, Bias: 0.000000, T: 6768, Avg. loss: 0.688462\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.44, NNZs: 21038, Bias: 0.000000, T: 9024, Avg. loss: 0.684157\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.49, NNZs: 21038, Bias: 0.000000, T: 11280, Avg. loss: 0.680558\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.53, NNZs: 21038, Bias: 0.000000, T: 13536, Avg. loss: 0.677214\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.41, NNZs: 21038, Bias: 0.000000, T: 2256, Avg. loss: 0.655676\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.56, NNZs: 21038, Bias: 0.000000, T: 4512, Avg. loss: 0.621560\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.67, NNZs: 21038, Bias: 0.000000, T: 6768, Avg. loss: 0.597637\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.76, NNZs: 21038, Bias: 0.000000, T: 9024, Avg. loss: 0.580788\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.84, NNZs: 21038, Bias: 0.000000, T: 11280, Avg. loss: 0.563442\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.91, NNZs: 21038, Bias: 0.000000, T: 13536, Avg. loss: 0.554120\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 4/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.28658617296069355, clf__eta0=0.03398405924608927, clf__fit_intercept=False, clf__l1_ratio=0.08227014493927165, clf__learning_rate=invscaling, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.5467473202425025, clf__shuffle=True, clf__tol=0.9099604695658384, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.387 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.24, NNZs: 20988, Bias: 0.000000, T: 2256, Avg. loss: 0.697959\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.33, NNZs: 20988, Bias: 0.000000, T: 4512, Avg. loss: 0.684100\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.40, NNZs: 20988, Bias: 0.000000, T: 6768, Avg. loss: 0.675693\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.46, NNZs: 20988, Bias: 0.000000, T: 9024, Avg. loss: 0.669033\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.51, NNZs: 20988, Bias: 0.000000, T: 11280, Avg. loss: 0.663383\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.56, NNZs: 20988, Bias: 0.000000, T: 13536, Avg. loss: 0.658393\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.36, NNZs: 20988, Bias: 0.000000, T: 2256, Avg. loss: 0.667899\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.48, NNZs: 20988, Bias: 0.000000, T: 4512, Avg. loss: 0.632249\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.58, NNZs: 20988, Bias: 0.000000, T: 6768, Avg. loss: 0.609971\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.66, NNZs: 20988, Bias: 0.000000, T: 9024, Avg. loss: 0.592377\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.73, NNZs: 20988, Bias: 0.000000, T: 11280, Avg. loss: 0.578308\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.80, NNZs: 20988, Bias: 0.000000, T: 13536, Avg. loss: 0.564874\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.26, NNZs: 20988, Bias: 0.000000, T: 2256, Avg. loss: 0.701343\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.36, NNZs: 20988, Bias: 0.000000, T: 4512, Avg. loss: 0.691074\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.43, NNZs: 20988, Bias: 0.000000, T: 6768, Avg. loss: 0.685014\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.49, NNZs: 20988, Bias: 0.000000, T: 9024, Avg. loss: 0.680213\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.54, NNZs: 20988, Bias: 0.000000, T: 11280, Avg. loss: 0.676211\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.58, NNZs: 20988, Bias: 0.000000, T: 13536, Avg. loss: 0.672537\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.43, NNZs: 20988, Bias: 0.000000, T: 2256, Avg. loss: 0.680900\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.56, NNZs: 20988, Bias: 0.000000, T: 4512, Avg. loss: 0.641034\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.67, NNZs: 20988, Bias: 0.000000, T: 6768, Avg. loss: 0.624003\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.76, NNZs: 20988, Bias: 0.000000, T: 9024, Avg. loss: 0.605572\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.83, NNZs: 20988, Bias: 0.000000, T: 11280, Avg. loss: 0.590484\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.90, NNZs: 20988, Bias: 0.000000, T: 13536, Avg. loss: 0.576100\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 5/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.28658617296069355, clf__eta0=0.03398405924608927, clf__fit_intercept=False, clf__l1_ratio=0.08227014493927165, clf__learning_rate=invscaling, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.5467473202425025, clf__shuffle=True, clf__tol=0.9099604695658384, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.379 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 20.03, NNZs: 20245, Bias: 0.000000, T: 2256, Avg. loss: 0.328345\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 26.87, NNZs: 20245, Bias: 0.000000, T: 4512, Avg. loss: 0.195752\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 30.72, NNZs: 20245, Bias: 0.000000, T: 6768, Avg. loss: 0.158840\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 33.18, NNZs: 20245, Bias: 0.000000, T: 9024, Avg. loss: 0.140206\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 34.84, NNZs: 20245, Bias: 0.000000, T: 11280, Avg. loss: 0.129086\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 36.01, NNZs: 20245, Bias: 0.000000, T: 13536, Avg. loss: 0.121914\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 36.28, NNZs: 20245, Bias: 0.000000, T: 15792, Avg. loss: 0.118053\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 36.48, NNZs: 20245, Bias: 0.000000, T: 18048, Avg. loss: 0.114382\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 36.65, NNZs: 20245, Bias: 0.000000, T: 20304, Avg. loss: 0.112944\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 36.80, NNZs: 20245, Bias: 0.000000, T: 22560, Avg. loss: 0.112011\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 36.93, NNZs: 20245, Bias: 0.000000, T: 24816, Avg. loss: 0.111280\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 36.95, NNZs: 20245, Bias: 0.000000, T: 27072, Avg. loss: 0.110131\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 36.98, NNZs: 20245, Bias: 0.000000, T: 29328, Avg. loss: 0.109890\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 37.00, NNZs: 20245, Bias: 0.000000, T: 31584, Avg. loss: 0.109710\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 37.03, NNZs: 20245, Bias: 0.000000, T: 33840, Avg. loss: 0.109562\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 37.05, NNZs: 20245, Bias: 0.000000, T: 36096, Avg. loss: 0.109430\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 37.05, NNZs: 20245, Bias: 0.000000, T: 38352, Avg. loss: 0.109108\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 37.06, NNZs: 20245, Bias: 0.000000, T: 40608, Avg. loss: 0.109083\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 37.06, NNZs: 20245, Bias: 0.000000, T: 42864, Avg. loss: 0.109059\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 37.07, NNZs: 20245, Bias: 0.000000, T: 45120, Avg. loss: 0.109036\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 36.44, NNZs: 20245, Bias: 0.000000, T: 2256, Avg. loss: 0.297806\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 40.38, NNZs: 20245, Bias: 0.000000, T: 4512, Avg. loss: 0.103436\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 41.37, NNZs: 20245, Bias: 0.000000, T: 6768, Avg. loss: 0.063649\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 41.59, NNZs: 20245, Bias: 0.000000, T: 9024, Avg. loss: 0.052312\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 41.65, NNZs: 20245, Bias: 0.000000, T: 11280, Avg. loss: 0.048811\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 41.68, NNZs: 20245, Bias: 0.000000, T: 13536, Avg. loss: 0.047693\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 41.54, NNZs: 20245, Bias: 0.000000, T: 15792, Avg. loss: 0.046921\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 41.39, NNZs: 20245, Bias: 0.000000, T: 18048, Avg. loss: 0.043254\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 41.26, NNZs: 20245, Bias: 0.000000, T: 20304, Avg. loss: 0.042855\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 41.14, NNZs: 20245, Bias: 0.000000, T: 22560, Avg. loss: 0.042719\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 41.02, NNZs: 20245, Bias: 0.000000, T: 24816, Avg. loss: 0.042687\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 40.99, NNZs: 20245, Bias: 0.000000, T: 27072, Avg. loss: 0.043972\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 40.97, NNZs: 20245, Bias: 0.000000, T: 29328, Avg. loss: 0.043052\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 40.94, NNZs: 20245, Bias: 0.000000, T: 31584, Avg. loss: 0.042558\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 40.91, NNZs: 20245, Bias: 0.000000, T: 33840, Avg. loss: 0.042290\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 40.89, NNZs: 20245, Bias: 0.000000, T: 36096, Avg. loss: 0.042144\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 40.88, NNZs: 20245, Bias: 0.000000, T: 38352, Avg. loss: 0.042516\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 40.88, NNZs: 20245, Bias: 0.000000, T: 40608, Avg. loss: 0.042436\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 40.87, NNZs: 20245, Bias: 0.000000, T: 42864, Avg. loss: 0.042366\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 40.87, NNZs: 20245, Bias: 0.000000, T: 45120, Avg. loss: 0.042303\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 15.18, NNZs: 20245, Bias: 0.000000, T: 2256, Avg. loss: 0.388371\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 20.44, NNZs: 20245, Bias: 0.000000, T: 4512, Avg. loss: 0.255353\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 23.42, NNZs: 20245, Bias: 0.000000, T: 6768, Avg. loss: 0.204503\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 25.27, NNZs: 20245, Bias: 0.000000, T: 9024, Avg. loss: 0.180416\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 26.50, NNZs: 20245, Bias: 0.000000, T: 11280, Avg. loss: 0.166697\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27.34, NNZs: 20245, Bias: 0.000000, T: 13536, Avg. loss: 0.158138\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 27.42, NNZs: 20245, Bias: 0.000000, T: 15792, Avg. loss: 0.173960\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 27.52, NNZs: 20245, Bias: 0.000000, T: 18048, Avg. loss: 0.159033\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 27.63, NNZs: 20245, Bias: 0.000000, T: 20304, Avg. loss: 0.153363\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 27.73, NNZs: 20245, Bias: 0.000000, T: 22560, Avg. loss: 0.150789\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 27.83, NNZs: 20245, Bias: 0.000000, T: 24816, Avg. loss: 0.149345\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 27.84, NNZs: 20245, Bias: 0.000000, T: 27072, Avg. loss: 0.153135\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 27.86, NNZs: 20245, Bias: 0.000000, T: 29328, Avg. loss: 0.152008\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 27.87, NNZs: 20245, Bias: 0.000000, T: 31584, Avg. loss: 0.151067\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 27.89, NNZs: 20245, Bias: 0.000000, T: 33840, Avg. loss: 0.150277\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 27.90, NNZs: 20245, Bias: 0.000000, T: 36096, Avg. loss: 0.149609\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 27.91, NNZs: 20245, Bias: 0.000000, T: 38352, Avg. loss: 0.150071\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 27.91, NNZs: 20245, Bias: 0.000000, T: 40608, Avg. loss: 0.149922\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 27.91, NNZs: 20245, Bias: 0.000000, T: 42864, Avg. loss: 0.149779\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 27.92, NNZs: 20245, Bias: 0.000000, T: 45120, Avg. loss: 0.149640\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 90.45, NNZs: 20245, Bias: 0.000000, T: 2256, Avg. loss: 1.177374\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 95.31, NNZs: 20245, Bias: 0.000000, T: 4512, Avg. loss: 0.186893\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 96.67, NNZs: 20245, Bias: 0.000000, T: 6768, Avg. loss: 0.322241\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 83.62, NNZs: 20245, Bias: 0.000000, T: 9024, Avg. loss: 0.075188\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 72.66, NNZs: 20245, Bias: 0.000000, T: 11280, Avg. loss: 0.018452\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 63.47, NNZs: 20245, Bias: 0.000000, T: 13536, Avg. loss: 0.017276\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 61.82, NNZs: 20245, Bias: 0.000000, T: 15792, Avg. loss: 0.017468\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 60.24, NNZs: 20245, Bias: 0.000000, T: 18048, Avg. loss: 0.017606\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 58.71, NNZs: 20245, Bias: 0.000000, T: 20304, Avg. loss: 0.017772\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 57.25, NNZs: 20245, Bias: 0.000000, T: 22560, Avg. loss: 0.017962\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 55.85, NNZs: 20245, Bias: 0.000000, T: 24816, Avg. loss: 0.018175\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 55.57, NNZs: 20245, Bias: 0.000000, T: 27072, Avg. loss: 0.018310\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 55.30, NNZs: 20245, Bias: 0.000000, T: 29328, Avg. loss: 0.018352\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 55.03, NNZs: 20245, Bias: 0.000000, T: 31584, Avg. loss: 0.018394\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 54.77, NNZs: 20245, Bias: 0.000000, T: 33840, Avg. loss: 0.018438\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 54.50, NNZs: 20245, Bias: 0.000000, T: 36096, Avg. loss: 0.018483\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 54.45, NNZs: 20245, Bias: 0.000000, T: 38352, Avg. loss: 0.018509\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 54.40, NNZs: 20245, Bias: 0.000000, T: 40608, Avg. loss: 0.018518\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 54.34, NNZs: 20245, Bias: 0.000000, T: 42864, Avg. loss: 0.018527\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 54.29, NNZs: 20245, Bias: 0.000000, T: 45120, Avg. loss: 0.018536\n",
      "Total training time: 0.07 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.3s finished\n",
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.42493015701647596, clf__eta0=0.6773009699604285, clf__fit_intercept=False, clf__l1_ratio=0.7301998277223162, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.017782879504616322, clf__shuffle=False, clf__tol=0.19519881462597577, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.464 total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 19.84, NNZs: 20280, Bias: 0.000000, T: 2256, Avg. loss: 0.332221\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 26.67, NNZs: 20280, Bias: 0.000000, T: 4512, Avg. loss: 0.203957\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 30.59, NNZs: 20280, Bias: 0.000000, T: 6768, Avg. loss: 0.167036\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 33.12, NNZs: 20280, Bias: 0.000000, T: 9024, Avg. loss: 0.147981\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 34.85, NNZs: 20280, Bias: 0.000000, T: 11280, Avg. loss: 0.136463\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 36.06, NNZs: 20280, Bias: 0.000000, T: 13536, Avg. loss: 0.128963\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 36.34, NNZs: 20280, Bias: 0.000000, T: 15792, Avg. loss: 0.126872\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 36.57, NNZs: 20280, Bias: 0.000000, T: 18048, Avg. loss: 0.122686\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 36.76, NNZs: 20280, Bias: 0.000000, T: 20304, Avg. loss: 0.121070\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 36.92, NNZs: 20280, Bias: 0.000000, T: 22560, Avg. loss: 0.119987\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 37.07, NNZs: 20280, Bias: 0.000000, T: 24816, Avg. loss: 0.119114\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 37.10, NNZs: 20280, Bias: 0.000000, T: 27072, Avg. loss: 0.117860\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 37.13, NNZs: 20280, Bias: 0.000000, T: 29328, Avg. loss: 0.117601\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 37.16, NNZs: 20280, Bias: 0.000000, T: 31584, Avg. loss: 0.117402\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 37.19, NNZs: 20280, Bias: 0.000000, T: 33840, Avg. loss: 0.117231\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 37.21, NNZs: 20280, Bias: 0.000000, T: 36096, Avg. loss: 0.117076\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 37.22, NNZs: 20280, Bias: 0.000000, T: 38352, Avg. loss: 0.116728\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 37.22, NNZs: 20280, Bias: 0.000000, T: 40608, Avg. loss: 0.116699\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 37.23, NNZs: 20280, Bias: 0.000000, T: 42864, Avg. loss: 0.116671\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 37.23, NNZs: 20280, Bias: 0.000000, T: 45120, Avg. loss: 0.116643\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 37.84, NNZs: 20280, Bias: 0.000000, T: 2256, Avg. loss: 0.297769\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 41.15, NNZs: 20280, Bias: 0.000000, T: 4512, Avg. loss: 0.113622\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 41.67, NNZs: 20280, Bias: 0.000000, T: 6768, Avg. loss: 0.066744\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 41.58, NNZs: 20280, Bias: 0.000000, T: 9024, Avg. loss: 0.053900\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 41.55, NNZs: 20280, Bias: 0.000000, T: 11280, Avg. loss: 0.051195\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 41.54, NNZs: 20280, Bias: 0.000000, T: 13536, Avg. loss: 0.050093\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 41.42, NNZs: 20280, Bias: 0.000000, T: 15792, Avg. loss: 0.049989\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 41.31, NNZs: 20280, Bias: 0.000000, T: 18048, Avg. loss: 0.046753\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 41.21, NNZs: 20280, Bias: 0.000000, T: 20304, Avg. loss: 0.046248\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 41.11, NNZs: 20280, Bias: 0.000000, T: 22560, Avg. loss: 0.045961\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 41.02, NNZs: 20280, Bias: 0.000000, T: 24816, Avg. loss: 0.045784\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 40.99, NNZs: 20280, Bias: 0.000000, T: 27072, Avg. loss: 0.047460\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 40.97, NNZs: 20280, Bias: 0.000000, T: 29328, Avg. loss: 0.046161\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 40.94, NNZs: 20280, Bias: 0.000000, T: 31584, Avg. loss: 0.045504\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 40.92, NNZs: 20280, Bias: 0.000000, T: 33840, Avg. loss: 0.045164\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 40.90, NNZs: 20280, Bias: 0.000000, T: 36096, Avg. loss: 0.044985\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 40.90, NNZs: 20280, Bias: 0.000000, T: 38352, Avg. loss: 0.045238\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 40.89, NNZs: 20280, Bias: 0.000000, T: 40608, Avg. loss: 0.045155\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 40.89, NNZs: 20280, Bias: 0.000000, T: 42864, Avg. loss: 0.045082\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 40.88, NNZs: 20280, Bias: 0.000000, T: 45120, Avg. loss: 0.045018\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 15.23, NNZs: 20280, Bias: 0.000000, T: 2256, Avg. loss: 0.398262\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 20.37, NNZs: 20280, Bias: 0.000000, T: 4512, Avg. loss: 0.264440\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 23.36, NNZs: 20280, Bias: 0.000000, T: 6768, Avg. loss: 0.214907\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 25.26, NNZs: 20280, Bias: 0.000000, T: 9024, Avg. loss: 0.190667\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 26.52, NNZs: 20280, Bias: 0.000000, T: 11280, Avg. loss: 0.176609\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27.38, NNZs: 20280, Bias: 0.000000, T: 13536, Avg. loss: 0.167722\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 27.46, NNZs: 20280, Bias: 0.000000, T: 15792, Avg. loss: 0.186012\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 27.57, NNZs: 20280, Bias: 0.000000, T: 18048, Avg. loss: 0.169859\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 27.68, NNZs: 20280, Bias: 0.000000, T: 20304, Avg. loss: 0.163974\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 27.79, NNZs: 20280, Bias: 0.000000, T: 22560, Avg. loss: 0.161334\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 27.90, NNZs: 20280, Bias: 0.000000, T: 24816, Avg. loss: 0.159824\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 27.92, NNZs: 20280, Bias: 0.000000, T: 27072, Avg. loss: 0.163071\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 27.93, NNZs: 20280, Bias: 0.000000, T: 29328, Avg. loss: 0.161988\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 27.95, NNZs: 20280, Bias: 0.000000, T: 31584, Avg. loss: 0.161087\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 27.97, NNZs: 20280, Bias: 0.000000, T: 33840, Avg. loss: 0.160331\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 27.98, NNZs: 20280, Bias: 0.000000, T: 36096, Avg. loss: 0.159691\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 27.99, NNZs: 20280, Bias: 0.000000, T: 38352, Avg. loss: 0.160017\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 27.99, NNZs: 20280, Bias: 0.000000, T: 40608, Avg. loss: 0.159877\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 27.99, NNZs: 20280, Bias: 0.000000, T: 42864, Avg. loss: 0.159742\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 28.00, NNZs: 20280, Bias: 0.000000, T: 45120, Avg. loss: 0.159610\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 84.81, NNZs: 20280, Bias: 0.000000, T: 2256, Avg. loss: 0.897555\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 98.79, NNZs: 20280, Bias: 0.000000, T: 4512, Avg. loss: 0.642539\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 83.68, NNZs: 20280, Bias: 0.000000, T: 6768, Avg. loss: 0.223785\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 72.57, NNZs: 20280, Bias: 0.000000, T: 9024, Avg. loss: 0.025138\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 63.29, NNZs: 20280, Bias: 0.000000, T: 11280, Avg. loss: 0.018610\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 55.66, NNZs: 20280, Bias: 0.000000, T: 13536, Avg. loss: 0.018256\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 49.43, NNZs: 20280, Bias: 0.000000, T: 15792, Avg. loss: 0.019269\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 44.54, NNZs: 20280, Bias: 0.000000, T: 18048, Avg. loss: 0.020544\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 43.70, NNZs: 20280, Bias: 0.000000, T: 20304, Avg. loss: 0.022073\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 42.90, NNZs: 20280, Bias: 0.000000, T: 22560, Avg. loss: 0.022169\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 42.15, NNZs: 20280, Bias: 0.000000, T: 24816, Avg. loss: 0.022357\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 41.45, NNZs: 20280, Bias: 0.000000, T: 27072, Avg. loss: 0.022625\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 40.80, NNZs: 20280, Bias: 0.000000, T: 29328, Avg. loss: 0.022959\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 40.67, NNZs: 20280, Bias: 0.000000, T: 31584, Avg. loss: 0.023280\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 40.54, NNZs: 20280, Bias: 0.000000, T: 33840, Avg. loss: 0.023335\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 40.42, NNZs: 20280, Bias: 0.000000, T: 36096, Avg. loss: 0.023393\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 40.30, NNZs: 20280, Bias: 0.000000, T: 38352, Avg. loss: 0.023454\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 40.18, NNZs: 20280, Bias: 0.000000, T: 40608, Avg. loss: 0.023517\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 40.16, NNZs: 20280, Bias: 0.000000, T: 42864, Avg. loss: 0.023574\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 40.13, NNZs: 20280, Bias: 0.000000, T: 45120, Avg. loss: 0.023587\n",
      "Total training time: 0.07 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.3s finished\n",
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.42493015701647596, clf__eta0=0.6773009699604285, clf__fit_intercept=False, clf__l1_ratio=0.7301998277223162, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.017782879504616322, clf__shuffle=False, clf__tol=0.19519881462597577, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.564 total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 20.66, NNZs: 20905, Bias: 0.000000, T: 2256, Avg. loss: 0.339505\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 27.21, NNZs: 20905, Bias: 0.000000, T: 4512, Avg. loss: 0.204053\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 30.96, NNZs: 20905, Bias: 0.000000, T: 6768, Avg. loss: 0.167866\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 33.39, NNZs: 20905, Bias: 0.000000, T: 9024, Avg. loss: 0.149224\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 35.08, NNZs: 20905, Bias: 0.000000, T: 11280, Avg. loss: 0.137902\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 36.27, NNZs: 20905, Bias: 0.000000, T: 13536, Avg. loss: 0.130479\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 36.51, NNZs: 20905, Bias: 0.000000, T: 15792, Avg. loss: 0.127341\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 36.72, NNZs: 20905, Bias: 0.000000, T: 18048, Avg. loss: 0.124284\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 36.89, NNZs: 20905, Bias: 0.000000, T: 20304, Avg. loss: 0.122979\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 37.05, NNZs: 20905, Bias: 0.000000, T: 22560, Avg. loss: 0.122015\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 37.19, NNZs: 20905, Bias: 0.000000, T: 24816, Avg. loss: 0.121201\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 37.22, NNZs: 20905, Bias: 0.000000, T: 27072, Avg. loss: 0.119792\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 37.25, NNZs: 20905, Bias: 0.000000, T: 29328, Avg. loss: 0.119614\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 37.27, NNZs: 20905, Bias: 0.000000, T: 31584, Avg. loss: 0.119459\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 37.30, NNZs: 20905, Bias: 0.000000, T: 33840, Avg. loss: 0.119314\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 37.33, NNZs: 20905, Bias: 0.000000, T: 36096, Avg. loss: 0.119176\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 37.33, NNZs: 20905, Bias: 0.000000, T: 38352, Avg. loss: 0.118837\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 37.34, NNZs: 20905, Bias: 0.000000, T: 40608, Avg. loss: 0.118811\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 37.34, NNZs: 20905, Bias: 0.000000, T: 42864, Avg. loss: 0.118785\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 37.35, NNZs: 20905, Bias: 0.000000, T: 45120, Avg. loss: 0.118759\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 38.79, NNZs: 20905, Bias: 0.000000, T: 2256, Avg. loss: 0.305165\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 41.78, NNZs: 20905, Bias: 0.000000, T: 4512, Avg. loss: 0.106653\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 42.21, NNZs: 20905, Bias: 0.000000, T: 6768, Avg. loss: 0.062577\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 42.03, NNZs: 20905, Bias: 0.000000, T: 9024, Avg. loss: 0.049684\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 41.88, NNZs: 20905, Bias: 0.000000, T: 11280, Avg. loss: 0.047922\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 41.79, NNZs: 20905, Bias: 0.000000, T: 13536, Avg. loss: 0.047302\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 41.64, NNZs: 20905, Bias: 0.000000, T: 15792, Avg. loss: 0.045981\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 41.50, NNZs: 20905, Bias: 0.000000, T: 18048, Avg. loss: 0.044271\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 41.37, NNZs: 20905, Bias: 0.000000, T: 20304, Avg. loss: 0.043933\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 41.24, NNZs: 20905, Bias: 0.000000, T: 22560, Avg. loss: 0.043779\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 41.13, NNZs: 20905, Bias: 0.000000, T: 24816, Avg. loss: 0.043719\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 41.10, NNZs: 20905, Bias: 0.000000, T: 27072, Avg. loss: 0.044422\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 41.08, NNZs: 20905, Bias: 0.000000, T: 29328, Avg. loss: 0.043806\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 41.05, NNZs: 20905, Bias: 0.000000, T: 31584, Avg. loss: 0.043467\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 41.03, NNZs: 20905, Bias: 0.000000, T: 33840, Avg. loss: 0.043278\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 41.00, NNZs: 20905, Bias: 0.000000, T: 36096, Avg. loss: 0.043173\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 40.99, NNZs: 20905, Bias: 0.000000, T: 38352, Avg. loss: 0.043314\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 40.99, NNZs: 20905, Bias: 0.000000, T: 40608, Avg. loss: 0.043267\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 40.98, NNZs: 20905, Bias: 0.000000, T: 42864, Avg. loss: 0.043225\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 40.98, NNZs: 20905, Bias: 0.000000, T: 45120, Avg. loss: 0.043188\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 15.36, NNZs: 20905, Bias: 0.000000, T: 2256, Avg. loss: 0.416620\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 20.51, NNZs: 20905, Bias: 0.000000, T: 4512, Avg. loss: 0.267619\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 23.47, NNZs: 20905, Bias: 0.000000, T: 6768, Avg. loss: 0.217182\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 25.34, NNZs: 20905, Bias: 0.000000, T: 9024, Avg. loss: 0.192745\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 26.58, NNZs: 20905, Bias: 0.000000, T: 11280, Avg. loss: 0.178641\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27.43, NNZs: 20905, Bias: 0.000000, T: 13536, Avg. loss: 0.169754\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 27.51, NNZs: 20905, Bias: 0.000000, T: 15792, Avg. loss: 0.179347\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 27.62, NNZs: 20905, Bias: 0.000000, T: 18048, Avg. loss: 0.167300\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 27.73, NNZs: 20905, Bias: 0.000000, T: 20304, Avg. loss: 0.162783\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 27.84, NNZs: 20905, Bias: 0.000000, T: 22560, Avg. loss: 0.160672\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 27.94, NNZs: 20905, Bias: 0.000000, T: 24816, Avg. loss: 0.159406\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 27.96, NNZs: 20905, Bias: 0.000000, T: 27072, Avg. loss: 0.161429\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 27.98, NNZs: 20905, Bias: 0.000000, T: 29328, Avg. loss: 0.160592\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 27.99, NNZs: 20905, Bias: 0.000000, T: 31584, Avg. loss: 0.159892\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 28.01, NNZs: 20905, Bias: 0.000000, T: 33840, Avg. loss: 0.159300\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 28.03, NNZs: 20905, Bias: 0.000000, T: 36096, Avg. loss: 0.158796\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 28.03, NNZs: 20905, Bias: 0.000000, T: 38352, Avg. loss: 0.159005\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 28.03, NNZs: 20905, Bias: 0.000000, T: 40608, Avg. loss: 0.158894\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 28.04, NNZs: 20905, Bias: 0.000000, T: 42864, Avg. loss: 0.158787\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 28.04, NNZs: 20905, Bias: 0.000000, T: 45120, Avg. loss: 0.158682\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 91.44, NNZs: 20905, Bias: 0.000000, T: 2256, Avg. loss: 1.300352\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 86.88, NNZs: 20905, Bias: 0.000000, T: 4512, Avg. loss: 0.380232\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 90.63, NNZs: 20905, Bias: 0.000000, T: 6768, Avg. loss: 0.266018\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 77.11, NNZs: 20905, Bias: 0.000000, T: 9024, Avg. loss: 0.144638\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 67.06, NNZs: 20905, Bias: 0.000000, T: 11280, Avg. loss: 0.018203\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 58.67, NNZs: 20905, Bias: 0.000000, T: 13536, Avg. loss: 0.017360\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 57.18, NNZs: 20905, Bias: 0.000000, T: 15792, Avg. loss: 0.017581\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 55.74, NNZs: 20905, Bias: 0.000000, T: 18048, Avg. loss: 0.017809\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 54.37, NNZs: 20905, Bias: 0.000000, T: 20304, Avg. loss: 0.018058\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 53.06, NNZs: 20905, Bias: 0.000000, T: 22560, Avg. loss: 0.018331\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 51.80, NNZs: 20905, Bias: 0.000000, T: 24816, Avg. loss: 0.018630\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 51.55, NNZs: 20905, Bias: 0.000000, T: 27072, Avg. loss: 0.018779\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 51.31, NNZs: 20905, Bias: 0.000000, T: 29328, Avg. loss: 0.018845\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 51.07, NNZs: 20905, Bias: 0.000000, T: 31584, Avg. loss: 0.018912\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 50.84, NNZs: 20905, Bias: 0.000000, T: 33840, Avg. loss: 0.018981\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 50.60, NNZs: 20905, Bias: 0.000000, T: 36096, Avg. loss: 0.019050\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 50.55, NNZs: 20905, Bias: 0.000000, T: 38352, Avg. loss: 0.019084\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 50.51, NNZs: 20905, Bias: 0.000000, T: 40608, Avg. loss: 0.019098\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 50.46, NNZs: 20905, Bias: 0.000000, T: 42864, Avg. loss: 0.019112\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 50.41, NNZs: 20905, Bias: 0.000000, T: 45120, Avg. loss: 0.019127\n",
      "Total training time: 0.07 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.3s finished\n",
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.42493015701647596, clf__eta0=0.6773009699604285, clf__fit_intercept=False, clf__l1_ratio=0.7301998277223162, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.017782879504616322, clf__shuffle=False, clf__tol=0.19519881462597577, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.485 total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 20.52, NNZs: 21039, Bias: 0.000000, T: 2256, Avg. loss: 0.333753\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 26.94, NNZs: 21039, Bias: 0.000000, T: 4512, Avg. loss: 0.196047\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 30.62, NNZs: 21039, Bias: 0.000000, T: 6768, Avg. loss: 0.159833\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 33.00, NNZs: 21039, Bias: 0.000000, T: 9024, Avg. loss: 0.141421\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 34.62, NNZs: 21039, Bias: 0.000000, T: 11280, Avg. loss: 0.130387\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 35.77, NNZs: 21039, Bias: 0.000000, T: 13536, Avg. loss: 0.123248\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 36.00, NNZs: 21039, Bias: 0.000000, T: 15792, Avg. loss: 0.116915\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 36.18, NNZs: 21039, Bias: 0.000000, T: 18048, Avg. loss: 0.114930\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 36.34, NNZs: 21039, Bias: 0.000000, T: 20304, Avg. loss: 0.113883\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 36.48, NNZs: 21039, Bias: 0.000000, T: 22560, Avg. loss: 0.113092\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 36.61, NNZs: 21039, Bias: 0.000000, T: 24816, Avg. loss: 0.112427\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 36.64, NNZs: 21039, Bias: 0.000000, T: 27072, Avg. loss: 0.111114\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 36.66, NNZs: 21039, Bias: 0.000000, T: 29328, Avg. loss: 0.110977\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 36.69, NNZs: 21039, Bias: 0.000000, T: 31584, Avg. loss: 0.110848\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 36.72, NNZs: 21039, Bias: 0.000000, T: 33840, Avg. loss: 0.110726\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 36.74, NNZs: 21039, Bias: 0.000000, T: 36096, Avg. loss: 0.110607\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 36.74, NNZs: 21039, Bias: 0.000000, T: 38352, Avg. loss: 0.110317\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 36.75, NNZs: 21039, Bias: 0.000000, T: 40608, Avg. loss: 0.110294\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 36.75, NNZs: 21039, Bias: 0.000000, T: 42864, Avg. loss: 0.110272\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 36.76, NNZs: 21039, Bias: 0.000000, T: 45120, Avg. loss: 0.110249\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 36.99, NNZs: 21039, Bias: 0.000000, T: 2256, Avg. loss: 0.285665\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 41.19, NNZs: 21039, Bias: 0.000000, T: 4512, Avg. loss: 0.105319\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 41.73, NNZs: 21039, Bias: 0.000000, T: 6768, Avg. loss: 0.061631\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 41.58, NNZs: 21039, Bias: 0.000000, T: 9024, Avg. loss: 0.050151\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 41.45, NNZs: 21039, Bias: 0.000000, T: 11280, Avg. loss: 0.047620\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 41.38, NNZs: 21039, Bias: 0.000000, T: 13536, Avg. loss: 0.046749\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 41.24, NNZs: 21039, Bias: 0.000000, T: 15792, Avg. loss: 0.047967\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 41.11, NNZs: 21039, Bias: 0.000000, T: 18048, Avg. loss: 0.043602\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 40.99, NNZs: 21039, Bias: 0.000000, T: 20304, Avg. loss: 0.043145\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 40.87, NNZs: 21039, Bias: 0.000000, T: 22560, Avg. loss: 0.042960\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 40.77, NNZs: 21039, Bias: 0.000000, T: 24816, Avg. loss: 0.042867\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 40.74, NNZs: 21039, Bias: 0.000000, T: 27072, Avg. loss: 0.044892\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 40.72, NNZs: 21039, Bias: 0.000000, T: 29328, Avg. loss: 0.043616\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 40.69, NNZs: 21039, Bias: 0.000000, T: 31584, Avg. loss: 0.042913\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 40.67, NNZs: 21039, Bias: 0.000000, T: 33840, Avg. loss: 0.042519\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 40.64, NNZs: 21039, Bias: 0.000000, T: 36096, Avg. loss: 0.042297\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 40.64, NNZs: 21039, Bias: 0.000000, T: 38352, Avg. loss: 0.042627\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 40.63, NNZs: 21039, Bias: 0.000000, T: 40608, Avg. loss: 0.042540\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 40.63, NNZs: 21039, Bias: 0.000000, T: 42864, Avg. loss: 0.042463\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 40.62, NNZs: 21039, Bias: 0.000000, T: 45120, Avg. loss: 0.042394\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 15.39, NNZs: 21039, Bias: 0.000000, T: 2256, Avg. loss: 0.407237\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 20.48, NNZs: 21039, Bias: 0.000000, T: 4512, Avg. loss: 0.253317\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 23.37, NNZs: 21039, Bias: 0.000000, T: 6768, Avg. loss: 0.204189\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 25.18, NNZs: 21039, Bias: 0.000000, T: 9024, Avg. loss: 0.180629\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 26.38, NNZs: 21039, Bias: 0.000000, T: 11280, Avg. loss: 0.167139\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27.20, NNZs: 21039, Bias: 0.000000, T: 13536, Avg. loss: 0.158699\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 27.29, NNZs: 21039, Bias: 0.000000, T: 15792, Avg. loss: 0.164648\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 27.40, NNZs: 21039, Bias: 0.000000, T: 18048, Avg. loss: 0.155079\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 27.51, NNZs: 21039, Bias: 0.000000, T: 20304, Avg. loss: 0.151239\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 27.62, NNZs: 21039, Bias: 0.000000, T: 22560, Avg. loss: 0.149348\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 27.71, NNZs: 21039, Bias: 0.000000, T: 24816, Avg. loss: 0.148183\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 27.73, NNZs: 21039, Bias: 0.000000, T: 27072, Avg. loss: 0.150045\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 27.75, NNZs: 21039, Bias: 0.000000, T: 29328, Avg. loss: 0.149291\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 27.76, NNZs: 21039, Bias: 0.000000, T: 31584, Avg. loss: 0.148655\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 27.78, NNZs: 21039, Bias: 0.000000, T: 33840, Avg. loss: 0.148113\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 27.80, NNZs: 21039, Bias: 0.000000, T: 36096, Avg. loss: 0.147647\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 27.80, NNZs: 21039, Bias: 0.000000, T: 38352, Avg. loss: 0.147864\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 27.80, NNZs: 21039, Bias: 0.000000, T: 40608, Avg. loss: 0.147761\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 27.81, NNZs: 21039, Bias: 0.000000, T: 42864, Avg. loss: 0.147661\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 27.81, NNZs: 21039, Bias: 0.000000, T: 45120, Avg. loss: 0.147564\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 99.44, NNZs: 21039, Bias: 0.000000, T: 2256, Avg. loss: 1.389675\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 96.03, NNZs: 21039, Bias: 0.000000, T: 4512, Avg. loss: 0.361562\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 82.53, NNZs: 21039, Bias: 0.000000, T: 6768, Avg. loss: 0.081076\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 71.63, NNZs: 21039, Bias: 0.000000, T: 9024, Avg. loss: 0.019179\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 62.54, NNZs: 21039, Bias: 0.000000, T: 11280, Avg. loss: 0.016919\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 55.08, NNZs: 21039, Bias: 0.000000, T: 13536, Avg. loss: 0.017706\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 53.74, NNZs: 21039, Bias: 0.000000, T: 15792, Avg. loss: 0.018660\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 52.46, NNZs: 21039, Bias: 0.000000, T: 18048, Avg. loss: 0.018719\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 51.24, NNZs: 21039, Bias: 0.000000, T: 20304, Avg. loss: 0.018828\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 50.07, NNZs: 21039, Bias: 0.000000, T: 22560, Avg. loss: 0.018981\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 48.95, NNZs: 21039, Bias: 0.000000, T: 24816, Avg. loss: 0.019174\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 48.74, NNZs: 21039, Bias: 0.000000, T: 27072, Avg. loss: 0.019316\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 48.52, NNZs: 21039, Bias: 0.000000, T: 29328, Avg. loss: 0.019357\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 48.31, NNZs: 21039, Bias: 0.000000, T: 31584, Avg. loss: 0.019399\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 48.10, NNZs: 21039, Bias: 0.000000, T: 33840, Avg. loss: 0.019443\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 47.89, NNZs: 21039, Bias: 0.000000, T: 36096, Avg. loss: 0.019488\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 47.84, NNZs: 21039, Bias: 0.000000, T: 38352, Avg. loss: 0.019517\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 47.80, NNZs: 21039, Bias: 0.000000, T: 40608, Avg. loss: 0.019526\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 47.76, NNZs: 21039, Bias: 0.000000, T: 42864, Avg. loss: 0.019535\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 47.72, NNZs: 21039, Bias: 0.000000, T: 45120, Avg. loss: 0.019544\n",
      "Total training time: 0.07 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.3s finished\n",
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.42493015701647596, clf__eta0=0.6773009699604285, clf__fit_intercept=False, clf__l1_ratio=0.7301998277223162, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.017782879504616322, clf__shuffle=False, clf__tol=0.19519881462597577, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.468 total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 20.46, NNZs: 20996, Bias: 0.000000, T: 2256, Avg. loss: 0.329812\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 26.91, NNZs: 20996, Bias: 0.000000, T: 4512, Avg. loss: 0.196633\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 30.59, NNZs: 20996, Bias: 0.000000, T: 6768, Avg. loss: 0.160794\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 32.98, NNZs: 20996, Bias: 0.000000, T: 9024, Avg. loss: 0.142335\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 34.62, NNZs: 20996, Bias: 0.000000, T: 11280, Avg. loss: 0.131207\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 35.78, NNZs: 20996, Bias: 0.000000, T: 13536, Avg. loss: 0.123983\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 36.03, NNZs: 20996, Bias: 0.000000, T: 15792, Avg. loss: 0.120410\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 36.24, NNZs: 20996, Bias: 0.000000, T: 18048, Avg. loss: 0.116650\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 36.41, NNZs: 20996, Bias: 0.000000, T: 20304, Avg. loss: 0.115184\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 36.56, NNZs: 20996, Bias: 0.000000, T: 22560, Avg. loss: 0.114232\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 36.70, NNZs: 20996, Bias: 0.000000, T: 24816, Avg. loss: 0.113482\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 36.72, NNZs: 20996, Bias: 0.000000, T: 27072, Avg. loss: 0.112204\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 36.75, NNZs: 20996, Bias: 0.000000, T: 29328, Avg. loss: 0.112004\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 36.78, NNZs: 20996, Bias: 0.000000, T: 31584, Avg. loss: 0.111845\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 36.80, NNZs: 20996, Bias: 0.000000, T: 33840, Avg. loss: 0.111706\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 36.83, NNZs: 20996, Bias: 0.000000, T: 36096, Avg. loss: 0.111579\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 36.83, NNZs: 20996, Bias: 0.000000, T: 38352, Avg. loss: 0.111266\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 36.83, NNZs: 20996, Bias: 0.000000, T: 40608, Avg. loss: 0.111242\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 36.84, NNZs: 20996, Bias: 0.000000, T: 42864, Avg. loss: 0.111219\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 36.84, NNZs: 20996, Bias: 0.000000, T: 45120, Avg. loss: 0.111196\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 36.70, NNZs: 20996, Bias: 0.000000, T: 2256, Avg. loss: 0.262538\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 41.08, NNZs: 20996, Bias: 0.000000, T: 4512, Avg. loss: 0.117637\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 41.58, NNZs: 20996, Bias: 0.000000, T: 6768, Avg. loss: 0.058888\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 41.46, NNZs: 20996, Bias: 0.000000, T: 9024, Avg. loss: 0.048021\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 41.34, NNZs: 20996, Bias: 0.000000, T: 11280, Avg. loss: 0.046108\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 41.27, NNZs: 20996, Bias: 0.000000, T: 13536, Avg. loss: 0.045363\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 41.15, NNZs: 20996, Bias: 0.000000, T: 15792, Avg. loss: 0.049815\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 41.03, NNZs: 20996, Bias: 0.000000, T: 18048, Avg. loss: 0.044141\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 40.91, NNZs: 20996, Bias: 0.000000, T: 20304, Avg. loss: 0.043165\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 40.80, NNZs: 20996, Bias: 0.000000, T: 22560, Avg. loss: 0.042671\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 40.70, NNZs: 20996, Bias: 0.000000, T: 24816, Avg. loss: 0.042383\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 40.68, NNZs: 20996, Bias: 0.000000, T: 27072, Avg. loss: 0.043668\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 40.65, NNZs: 20996, Bias: 0.000000, T: 29328, Avg. loss: 0.042831\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 40.62, NNZs: 20996, Bias: 0.000000, T: 31584, Avg. loss: 0.042337\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 40.60, NNZs: 20996, Bias: 0.000000, T: 33840, Avg. loss: 0.042039\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 40.58, NNZs: 20996, Bias: 0.000000, T: 36096, Avg. loss: 0.041853\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 40.57, NNZs: 20996, Bias: 0.000000, T: 38352, Avg. loss: 0.041948\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 40.57, NNZs: 20996, Bias: 0.000000, T: 40608, Avg. loss: 0.041895\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 40.56, NNZs: 20996, Bias: 0.000000, T: 42864, Avg. loss: 0.041847\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 40.56, NNZs: 20996, Bias: 0.000000, T: 45120, Avg. loss: 0.041803\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 15.57, NNZs: 20996, Bias: 0.000000, T: 2256, Avg. loss: 0.398564\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 20.56, NNZs: 20996, Bias: 0.000000, T: 4512, Avg. loss: 0.255096\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 23.42, NNZs: 20996, Bias: 0.000000, T: 6768, Avg. loss: 0.205146\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 25.22, NNZs: 20996, Bias: 0.000000, T: 9024, Avg. loss: 0.181301\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 26.41, NNZs: 20996, Bias: 0.000000, T: 11280, Avg. loss: 0.167662\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27.22, NNZs: 20996, Bias: 0.000000, T: 13536, Avg. loss: 0.159133\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 27.28, NNZs: 20996, Bias: 0.000000, T: 15792, Avg. loss: 0.175812\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 27.38, NNZs: 20996, Bias: 0.000000, T: 18048, Avg. loss: 0.159610\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 27.48, NNZs: 20996, Bias: 0.000000, T: 20304, Avg. loss: 0.153665\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 27.58, NNZs: 20996, Bias: 0.000000, T: 22560, Avg. loss: 0.151054\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 27.68, NNZs: 20996, Bias: 0.000000, T: 24816, Avg. loss: 0.149624\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 27.70, NNZs: 20996, Bias: 0.000000, T: 27072, Avg. loss: 0.152412\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 27.71, NNZs: 20996, Bias: 0.000000, T: 29328, Avg. loss: 0.151465\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 27.73, NNZs: 20996, Bias: 0.000000, T: 31584, Avg. loss: 0.150672\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 27.74, NNZs: 20996, Bias: 0.000000, T: 33840, Avg. loss: 0.150005\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 27.76, NNZs: 20996, Bias: 0.000000, T: 36096, Avg. loss: 0.149439\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 27.76, NNZs: 20996, Bias: 0.000000, T: 38352, Avg. loss: 0.149734\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 27.77, NNZs: 20996, Bias: 0.000000, T: 40608, Avg. loss: 0.149610\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 27.77, NNZs: 20996, Bias: 0.000000, T: 42864, Avg. loss: 0.149490\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 27.77, NNZs: 20996, Bias: 0.000000, T: 45120, Avg. loss: 0.149374\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 92.74, NNZs: 20996, Bias: 0.000000, T: 2256, Avg. loss: 0.878125\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 105.99, NNZs: 20996, Bias: 0.000000, T: 4512, Avg. loss: 0.798832\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 87.96, NNZs: 20996, Bias: 0.000000, T: 6768, Avg. loss: 0.331102\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 75.88, NNZs: 20996, Bias: 0.000000, T: 9024, Avg. loss: 0.051778\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 65.92, NNZs: 20996, Bias: 0.000000, T: 11280, Avg. loss: 0.021615\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 57.75, NNZs: 20996, Bias: 0.000000, T: 13536, Avg. loss: 0.017457\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 56.29, NNZs: 20996, Bias: 0.000000, T: 15792, Avg. loss: 0.017986\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 54.89, NNZs: 20996, Bias: 0.000000, T: 18048, Avg. loss: 0.017840\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 53.55, NNZs: 20996, Bias: 0.000000, T: 20304, Avg. loss: 0.017838\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 52.26, NNZs: 20996, Bias: 0.000000, T: 22560, Avg. loss: 0.017946\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 51.04, NNZs: 20996, Bias: 0.000000, T: 24816, Avg. loss: 0.018137\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 50.80, NNZs: 20996, Bias: 0.000000, T: 27072, Avg. loss: 0.018369\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 50.56, NNZs: 20996, Bias: 0.000000, T: 29328, Avg. loss: 0.018408\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 50.33, NNZs: 20996, Bias: 0.000000, T: 31584, Avg. loss: 0.018450\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 50.10, NNZs: 20996, Bias: 0.000000, T: 33840, Avg. loss: 0.018494\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 49.87, NNZs: 20996, Bias: 0.000000, T: 36096, Avg. loss: 0.018541\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 49.82, NNZs: 20996, Bias: 0.000000, T: 38352, Avg. loss: 0.018586\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 49.77, NNZs: 20996, Bias: 0.000000, T: 40608, Avg. loss: 0.018595\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 49.73, NNZs: 20996, Bias: 0.000000, T: 42864, Avg. loss: 0.018605\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 49.68, NNZs: 20996, Bias: 0.000000, T: 45120, Avg. loss: 0.018614\n",
      "Total training time: 0.07 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.3s finished\n",
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.42493015701647596, clf__eta0=0.6773009699604285, clf__fit_intercept=False, clf__l1_ratio=0.7301998277223162, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.017782879504616322, clf__shuffle=False, clf__tol=0.19519881462597577, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.460 total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 31.65, NNZs: 11746, Bias: -0.907718, T: 2256, Avg. loss: 0.035831\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 22.46, NNZs: 13771, Bias: -0.899890, T: 4512, Avg. loss: 0.006988\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 16.61, NNZs: 13980, Bias: -0.864159, T: 6768, Avg. loss: 0.000748\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 13.25, NNZs: 14114, Bias: -0.848974, T: 9024, Avg. loss: 0.000631\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 11.13, NNZs: 14248, Bias: -0.824243, T: 11280, Avg. loss: 0.000224\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 9.87, NNZs: 14415, Bias: -0.799354, T: 13536, Avg. loss: 0.000280\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 155.70, NNZs: 11550, Bias: -1.857560, T: 2256, Avg. loss: 0.711657\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 110.21, NNZs: 12566, Bias: -2.122127, T: 4512, Avg. loss: 0.181174\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 85.93, NNZs: 13031, Bias: -2.268135, T: 6768, Avg. loss: 0.061977\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 72.44, NNZs: 13323, Bias: -2.250780, T: 9024, Avg. loss: 0.049106\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 60.61, NNZs: 13360, Bias: -2.260383, T: 11280, Avg. loss: 0.011357\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 51.15, NNZs: 13362, Bias: -2.276048, T: 13536, Avg. loss: 0.000379\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 18.37, NNZs: 9889, Bias: 0.497664, T: 2256, Avg. loss: 0.016883\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 12.82, NNZs: 11900, Bias: 0.513464, T: 4512, Avg. loss: 0.002781\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 9.67, NNZs: 12120, Bias: 0.487876, T: 6768, Avg. loss: 0.000558\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 7.73, NNZs: 12152, Bias: 0.471565, T: 9024, Avg. loss: 0.000088\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 6.41, NNZs: 12169, Bias: 0.466505, T: 11280, Avg. loss: 0.000025\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 5.65, NNZs: 12334, Bias: 0.452177, T: 13536, Avg. loss: 0.000046\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 397.50, NNZs: 13983, Bias: -5.357616, T: 2256, Avg. loss: 7.188578\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 303.99, NNZs: 14482, Bias: -5.851719, T: 4512, Avg. loss: 1.959108\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 241.40, NNZs: 14723, Bias: -6.107026, T: 6768, Avg. loss: 0.561361\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 183.27, NNZs: 14762, Bias: -6.973082, T: 9024, Avg. loss: 0.163718\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 149.40, NNZs: 14762, Bias: -7.015435, T: 11280, Avg. loss: 0.002428\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 126.21, NNZs: 14762, Bias: -7.015435, T: 13536, Avg. loss: 0.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "[CV 1/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.21123614325601048, clf__eta0=0.32979731781585486, clf__fit_intercept=True, clf__l1_ratio=0.4775095579144826, clf__learning_rate=optimal, clf__loss=perceptron, clf__max_iter=30, clf__penalty=l2, clf__power_t=0.6427671735097384, clf__shuffle=False, clf__tol=0.2651165400908262, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.584 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 32.09, NNZs: 12446, Bias: -0.953273, T: 2256, Avg. loss: 0.048808\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 22.47, NNZs: 13795, Bias: -0.926439, T: 4512, Avg. loss: 0.004817\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 17.28, NNZs: 14426, Bias: -0.922077, T: 6768, Avg. loss: 0.001309\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 13.87, NNZs: 14548, Bias: -0.907301, T: 9024, Avg. loss: 0.000356\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 11.78, NNZs: 14716, Bias: -0.887206, T: 11280, Avg. loss: 0.000391\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 10.41, NNZs: 14798, Bias: -0.856095, T: 13536, Avg. loss: 0.000309\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 193.24, NNZs: 14426, Bias: -3.269940, T: 2256, Avg. loss: 1.249629\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 127.96, NNZs: 15298, Bias: -3.932056, T: 4512, Avg. loss: 0.169346\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 97.32, NNZs: 15533, Bias: -3.974822, T: 6768, Avg. loss: 0.081755\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 76.97, NNZs: 15557, Bias: -3.981249, T: 9024, Avg. loss: 0.014262\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 64.44, NNZs: 15557, Bias: -3.967621, T: 11280, Avg. loss: 0.013710\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 55.61, NNZs: 15563, Bias: -3.957225, T: 13536, Avg. loss: 0.012705\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 50.53, NNZs: 15610, Bias: -3.890882, T: 15792, Avg. loss: 0.018686\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 7 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 19.79, NNZs: 10843, Bias: 0.580187, T: 2256, Avg. loss: 0.023117\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 13.25, NNZs: 11739, Bias: 0.609089, T: 4512, Avg. loss: 0.002567\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 10.14, NNZs: 12369, Bias: 0.596725, T: 6768, Avg. loss: 0.001066\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 8.11, NNZs: 12694, Bias: 0.583095, T: 9024, Avg. loss: 0.000357\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 6.90, NNZs: 12840, Bias: 0.566310, T: 11280, Avg. loss: 0.000082\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 6.08, NNZs: 13029, Bias: 0.557986, T: 13536, Avg. loss: 0.000248\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 408.71, NNZs: 16242, Bias: -6.161259, T: 2256, Avg. loss: 5.941156\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 312.87, NNZs: 16890, Bias: -7.110850, T: 4512, Avg. loss: 2.417685\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 236.76, NNZs: 17098, Bias: -7.643128, T: 6768, Avg. loss: 0.865115\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 180.02, NNZs: 17196, Bias: -8.190073, T: 9024, Avg. loss: 0.165437\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 146.63, NNZs: 17196, Bias: -8.227122, T: 11280, Avg. loss: 0.015869\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 123.68, NNZs: 17196, Bias: -8.250517, T: 13536, Avg. loss: 0.006960\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 2/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.21123614325601048, clf__eta0=0.32979731781585486, clf__fit_intercept=True, clf__l1_ratio=0.4775095579144826, clf__learning_rate=optimal, clf__loss=perceptron, clf__max_iter=30, clf__penalty=l2, clf__power_t=0.6427671735097384, clf__shuffle=False, clf__tol=0.2651165400908262, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.495 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 32.83, NNZs: 13034, Bias: -1.046340, T: 2256, Avg. loss: 0.053097\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 22.80, NNZs: 14293, Bias: -1.096419, T: 4512, Avg. loss: 0.005796\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 17.14, NNZs: 14657, Bias: -1.050610, T: 6768, Avg. loss: 0.001076\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 13.81, NNZs: 14849, Bias: -1.025520, T: 9024, Avg. loss: 0.000785\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 11.75, NNZs: 14968, Bias: -1.003698, T: 11280, Avg. loss: 0.000324\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 10.41, NNZs: 15150, Bias: -0.979134, T: 13536, Avg. loss: 0.000364\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 176.80, NNZs: 13747, Bias: -2.643294, T: 2256, Avg. loss: 1.230971\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 126.71, NNZs: 15737, Bias: -3.091533, T: 4512, Avg. loss: 0.172820\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 97.28, NNZs: 16061, Bias: -3.102442, T: 6768, Avg. loss: 0.058694\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 76.92, NNZs: 16092, Bias: -3.132698, T: 9024, Avg. loss: 0.013271\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 64.61, NNZs: 16108, Bias: -3.084787, T: 11280, Avg. loss: 0.007469\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 55.65, NNZs: 16116, Bias: -3.075195, T: 13536, Avg. loss: 0.010222\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 19.45, NNZs: 11045, Bias: 0.622761, T: 2256, Avg. loss: 0.028022\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 13.11, NNZs: 12443, Bias: 0.632476, T: 4512, Avg. loss: 0.003173\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 10.01, NNZs: 12793, Bias: 0.608123, T: 6768, Avg. loss: 0.000776\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 8.26, NNZs: 13177, Bias: 0.592469, T: 9024, Avg. loss: 0.000704\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 7.09, NNZs: 13328, Bias: 0.577243, T: 11280, Avg. loss: 0.000175\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 6.29, NNZs: 13417, Bias: 0.561515, T: 13536, Avg. loss: 0.000103\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 413.17, NNZs: 15530, Bias: -6.662912, T: 2256, Avg. loss: 8.905369\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 311.39, NNZs: 16036, Bias: -6.924884, T: 4512, Avg. loss: 2.182681\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 243.97, NNZs: 16310, Bias: -7.089520, T: 6768, Avg. loss: 0.588321\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 183.92, NNZs: 16379, Bias: -7.962471, T: 9024, Avg. loss: 0.290456\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 149.89, NNZs: 16379, Bias: -8.006034, T: 11280, Avg. loss: 0.004058\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 126.62, NNZs: 16379, Bias: -8.006034, T: 13536, Avg. loss: 0.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "[CV 3/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.21123614325601048, clf__eta0=0.32979731781585486, clf__fit_intercept=True, clf__l1_ratio=0.4775095579144826, clf__learning_rate=optimal, clf__loss=perceptron, clf__max_iter=30, clf__penalty=l2, clf__power_t=0.6427671735097384, clf__shuffle=False, clf__tol=0.2651165400908262, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.624 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 31.84, NNZs: 12120, Bias: -0.983189, T: 2256, Avg. loss: 0.042207\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 22.13, NNZs: 13684, Bias: -1.062159, T: 4512, Avg. loss: 0.005713\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 16.97, NNZs: 14370, Bias: -1.034520, T: 6768, Avg. loss: 0.002033\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 13.55, NNZs: 14635, Bias: -1.016019, T: 9024, Avg. loss: 0.000435\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 11.63, NNZs: 14832, Bias: -0.977503, T: 11280, Avg. loss: 0.000585\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 10.18, NNZs: 14984, Bias: -0.959852, T: 13536, Avg. loss: 0.000156\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 166.72, NNZs: 13927, Bias: -3.242408, T: 2256, Avg. loss: 1.108388\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 117.75, NNZs: 14557, Bias: -3.423149, T: 4512, Avg. loss: 0.181012\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 87.92, NNZs: 14663, Bias: -3.467769, T: 6768, Avg. loss: 0.046514\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 73.57, NNZs: 14789, Bias: -3.309267, T: 9024, Avg. loss: 0.012450\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 61.32, NNZs: 15050, Bias: -3.353526, T: 11280, Avg. loss: 0.011961\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 53.31, NNZs: 15139, Bias: -3.336316, T: 13536, Avg. loss: 0.006191\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 19.59, NNZs: 10492, Bias: 0.547303, T: 2256, Avg. loss: 0.024191\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 13.20, NNZs: 11985, Bias: 0.626437, T: 4512, Avg. loss: 0.003766\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 9.88, NNZs: 12585, Bias: 0.602670, T: 6768, Avg. loss: 0.001051\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 7.97, NNZs: 12855, Bias: 0.597560, T: 9024, Avg. loss: 0.000503\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 6.86, NNZs: 13077, Bias: 0.577588, T: 11280, Avg. loss: 0.000237\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 6.02, NNZs: 13366, Bias: 0.566103, T: 13536, Avg. loss: 0.000085\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 484.48, NNZs: 16403, Bias: -6.252301, T: 2256, Avg. loss: 9.591355\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 344.05, NNZs: 17562, Bias: -7.027907, T: 4512, Avg. loss: 1.892126\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 235.68, NNZs: 17912, Bias: -8.620392, T: 6768, Avg. loss: 0.588933\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 182.22, NNZs: 17912, Bias: -8.693544, T: 9024, Avg. loss: 0.020143\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 148.55, NNZs: 17912, Bias: -8.722458, T: 11280, Avg. loss: 0.007367\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 125.43, NNZs: 17912, Bias: -8.730518, T: 13536, Avg. loss: 0.002576\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 4/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.21123614325601048, clf__eta0=0.32979731781585486, clf__fit_intercept=True, clf__l1_ratio=0.4775095579144826, clf__learning_rate=optimal, clf__loss=perceptron, clf__max_iter=30, clf__penalty=l2, clf__power_t=0.6427671735097384, clf__shuffle=False, clf__tol=0.2651165400908262, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.596 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 30.61, NNZs: 12093, Bias: -0.997121, T: 2256, Avg. loss: 0.046681\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 21.05, NNZs: 13490, Bias: -1.017995, T: 4512, Avg. loss: 0.005288\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 16.36, NNZs: 13984, Bias: -0.964272, T: 6768, Avg. loss: 0.001016\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 13.38, NNZs: 14419, Bias: -0.952669, T: 9024, Avg. loss: 0.000895\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 11.23, NNZs: 14529, Bias: -0.930285, T: 11280, Avg. loss: 0.000178\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 9.91, NNZs: 14760, Bias: -0.912427, T: 13536, Avg. loss: 0.000262\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 166.69, NNZs: 12578, Bias: -2.567970, T: 2256, Avg. loss: 0.842213\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 117.87, NNZs: 14111, Bias: -3.277933, T: 4512, Avg. loss: 0.243189\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 88.45, NNZs: 14403, Bias: -3.541264, T: 6768, Avg. loss: 0.071830\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 72.91, NNZs: 14566, Bias: -3.494096, T: 9024, Avg. loss: 0.037904\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 62.78, NNZs: 14762, Bias: -3.448491, T: 11280, Avg. loss: 0.022441\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 52.86, NNZs: 14762, Bias: -3.479346, T: 13536, Avg. loss: 0.001117\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 18.52, NNZs: 10627, Bias: 0.611923, T: 2256, Avg. loss: 0.024569\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 12.00, NNZs: 11413, Bias: 0.604729, T: 4512, Avg. loss: 0.001387\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 9.28, NNZs: 12153, Bias: 0.585166, T: 6768, Avg. loss: 0.000560\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 7.49, NNZs: 12367, Bias: 0.576631, T: 9024, Avg. loss: 0.000288\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 6.59, NNZs: 12569, Bias: 0.552869, T: 11280, Avg. loss: 0.000222\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 5.77, NNZs: 12736, Bias: 0.547257, T: 13536, Avg. loss: 0.000218\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 535.82, NNZs: 18319, Bias: -6.148311, T: 2256, Avg. loss: 10.411628\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 326.67, NNZs: 18708, Bias: -8.412833, T: 4512, Avg. loss: 1.524666\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 228.66, NNZs: 18711, Bias: -9.135146, T: 6768, Avg. loss: 0.146535\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 176.79, NNZs: 18711, Bias: -9.213762, T: 9024, Avg. loss: 0.008338\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 144.26, NNZs: 18711, Bias: -9.221960, T: 11280, Avg. loss: 0.000362\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 121.87, NNZs: 18711, Bias: -9.221960, T: 13536, Avg. loss: 0.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "[CV 5/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.21123614325601048, clf__eta0=0.32979731781585486, clf__fit_intercept=True, clf__l1_ratio=0.4775095579144826, clf__learning_rate=optimal, clf__loss=perceptron, clf__max_iter=30, clf__penalty=l2, clf__power_t=0.6427671735097384, clf__shuffle=False, clf__tol=0.2651165400908262, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.551 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 40.59, NNZs: 9936, Bias: 0.000000, T: 2820, Avg. loss: 0.221910\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 48.99, NNZs: 3769, Bias: 0.000000, T: 5640, Avg. loss: 0.061477\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 55.91, NNZs: 2609, Bias: 0.000000, T: 8460, Avg. loss: 0.051451\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 61.51, NNZs: 2017, Bias: 0.000000, T: 11280, Avg. loss: 0.042721\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 66.40, NNZs: 1678, Bias: 0.000000, T: 14100, Avg. loss: 0.040107\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 70.77, NNZs: 1462, Bias: 0.000000, T: 16920, Avg. loss: 0.037562\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 6 epochs took 0.05 seconds\n",
      "-- Epoch 1\n",
      "Norm: 25.93, NNZs: 4116, Bias: 0.000000, T: 2820, Avg. loss: 0.089652\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 31.64, NNZs: 1853, Bias: 0.000000, T: 5640, Avg. loss: 0.026766\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 36.61, NNZs: 1311, Bias: 0.000000, T: 8460, Avg. loss: 0.024746\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 40.37, NNZs: 1067, Bias: 0.000000, T: 11280, Avg. loss: 0.020127\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 43.80, NNZs: 898, Bias: 0.000000, T: 14100, Avg. loss: 0.017994\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 46.75, NNZs: 756, Bias: 0.000000, T: 16920, Avg. loss: 0.014832\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 37.63, NNZs: 8519, Bias: 0.000000, T: 2820, Avg. loss: 0.165162\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 44.96, NNZs: 3334, Bias: 0.000000, T: 5640, Avg. loss: 0.040394\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 50.87, NNZs: 2289, Bias: 0.000000, T: 8460, Avg. loss: 0.034387\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 55.93, NNZs: 1778, Bias: 0.000000, T: 11280, Avg. loss: 0.031291\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 60.21, NNZs: 1529, Bias: 0.000000, T: 14100, Avg. loss: 0.028134\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 64.15, NNZs: 1360, Bias: 0.000000, T: 16920, Avg. loss: 0.026279\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.05 seconds\n",
      "-- Epoch 1\n",
      "Norm: 20.77, NNZs: 2370, Bias: 0.000000, T: 2820, Avg. loss: 0.048678\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 25.24, NNZs: 1296, Bias: 0.000000, T: 5640, Avg. loss: 0.015478\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 28.75, NNZs: 874, Bias: 0.000000, T: 8460, Avg. loss: 0.014492\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 31.87, NNZs: 721, Bias: 0.000000, T: 11280, Avg. loss: 0.011670\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 34.29, NNZs: 597, Bias: 0.000000, T: 14100, Avg. loss: 0.011724\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 36.74, NNZs: 534, Bias: 0.000000, T: 16920, Avg. loss: 0.009866\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 6 epochs took 0.04 seconds\n",
      "0.9744680851063829\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      precision    recall  f1-score   support\n",
      "\n",
      "      Geen gebruiker       0.94      0.99      0.96       274\n",
      "   Huidige gebruiker       1.00      0.30      0.46        10\n",
      "      Niets gevonden       0.99      0.98      0.99       655\n",
      "Voormalige gebruiker       0.00      0.00      0.00         1\n",
      "\n",
      "            accuracy                           0.97       940\n",
      "           macro avg       0.73      0.57      0.60       940\n",
      "        weighted avg       0.97      0.97      0.97       940\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Ngram 2 Stopwords kept\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1,2), lowercase=True, token_pattern=r\"(?u)\\b\\w\\w+\\b|\\+|\\-\")),\n",
    "    ('clf', SGDClassifier(early_stopping=True, n_iter_no_change=5, validation_fraction = 0.25, verbose=3)),\n",
    "])\n",
    "random_search = RandomizedSearchCV(estimator=pipeline, param_distributions=parameter_grid, random_state=500, verbose=3, scoring='f1_macro')\n",
    "random_search.fit(train_set['text'], train_set['label'])  \n",
    "predicted_nb = random_search.predict(test_set['text'])\n",
    "print(np.mean(predicted_nb == test_set['label']))\n",
    "cm = confusion_matrix(test_set['label'], predicted_nb)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=random_search.classes_)\n",
    "disp.plot()\n",
    "\n",
    "plt.show()\n",
    "print(metrics.classification_report(test_set['label'], predicted_nb,\n",
    "    target_names=random_search.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886b30f2",
   "metadata": {},
   "source": [
    "## Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "77c44062",
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs_corpus = drugs_corpus_backup.copy()\n",
    "stemmer = SnowballStemmer(\"dutch\")\n",
    "drugs_corpus['text'] = drugs_corpus['text'].str.lower()\n",
    "drugs_corpus['text'] = [stemmer.stem(text) for text in drugs_corpus['text']]\n",
    "drugs_corpus['label'] = drugs_corpus['label'].str.replace('Niets gevonden','Geen gebruiker')\n",
    "drugs_corpus['label'] = drugs_corpus['label'].str.replace('Voormalige gebruiker','Geen gebruiker')\n",
    "drugs_corpus = drugs_corpus.drop(drugs_corpus[drugs_corpus.label == '--'].index)\n",
    "drugs_corpus = drugs_corpus.drop(drugs_corpus[drugs_corpus.label == 'Onbekend'].index)\n",
    "drugs_corpus_backup = drugs_corpus.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aeb1ae85",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(drugs_corpus['text'], drugs_corpus['label'], test_size=0.4, random_state=50, stratify=drugs_corpus['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c168eeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = {'clf__loss':              ['hinge', 'log_loss', 'log', 'modified_huber', 'squared_hinge', 'perceptron', 'squared_error', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "                  'clf__penalty':           ['l2', 'l1'],\n",
    "                  'clf__l1_ratio':          sp_randFloat(),\n",
    "                  'clf__fit_intercept':     [True, False],\n",
    "                  'clf__max_iter':          [int(x) for x in np.linspace(start = 10, stop = 100, num = 10)],\n",
    "                  'clf__tol':               sp_randFloat(),\n",
    "                  'clf__shuffle':           [True, False],\n",
    "                  'clf__epsilon':           sp_randFloat(),\n",
    "                  'clf__learning_rate':     ['constant', 'optimal', 'invscaling', 'adaptive'],\n",
    "                  'clf__eta0':              sp_randFloat(),\n",
    "                  'clf__power_t':           sp_randFloat(),\n",
    "                  'clf__class_weight':      ['balanced', None],\n",
    "                  'clf__warm_start':        [True, False],\n",
    "                  'clf__average':           [True, False],\n",
    "                  'tfidf__max_df':          [0.90, 0.95],\n",
    "                  'tfidf__min_df':          [3, 5]\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3f60be00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "-- Epoch 1\n",
      "Norm: 18.47, NNZs: 2696, Bias: 0.000000, T: 1692, Avg. loss: 0.199440\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 23.45, NNZs: 1399, Bias: 0.000000, T: 3384, Avg. loss: 0.120576\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 27.12, NNZs: 1125, Bias: 0.000000, T: 5076, Avg. loss: 0.106255\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 30.00, NNZs: 927, Bias: 0.000000, T: 6768, Avg. loss: 0.097759\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 32.59, NNZs: 837, Bias: 0.000000, T: 8460, Avg. loss: 0.092464\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 35.08, NNZs: 715, Bias: 0.000000, T: 10152, Avg. loss: 0.088493\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 35.48, NNZs: 683, Bias: 0.000000, T: 11844, Avg. loss: 0.085685\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 35.87, NNZs: 676, Bias: 0.000000, T: 13536, Avg. loss: 0.085222\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 36.27, NNZs: 654, Bias: 0.000000, T: 15228, Avg. loss: 0.084620\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 36.66, NNZs: 649, Bias: 0.000000, T: 16920, Avg. loss: 0.084068\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 37.04, NNZs: 635, Bias: 0.000000, T: 18612, Avg. loss: 0.083561\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 37.12, NNZs: 634, Bias: 0.000000, T: 20304, Avg. loss: 0.083114\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 37.20, NNZs: 632, Bias: 0.000000, T: 21996, Avg. loss: 0.083024\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 37.28, NNZs: 630, Bias: 0.000000, T: 23688, Avg. loss: 0.082924\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 37.35, NNZs: 630, Bias: 0.000000, T: 25380, Avg. loss: 0.082843\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 37.43, NNZs: 627, Bias: 0.000000, T: 27072, Avg. loss: 0.082750\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 37.44, NNZs: 627, Bias: 0.000000, T: 28764, Avg. loss: 0.082656\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 37.46, NNZs: 627, Bias: 0.000000, T: 30456, Avg. loss: 0.082638\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 37.48, NNZs: 626, Bias: 0.000000, T: 32148, Avg. loss: 0.082619\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 37.49, NNZs: 626, Bias: 0.000000, T: 33840, Avg. loss: 0.082600\n",
      "Total training time: 0.09 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.06171699256249541, clf__eta0=0.6666115972798587, clf__fit_intercept=False, clf__l1_ratio=0.9792901432894962, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.15075392531110676, clf__shuffle=True, clf__tol=0.365636830734297, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.496 total time=   1.0s\n",
      "-- Epoch 1\n",
      "Norm: 18.82, NNZs: 2774, Bias: 0.000000, T: 1692, Avg. loss: 0.199068\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 23.65, NNZs: 1436, Bias: 0.000000, T: 3384, Avg. loss: 0.119559\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 27.27, NNZs: 1132, Bias: 0.000000, T: 5076, Avg. loss: 0.104558\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 30.40, NNZs: 958, Bias: 0.000000, T: 6768, Avg. loss: 0.095440\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 32.79, NNZs: 840, Bias: 0.000000, T: 8460, Avg. loss: 0.089932\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 35.42, NNZs: 751, Bias: 0.000000, T: 10152, Avg. loss: 0.085855\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 35.82, NNZs: 731, Bias: 0.000000, T: 11844, Avg. loss: 0.082806\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 36.23, NNZs: 719, Bias: 0.000000, T: 13536, Avg. loss: 0.082246\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 36.64, NNZs: 711, Bias: 0.000000, T: 15228, Avg. loss: 0.081728\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 37.04, NNZs: 700, Bias: 0.000000, T: 16920, Avg. loss: 0.081279\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 37.44, NNZs: 694, Bias: 0.000000, T: 18612, Avg. loss: 0.080771\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 37.52, NNZs: 693, Bias: 0.000000, T: 20304, Avg. loss: 0.080238\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 37.60, NNZs: 691, Bias: 0.000000, T: 21996, Avg. loss: 0.080136\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 37.67, NNZs: 688, Bias: 0.000000, T: 23688, Avg. loss: 0.080039\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 37.75, NNZs: 687, Bias: 0.000000, T: 25380, Avg. loss: 0.079937\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 37.83, NNZs: 681, Bias: 0.000000, T: 27072, Avg. loss: 0.079853\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 37.84, NNZs: 681, Bias: 0.000000, T: 28764, Avg. loss: 0.079773\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 37.86, NNZs: 681, Bias: 0.000000, T: 30456, Avg. loss: 0.079749\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 37.88, NNZs: 680, Bias: 0.000000, T: 32148, Avg. loss: 0.079731\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 37.89, NNZs: 679, Bias: 0.000000, T: 33840, Avg. loss: 0.079718\n",
      "Total training time: 0.09 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.06171699256249541, clf__eta0=0.6666115972798587, clf__fit_intercept=False, clf__l1_ratio=0.9792901432894962, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.15075392531110676, clf__shuffle=True, clf__tol=0.365636830734297, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.497 total time=   1.0s\n",
      "-- Epoch 1\n",
      "Norm: 18.07, NNZs: 2704, Bias: 0.000000, T: 1692, Avg. loss: 0.201281\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 23.28, NNZs: 1415, Bias: 0.000000, T: 3384, Avg. loss: 0.121100\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 26.97, NNZs: 1101, Bias: 0.000000, T: 5076, Avg. loss: 0.105554\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 30.06, NNZs: 974, Bias: 0.000000, T: 6768, Avg. loss: 0.096842\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 32.71, NNZs: 864, Bias: 0.000000, T: 8460, Avg. loss: 0.090875\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 35.02, NNZs: 784, Bias: 0.000000, T: 10152, Avg. loss: 0.087381\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 35.45, NNZs: 759, Bias: 0.000000, T: 11844, Avg. loss: 0.084455\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 35.87, NNZs: 748, Bias: 0.000000, T: 13536, Avg. loss: 0.083907\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 36.30, NNZs: 732, Bias: 0.000000, T: 15228, Avg. loss: 0.083241\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 36.72, NNZs: 704, Bias: 0.000000, T: 16920, Avg. loss: 0.082713\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 37.12, NNZs: 692, Bias: 0.000000, T: 18612, Avg. loss: 0.082390\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 37.20, NNZs: 686, Bias: 0.000000, T: 20304, Avg. loss: 0.081861\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 37.27, NNZs: 683, Bias: 0.000000, T: 21996, Avg. loss: 0.081766\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 37.35, NNZs: 679, Bias: 0.000000, T: 23688, Avg. loss: 0.081684\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 37.43, NNZs: 677, Bias: 0.000000, T: 25380, Avg. loss: 0.081590\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 37.51, NNZs: 676, Bias: 0.000000, T: 27072, Avg. loss: 0.081491\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 37.52, NNZs: 676, Bias: 0.000000, T: 28764, Avg. loss: 0.081396\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 37.54, NNZs: 676, Bias: 0.000000, T: 30456, Avg. loss: 0.081379\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 37.55, NNZs: 676, Bias: 0.000000, T: 32148, Avg. loss: 0.081363\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 37.57, NNZs: 675, Bias: 0.000000, T: 33840, Avg. loss: 0.081346\n",
      "Total training time: 0.09 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.06171699256249541, clf__eta0=0.6666115972798587, clf__fit_intercept=False, clf__l1_ratio=0.9792901432894962, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.15075392531110676, clf__shuffle=True, clf__tol=0.365636830734297, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.497 total time=   1.0s\n",
      "-- Epoch 1\n",
      "Norm: 18.66, NNZs: 2893, Bias: 0.000000, T: 1692, Avg. loss: 0.199789\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 24.04, NNZs: 1439, Bias: 0.000000, T: 3384, Avg. loss: 0.118616\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 27.63, NNZs: 1113, Bias: 0.000000, T: 5076, Avg. loss: 0.102587\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 30.63, NNZs: 961, Bias: 0.000000, T: 6768, Avg. loss: 0.094364\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 33.29, NNZs: 841, Bias: 0.000000, T: 8460, Avg. loss: 0.088701\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 35.73, NNZs: 758, Bias: 0.000000, T: 10152, Avg. loss: 0.085287\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 36.17, NNZs: 742, Bias: 0.000000, T: 11844, Avg. loss: 0.081982\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 36.60, NNZs: 724, Bias: 0.000000, T: 13536, Avg. loss: 0.081463\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 37.03, NNZs: 699, Bias: 0.000000, T: 15228, Avg. loss: 0.080871\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 37.44, NNZs: 692, Bias: 0.000000, T: 16920, Avg. loss: 0.080469\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 37.85, NNZs: 677, Bias: 0.000000, T: 18612, Avg. loss: 0.079976\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 37.93, NNZs: 676, Bias: 0.000000, T: 20304, Avg. loss: 0.079500\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 38.01, NNZs: 670, Bias: 0.000000, T: 21996, Avg. loss: 0.079422\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 38.08, NNZs: 666, Bias: 0.000000, T: 23688, Avg. loss: 0.079332\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 38.16, NNZs: 663, Bias: 0.000000, T: 25380, Avg. loss: 0.079246\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 38.24, NNZs: 663, Bias: 0.000000, T: 27072, Avg. loss: 0.079154\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 38.26, NNZs: 663, Bias: 0.000000, T: 28764, Avg. loss: 0.079056\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 38.27, NNZs: 663, Bias: 0.000000, T: 30456, Avg. loss: 0.079042\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 38.29, NNZs: 663, Bias: 0.000000, T: 32148, Avg. loss: 0.079023\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 38.31, NNZs: 663, Bias: 0.000000, T: 33840, Avg. loss: 0.079004\n",
      "Total training time: 0.09 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.06171699256249541, clf__eta0=0.6666115972798587, clf__fit_intercept=False, clf__l1_ratio=0.9792901432894962, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.15075392531110676, clf__shuffle=True, clf__tol=0.365636830734297, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.497 total time=   1.0s\n",
      "-- Epoch 1\n",
      "Norm: 18.43, NNZs: 2651, Bias: 0.000000, T: 1692, Avg. loss: 0.199172\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 23.46, NNZs: 1383, Bias: 0.000000, T: 3384, Avg. loss: 0.121110\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 26.91, NNZs: 1053, Bias: 0.000000, T: 5076, Avg. loss: 0.106703\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 29.72, NNZs: 902, Bias: 0.000000, T: 6768, Avg. loss: 0.097707\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 32.46, NNZs: 802, Bias: 0.000000, T: 8460, Avg. loss: 0.093073\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 34.77, NNZs: 741, Bias: 0.000000, T: 10152, Avg. loss: 0.088432\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 35.19, NNZs: 721, Bias: 0.000000, T: 11844, Avg. loss: 0.085662\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 35.60, NNZs: 711, Bias: 0.000000, T: 13536, Avg. loss: 0.085119\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 36.02, NNZs: 695, Bias: 0.000000, T: 15228, Avg. loss: 0.084466\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 36.42, NNZs: 687, Bias: 0.000000, T: 16920, Avg. loss: 0.083992\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 36.82, NNZs: 678, Bias: 0.000000, T: 18612, Avg. loss: 0.083560\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 36.90, NNZs: 668, Bias: 0.000000, T: 20304, Avg. loss: 0.082998\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 36.97, NNZs: 668, Bias: 0.000000, T: 21996, Avg. loss: 0.082912\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 37.05, NNZs: 666, Bias: 0.000000, T: 23688, Avg. loss: 0.082816\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 37.13, NNZs: 665, Bias: 0.000000, T: 25380, Avg. loss: 0.082725\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 37.21, NNZs: 660, Bias: 0.000000, T: 27072, Avg. loss: 0.082626\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 37.22, NNZs: 659, Bias: 0.000000, T: 28764, Avg. loss: 0.082522\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 37.24, NNZs: 658, Bias: 0.000000, T: 30456, Avg. loss: 0.082507\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 37.25, NNZs: 658, Bias: 0.000000, T: 32148, Avg. loss: 0.082488\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 37.27, NNZs: 658, Bias: 0.000000, T: 33840, Avg. loss: 0.082465\n",
      "Total training time: 0.09 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.06171699256249541, clf__eta0=0.6666115972798587, clf__fit_intercept=False, clf__l1_ratio=0.9792901432894962, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.15075392531110676, clf__shuffle=True, clf__tol=0.365636830734297, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.496 total time=   1.0s\n",
      "-- Epoch 1\n",
      "Norm: 129708398208349.47, NNZs: 15958, Bias: 0.000000, T: 1692, Avg. loss: 3465118249261160573435904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 82386468135499.41, NNZs: 15958, Bias: 0.000000, T: 3384, Avg. loss: 8254489573177965307494400.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 56500264473418.91, NNZs: 15958, Bias: 0.000000, T: 5076, Avg. loss: 2985567971803376534945792.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 40983830317346.35, NNZs: 15958, Bias: 0.000000, T: 6768, Avg. loss: 1266067714408781229064192.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 30589117382575.93, NNZs: 15958, Bias: 0.000000, T: 8460, Avg. loss: 617113332209135443247104.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 23267684129630.54, NNZs: 15958, Bias: 0.000000, T: 10152, Avg. loss: 316848153689085368598528.000000\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 1/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.7915127974877743, clf__eta0=0.05539740212799926, clf__fit_intercept=False, clf__l1_ratio=0.9152680641407671, clf__learning_rate=optimal, clf__loss=squared_epsilon_insensitive, clf__max_iter=80, clf__penalty=l1, clf__power_t=0.6359093112142983, clf__shuffle=True, clf__tol=0.9361199211609239, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.342 total time=   0.9s\n",
      "-- Epoch 1\n",
      "Norm: 129808940908659.44, NNZs: 15973, Bias: 0.000000, T: 1692, Avg. loss: 3268848506431335544389632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 84984624160188.53, NNZs: 15974, Bias: 0.000000, T: 3384, Avg. loss: 8079620518604112731832320.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 60534013539521.55, NNZs: 15974, Bias: 0.000000, T: 5076, Avg. loss: 3047500800402911452463104.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 44490130605836.99, NNZs: 15974, Bias: 0.000000, T: 6768, Avg. loss: 1415761500571844254629888.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 32826058597920.66, NNZs: 15974, Bias: 0.000000, T: 8460, Avg. loss: 726951500588583359610880.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 25026133880051.67, NNZs: 15974, Bias: 0.000000, T: 10152, Avg. loss: 354189588268560781672448.000000\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 2/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.7915127974877743, clf__eta0=0.05539740212799926, clf__fit_intercept=False, clf__l1_ratio=0.9152680641407671, clf__learning_rate=optimal, clf__loss=squared_epsilon_insensitive, clf__max_iter=80, clf__penalty=l1, clf__power_t=0.6359093112142983, clf__shuffle=True, clf__tol=0.9361199211609239, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.310 total time=   1.0s\n",
      "-- Epoch 1\n",
      "Norm: 121743784941994.48, NNZs: 16407, Bias: 0.000000, T: 1692, Avg. loss: 2634408437431117937639424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 77922205086709.78, NNZs: 16410, Bias: 0.000000, T: 3384, Avg. loss: 7355680428467144326381568.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 54561658684420.00, NNZs: 16410, Bias: 0.000000, T: 5076, Avg. loss: 2655025916030422655959040.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 39843465744345.48, NNZs: 16410, Bias: 0.000000, T: 6768, Avg. loss: 1185481719494394372947968.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 29715500099430.98, NNZs: 16410, Bias: 0.000000, T: 8460, Avg. loss: 598209676236965785108480.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 22425383281019.94, NNZs: 16410, Bias: 0.000000, T: 10152, Avg. loss: 309028708083806236573696.000000\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 3/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.7915127974877743, clf__eta0=0.05539740212799926, clf__fit_intercept=False, clf__l1_ratio=0.9152680641407671, clf__learning_rate=optimal, clf__loss=squared_epsilon_insensitive, clf__max_iter=80, clf__penalty=l1, clf__power_t=0.6359093112142983, clf__shuffle=True, clf__tol=0.9361199211609239, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.352 total time=   1.0s\n",
      "-- Epoch 1\n",
      "Norm: 129296734543615.95, NNZs: 16257, Bias: 0.000000, T: 1692, Avg. loss: 3407524182982996258717696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 83801307130526.95, NNZs: 16257, Bias: 0.000000, T: 3384, Avg. loss: 8058407211707590898614272.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 59144931454190.72, NNZs: 16257, Bias: 0.000000, T: 5076, Avg. loss: 2969797457111170559246336.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 43273583263010.36, NNZs: 16257, Bias: 0.000000, T: 6768, Avg. loss: 1381792546855226473185280.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 32537548330589.77, NNZs: 16257, Bias: 0.000000, T: 8460, Avg. loss: 663408310265783311663104.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 24615513657668.75, NNZs: 16257, Bias: 0.000000, T: 10152, Avg. loss: 356613737599390260920320.000000\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 4/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.7915127974877743, clf__eta0=0.05539740212799926, clf__fit_intercept=False, clf__l1_ratio=0.9152680641407671, clf__learning_rate=optimal, clf__loss=squared_epsilon_insensitive, clf__max_iter=80, clf__penalty=l1, clf__power_t=0.6359093112142983, clf__shuffle=True, clf__tol=0.9361199211609239, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.384 total time=   0.9s\n",
      "-- Epoch 1\n",
      "Norm: 118071871423697.09, NNZs: 15887, Bias: 0.000000, T: 1692, Avg. loss: 2547455795915108665786368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 76164325060589.55, NNZs: 15888, Bias: 0.000000, T: 3384, Avg. loss: 6970318958382983889813504.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 53045098412813.91, NNZs: 15888, Bias: 0.000000, T: 5076, Avg. loss: 2541876663592585724428288.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 39504522429281.55, NNZs: 15888, Bias: 0.000000, T: 6768, Avg. loss: 1105801638494181500387328.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 29486269084718.14, NNZs: 15888, Bias: 0.000000, T: 8460, Avg. loss: 588038685216317378658304.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 22360094736024.07, NNZs: 15888, Bias: 0.000000, T: 10152, Avg. loss: 305156171029719526932480.000000\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 5/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.7915127974877743, clf__eta0=0.05539740212799926, clf__fit_intercept=False, clf__l1_ratio=0.9152680641407671, clf__learning_rate=optimal, clf__loss=squared_epsilon_insensitive, clf__max_iter=80, clf__penalty=l1, clf__power_t=0.6359093112142983, clf__shuffle=True, clf__tol=0.9361199211609239, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.387 total time=   0.9s\n",
      "-- Epoch 1\n",
      "Norm: 20.66, NNZs: 4939, Bias: 0.000000, T: 1692, Avg. loss: 0.106000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 24.67, NNZs: 2658, Bias: 0.000000, T: 3384, Avg. loss: 0.022352\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 27.80, NNZs: 1890, Bias: 0.000000, T: 5076, Avg. loss: 0.017199\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 30.46, NNZs: 1502, Bias: 0.000000, T: 6768, Avg. loss: 0.014576\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 32.71, NNZs: 1266, Bias: 0.000000, T: 8460, Avg. loss: 0.011019\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 34.78, NNZs: 1093, Bias: 0.000000, T: 10152, Avg. loss: 0.011832\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 1/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.03646223783802971, clf__eta0=0.7491267567674796, clf__fit_intercept=False, clf__l1_ratio=0.775818217437024, clf__learning_rate=constant, clf__loss=squared_hinge, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.4028006727705291, clf__shuffle=True, clf__tol=0.1730703028465106, clf__warm_start=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.497 total time=   1.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 20.84, NNZs: 5189, Bias: 0.000000, T: 1692, Avg. loss: 0.098922\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 24.25, NNZs: 2555, Bias: 0.000000, T: 3384, Avg. loss: 0.018837\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 27.39, NNZs: 1697, Bias: 0.000000, T: 5076, Avg. loss: 0.016303\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 29.92, NNZs: 1356, Bias: 0.000000, T: 6768, Avg. loss: 0.012610\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 32.19, NNZs: 1145, Bias: 0.000000, T: 8460, Avg. loss: 0.010149\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 34.16, NNZs: 1009, Bias: 0.000000, T: 10152, Avg. loss: 0.009694\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 2/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.03646223783802971, clf__eta0=0.7491267567674796, clf__fit_intercept=False, clf__l1_ratio=0.775818217437024, clf__learning_rate=constant, clf__loss=squared_hinge, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.4028006727705291, clf__shuffle=True, clf__tol=0.1730703028465106, clf__warm_start=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.622 total time=   1.0s\n",
      "-- Epoch 1\n",
      "Norm: 20.67, NNZs: 5120, Bias: 0.000000, T: 1692, Avg. loss: 0.102708\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 24.49, NNZs: 2675, Bias: 0.000000, T: 3384, Avg. loss: 0.022118\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 27.79, NNZs: 1847, Bias: 0.000000, T: 5076, Avg. loss: 0.016785\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 30.38, NNZs: 1422, Bias: 0.000000, T: 6768, Avg. loss: 0.014216\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 32.74, NNZs: 1212, Bias: 0.000000, T: 8460, Avg. loss: 0.011735\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 34.81, NNZs: 1050, Bias: 0.000000, T: 10152, Avg. loss: 0.011610\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 3/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.03646223783802971, clf__eta0=0.7491267567674796, clf__fit_intercept=False, clf__l1_ratio=0.775818217437024, clf__learning_rate=constant, clf__loss=squared_hinge, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.4028006727705291, clf__shuffle=True, clf__tol=0.1730703028465106, clf__warm_start=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.798 total time=   1.0s\n",
      "-- Epoch 1\n",
      "Norm: 20.40, NNZs: 4980, Bias: 0.000000, T: 1692, Avg. loss: 0.104288\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 24.40, NNZs: 2596, Bias: 0.000000, T: 3384, Avg. loss: 0.023974\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 27.63, NNZs: 1868, Bias: 0.000000, T: 5076, Avg. loss: 0.017876\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 30.18, NNZs: 1441, Bias: 0.000000, T: 6768, Avg. loss: 0.013867\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 32.68, NNZs: 1242, Bias: 0.000000, T: 8460, Avg. loss: 0.013328\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 34.78, NNZs: 1098, Bias: 0.000000, T: 10152, Avg. loss: 0.011984\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 4/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.03646223783802971, clf__eta0=0.7491267567674796, clf__fit_intercept=False, clf__l1_ratio=0.775818217437024, clf__learning_rate=constant, clf__loss=squared_hinge, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.4028006727705291, clf__shuffle=True, clf__tol=0.1730703028465106, clf__warm_start=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.497 total time=   1.0s\n",
      "-- Epoch 1\n",
      "Norm: 20.77, NNZs: 5051, Bias: 0.000000, T: 1692, Avg. loss: 0.100236\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 24.42, NNZs: 2553, Bias: 0.000000, T: 3384, Avg. loss: 0.022925\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 27.37, NNZs: 1786, Bias: 0.000000, T: 5076, Avg. loss: 0.014661\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 29.96, NNZs: 1413, Bias: 0.000000, T: 6768, Avg. loss: 0.015664\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 32.39, NNZs: 1201, Bias: 0.000000, T: 8460, Avg. loss: 0.012530\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 34.48, NNZs: 1059, Bias: 0.000000, T: 10152, Avg. loss: 0.011152\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 5/5] END clf__average=False, clf__class_weight=None, clf__epsilon=0.03646223783802971, clf__eta0=0.7491267567674796, clf__fit_intercept=False, clf__l1_ratio=0.775818217437024, clf__learning_rate=constant, clf__loss=squared_hinge, clf__max_iter=20, clf__penalty=l1, clf__power_t=0.4028006727705291, clf__shuffle=True, clf__tol=0.1730703028465106, clf__warm_start=True, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.496 total time=   1.0s\n",
      "-- Epoch 1\n",
      "Norm: 512597.33, NNZs: 15952, Bias: 0.000000, T: 1692, Avg. loss: 166208200.165370\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1743883964.08, NNZs: 15953, Bias: 0.000000, T: 3384, Avg. loss: 1492037926029701.250000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 17805430512806.12, NNZs: 15953, Bias: 0.000000, T: 5076, Avg. loss: 67266968555294956716032.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 32647658841967.72, NNZs: 15953, Bias: 0.000000, T: 6768, Avg. loss: 642389966774541295288320.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 35357743789469.99, NNZs: 15953, Bias: 0.000000, T: 8460, Avg. loss: 1884642123612249909100544.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 39580735244109.41, NNZs: 15953, Bias: 0.000000, T: 10152, Avg. loss: 1764132149122644173651968.000000\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 1/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.24457156361183285, clf__eta0=0.332929742792607, clf__fit_intercept=False, clf__l1_ratio=0.920539731041378, clf__learning_rate=constant, clf__loss=squared_error, clf__max_iter=100, clf__penalty=l1, clf__power_t=0.5734177157821045, clf__shuffle=True, clf__tol=0.6492274795888617, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.364 total time=   0.9s\n",
      "-- Epoch 1\n",
      "Norm: 9498.50, NNZs: 15479, Bias: 0.000000, T: 1692, Avg. loss: 8477.288362\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 148544629.96, NNZs: 15978, Bias: 0.000000, T: 3384, Avg. loss: 8901154686615.980469\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 5387165001.08, NNZs: 15978, Bias: 0.000000, T: 5076, Avg. loss: 14087550966578662.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 26337963653176.05, NNZs: 15978, Bias: 0.000000, T: 6768, Avg. loss: 265142217205125937627136.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 33545071406317.45, NNZs: 15978, Bias: 0.000000, T: 8460, Avg. loss: 1361637861201405443833856.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 35071500978398.18, NNZs: 15978, Bias: 0.000000, T: 10152, Avg. loss: 2356256763759662540521472.000000\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 2/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.24457156361183285, clf__eta0=0.332929742792607, clf__fit_intercept=False, clf__l1_ratio=0.920539731041378, clf__learning_rate=constant, clf__loss=squared_error, clf__max_iter=100, clf__penalty=l1, clf__power_t=0.5734177157821045, clf__shuffle=True, clf__tol=0.6492274795888617, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.359 total time=   0.9s\n",
      "-- Epoch 1\n",
      "Norm: 5112.18, NNZs: 16190, Bias: 0.000000, T: 1692, Avg. loss: 6413.478920\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 936603.28, NNZs: 16408, Bias: 0.000000, T: 3384, Avg. loss: 148290464.646781\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 597546548.54, NNZs: 16414, Bias: 0.000000, T: 5076, Avg. loss: 129281089634168.515625\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 389795504510.51, NNZs: 16414, Bias: 0.000000, T: 6768, Avg. loss: 10443378873163186176.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 24481593600237.00, NNZs: 16414, Bias: 0.000000, T: 8460, Avg. loss: 324353845989733226774528.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 31437412944215.23, NNZs: 16414, Bias: 0.000000, T: 10152, Avg. loss: 1272808727327662814527488.000000\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 3/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.24457156361183285, clf__eta0=0.332929742792607, clf__fit_intercept=False, clf__l1_ratio=0.920539731041378, clf__learning_rate=constant, clf__loss=squared_error, clf__max_iter=100, clf__penalty=l1, clf__power_t=0.5734177157821045, clf__shuffle=True, clf__tol=0.6492274795888617, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.347 total time=   0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 5147458.56, NNZs: 16258, Bias: 0.000000, T: 1692, Avg. loss: 13839620501.327869\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 369052242004.25, NNZs: 16258, Bias: 0.000000, T: 3384, Avg. loss: 33088783671689555968.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 34546936173321.74, NNZs: 16258, Bias: 0.000000, T: 5076, Avg. loss: 568308780723587298361344.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 27410264994667.27, NNZs: 16258, Bias: 0.000000, T: 6768, Avg. loss: 1270426362493890723840000.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 29934611278201.66, NNZs: 16258, Bias: 0.000000, T: 8460, Avg. loss: 1131294266053912577441792.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 30908995010136.66, NNZs: 16258, Bias: 0.000000, T: 10152, Avg. loss: 1553660331940965542526976.000000\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 4/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.24457156361183285, clf__eta0=0.332929742792607, clf__fit_intercept=False, clf__l1_ratio=0.920539731041378, clf__learning_rate=constant, clf__loss=squared_error, clf__max_iter=100, clf__penalty=l1, clf__power_t=0.5734177157821045, clf__shuffle=True, clf__tol=0.6492274795888617, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.368 total time=   0.9s\n",
      "-- Epoch 1\n",
      "Norm: 25968.16, NNZs: 15870, Bias: 0.000000, T: 1692, Avg. loss: 259810.863819\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1334413635.01, NNZs: 15899, Bias: 0.000000, T: 3384, Avg. loss: 643141467847272.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2486067002049.79, NNZs: 15899, Bias: 0.000000, T: 5076, Avg. loss: 3654638119374680489984.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 33443386573488.96, NNZs: 15899, Bias: 0.000000, T: 6768, Avg. loss: 621121188013151958859776.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 33214628347683.88, NNZs: 15899, Bias: 0.000000, T: 8460, Avg. loss: 2096486787325591738646528.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 35643255256274.32, NNZs: 15899, Bias: 0.000000, T: 10152, Avg. loss: 1530036532959708314599424.000000\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 5/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.24457156361183285, clf__eta0=0.332929742792607, clf__fit_intercept=False, clf__l1_ratio=0.920539731041378, clf__learning_rate=constant, clf__loss=squared_error, clf__max_iter=100, clf__penalty=l1, clf__power_t=0.5734177157821045, clf__shuffle=True, clf__tol=0.6492274795888617, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.309 total time=   0.9s\n",
      "-- Epoch 1\n",
      "Norm: 2.03, NNZs: 28212, Bias: -0.097565, T: 1692, Avg. loss: 0.136742\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2.55, NNZs: 28212, Bias: -0.132382, T: 3384, Avg. loss: 0.081839\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.80, NNZs: 28212, Bias: -0.154365, T: 5076, Avg. loss: 0.065069\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.96, NNZs: 28212, Bias: -0.170576, T: 6768, Avg. loss: 0.056080\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3.08, NNZs: 28212, Bias: -0.183543, T: 8460, Avg. loss: 0.050096\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.17, NNZs: 28212, Bias: -0.194432, T: 10152, Avg. loss: 0.045693\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 1/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.2527955528897454, clf__eta0=0.4377192284389271, clf__fit_intercept=True, clf__l1_ratio=0.6515110441465675, clf__learning_rate=invscaling, clf__loss=huber, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.47239053945705856, clf__shuffle=False, clf__tol=0.9089234089706554, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.497 total time=   1.0s\n",
      "-- Epoch 1\n",
      "Norm: 2.05, NNZs: 28122, Bias: -0.099184, T: 1692, Avg. loss: 0.134938\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2.55, NNZs: 28122, Bias: -0.133622, T: 3384, Avg. loss: 0.081163\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.80, NNZs: 28122, Bias: -0.155543, T: 5076, Avg. loss: 0.064709\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.97, NNZs: 28122, Bias: -0.171810, T: 6768, Avg. loss: 0.055757\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3.09, NNZs: 28122, Bias: -0.184877, T: 8460, Avg. loss: 0.049766\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.18, NNZs: 28122, Bias: -0.195868, T: 10152, Avg. loss: 0.045345\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 2/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.2527955528897454, clf__eta0=0.4377192284389271, clf__fit_intercept=True, clf__l1_ratio=0.6515110441465675, clf__learning_rate=invscaling, clf__loss=huber, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.47239053945705856, clf__shuffle=False, clf__tol=0.9089234089706554, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.497 total time=   0.9s\n",
      "-- Epoch 1\n",
      "Norm: 2.07, NNZs: 29076, Bias: -0.098326, T: 1692, Avg. loss: 0.131853\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2.54, NNZs: 29076, Bias: -0.131442, T: 3384, Avg. loss: 0.079824\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.78, NNZs: 29076, Bias: -0.152616, T: 5076, Avg. loss: 0.064441\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.93, NNZs: 29076, Bias: -0.168466, T: 6768, Avg. loss: 0.055841\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3.04, NNZs: 29076, Bias: -0.181272, T: 8460, Avg. loss: 0.050004\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.14, NNZs: 29076, Bias: -0.192069, T: 10152, Avg. loss: 0.045683\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 3/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.2527955528897454, clf__eta0=0.4377192284389271, clf__fit_intercept=True, clf__l1_ratio=0.6515110441465675, clf__learning_rate=invscaling, clf__loss=huber, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.47239053945705856, clf__shuffle=False, clf__tol=0.9089234089706554, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.497 total time=   1.0s\n",
      "-- Epoch 1\n",
      "Norm: 2.08, NNZs: 28510, Bias: -0.098823, T: 1692, Avg. loss: 0.132280\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2.57, NNZs: 28510, Bias: -0.132316, T: 3384, Avg. loss: 0.079103\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.81, NNZs: 28510, Bias: -0.153573, T: 5076, Avg. loss: 0.063384\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.97, NNZs: 28510, Bias: -0.169410, T: 6768, Avg. loss: 0.054727\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3.08, NNZs: 28510, Bias: -0.182177, T: 8460, Avg. loss: 0.048898\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.18, NNZs: 28510, Bias: -0.192938, T: 10152, Avg. loss: 0.044593\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 4/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.2527955528897454, clf__eta0=0.4377192284389271, clf__fit_intercept=True, clf__l1_ratio=0.6515110441465675, clf__learning_rate=invscaling, clf__loss=huber, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.47239053945705856, clf__shuffle=False, clf__tol=0.9089234089706554, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.497 total time=   0.9s\n",
      "-- Epoch 1\n",
      "Norm: 2.08, NNZs: 28034, Bias: -0.099294, T: 1692, Avg. loss: 0.133239\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2.57, NNZs: 28034, Bias: -0.133249, T: 3384, Avg. loss: 0.079590\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.82, NNZs: 28034, Bias: -0.154780, T: 5076, Avg. loss: 0.063793\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.97, NNZs: 28034, Bias: -0.170818, T: 6768, Avg. loss: 0.055113\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3.09, NNZs: 28034, Bias: -0.183743, T: 8460, Avg. loss: 0.049201\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.18, NNZs: 28034, Bias: -0.194646, T: 10152, Avg. loss: 0.044792\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 5/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.2527955528897454, clf__eta0=0.4377192284389271, clf__fit_intercept=True, clf__l1_ratio=0.6515110441465675, clf__learning_rate=invscaling, clf__loss=huber, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.47239053945705856, clf__shuffle=False, clf__tol=0.9089234089706554, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=3;, score=0.496 total time=   1.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 95.63, NNZs: 27832, Bias: -0.873485, T: 1692, Avg. loss: 0.955375\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 44.53, NNZs: 28079, Bias: -0.715885, T: 3384, Avg. loss: 1.238390\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 35.09, NNZs: 28197, Bias: -0.857775, T: 5076, Avg. loss: 0.393132\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 24.01, NNZs: 28196, Bias: -0.852115, T: 6768, Avg. loss: 0.320709\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 19.63, NNZs: 28201, Bias: -0.939676, T: 8460, Avg. loss: 0.134461\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 15.64, NNZs: 28192, Bias: -0.932215, T: 10152, Avg. loss: 0.072931\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 13.07, NNZs: 28182, Bias: -0.882960, T: 11844, Avg. loss: 0.032707\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 11.83, NNZs: 28172, Bias: -0.897661, T: 13536, Avg. loss: 0.013664\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 11.05, NNZs: 28163, Bias: -0.878288, T: 15228, Avg. loss: 0.004478\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 10.82, NNZs: 28167, Bias: -0.901064, T: 16920, Avg. loss: 0.001840\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 10.48, NNZs: 28164, Bias: -0.890447, T: 18612, Avg. loss: 0.001243\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 11 epochs took 0.03 seconds\n",
      "[CV 1/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.3241670976844645, clf__eta0=0.9631840511405841, clf__fit_intercept=True, clf__l1_ratio=0.5912641309775509, clf__learning_rate=optimal, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.6710686638981408, clf__shuffle=True, clf__tol=0.09654933943827881, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.497 total time=   1.0s\n",
      "-- Epoch 1\n",
      "Norm: 96.22, NNZs: 27650, Bias: -1.012840, T: 1692, Avg. loss: 0.953588\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 42.20, NNZs: 27962, Bias: -0.766212, T: 3384, Avg. loss: 1.274110\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 34.64, NNZs: 28065, Bias: -0.822024, T: 5076, Avg. loss: 0.357408\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 24.00, NNZs: 28063, Bias: -0.812590, T: 6768, Avg. loss: 0.303609\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 18.62, NNZs: 28065, Bias: -0.899828, T: 8460, Avg. loss: 0.146198\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 15.61, NNZs: 28049, Bias: -0.895565, T: 10152, Avg. loss: 0.074303\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 13.39, NNZs: 28031, Bias: -0.886198, T: 11844, Avg. loss: 0.034603\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 7 epochs took 0.02 seconds\n",
      "[CV 2/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.3241670976844645, clf__eta0=0.9631840511405841, clf__fit_intercept=True, clf__l1_ratio=0.5912641309775509, clf__learning_rate=optimal, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.6710686638981408, clf__shuffle=True, clf__tol=0.09654933943827881, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.497 total time=   0.9s\n",
      "-- Epoch 1\n",
      "Norm: 96.51, NNZs: 28572, Bias: -0.814902, T: 1692, Avg. loss: 0.929817\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 41.60, NNZs: 28899, Bias: -0.725683, T: 3384, Avg. loss: 1.306179\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 34.46, NNZs: 28984, Bias: -0.897826, T: 5076, Avg. loss: 0.369687\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 24.15, NNZs: 28987, Bias: -0.873483, T: 6768, Avg. loss: 0.303350\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 18.45, NNZs: 28988, Bias: -0.867226, T: 8460, Avg. loss: 0.147129\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 15.27, NNZs: 28969, Bias: -0.887106, T: 10152, Avg. loss: 0.075851\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 3/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.3241670976844645, clf__eta0=0.9631840511405841, clf__fit_intercept=True, clf__l1_ratio=0.5912641309775509, clf__learning_rate=optimal, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.6710686638981408, clf__shuffle=True, clf__tol=0.09654933943827881, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.622 total time=   1.0s\n",
      "-- Epoch 1\n",
      "Norm: 96.79, NNZs: 28119, Bias: -1.020970, T: 1692, Avg. loss: 0.953836\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 42.03, NNZs: 28335, Bias: -0.954247, T: 3384, Avg. loss: 1.300842\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 34.38, NNZs: 28456, Bias: -0.951639, T: 5076, Avg. loss: 0.366176\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 23.54, NNZs: 28441, Bias: -1.008316, T: 6768, Avg. loss: 0.310257\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 18.87, NNZs: 28451, Bias: -0.934702, T: 8460, Avg. loss: 0.139017\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 15.03, NNZs: 28436, Bias: -0.914059, T: 10152, Avg. loss: 0.072273\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 13.16, NNZs: 28418, Bias: -0.948052, T: 11844, Avg. loss: 0.032707\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 12.18, NNZs: 28402, Bias: -0.904464, T: 13536, Avg. loss: 0.012890\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 11.35, NNZs: 28405, Bias: -0.930991, T: 15228, Avg. loss: 0.003684\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 11.16, NNZs: 28406, Bias: -0.913643, T: 16920, Avg. loss: 0.001887\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 10 epochs took 0.03 seconds\n",
      "[CV 4/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.3241670976844645, clf__eta0=0.9631840511405841, clf__fit_intercept=True, clf__l1_ratio=0.5912641309775509, clf__learning_rate=optimal, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.6710686638981408, clf__shuffle=True, clf__tol=0.09654933943827881, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.497 total time=   1.0s\n",
      "-- Epoch 1\n",
      "Norm: 95.96, NNZs: 27674, Bias: -0.747042, T: 1692, Avg. loss: 0.982630\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 42.52, NNZs: 27927, Bias: -0.994996, T: 3384, Avg. loss: 1.284359\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 35.24, NNZs: 28043, Bias: -0.907629, T: 5076, Avg. loss: 0.374204\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 24.51, NNZs: 28019, Bias: -0.896654, T: 6768, Avg. loss: 0.325409\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 18.82, NNZs: 28002, Bias: -0.920112, T: 8460, Avg. loss: 0.141609\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 14.93, NNZs: 27993, Bias: -0.861904, T: 10152, Avg. loss: 0.073894\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 12.60, NNZs: 27987, Bias: -0.903595, T: 11844, Avg. loss: 0.030293\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 7 epochs took 0.02 seconds\n",
      "[CV 5/5] END clf__average=True, clf__class_weight=None, clf__epsilon=0.3241670976844645, clf__eta0=0.9631840511405841, clf__fit_intercept=True, clf__l1_ratio=0.5912641309775509, clf__learning_rate=optimal, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.6710686638981408, clf__shuffle=True, clf__tol=0.09654933943827881, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=3;, score=0.496 total time=   0.9s\n",
      "-- Epoch 1\n",
      "Norm: 98.20, NNZs: 8545, Bias: 0.000000, T: 1692, Avg. loss: 1.640118\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 114.02, NNZs: 5294, Bias: 0.000000, T: 3384, Avg. loss: 0.738500\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 124.13, NNZs: 4264, Bias: 0.000000, T: 5076, Avg. loss: 0.532468\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 133.39, NNZs: 3648, Bias: 0.000000, T: 6768, Avg. loss: 0.439902\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 140.85, NNZs: 3252, Bias: 0.000000, T: 8460, Avg. loss: 0.494220\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 145.48, NNZs: 2856, Bias: 0.000000, T: 10152, Avg. loss: 0.131329\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 1/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.3509613152086368, clf__eta0=0.9934401124631351, clf__fit_intercept=False, clf__l1_ratio=0.5204998682261415, clf__learning_rate=constant, clf__loss=hinge, clf__max_iter=40, clf__penalty=l1, clf__power_t=0.5098574122392232, clf__shuffle=False, clf__tol=0.5563103350645606, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.677 total time=   0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 96.56, NNZs: 8349, Bias: 0.000000, T: 1692, Avg. loss: 1.367029\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 114.74, NNZs: 6083, Bias: 0.000000, T: 3384, Avg. loss: 0.752709\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 131.02, NNZs: 4707, Bias: 0.000000, T: 5076, Avg. loss: 0.476471\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 135.61, NNZs: 3829, Bias: 0.000000, T: 6768, Avg. loss: 0.303964\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 144.83, NNZs: 3429, Bias: 0.000000, T: 8460, Avg. loss: 0.416648\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 148.99, NNZs: 2985, Bias: 0.000000, T: 10152, Avg. loss: 0.284858\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 2/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.3509613152086368, clf__eta0=0.9934401124631351, clf__fit_intercept=False, clf__l1_ratio=0.5204998682261415, clf__learning_rate=constant, clf__loss=hinge, clf__max_iter=40, clf__penalty=l1, clf__power_t=0.5098574122392232, clf__shuffle=False, clf__tol=0.5563103350645606, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.606 total time=   0.9s\n",
      "-- Epoch 1\n",
      "Norm: 90.00, NNZs: 8096, Bias: 0.000000, T: 1692, Avg. loss: 1.472648\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 107.51, NNZs: 5569, Bias: 0.000000, T: 3384, Avg. loss: 0.783835\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 117.14, NNZs: 4369, Bias: 0.000000, T: 5076, Avg. loss: 0.543167\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 127.77, NNZs: 3762, Bias: 0.000000, T: 6768, Avg. loss: 0.351583\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 137.61, NNZs: 3276, Bias: 0.000000, T: 8460, Avg. loss: 0.362973\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 141.20, NNZs: 2886, Bias: 0.000000, T: 10152, Avg. loss: 0.467330\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 3/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.3509613152086368, clf__eta0=0.9934401124631351, clf__fit_intercept=False, clf__l1_ratio=0.5204998682261415, clf__learning_rate=constant, clf__loss=hinge, clf__max_iter=40, clf__penalty=l1, clf__power_t=0.5098574122392232, clf__shuffle=False, clf__tol=0.5563103350645606, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.641 total time=   0.9s\n",
      "-- Epoch 1\n",
      "Norm: 96.21, NNZs: 8394, Bias: 0.000000, T: 1692, Avg. loss: 1.593869\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 110.88, NNZs: 5737, Bias: 0.000000, T: 3384, Avg. loss: 1.062047\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 126.63, NNZs: 4592, Bias: 0.000000, T: 5076, Avg. loss: 0.534088\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 130.45, NNZs: 3807, Bias: 0.000000, T: 6768, Avg. loss: 0.373827\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 140.34, NNZs: 3438, Bias: 0.000000, T: 8460, Avg. loss: 0.198664\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 139.97, NNZs: 2914, Bias: 0.000000, T: 10152, Avg. loss: 0.132490\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "[CV 4/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.3509613152086368, clf__eta0=0.9934401124631351, clf__fit_intercept=False, clf__l1_ratio=0.5204998682261415, clf__learning_rate=constant, clf__loss=hinge, clf__max_iter=40, clf__penalty=l1, clf__power_t=0.5098574122392232, clf__shuffle=False, clf__tol=0.5563103350645606, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.596 total time=   0.9s\n",
      "-- Epoch 1\n",
      "Norm: 101.89, NNZs: 9019, Bias: 0.000000, T: 1692, Avg. loss: 1.795847\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 123.20, NNZs: 6077, Bias: 0.000000, T: 3384, Avg. loss: 0.999176\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 132.34, NNZs: 4716, Bias: 0.000000, T: 5076, Avg. loss: 0.682557\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 137.81, NNZs: 3770, Bias: 0.000000, T: 6768, Avg. loss: 0.208875\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 142.52, NNZs: 3258, Bias: 0.000000, T: 8460, Avg. loss: 0.245136\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 146.36, NNZs: 2853, Bias: 0.000000, T: 10152, Avg. loss: 0.225033\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "[CV 5/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.3509613152086368, clf__eta0=0.9934401124631351, clf__fit_intercept=False, clf__l1_ratio=0.5204998682261415, clf__learning_rate=constant, clf__loss=hinge, clf__max_iter=40, clf__penalty=l1, clf__power_t=0.5098574122392232, clf__shuffle=False, clf__tol=0.5563103350645606, clf__warm_start=False, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.664 total time=   0.9s\n",
      "-- Epoch 1\n",
      "Norm: 0.29, NNZs: 15953, Bias: 0.000000, T: 1692, Avg. loss: 0.718034\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.45, NNZs: 15953, Bias: 0.000000, T: 3384, Avg. loss: 0.746080\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.56, NNZs: 15953, Bias: 0.000000, T: 5076, Avg. loss: 0.757949\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.66, NNZs: 15953, Bias: 0.000000, T: 6768, Avg. loss: 0.771101\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.74, NNZs: 15953, Bias: 0.000000, T: 8460, Avg. loss: 0.778118\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.82, NNZs: 15953, Bias: 0.000000, T: 10152, Avg. loss: 0.791857\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "[CV 1/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.28658617296069355, clf__eta0=0.03398405924608927, clf__fit_intercept=False, clf__l1_ratio=0.08227014493927165, clf__learning_rate=invscaling, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.5467473202425025, clf__shuffle=True, clf__tol=0.9099604695658384, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.160 total time=   1.0s\n",
      "-- Epoch 1\n",
      "Norm: 0.40, NNZs: 15976, Bias: 0.000000, T: 1692, Avg. loss: 0.734350\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.56, NNZs: 15976, Bias: 0.000000, T: 3384, Avg. loss: 0.757901\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.68, NNZs: 15976, Bias: 0.000000, T: 5076, Avg. loss: 0.772880\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.79, NNZs: 15976, Bias: 0.000000, T: 6768, Avg. loss: 0.782790\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.87, NNZs: 15976, Bias: 0.000000, T: 8460, Avg. loss: 0.792553\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.95, NNZs: 15976, Bias: 0.000000, T: 10152, Avg. loss: 0.802841\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "[CV 2/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.28658617296069355, clf__eta0=0.03398405924608927, clf__fit_intercept=False, clf__l1_ratio=0.08227014493927165, clf__learning_rate=invscaling, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.5467473202425025, clf__shuffle=True, clf__tol=0.9099604695658384, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.143 total time=   0.9s\n",
      "-- Epoch 1\n",
      "Norm: 0.49, NNZs: 16412, Bias: 0.000000, T: 1692, Avg. loss: 0.756612\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.64, NNZs: 16412, Bias: 0.000000, T: 3384, Avg. loss: 0.778664\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.75, NNZs: 16412, Bias: 0.000000, T: 5076, Avg. loss: 0.791318\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.84, NNZs: 16412, Bias: 0.000000, T: 6768, Avg. loss: 0.805872\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.93, NNZs: 16412, Bias: 0.000000, T: 8460, Avg. loss: 0.814441\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.00, NNZs: 16412, Bias: 0.000000, T: 10152, Avg. loss: 0.825170\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "[CV 3/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.28658617296069355, clf__eta0=0.03398405924608927, clf__fit_intercept=False, clf__l1_ratio=0.08227014493927165, clf__learning_rate=invscaling, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.5467473202425025, clf__shuffle=True, clf__tol=0.9099604695658384, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.112 total time=   1.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.35, NNZs: 16259, Bias: 0.000000, T: 1692, Avg. loss: 0.727358\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.52, NNZs: 16259, Bias: 0.000000, T: 3384, Avg. loss: 0.759480\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.64, NNZs: 16259, Bias: 0.000000, T: 5076, Avg. loss: 0.775454\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.75, NNZs: 16259, Bias: 0.000000, T: 6768, Avg. loss: 0.787766\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.84, NNZs: 16259, Bias: 0.000000, T: 8460, Avg. loss: 0.798212\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.92, NNZs: 16259, Bias: 0.000000, T: 10152, Avg. loss: 0.807796\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "[CV 4/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.28658617296069355, clf__eta0=0.03398405924608927, clf__fit_intercept=False, clf__l1_ratio=0.08227014493927165, clf__learning_rate=invscaling, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.5467473202425025, clf__shuffle=True, clf__tol=0.9099604695658384, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.128 total time=   0.9s\n",
      "-- Epoch 1\n",
      "Norm: 0.44, NNZs: 15898, Bias: 0.000000, T: 1692, Avg. loss: 0.754092\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.58, NNZs: 15898, Bias: 0.000000, T: 3384, Avg. loss: 0.774614\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.68, NNZs: 15898, Bias: 0.000000, T: 5076, Avg. loss: 0.783099\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.76, NNZs: 15898, Bias: 0.000000, T: 6768, Avg. loss: 0.798283\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.84, NNZs: 15898, Bias: 0.000000, T: 8460, Avg. loss: 0.806636\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.90, NNZs: 15898, Bias: 0.000000, T: 10152, Avg. loss: 0.811825\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "[CV 5/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.28658617296069355, clf__eta0=0.03398405924608927, clf__fit_intercept=False, clf__l1_ratio=0.08227014493927165, clf__learning_rate=invscaling, clf__loss=epsilon_insensitive, clf__max_iter=60, clf__penalty=l2, clf__power_t=0.5467473202425025, clf__shuffle=True, clf__tol=0.9099604695658384, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.109 total time=   0.9s\n",
      "-- Epoch 1\n",
      "Norm: 42.36, NNZs: 15955, Bias: 0.000000, T: 1692, Avg. loss: 0.745999\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 47.40, NNZs: 15955, Bias: 0.000000, T: 3384, Avg. loss: 0.357566\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 47.35, NNZs: 15955, Bias: 0.000000, T: 5076, Avg. loss: 0.163314\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 45.36, NNZs: 15955, Bias: 0.000000, T: 6768, Avg. loss: 0.113583\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 44.37, NNZs: 15955, Bias: 0.000000, T: 8460, Avg. loss: 0.142451\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 42.65, NNZs: 15955, Bias: 0.000000, T: 10152, Avg. loss: 0.081862\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 42.30, NNZs: 15955, Bias: 0.000000, T: 11844, Avg. loss: 0.062813\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 41.92, NNZs: 15955, Bias: 0.000000, T: 13536, Avg. loss: 0.063239\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 41.56, NNZs: 15955, Bias: 0.000000, T: 15228, Avg. loss: 0.062481\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 41.22, NNZs: 15955, Bias: 0.000000, T: 16920, Avg. loss: 0.062081\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 40.89, NNZs: 15955, Bias: 0.000000, T: 18612, Avg. loss: 0.061944\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 40.83, NNZs: 15955, Bias: 0.000000, T: 20304, Avg. loss: 0.058839\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 40.77, NNZs: 15955, Bias: 0.000000, T: 21996, Avg. loss: 0.059483\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 40.70, NNZs: 15955, Bias: 0.000000, T: 23688, Avg. loss: 0.059957\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 40.64, NNZs: 15955, Bias: 0.000000, T: 25380, Avg. loss: 0.060307\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 40.58, NNZs: 15955, Bias: 0.000000, T: 27072, Avg. loss: 0.060569\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 40.57, NNZs: 15955, Bias: 0.000000, T: 28764, Avg. loss: 0.059973\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 40.56, NNZs: 15955, Bias: 0.000000, T: 30456, Avg. loss: 0.060044\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 40.54, NNZs: 15955, Bias: 0.000000, T: 32148, Avg. loss: 0.060111\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 40.53, NNZs: 15955, Bias: 0.000000, T: 33840, Avg. loss: 0.060174\n",
      "Total training time: 0.05 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.42493015701647596, clf__eta0=0.6773009699604285, clf__fit_intercept=False, clf__l1_ratio=0.7301998277223162, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.017782879504616322, clf__shuffle=False, clf__tol=0.19519881462597577, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.695 total time=   1.0s\n",
      "-- Epoch 1\n",
      "Norm: 41.40, NNZs: 15979, Bias: 0.000000, T: 1692, Avg. loss: 0.841834\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 43.34, NNZs: 15979, Bias: 0.000000, T: 3384, Avg. loss: 0.287261\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 44.60, NNZs: 15979, Bias: 0.000000, T: 5076, Avg. loss: 0.207921\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 43.08, NNZs: 15979, Bias: 0.000000, T: 6768, Avg. loss: 0.102306\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 41.52, NNZs: 15979, Bias: 0.000000, T: 8460, Avg. loss: 0.077585\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 40.20, NNZs: 15979, Bias: 0.000000, T: 10152, Avg. loss: 0.070325\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 39.89, NNZs: 15979, Bias: 0.000000, T: 11844, Avg. loss: 0.068497\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 39.62, NNZs: 15979, Bias: 0.000000, T: 13536, Avg. loss: 0.064454\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 39.37, NNZs: 15979, Bias: 0.000000, T: 15228, Avg. loss: 0.063955\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 39.14, NNZs: 15979, Bias: 0.000000, T: 16920, Avg. loss: 0.064140\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 38.92, NNZs: 15979, Bias: 0.000000, T: 18612, Avg. loss: 0.064478\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 38.88, NNZs: 15979, Bias: 0.000000, T: 20304, Avg. loss: 0.064736\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 38.83, NNZs: 15979, Bias: 0.000000, T: 21996, Avg. loss: 0.064479\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 38.79, NNZs: 15979, Bias: 0.000000, T: 23688, Avg. loss: 0.064318\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 38.75, NNZs: 15979, Bias: 0.000000, T: 25380, Avg. loss: 0.064227\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 38.71, NNZs: 15979, Bias: 0.000000, T: 27072, Avg. loss: 0.064185\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 38.70, NNZs: 15979, Bias: 0.000000, T: 28764, Avg. loss: 0.064165\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 38.69, NNZs: 15979, Bias: 0.000000, T: 30456, Avg. loss: 0.064151\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 38.68, NNZs: 15979, Bias: 0.000000, T: 32148, Avg. loss: 0.064140\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 38.67, NNZs: 15979, Bias: 0.000000, T: 33840, Avg. loss: 0.064130\n",
      "Total training time: 0.05 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.42493015701647596, clf__eta0=0.6773009699604285, clf__fit_intercept=False, clf__l1_ratio=0.7301998277223162, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.017782879504616322, clf__shuffle=False, clf__tol=0.19519881462597577, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.561 total time=   1.0s\n",
      "-- Epoch 1\n",
      "Norm: 39.19, NNZs: 16411, Bias: 0.000000, T: 1692, Avg. loss: 0.813075\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 42.94, NNZs: 16411, Bias: 0.000000, T: 3384, Avg. loss: 0.235980\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 42.69, NNZs: 16411, Bias: 0.000000, T: 5076, Avg. loss: 0.142817\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 41.17, NNZs: 16411, Bias: 0.000000, T: 6768, Avg. loss: 0.093065\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 39.96, NNZs: 16411, Bias: 0.000000, T: 8460, Avg. loss: 0.078322\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 38.92, NNZs: 16411, Bias: 0.000000, T: 10152, Avg. loss: 0.072227\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 38.67, NNZs: 16411, Bias: 0.000000, T: 11844, Avg. loss: 0.067736\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 38.45, NNZs: 16411, Bias: 0.000000, T: 13536, Avg. loss: 0.067070\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 38.23, NNZs: 16411, Bias: 0.000000, T: 15228, Avg. loss: 0.066829\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 38.03, NNZs: 16411, Bias: 0.000000, T: 16920, Avg. loss: 0.066737\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 37.84, NNZs: 16411, Bias: 0.000000, T: 18612, Avg. loss: 0.066737\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 37.81, NNZs: 16411, Bias: 0.000000, T: 20304, Avg. loss: 0.064390\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 37.77, NNZs: 16411, Bias: 0.000000, T: 21996, Avg. loss: 0.064823\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 37.73, NNZs: 16411, Bias: 0.000000, T: 23688, Avg. loss: 0.065124\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 37.69, NNZs: 16411, Bias: 0.000000, T: 25380, Avg. loss: 0.065335\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 37.66, NNZs: 16411, Bias: 0.000000, T: 27072, Avg. loss: 0.065485\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 37.65, NNZs: 16411, Bias: 0.000000, T: 28764, Avg. loss: 0.065046\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 37.64, NNZs: 16411, Bias: 0.000000, T: 30456, Avg. loss: 0.065087\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 37.64, NNZs: 16411, Bias: 0.000000, T: 32148, Avg. loss: 0.065126\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 37.63, NNZs: 16411, Bias: 0.000000, T: 33840, Avg. loss: 0.065162\n",
      "Total training time: 0.05 seconds.\n",
      "[CV 3/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.42493015701647596, clf__eta0=0.6773009699604285, clf__fit_intercept=False, clf__l1_ratio=0.7301998277223162, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.017782879504616322, clf__shuffle=False, clf__tol=0.19519881462597577, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.667 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 44.65, NNZs: 16258, Bias: 0.000000, T: 1692, Avg. loss: 0.749191\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 46.67, NNZs: 16258, Bias: 0.000000, T: 3384, Avg. loss: 0.334475\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 48.30, NNZs: 16258, Bias: 0.000000, T: 5076, Avg. loss: 0.253952\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 48.73, NNZs: 16258, Bias: 0.000000, T: 6768, Avg. loss: 0.178092\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 46.04, NNZs: 16258, Bias: 0.000000, T: 8460, Avg. loss: 0.082572\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 43.74, NNZs: 16258, Bias: 0.000000, T: 10152, Avg. loss: 0.066176\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 43.31, NNZs: 16258, Bias: 0.000000, T: 11844, Avg. loss: 0.059944\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 42.89, NNZs: 16258, Bias: 0.000000, T: 13536, Avg. loss: 0.061639\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 42.48, NNZs: 16258, Bias: 0.000000, T: 15228, Avg. loss: 0.061855\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 42.10, NNZs: 16258, Bias: 0.000000, T: 16920, Avg. loss: 0.061959\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 41.73, NNZs: 16258, Bias: 0.000000, T: 18612, Avg. loss: 0.062103\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 41.66, NNZs: 16258, Bias: 0.000000, T: 20304, Avg. loss: 0.060114\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 41.58, NNZs: 16258, Bias: 0.000000, T: 21996, Avg. loss: 0.060519\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 41.51, NNZs: 16258, Bias: 0.000000, T: 23688, Avg. loss: 0.060813\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 41.44, NNZs: 16258, Bias: 0.000000, T: 25380, Avg. loss: 0.061031\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 41.37, NNZs: 16258, Bias: 0.000000, T: 27072, Avg. loss: 0.061196\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 41.36, NNZs: 16258, Bias: 0.000000, T: 28764, Avg. loss: 0.060929\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 41.34, NNZs: 16258, Bias: 0.000000, T: 30456, Avg. loss: 0.060963\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 41.33, NNZs: 16258, Bias: 0.000000, T: 32148, Avg. loss: 0.060996\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 41.31, NNZs: 16258, Bias: 0.000000, T: 33840, Avg. loss: 0.061028\n",
      "Total training time: 0.05 seconds.\n",
      "[CV 4/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.42493015701647596, clf__eta0=0.6773009699604285, clf__fit_intercept=False, clf__l1_ratio=0.7301998277223162, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.017782879504616322, clf__shuffle=False, clf__tol=0.19519881462597577, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.556 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 43.70, NNZs: 15894, Bias: 0.000000, T: 1692, Avg. loss: 0.785658\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 42.96, NNZs: 15894, Bias: 0.000000, T: 3384, Avg. loss: 0.231927\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 43.37, NNZs: 15894, Bias: 0.000000, T: 5076, Avg. loss: 0.133720\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 42.01, NNZs: 15894, Bias: 0.000000, T: 6768, Avg. loss: 0.089134\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 40.64, NNZs: 15894, Bias: 0.000000, T: 8460, Avg. loss: 0.076629\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 39.49, NNZs: 15894, Bias: 0.000000, T: 10152, Avg. loss: 0.072297\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 38.60, NNZs: 15894, Bias: 0.000000, T: 11844, Avg. loss: 0.070866\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 38.40, NNZs: 15894, Bias: 0.000000, T: 13536, Avg. loss: 0.064518\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 38.21, NNZs: 15894, Bias: 0.000000, T: 15228, Avg. loss: 0.065815\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 38.02, NNZs: 15894, Bias: 0.000000, T: 16920, Avg. loss: 0.066064\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 37.85, NNZs: 15894, Bias: 0.000000, T: 18612, Avg. loss: 0.066218\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 37.69, NNZs: 15894, Bias: 0.000000, T: 20304, Avg. loss: 0.066399\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 37.66, NNZs: 15894, Bias: 0.000000, T: 21996, Avg. loss: 0.064485\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 37.62, NNZs: 15894, Bias: 0.000000, T: 23688, Avg. loss: 0.064823\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 37.59, NNZs: 15894, Bias: 0.000000, T: 25380, Avg. loss: 0.065076\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 37.56, NNZs: 15894, Bias: 0.000000, T: 27072, Avg. loss: 0.065269\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 37.53, NNZs: 15894, Bias: 0.000000, T: 28764, Avg. loss: 0.065420\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 37.52, NNZs: 15894, Bias: 0.000000, T: 30456, Avg. loss: 0.065103\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 37.52, NNZs: 15894, Bias: 0.000000, T: 32148, Avg. loss: 0.065138\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 37.51, NNZs: 15894, Bias: 0.000000, T: 33840, Avg. loss: 0.065171\n",
      "Total training time: 0.05 seconds.\n",
      "[CV 5/5] END clf__average=True, clf__class_weight=balanced, clf__epsilon=0.42493015701647596, clf__eta0=0.6773009699604285, clf__fit_intercept=False, clf__l1_ratio=0.7301998277223162, clf__learning_rate=adaptive, clf__loss=log_loss, clf__max_iter=20, clf__penalty=l2, clf__power_t=0.017782879504616322, clf__shuffle=False, clf__tol=0.19519881462597577, clf__warm_start=False, tfidf__max_df=0.9, tfidf__min_df=5;, score=0.696 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjmuizelaar/miniconda3/envs/thesis_hielke/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 272.92, NNZs: 14503, Bias: -5.225586, T: 1692, Avg. loss: 7.265153\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 210.27, NNZs: 14731, Bias: -5.144568, T: 3384, Avg. loss: 1.900156\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 172.82, NNZs: 14877, Bias: -4.902050, T: 5076, Avg. loss: 0.452705\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 148.45, NNZs: 14904, Bias: -4.809943, T: 6768, Avg. loss: 0.612026\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 133.08, NNZs: 14908, Bias: -4.704384, T: 8460, Avg. loss: 0.388061\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 111.45, NNZs: 14928, Bias: -5.000153, T: 10152, Avg. loss: 0.077611\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "[CV 1/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.21123614325601048, clf__eta0=0.32979731781585486, clf__fit_intercept=True, clf__l1_ratio=0.4775095579144826, clf__learning_rate=optimal, clf__loss=perceptron, clf__max_iter=30, clf__penalty=l2, clf__power_t=0.6427671735097384, clf__shuffle=False, clf__tol=0.2651165400908262, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.661 total time=   0.9s\n",
      "-- Epoch 1\n",
      "Norm: 352.46, NNZs: 15204, Bias: -3.577721, T: 1692, Avg. loss: 8.593054\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 235.04, NNZs: 15350, Bias: -5.129998, T: 3384, Avg. loss: 1.626728\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 184.58, NNZs: 15399, Bias: -5.279069, T: 5076, Avg. loss: 1.107461\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 153.11, NNZs: 15399, Bias: -5.051799, T: 6768, Avg. loss: 0.071565\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 131.18, NNZs: 15408, Bias: -4.993923, T: 8460, Avg. loss: 0.195356\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 116.02, NNZs: 15408, Bias: -4.889317, T: 10152, Avg. loss: 0.168331\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "[CV 2/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.21123614325601048, clf__eta0=0.32979731781585486, clf__fit_intercept=True, clf__l1_ratio=0.4775095579144826, clf__learning_rate=optimal, clf__loss=perceptron, clf__max_iter=30, clf__penalty=l2, clf__power_t=0.6427671735097384, clf__shuffle=False, clf__tol=0.2651165400908262, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.580 total time=   0.9s\n",
      "-- Epoch 1\n",
      "Norm: 304.60, NNZs: 14889, Bias: -2.434785, T: 1692, Avg. loss: 6.341882\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 226.15, NNZs: 15131, Bias: -2.981560, T: 3384, Avg. loss: 2.283333\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 172.84, NNZs: 15201, Bias: -3.695645, T: 5076, Avg. loss: 1.785730\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 146.97, NNZs: 15205, Bias: -3.553463, T: 6768, Avg. loss: 0.563461\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 129.96, NNZs: 15218, Bias: -3.584436, T: 8460, Avg. loss: 0.553985\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 114.31, NNZs: 15218, Bias: -3.582724, T: 10152, Avg. loss: 0.172830\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "[CV 3/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.21123614325601048, clf__eta0=0.32979731781585486, clf__fit_intercept=True, clf__l1_ratio=0.4775095579144826, clf__learning_rate=optimal, clf__loss=perceptron, clf__max_iter=30, clf__penalty=l2, clf__power_t=0.6427671735097384, clf__shuffle=False, clf__tol=0.2651165400908262, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.564 total time=   0.9s\n",
      "-- Epoch 1\n",
      "Norm: 306.76, NNZs: 14927, Bias: -3.661207, T: 1692, Avg. loss: 5.885367\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 226.84, NNZs: 15318, Bias: -4.757408, T: 3384, Avg. loss: 1.866508\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 187.14, NNZs: 15449, Bias: -4.822084, T: 5076, Avg. loss: 1.170315\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 150.88, NNZs: 15468, Bias: -4.984767, T: 6768, Avg. loss: 0.343325\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 135.70, NNZs: 15469, Bias: -4.689440, T: 8460, Avg. loss: 0.298919\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 118.40, NNZs: 15478, Bias: -4.730502, T: 10152, Avg. loss: 0.248017\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "[CV 4/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.21123614325601048, clf__eta0=0.32979731781585486, clf__fit_intercept=True, clf__l1_ratio=0.4775095579144826, clf__learning_rate=optimal, clf__loss=perceptron, clf__max_iter=30, clf__penalty=l2, clf__power_t=0.6427671735097384, clf__shuffle=False, clf__tol=0.2651165400908262, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.614 total time=   0.9s\n",
      "-- Epoch 1\n",
      "Norm: 322.00, NNZs: 14833, Bias: -4.042467, T: 1692, Avg. loss: 5.919087\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 224.15, NNZs: 15016, Bias: -4.423235, T: 3384, Avg. loss: 1.111493\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 181.43, NNZs: 15110, Bias: -4.582761, T: 5076, Avg. loss: 0.637955\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 152.49, NNZs: 15182, Bias: -4.897967, T: 6768, Avg. loss: 0.709070\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 134.57, NNZs: 15216, Bias: -5.028923, T: 8460, Avg. loss: 0.564352\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 118.20, NNZs: 15219, Bias: -5.014851, T: 10152, Avg. loss: 0.176988\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "[CV 5/5] END clf__average=False, clf__class_weight=balanced, clf__epsilon=0.21123614325601048, clf__eta0=0.32979731781585486, clf__fit_intercept=True, clf__l1_ratio=0.4775095579144826, clf__learning_rate=optimal, clf__loss=perceptron, clf__max_iter=30, clf__penalty=l2, clf__power_t=0.6427671735097384, clf__shuffle=False, clf__tol=0.2651165400908262, clf__warm_start=True, tfidf__max_df=0.95, tfidf__min_df=5;, score=0.592 total time=   0.9s\n",
      "-- Epoch 1\n",
      "Norm: 102.19, NNZs: 7947, Bias: 0.000000, T: 2115, Avg. loss: 1.665702\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 112.01, NNZs: 4606, Bias: 0.000000, T: 4230, Avg. loss: 0.586027\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 132.57, NNZs: 4106, Bias: 0.000000, T: 6345, Avg. loss: 0.597119\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 147.21, NNZs: 3621, Bias: 0.000000, T: 8460, Avg. loss: 0.339660\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 156.62, NNZs: 3165, Bias: 0.000000, T: 10575, Avg. loss: 0.161061\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 160.80, NNZs: 2682, Bias: 0.000000, T: 12690, Avg. loss: 0.232927\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "0.9824468085106383\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEGCAYAAABPdROvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAAm6UlEQVR4nO3de7hd073/8fcnCZIIJUJOrkIbKrRSCaUuVTTBaYtTilJ1OO56U+2hp61b/XqjTrVE43JQ6t6Wti5xOa1yEiRECEJISCKkSUiaIJK9v78/5tjJtLP22muvtXfmvnxezzMfc4015hhjrhXru8cYc46piMDMzKxa3YpugJmZdWwOJGZmVhMHEjMzq4kDiZmZ1cSBxMzMatKj6AZY2+jXt3sMG7Je0c2wFnhxWu+im2At8B7LeT9WqJYyxn5mw1i0uK6ivFOmrbgvIvavpb624kDSSQ0bsh6P3zek6GZYC4wd9Imim2At8Fj9AzWXsXBxHY/dN7iivOsNeLlfzRW2EQcSM7PCBHVRX3QjauZAYmZWkADq6fg3hTuQmJkVqB73SMzMrEpBsNJDW2ZmVq0A6jrB0JbvIzEzK1A9UdHWHEnXSFog6dlc2i2SpqZttqSpKX2YpHdz712RO2aUpGckzZR0qaRmL3F2j8TMrCAB1LXeCuzXAr8Grl9dfsThDfuSLgaW5PK/HBEjS5QzDjgBeAy4G9gfuKdcxe6RmJkVqL7CrTkR8TCwuNR7qVfxJeCmcmVIGgBsHBGTInvGyPXAwc3V7UBiZlaQIKircKvRnsCbEfFSLm0rSU9J+pukPVPaIGBuLs/clFaWh7bMzAoSASsrjxH9JE3OvR4fEeMrPPZIPtgbmQ8MjYhFkkYBf5S0fcUtacSBxMysMKKOipfrWhgRo1tcg9QD+DdgVENaRKwAVqT9KZJeBrYB5gH5NVsGp7SyPLRlZlaQAOqjsq0G+wEvRMTqIStJm0vqnva3BoYDr0TEfGCppF3TvMoxwJ3NVeBAYmZWoLrUK2lua46km4CJwLaS5ko6Pr11BGtPsu8FTEuXA98OnBwRDRP1pwJXATOBl2nmii3w0JaZWWGyGxJrWol+TVkRRzaRfmyJtDuAO5rIPxnYoSV1O5CYmRUkgJXR8QeGHEjMzAoSiLpOMMPgQGJmVqD6aJ2hrSI5kJiZFaQ150iK5EBiZlYYUec5EjMzq1b2hEQHEjMzq1KEeD+6F92MmjmQmJkVqN5zJGZmVq1sst1DW2ZmVjVPtpuZWQ082W5mZjWr8w2JZmZWrUCsjI7/M9zxz8DMrIPyZLuZmdUkkIe2zMysNp5sNzOzqkXgy3/NzKx62WS7l0gxM7MaeLLdzMyqFsgPtjIzs9p0hh5Jxz8DM7MOKoD66FbR1hxJ10haIOnZXNq5kuZJmpq2A3PvnS1ppqQZksbm0vdPaTMlnVXJeTiQmJkVRtRVuFXgWmD/EumXRMTItN0NIGkEcASwfTrmckndJXUHLgMOAEYAR6a8ZXloy8ysIAGtdtVWRDwsaViF2Q8Cbo6IFcAsSTOBXdJ7MyPiFQBJN6e8z5UrzD0SM7OCRKglQ1v9JE3ObSdWWM3pkqaloa9NU9ogYE4uz9yU1lR6We6RmJkVqAU3JC6MiNEtLH4ccAFZ5+cC4GLguBaW0SwHEjOzgmTPI2m7y38j4s2GfUlXAn9OL+cBQ3JZB6c0yqQ3yUNbZmaFyZ6QWMlWVenSgNzLQ4CGK7ruAo6QtIGkrYDhwOPAE8BwSVtJWp9sQv6u5upxj8TMrCDZ5b+t0yORdBOwN9lcylzgHGBvSSNTVbOBkwAiYrqkW8km0VcBp0VEXSrndOA+oDtwTURMb65uBxIzs4K05lpbEXFkieSry+S/ELiwRPrdwN0tqduBxMysQF5G3szMqpYtI++1tszMrAZetNHMzKqWrf7roS0zM6tStkSKA4lZTS7+1hAee2BjNum3ivH/OwOAl5/txaVnDeb997rRvUdw+o/n8tFPvMP/3bsx1/98ABJ07xGcfN48dvjkcgAWzF2PS84cwj9eXx8JLrjhFf5lyPtFnlqXs/nA9/nOL19jk34rIcTdN27GH6/enI02WcX3xs2m/5D3eXPO+lx48jCWLfFPT6Zz9EjazRlI6i/pd5JekTRF0kRJhxTdrjxJw/JLNFdZxmhJl6b9cyWd2Tqt65jGHL6YC2985QNpV/1oAEef8QbjHpjBMd+Zz9U/GgjAJ/ZcxrgHZjDugRmc8YvXuOTMNTfg/vwbW3LoKQu46uEXuPTuF9lks5Xr9DwM6laJ8ecN5MTPbMc3Pj+czx+7kKHD3+NLpy3gqUc24rg9RvDUIxtx+GkLim5qu1KPKtras3YRSCQJ+CPwcERsHRGjyO6oHFxow6qUlmIuKSImR8TX27KOjuRjuy5no03rPpAmwfJ/Zqe3fGl3+vbPgkKvDetR+v/pvXe6rd5/9cUNqFsFoz69bHW+nr1j3ZyArbZ4wXrMfLY3AO8u786clzag37+sZLexS3jgtr4APHBbX3bbf0mRzWxXGq7aqmRrz9pFIAH2Ad6PiCsaEiLi1Yj4FWQ/mpJ+LumJtIrlSQ35JH0nl35eShsm6XlJV0qaLmmCpF6NK5X0YUmTJD0j6UeSlpUrN+kh6cZU/u2Seqf8syX9VNKTwGGS/ippdHqvn6TZaX9vSX+mEUknSLpHUi9JR0t6PD2I5jcNQUPSMkkXS3oa2K2Gz7tdO/n8eVx1wUCOGjWCKy8YyHHfe331e4/e8yGO3/Oj/OCYrTnjF68BMO/lnmz4oTrOP34Yp352G648fyB1dU2VbutC/8Er+PAO7/LCU73ZtN9KFi9YD4DFC3qwaT/3FvNa68FWRWovrdseeLLM+8cDSyJiZ2Bn4IS0FswYsjVidgFGAqMk7ZWOGQ5cFhHbA28DXyxR7i+BX0bEx8iWSwagmXK3BS6PiO2ApcCpufIWRcROEXFzpSee6jsd+BxwMDAMOBzYPSJGAnXAUSnrhsBjEbFjRDxSopwTG5aY/seijvtL+ufr+nHSefO4ccpznHTu6/zijKGr39v9gCVc/fcXOPeaWVz3s2wZobo6ePaxPpzww9f51T0vMv+19bn/lr5FNb/L69m7jh9cOZsrzhnEO8sad5xFtPO/rtelhme2V7K1Z+0lkHyApMskPS3piZQ0BjhG0lTgMWAzsh/6MWl7iiwQfTSlA8yKiKlpfwrZD3RjuwG3pf3f5dLLlTsnIh5N+zcAe+SOu6Ul55kcQ/Y0skPTQ2b2BUYBT6Tz3RfYOuWtA+5oqqCIGB8RoyNi9OabddyRr/tv68seB2bDH3t9/m1enNp7rTwf23U5b7y2PksWdaffgJV8ePt3GbDl+3TvAZ/afwkzn1mrA2rrQPcewQ+unM1Df9iUR+/ZBIC3Fq5H3y2yXkjfLVby9iJPtDcIYFV0q2hrz9pL66YDOzW8iIjTyH5AN09JAr6We1zkVhExIaX/OJf+kYhoWFtmRa78Olp2hVq5chsPvudfL8/tr2LN59uzTF3PkAW5hvkgAdfl6t42Is5N773XsLBaZ7ZZ/5VMm9gHgKmP9GHgVtlXOW/W+kT6tF+a1ouV74uN+9axzch3WLa0O28v6r76mKHbrChZtrWl4IyLX2POzA34/fgtVqdOmrAx+x22GID9DlvMxPs+VFQD26XOMLTVXv40eAj4f5JOiYhxKS3/Z+h9wCmSHoqIlZK2IVsj/z7gAkk3RsQySYOAlgzATiIb8rqFbHI/X19T5Q6VtFtETAS+DKw1xJTMJutZPA4cWqYNT5E9fOYuSWOBB4E7JV0SEQsk9QU2iohXW3BeHcaPT9mSaRP7sGRxD44aNYKvfPsNvvnzOYz74SDq6sT6G9TzzZ9nD2x75C+b8MDtm9KjB2zQq57vjXs1uxS4O5zwg3mc9aWPEAHDP/4uBxy1qOAz63q233k5+x36Fq8815PLJ7wAwP/8ZCC3XNaf/7piNvsfuYgFc7PLfy3pAMNWlWgXgSQiQtLBwCWSvgv8g+yv+/9MWa4i+6v9yXSF1z+AgyNigqTtgIlZMsuAo8l6IJX4JnCDpP8C7gWWpPaUK3cGcJqka8iWYB5XolyAi4Bb0+Mw/9LM+T+SLgP+C/BZ4PvABEndyALYaUCnDCRnjyt9Wpfd9+JaaYefvoDDTy996eioTy9j1IMzWrVt1jLTn+jD2EEjS7531uEfWbeN6SDa+sFW64oiuu5lkumKq3dTIDsCODIiDiq6Xa1h9I494/H7hjSf0dqNsYM+UXQTrAUeq3+ApbG4piiw6Ue3iL2vPqyivH/c4/IpVTxqd51oFz2SAo0Cfp16OW/TBs8yNjNrSms+2KpIXTqQRMTfgR2LboeZdU2BWFXfvifSK9GlA4mZWdE6wxyJA4mZWVHCQ1tmZlYDz5GYmVnNOkMg6fizPGZmHVQg6uq7VbQ1R9I1khbkH3WRFrt9IS0++wdJm6T0YZLeTQvDTpV0Re6YUWkh25mSLk1XtZblQGJmVqBWfB7JtcD+jdLuB3aIiI8DLwJn5957ObcU08m59HHACWTrCw4vUeZaHEjMzAoSabK9NVb/jYiHgcWN0iZExKr0chLNPONJ0gBg44iYFNnd6teTrUpelgOJmVmBIlTRBvRreExE2k5sYVXHAffkXm8l6SlJf5O0Z0obRO6RGml/UHMFe7LdzKwwLVq0cWG1S6Sk9QRXATempPnA0IhYJGkU8EdJ21dTNjiQmJkVqq0f9CXpWLIH5+2bhqtIzz5akfanSHoZaFhVPT/8NTilleWhLTOzgkRAXb0q2qohaX/gu8AXIuKdXPrmuUd4b002qf5KRMwHlkraNV2tdQxwZ3P1uEdiZlag1loiRdJNwN5kcylzgXPIrtLaALg/XcU7KV2htRdwvqSVQD1wckQ0TNSfSnYFWC+yOZX8vEpJDiRmZgUJWm9oKyKOLJF8dYk0IuIOmnhsd0RMBnZoSd0OJGZmhfETEs3MrEad4dmCDiRmZgVq66u21gUHEjOzgmRXbXX8i2cdSMzMCuShLTMzq4mHtszMrGqBHEjMzKw2nWBky4HEzKwwAVHl8iftiQOJmVmBPLRlZmY16dRXbUn6FWWG7yLi623SIjOzLqI119oqUrkeyeR11gozs64ogM4cSCLiuvxrSb3z69mbmVntOsPQVrP35kvaTdJzwAvp9Y6SLm/zlpmZdXoi6ivb2rNKFnn5b2AssAggIp4meyiKmZnVKirc2rGKrtqKiDnp6VoN6tqmOWZmXUh0/sn2BnMkfQoISesB3wCeb9tmmZl1Ee28t1GJSoa2TgZOAwYBrwMj02szM6uZKtzar2Z7JBGxEDhqHbTFzKzrqS+6AbWr5KqtrSX9SdI/JC2QdKekrddF48zMOrWG+0gq2dqxSoa2fgfcCgwABgK3ATe1ZaPMzLqKiMq25ki6Jv2x/2wura+k+yW9lP67aUqXpEslzZQ0TdJOuWO+mvK/JOmrlZxDJYGkd0T8NiJWpe0GoGclhZuZWTNa7/Lfa4H9G6WdBTwYEcOBB9NrgAOA4Wk7ERgHWeABzgE+CewCnNMQfMppMpCkSNYXuEfSWZKGSdpS0neBuys6LTMzK6+VhrYi4mFgcaPkg4CGVUquAw7OpV8fmUnAJpIGkN0zeH9ELI6It4D7WTs4raXcZPsUsjjYcAYn5dsMnN1c4WZmVp4qv/y3n6T8GojjI2J8M8f0j4j5af8NoH/aHwTMyeWbm9KaSi+r3FpbWzV3sJmZ1SAElS9/sjAiRlddVURILQhbLVDRne2SdgBGkJsbiYjr26JBZmZdStvekPimpAERMT8NXS1I6fOAIbl8g1PaPGDvRul/ba6SSi7/PQf4Vdo+A/wM+ELz7Tczs2a17VpbdwENV159Fbgzl35MunprV2BJGgK7DxgjadM0yT4mpZVVSY/kUGBH4KmI+HdJ/YEbWnYuZmZWUiv1SCTdRNab6CdpLtnVVz8BbpV0PPAq8KWU/W7gQGAm8A7w7wARsVjSBcATKd/5EdF4An8tlQSSdyOiXtIqSRuTdY2GNHeQmZk1oxUfbBURRzbx1r4l8gZNLHUVEdcA17Sk7koCyWRJmwBXkl3JtQyY2JJKzMystLaZ/l63Kllr69S0e4Wke4GNI2Ja2zbLzKyL6MyBJH/LfKn3IuLJtmmSmVnX0dl7JBeXeS+AfVq5LdaKXpzWm7EDRxbdDGuRTvCLYi3XzhdkrES5GxI/sy4bYmbW5XSAx+hWoqIbEs3MrI04kJiZWS3UCR5s5UBiZlakTtAjqWSJFEk6WtIP0+uhknZp+6aZmXVuisq39qySB1tdDuwGNNw1+U/gsjZrkZlZV9IJHrVbydDWJyNiJ0lPAUTEW5LWb+N2mZl1De28t1GJSgLJSkndSacraXOgE0wPmZkVr70PW1WikkByKfAHYAtJF5KtBvz9Nm2VmVlXEF3kqq2IuFHSFLIVJAUcHBHPt3nLzMy6gq7QI5E0lGy9+j/l0yLitbZsmJlZl9AVAgnwF7JTFdmjdrcCZgDbt2G7zMy6hC4xRxIRH8u/TqsCn9pEdjMz62JafGd7RDwp6ZNt0Rgzsy6nK/RIJJ2Re9kN2Al4vc1aZGbWVXSVq7aAjXL7q8jmTO5om+aYmXUxnb1Hkm5E3CgizlxH7TEz6zJE55hsb3KtLUk9IqIO2H0dtsfMrGuJCrcyJG0raWpuWyrpm5LOlTQvl35g7pizJc2UNEPS2FpOoVyP5HGy+ZCpku4CbgOWN7wZEb+vpWIzsy6vlVb2jYgZwEhYPZI0j2xFkn8HLomIi/L5JY0AjiC7jWMg8ICkbVLnocUqmSPpCSwie0Z7w/0kATiQmJnVqvUn2/cFXo6IV6UmVw0+CLg5IlYAsyTNBHYBJlZTYblAskW6YutZ1gSQBp1gVM/MrHgt6JH0kzQ593p8RIwvke8I4Kbc69MlHQNMBr4dEW8Bg4BJuTxzU1pVygWS7kAfPhhAGjiQmJm1hsp/TRdGxOhyGdIjPr4AnJ2SxgEXpFouAC4GjquqnWWUCyTzI+L81q7QzMySCibSW+gA4MmIeBOg4b8Akq4E/pxezgOG5I4bnNKqUu4Jie37kVxmZp1AKz9q90hyw1qSBuTeO4RsqgLgLuAISRtI2goYTnaBVVXK9Uj2rbZQMzOrUCv1SCRtCHwWOCmX/DNJI1Mtsxvei4jpkm4FniO70fy0aq/YgjKBJCIWV1uomZlVprWWSImI5cBmjdK+Uib/hcCFrVF3ixdtNDOzVtL6cySFcCAxMyuI6ByT0Q4kZmZFco/EzMxq0RkWbXQgMTMrkgOJmZlVrQs92MrMzNqKeyRmZlYLz5GYmVltHEjMzKwW7pGYmVn1grZ4sNU650BiZlYQ4R6JmZnVyoHEzMxqoej4kcSBxMysKF7918zMauU5EjMzq4mXSDEzs9q4R2JmZlULD22ZmVmtOkEg6VZ0A8zMuqqGGxIr2ZotS5ot6RlJUyVNTml9Jd0v6aX0301TuiRdKmmmpGmSdqrlPBxIzMwKpPqoaKvQZyJiZESMTq/PAh6MiOHAg+k1wAHA8LSdCIyr5RwcSMzMihIt2KpzEHBd2r8OODiXfn1kJgGbSBpQbSWeI7F264xfvMYn9/snby/swUn7bAvAMd+Zz25jlxIBby/swUXfHMriN9cruKUGpb+vPT/3Nl/59hsMGb6Crx84nJem9S64le1PK17+G8AESQH8JiLGA/0jYn56/w2gf9ofBMzJHTs3pc2nCm3WI5G0rNHrYyX9upljBkq6vYn3/ippdNq/W9ImrdbYFmh8XlUcv/ocK/lMurIJt/Tlv47a6gNpt4/bglP225ZTP7stjz2wMUd/682CWmeNlfq+Zr/Qk/P/YxjPTNqwoFZ1AJX3SPpJmpzbTmxU0h4RsRPZsNVpkvb6QDURbXYffbvqkUTE68ChFeQ7cB00p2qSekTEqlLvVXqOFdTRPSLqai2nPXv2sT70H/z+B9LeWdZ99X7PXvV0gmWKOo1S39ecmT0Lak3H0YLLfxfm5j7WEhHz0n8XSPoDsAvwpqQBETE/DV0tSNnnAUNyhw9OaVUpZI5E0rWSDs29Xpb+O0zSs2m/l6SbJT2fPpReufyzJfVL+z+QNEPSI5JuknRmSv+wpHslTZH0d0kfLdGOzdOVDNMlXSXp1Vy5R0t6PF0B8RtJ3XPHXZKOeVDS5intr5L+O10t8Y1KzrFRW/5V0kRJ/SSNSftPSrpNUp/cef9U0pPAYTV8BR3asf85nxsmP8c+//Y21//8X4pujln1AoiobCtD0oaSNmrYB8YAzwJ3AV9N2b4K3Jn27wKOSVdv7QosyQ2BtVhbBpJe6Ud4qqSpwPktPP4U4J2I2A44BxjVOIOknYEvAjuSdefy0Xo88LWIGAWcCVxeoo5zgIciYnvgdmBoKnc74HBg94gYCdQBR6VjNgQmp2P+lsposH5EjI6Ii1tyopIOIbuaoqGn9X1gv9RNnQyckcu+KCJ2ioibS5RzYkO3dyUrWtKEDuXanw7g6NEjeOj3m/CF4xYW3Ryzmqi+sq0Z/YFHJD0NPA78JSLuBX4CfFbSS8B+6TXA3cArwEzgSuDUWs6hLYe23k0/wkA2H8AHf+ibsxdwKUBETJM0rUSe3YE7I+I94D1Jf0p19QE+BdwmqSHvBiWO3wM4JNVxr6S3Uvq+ZIHriXR8L9Z0CeuBW9L+DcDvc+XdQsvtQ/a5jImIpZI+B4wAHk11rw9MrKSONLk2HmBj9e30gz4P/WFTfvTbWfz2IvdKrGNqrQdbRcQrZH9QN05fRPZ71jg9gNNqrzlT1BzJKlJvSFI3sh/L1tQNeDsfyFpIwHURcXYFefP/DJbn9is9x5eBrYFtyHofAu6PiCObyL+8ifQuYeBWK3h9VvY3wW5jlzBnZqm/D8w6iAqGrTqCou4jmc2aoaovAKWu33wY+DKApB2Aj5fI8yjweUk9Uy/kcwARsRSYJemwdLwkrRWt0/FfSnnGAJum9AeBQyVtkd7rK2nL9F431kyWfxl4pIZzBHiVbHjueknbA5OA3SV9JNW9oaRtmji2Uzvr8le55E8vMfjD73HD5OcYe+Qijv/efH7z0AzGPTCDUZ9exrgfDiq6mZaU+r4+tf8Sbpj8HNuNeocLfjuLC3/3ctHNbHda6872IhXVI7kSuDON591L6b+yxwH/I+l54HlgSuMMEfGEpLuAacCbwDPAkvT2UcA4Sd8n+xG/GXi6URHnATdJ+grZ8NEbwD8jYmE6bkLqTawk6wa+mtq6S3p/AdlcSrXn2HAeL0g6CrgN+DxwbGpXw5/b3wdebOr4zuonp265Vtp9N21WQEusEqW+L4D/u/dD67glHUw7DxKVUHTwbpWkPhGxTFJvsl7MiRHxZIXHbgDURcQqSbsB42oYDmtXNlbf+KTWGho1s1byWDzI0lis5nM2baNNBsdOe36jorwP//m7U8pd/lukdnUfSZXGSxoB9CSb16goiCRDgVtTr+N94IS2aKCZWUkB1HXsP+ahEwSSiPhyDce+BHyiFZtjZtYi7X3+oxIdPpCYmXVoHXx6ARxIzMwK5R6JmZlVr82WUVy3HEjMzAoiQJ5sNzOzWshzJGZmVjUPbZmZWW06x1pbDiRmZgXyVVtmZlYb90jMzKxq4au2zMysVh0/jjiQmJkVyZf/mplZbRxIzMysagHUF92I2jmQmJkVRESnGNoq6pntZmYGUF9f2VaGpCGS/lfSc5KmS/pGSj9X0jxJU9N2YO6YsyXNlDRD0thaTsE9EjOzorTe0NYq4NsR8aSkjYApku5P710SERflM6enyh4BbA8MBB6QtE1E1FVTuXskZmYFUkRFWzkRMb/hMeMR8U/geWBQmUMOAm6OiBURMQuYCexS7Tk4kJiZFSmisg36SZqc204sVZykYWSPEH8sJZ0uaZqkayRtmtIGAXNyh82lfOApy4HEzKwwFQaRLJAsjIjRuW1849Ik9QHuAL4ZEUuBccCHgZHAfODitjgLz5GYmRUlgFZaIkXSemRB5MaI+D1ARLyZe/9K4M/p5TxgSO7wwSmtKu6RmJkVqDXmSCQJuBp4PiJ+kUsfkMt2CPBs2r8LOELSBpK2AoYDj1d7Du6RmJkVqXXuI9kd+ArwjKSpKe17wJGSRpL1fWYDJ2VVxnRJtwLPkV3xdVq1V2yBA4mZWXECqK89kETEI2SPgG/s7jLHXAhcWHPlOJCYmRXIT0g0M7NaOZCYmVnVAqjr+Ks2OpCYmRUmIBxIzMysFh7aMjOzqrXSVVtFcyAxMyuSeyRmZlYTBxIzM6taBNRVfUN5u+FAYmZWJPdIzMysJg4kZmZWvfBVW2ZmVoOA8A2JZmZWEy+RYmZmVYuAegcSMzOrhSfbzcysFuEeiZmZVc8PtjIzs1p40UYzM6tFAOElUszMrGrhB1uZmVmNwkNbZmZWk07QI1F0gisGbG2S/gG8WnQ72kA/YGHRjbAW6azf2ZYRsXktBUi6l+zzqcTCiNi/lvraigOJdSiSJkfE6KLbYZXzd9b5dSu6AWZm1rE5kJiZWU0cSKyjGV90A6zF/J11cp4jMTOzmrhHYmZmNXEgMTOzmjiQWEmS+kv6naRXJE2RNFHSIUW3K0/SMEnP1ljGaEmXpv1zJZ3ZOq1rO5KWNXp9rKRfN3PMQEm3N/HeXyWNTvt3S9qk1RrbAo3Pq4rjV59jJZ+JtR7f2W5rkSTgj8B1EfHllLYl8IUi21UtSd0jouTKeBExGZjclnW0BxHxOnBoBfkOXAfNqZqkHhGxqtR7lZ5jBXW06++yPXKPxErZB3g/Iq5oSIiIVyPiV5D9jybp55KekDRN0kkN+SR9J5d+XkobJul5SVdKmi5pgqRejSuV9GFJkyQ9I+lH+b9QS5Wb9JB0Yyr/dkm9U/7Zkn4q6UngsEZ/dfeTNDvt7y3pzyXacoKkeyT1knS0pMclTZX0G0ndU55lki6W9DSwWw2fd6uRdK2kQ3Ovl6X/ru69pXO6OX1mfwB65fLPltQv7f9A0gxJj0i6qaG3lr6ne1NP9e+SPlqiHZtLuj9931dJejVXbsnPM713STrmQUmbp7S/SvpvSZOBb1Ryjo3a8q+pR91P0pi0/6Sk2yT1yZ336n8vNXwFXZIDiZWyPfBkmfePB5ZExM7AzsAJkraSNAYYDuwCjARGSdorHTMcuCwitgfeBr5YotxfAr+MiI8BcxsSmyl3W+DyiNgOWAqcmitvUUTsFBE3V3riqb7Tgc8BBwPDgMOB3SNiJFAHHJWybgg8FhE7RsQjLamjRr3Sj/BUSVOB81t4/CnAO+kzOwcY1TiDpJ3JvqMdgQOA/J3p44GvRcQo4Ezg8hJ1nAM8lL7v24GhqdztKP95Tk7H/C2V0WD9iBgdERe35ESVDceeBTT0tL4P7BcRO5H1RM/IZa/q34t5aMsqIOkyYA+yXsrOwBjg47m/Cj9E9kM/Jm1PpfQ+Kf01YFZETE3pU8h+oBvbjezHG+B3wEVpv1y5cyLi0ZR+A/D13HG3tPhk4RhgDnBwRKyUtC/ZD+0T2YgfvYAFKW8dcEcVddTq3fQjDGTzAXzwh745ewGXAkTENEnTSuTZHbgzIt4D3pP0p1RXH+BTwG3p8wDYoMTxewCHpDrulfRWSi/3edaz5ju7Afh9rrxqvst9yD6XMRGxVNLngBHAo6nu9YGJNdZhOJBYadPJ9Rgi4rQ0LNEwlyCyv0jvyx8kaSzw44j4TaP0YcCKXFIdueGUCqhMuY1vhMq/Xp7bX8WaHnjPMnU9Q9brGQzMSnVfFxFnl8j7XjscS199npK6kf1YtqZuwNv5QNZC5T7Pxpr9Lps5x5eBrYFtyP7tCrg/Io5sIv/yJtKtGR7aslIeAnpKOiWX1ju3fx9wiqT1ACRtI2nDlH5cbtx5kKQtWlDvJNYEsCMa1ddUuUMlNcxPfBloaohpNmuGcMpNyD4FnATcJWkg8CBwaEN9kvoqu/CgvZrNmvP8ArBeiTwPk31WSNoB+HiJPI8Cn5fUM33unwOIiKXALEmHpeMlaccmjv9SyjMG2DSll/s8u7Hmu6n0u2zqHCFb/fqLwPWStif797W7pI+kujeUtE0Tx1oLOJDYWiJb7uBg4NOSZkl6HLgO+M+U5SrgOeDJNLn5G6BHREwgG5KaKOkZsrHxjVpQ9TeBM9JQy0eAJak95cqdAZwm6XmyH6txTZR9EVnwe4pmlu1O8x1nAn8hG3b5PjAhtet+YEALzmldu5Lse2u4AKDUX9njgD7pMzufbKjxAyLiCeAuYBpwD1lPbUl6+yjg+FTHdOCgEnWcB4xJ/z4OA94A/hkRz9H057kc2CUdsw9Nz/1Uco4N5/FCau9twMbAscBNqe6JwFoXCljLeYkUazeUXXH1bkSEpCOAIyOi1I+UrQOS+kTEsvS9PAycGBHlLsLIH7sBUBcRq1KPcVwNw2HWznmOxNqTUcCvlc2Evg0cV2xzurzxkkaQzSldV2kQSYYCt6Y5jPeBE9qigdY+uEdiZmY18RyJmZnVxIHEzMxq4kBiZmY1cSCxLklSXVpi5Nm05lLv5o9qsqzVaz8pW1dqRJm8e0v6VBV1rF4Dq5L0RnlatKquOsgqyNZ+OJBYV/VuRIyMiB3Irio6Of+mpKquaIyI/0j3SjRlb7IlRsw6DQcSM/g78JHUW/i7pLuA59TEKsfpbu5fK1sZ9wFg9d37+uAqw/srW2X2aWWr2Q4jC1jfSr2hPZWtkntHquMJSbunYzdTtkrydElXkS3vUZakPypbkXe6pBMbvVdqVd1mV/E1q4TvI7EuLfU8DgDuTUk7ATtExKz0Y7wkInZON9g9KmkC8AmyVYdHAP3J7vK/plG5m5Pdgb1XKqtvRCyWdAWwLCIuSvl+B1wSEY9IGkq2HEzDqryPRMT5kv6VbMXl5hyX6uhFtijiHRGxiDWr6n5L0g9T2aeTreJ7ckS8JOmTZKv47lPFx2hdnAOJdVW9lC3BDlmP5GqyIafHI2JWSm9qleO9gJvSgo2vS3qoRPm7Ag83lBURi5tox37ACK1ZSXfjtLbVXsC/pWP/ojWr55bzda15iuWQ1NZFlFhVV5Wv4mvWLAcS66rebbxkR/pBza/b1NQqx635FMFuwK5pufbGbamYpL3JgtJuEfGOpL/S9CrHQe2r+Jqt5jkSs6Y1tcrxw8DhaQ5lAPCZEsdOAvaStFU6tm9K/ycfXMhyAvC1hheSRqbd/Aq9B7Bm9dymfAh4KwWRj5L1iBqstapuC1bxNWuWA4lZ00qucgz8AXgpvXc9H3w4EgAR8Q/gRLJhpKdZM7T0J+CQhsl2sgdxjU6T+c+x5uqx88gC0XSyIa7XmmnrvWSPHX4e+AlZIGvQ1Kq6lazia9Ysr7VlZmY1cY/EzMxq4kBiZmY1cSAxM7OaOJCYmVlNHEjMzKwmDiRmZlYTBxIzM6vJ/wdFwEPTapQU3AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "   Geen gebruiker       0.99      0.99      0.99      1856\n",
      "Huidige gebruiker       0.35      0.46      0.40        24\n",
      "\n",
      "         accuracy                           0.98      1880\n",
      "        macro avg       0.67      0.72      0.70      1880\n",
      "     weighted avg       0.98      0.98      0.98      1880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ngram 2 Stopwords kept\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1,2), lowercase=True, token_pattern=r\"(?u)\\b\\w\\w+\\b|\\+|\\-\")),\n",
    "    ('clf', SGDClassifier(early_stopping=True, n_iter_no_change=5, validation_fraction = 0.25, verbose=3)),\n",
    "])\n",
    "random_search = RandomizedSearchCV(estimator=pipeline, param_distributions=parameter_grid, random_state=500, verbose=3, scoring='f1_macro')\n",
    "random_search.fit(X_train, y_train)  \n",
    "predicted_nb = random_search.predict(X_test)\n",
    "print(np.mean(predicted_nb == y_test))\n",
    "cm = confusion_matrix(y_test, predicted_nb)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=random_search.classes_)\n",
    "disp.plot()\n",
    "\n",
    "plt.show()\n",
    "print(metrics.classification_report(y_test, predicted_nb,\n",
    "    target_names=random_search.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d06b68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (thesis_hielke)",
   "language": "python",
   "name": "thesis_hielke"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
