{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d869a690",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import sklearn\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy.stats import uniform as sp_randFloat\n",
    "from scipy.stats import randint as sp_randInt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import pickle\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bd1a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_labels = pd.read_csv('../input_data/full_datasets/fully_labelled_texts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d48a2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"dutch\")\n",
    "np.random.seed(500)\n",
    "\n",
    "def create_preprocess_corpus(input_corpus, content_name, label_name, smoking=False, second_experiment=False, skip_rows=[]):\n",
    "    corpus = input_corpus[['Unnamed: 0', content_name, label_name]]\n",
    "    corpus = corpus.rename({content_name:'text', label_name: 'label'}, axis=1)\n",
    "    corpus['processed_text'] = corpus['text'].str.replace('\\t',' ')\n",
    "    corpus.drop_duplicates(inplace=True)\n",
    "    corpus['processed_text'] = corpus['processed_text'].astype(str)\n",
    "    corpus['processed_text'] = corpus['processed_text'].str.lower()\n",
    "    corpus['processed_text'] = [stemmer.stem(text) for text in corpus['processed_text']]\n",
    "    if second_experiment:\n",
    "        if smoking:\n",
    "            replace_text = 'Rookt niet'\n",
    "            corpus['label'] = corpus['label'].str.replace('Niets gevonden', 'Rookt niet')\n",
    "            corpus['label'] = corpus['label'].str.replace('Rookte', 'Rookt niet')\n",
    "        else:\n",
    "            corpus['label'] = corpus['label'].str.replace('Niets gevonden', 'Nee')\n",
    "        \n",
    "    corpus = corpus.drop(corpus[corpus.label == '--'].index)\n",
    "    corpus = corpus.drop(corpus[corpus.label == 'Onbekend'].index)\n",
    "    corpus = corpus[~corpus.processed_text.str.contains('vertrouwelijk')]\n",
    "    corpus_backup = corpus.copy()\n",
    "    return corpus, corpus_backup\n",
    "\n",
    "def add_processed_text(input_corpus, text_column):\n",
    "    corpus = input_corpus.copy()\n",
    "    corpus['processed_text'] = corpus[text_column].str.replace('\\t',' ')\n",
    "    corpus.drop_duplicates(inplace=True)\n",
    "    corpus['processed_text'] = corpus['processed_text'].astype(str)\n",
    "    corpus['processed_text'] = corpus['processed_text'].str.lower()\n",
    "    corpus['processed_text'] = [stemmer.stem(text) for text in corpus['processed_text']]\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1318454f",
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_labels = pd.read_csv('full_texts_to_label_full4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83ccb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_random_labels = pd.read_csv('full_texts_to_label_random1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66adf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_random_labels2 = pd.read_csv('full_texts_to_label_random2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79b0b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_labels_no_dup = full_labels[~full_labels.content.isin(existing_random_labels.text)][~full_labels.content.isin(existing_random_labels2.text)][~full_labels.content.isin(existing_labels.text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d89f974",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_labels_no_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6370f20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_samples = full_labels_no_dup.sample(frac=1).head(501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2434d999",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac884c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_samples = add_processed_text(random_samples, 'content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf231148",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_texts_to_label = full_samples.rename(columns={'content':'text'})[['text', 'roken_answer_label', 'alcohol_answer_label', 'drugs_answer_label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304da070",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_texts_to_label.to_csv('full_texts_to_label_random3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69035646",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (thesis_hielke)",
   "language": "python",
   "name": "thesis_hielke"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
