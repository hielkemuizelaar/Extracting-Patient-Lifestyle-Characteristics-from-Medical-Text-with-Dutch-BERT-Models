{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a6e5142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid.\n",
      "Your token has been saved to /home/hjmuizelaar/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import lime\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import RobertaTokenizer, RobertaForMaskedLM, RobertaForSequenceClassification, AdamW, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
    "\n",
    "!huggingface-cli login --token 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\n",
    "filename_model = 'Hielke/finetuned_MedRoBERTa.nl_smoking'\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"CLTL/MedRoBERTa.nl\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(filename_model)\n",
    "class_names = [\"Geen gebruiker\", \"Huidige gebruiker\", \"Niets gevonden\", \"Voormalige gebruiker\"]\n",
    "\n",
    "def predictor(texts):\n",
    "    outputs = model(**tokenizer(texts, return_tensors=\"pt\", padding=True))\n",
    "    tensor_logits = outputs[0]\n",
    "    probas = F.softmax(tensor_logits).detach().numpy()\n",
    "    return probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b259d369",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9fa2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 2 Text 1\n",
    "import numpy as np\n",
    "import lime\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import RobertaTokenizer, RobertaForMaskedLM, RobertaForSequenceClassification, AdamW, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
    "def predictor(texts):\n",
    "    outputs = model(**tokenizer(texts, return_tensors=\"pt\", padding=True))\n",
    "    probas = F.softmax(outputs.logits).detach().numpy()\n",
    "    return probas\n",
    "class_names = [\"Geen gebruiker\", \"Huidige gebruiker\", \"Niets gevonden\", \"Voormalige gebruiker\"]\n",
    "\n",
    "explainer = LimeTextExplainer(class_names=class_names)\n",
    "\n",
    "text = 'Reden van komst / Verwijzing: \tReden verwijzing: liesbreuk links\t\tAnamnese: \tStatusvoering door co-ass I.Kivits:\tSupervisie: Dr. Horn \t\tReden van komst: liesbreuk links \t\tVoorgeschiedenis: \t2015 Hernia inguinalis rechts waarvoor TEP\t\tMedicatie:\tGeen \t\tAllergiÃƒÂ«n: \tGeen\t\tLiesbreuk sinds maand of 3. linkerzijde. Geleidelijk toegenomen gedurende afgelopen maanden. Heeft in verleden al aan de rechterzijde gehad, geopereerd via de navel. Voorkeur voor zelfde behandeling. Geen pijn, wel zeurderig gevoel. Geen beklemming gehad. Vooral tijdens krachtsport en toiletgang last van. \t\t\tLichamelijk onderzoek: \tLies links: \tMinimale bulging bij valsalva, bij HA evidente liesbreuk\t\t\tConclusie: \tConclusie: Hernia inguinalis links \t\tBeleid: \tBeleid: iom Dr. Horn:\t- Doorverwijzing LLZ vanwege wachttijden Haga \t- TEP links'\n",
    "exp = explainer.explain_instance(text, predictor, labels=[2, 1], num_features=20, num_samples=2000)\n",
    "exp.show_in_notebook(text=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752bbb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.show_in_notebook(text=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226e30e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 2 Text1\n",
    "import numpy as np\n",
    "import lime\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import RobertaTokenizer, RobertaForMaskedLM, RobertaForSequenceClassification, AdamW, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
    "def predictor(texts):\n",
    "    outputs = model(**tokenizer(texts, return_tensors=\"pt\", padding=True))\n",
    "    probas = F.softmax(outputs.logits).detach().numpy()\n",
    "    return probas\n",
    "class_names = [\"Geen gebruiker\", \"Huidige gebruiker\", \"Niets gevonden\", \"Voormalige gebruiker\"]\n",
    "\n",
    "explainer = LimeTextExplainer(class_names=class_names)\n",
    "\n",
    "text = 'Reden van komst / Verwijzing: \tReden verwijzing: Behandeling peri-implantitis 11\t\tAnamnese: \t10 jaar geleden implantaat geplaatst in Maasstad ziekenhuis. \t5 jaar geleden door tandarts kroon vervangen in verband met esthetiek.\tNu pijn en zwelling aan de binnenkant gehad, voelt veel druk bij bovenfront. In verleden parodontaal behandeld. Thans 6 wkn geleden gestopt met roken.\tAntibiotica 2 dgn geleden gestart, nu afname van klachten, maar nog steeds niet helemaal normaal gevoel.\t\tVanaf 7de jaar al bezig met gebit (na val op voortand), heeft ondertussen een angst ontwikkeld\t\t\tLichamelijk onderzoek: \tExtra-oraal onderzoek: geen bijzonderheden.\tIntra-oraal onderzoek: bleeding on probing, recessies gegeneraliseerd, pockets 1e kwadrant voornamelijk palatinaal, 11 implantaat palatinaal windingen sondeerbaar, labiaal mucosa: grijze doorschemering\t\t\tAanvullend onderzoek: \tOPT: gegeneraliseerd bot hoogte verlies, voornamelijk 1e kwadrant, bothoogte verlies 11 implantaat\t\t\tConclusie: \tConclusie: Periimplantitis 11.\tAdulte/locale parodontitis. (status na parodontale behandelingen)\tRecessies (gereduceerd parodontium).\tRecent gestopt met roken\t\t\tBeleid: \tBeleid: Momenteel zijn de klachten in remissie onder antibiotica. \tMevr. werd geadviseerd een afspraak te maken bij parodontoloog Hansma in Rijswijk voor intake en eventuele verdere behandelingen.\t\tIndien gewenst kan mevr. contact met ons opnemen voor een angstreductie traject bij onze afdeling Bijzondere Tandheelkunde.\t\tnb. uitleg behandeling periimplantitis zeer lastig, tot heden nog geen echte consensus over in de wetenschap. Voor nu lijkt initiele behandeling en frequente follow up en nauwlettend in de gaten houden de voorkeur te hebben'\n",
    "exp = explainer.explain_instance(text, predictor, labels=[1, 3], num_features=20, num_samples=2000)\n",
    "exp.show_in_notebook(text=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5afc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 2 Text2\n",
    "import numpy as np\n",
    "import lime\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import RobertaTokenizer, RobertaForMaskedLM, RobertaForSequenceClassification, AdamW, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
    "def predictor(texts):\n",
    "    outputs = model(**tokenizer(texts, return_tensors=\"pt\", padding=True))\n",
    "    probas = F.softmax(outputs.logits).detach().numpy()\n",
    "    return probas\n",
    "class_names = [\"Geen gebruiker\", \"Huidige gebruiker\", \"Niets gevonden\", \"Voormalige gebruiker\"]\n",
    "\n",
    "explainer = LimeTextExplainer(class_names=class_names)\n",
    "\n",
    "text = 'Reden van komst / Verwijzing: \tReden verwijzing: Reden van komst: \tvia MDL arts Bhalla  \tIs wat trillerig, met handen mn, in rugligging bijna aan het cententellen. Ook stramme  hand bij handen schudden. \t\tBij MDL-arts wegens obstipatie, dd neurogene oorzaak bij M. Parkinson of door chemoradiatie? \t\t\tAnamnese: \tVoorgeschiedenis: \temfyseem\tcholecystectomie\t2011 CLL. BINET B\t2012 (8) 6x FC-R, complete remissie,  hypogamma bij CLL \t2013 (9) start IVIG ivm pansinusitis\t2019 (1) lymfadenopathie hals, mediastium en buik, BINET C, geen TP53, geen del 17P, wel ongemuteerd IGHV\t2019 (4-3) Rituximab en start venetoclax \t2019 (1-4) start 400mg en Rituximab 2\t2019 (29-4) 3e R\t2019 (27/5) 4e R\t2019 (22/7) 6 de R\t2019 (12) afbouwen IVIG naar elke 6 weken\t2020 (4) IVIG on hold ivm Corona\t2020 (7) start zitromax ivm laag IgG\t2020 (9) complete remsisie CLL op CT\t2021 (1) analyse MDL ivm buikpijn, geen verklaring\t2021 (3) einde venetoclax, wait and see CLL\t2021 (5) analyse gyn en pijnteam: blokkade n iioinguinalis ivm pijnklachten\t\tMedicatie: \tmovicolon \tazitromycoine \tamitriptyline.'\n",
    "exp = explainer.explain_instance(text, predictor, labels=[2, 1], num_features=20, num_samples=2000)\n",
    "exp.show_in_notebook(text=text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scriptie-venv",
   "language": "python",
   "name": "scriptie-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
